V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['16_forward']
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/es/ceskliounr4qjtgyincvttn5ejgkizg3qcqw3ksye66pyixuv4ke.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_0 = async_compile.triton('triton_poi_fused_0', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_0(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 192
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vl/cvluqfigqu7hr34s4j3x5s6h2cgckevd74d3xjlnratfe63esdkw.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_1 = async_compile.triton('triton_poi_fused_1', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 4096, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_1(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 4096
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/h2/ch2ss523eeiiqvpckq6n3yddxgicasrxf4mgdffwogieocds47rs.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_2 = async_compile.triton('triton_poi_fused_2', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 4096}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_2(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 4096*y3), ymask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 12288*y1), tmp0, ymask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/z5/cz5lcpzem5jshoxsyxcxgxhiha6q7ktzqnt2hpqcbwodal3x5j3j.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_3 = async_compile.triton('triton_poi_fused_3', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 8192, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_3(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 8192
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/v2/cv2pmewnv75qopjeemipmicxycwgwldxplrujnsdidwoepu6aupv.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_4 = async_compile.triton('triton_poi_fused_4', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16384, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_4(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 16384
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3y/c3ybaagrpyprvu4qucwd5owykjor76dxa5rtm4m76njylkiiywna.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_5 = async_compile.triton('triton_poi_fused_5', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 32768, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_5(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 32768
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xz/cxzcrugq4kcwxq7htwrwvbkq7zxo3viqlah4bvlf6slq5i3eb3jh.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_6 = async_compile.triton('triton_poi_fused_6', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 65536, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_6(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 65536
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ji/cjiiii6yj6dav2b5dal6adytjxixn6ucudcxhtpwz2msreh7uxby.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x, x_1, x_37, x_38, l1_loss], Original ATen: [aten.convolution, aten.relu, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => sub
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => convolution
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => relu
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_4, %primals_2, %primals_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_1, %primals_2, %primals_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_4 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_sgn_sub_7 = async_compile.triton('triton_poi_fused_convolution_relu_sgn_sub_7', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_sgn_sub_7', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_sgn_sub_7(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ja/cja6rr7syjuu5ejhimstweh2m3zi4aetp23dkoxyy7vlkko4punz.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_8 = async_compile.triton('triton_per_fused_abs_mean_sub_8', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192, 'r': 128},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_8(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (64*((r2 % 64)) + 4096*((((r2 + 128*x1) // 64) % 64)) + 262144*((r2 + 128*x1 + 8192*x0) // 262144) + ((((r2 + 128*x1 + 8192*x0) // 4096) % 64))), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (64*((r2 % 64)) + 4096*((((r2 + 128*x1) // 64) % 64)) + 262144*((r2 + 128*x1 + 8192*x0) // 262144) + ((((r2 + 128*x1 + 8192*x0) // 4096) % 64))), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.sum(tmp4, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/iw/ciwxkxpg5wuap3e63isdtaqql6h3fwmagm35fteu6xj323puruhq.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_9 = async_compile.triton('triton_per_fused_abs_mean_sub_9', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128, 'r': 64},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_9(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*r1), xmask, other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pp/cpp5fkbmxbirfjuayra57zhkgbizp72jrjzmntcprlhicdc5fman.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_10 = async_compile.triton('triton_per_fused_abs_mean_sub_10', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 128},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_10', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_10(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ta/ctao2qea3kckvxtzeu2fgyjd2jquye2zlwkxry5dtgkr5dtnqn62.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_2, x_3], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => convolution_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => relu_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_5, %primals_6, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_11 = async_compile.triton('triton_poi_fused_convolution_relu_11', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_11', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_11(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/z5/cz5mzugr4fiklrv6viikqrrc7e4htndthyrl4pz4q2avk6tw4qw5.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_2, x_3, x_4], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => convolution_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => relu_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => _low_memory_max_pool2d_with_offsets
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_5, %primals_6, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_12 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_12', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_12(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (64 + x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4160 + x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/74/c74jrh6t4f5zydxbb5dk7smolt25662oxueejwtz4twluswcmwfq.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_41], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => getitem_10, getitem_11
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_10 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 0), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_13 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_13', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_13(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (64 + x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4160 + x0 + 128*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/el/cel6zosldswsjuopvzsxkryp2jgay4cqhza7cqran5nm4mu75brg.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_2, x_3, x_4, x_5, x_6, x_42, x_43, l1_loss_1], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => sub_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => convolution_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => relu_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => _low_memory_max_pool2d_with_offsets
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_18
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => convolution_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => relu_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_5, %primals_6, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %primals_7, %primals_8, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %primals_7, %primals_8, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_3 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7z/c7z2riyjagigpjkdtnhqland7kuj3oj6y6iutezwztylz7jpjknt.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_15 = async_compile.triton('triton_per_fused_abs_mean_sub_15', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096, 'r': 128},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_15(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (128*((r2 % 32)) + 4096*((((r2 + 128*x1) // 32) % 32)) + 131072*((r2 + 128*x1 + 8192*x0) // 131072) + ((((r2 + 128*x1 + 8192*x0) // 1024) % 128))), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (128*((r2 % 32)) + 4096*((((r2 + 128*x1) // 32) % 32)) + 131072*((r2 + 128*x1 + 8192*x0) // 131072) + ((((r2 + 128*x1 + 8192*x0) // 1024) % 128))), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.sum(tmp4, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/y7/cy7uireqousd5if3ywtjyrf7hxsragvkx3qecvv3dpwbcqnca7ib.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_16 = async_compile.triton('triton_per_fused_abs_mean_sub_16', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64, 'r': 64},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_16(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r1), xmask, other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ti/cti5632gnar4ugu6il5it7iziy6eanpk3mimxskqg7fyxgdc3mav.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_17 = async_compile.triton('triton_per_fused_abs_mean_sub_17', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 64},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_17(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yj/cyjntm3a4pgzfbhgbaucb7xu5krvxkikyzxckguvac2jfallzg46.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_7, x_8], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => convolution_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => relu_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %primals_9, %primals_10, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_18 = async_compile.triton('triton_poi_fused_convolution_relu_18', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_18', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_18(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xq/cxq4dtx7ekisowvnuzmstjkg4y5fta6huart3brvnctyaz2zveze.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_7, x_8, x_9], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => convolution_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => relu_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => _low_memory_max_pool2d_with_offsets_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %primals_9, %primals_10, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_19 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_19', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_19(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 128) % 16)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (128 + x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4224 + x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ax/caxndsk3jbcbsm5vw4oukxtk5rzx74pkcc7tddegake4ohnuicij.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_46], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => getitem_12, getitem_13
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_12 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_6, 0), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_13 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_6, 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_20 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_20', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_20(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 128) % 16)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (128 + x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4224 + x0 + 256*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4a/c4aau3ejauar22bbxsq2fvyh7wx6bt4rc52fg7wyt3rfuv4in7oj.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_7, x_8, x_9, x_10, x_11, x_47, x_48, l1_loss_2], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => sub_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => convolution_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => relu_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_20
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => convolution_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => relu_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => _low_memory_max_pool2d_with_offsets_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %primals_9, %primals_10, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %primals_11, %primals_12, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %primals_11, %primals_12, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_2 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/aq/caqotpjvy2cocnuhcu2krmeas7hy4ikt4beygh2f5edl4igpajav.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_22 = async_compile.triton('triton_per_fused_abs_mean_sub_22', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048, 'r': 128},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_22(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 32
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (256*((r2 % 16)) + 4096*((((r2 + 128*x1) // 16) % 16)) + 65536*((r2 + 128*x1 + 8192*x0) // 65536) + ((((r2 + 128*x1 + 8192*x0) // 256) % 256))), xmask, eviction_policy='evict_last', other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (256*((r2 % 16)) + 4096*((((r2 + 128*x1) // 16) % 16)) + 65536*((r2 + 128*x1 + 8192*x0) // 65536) + ((((r2 + 128*x1 + 8192*x0) // 256) % 256))), xmask, eviction_policy='evict_last', other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(xmask, tmp4, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.sum(tmp6, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nn/cnnkgj5k3ikpvf4rwu3eyrsllx43cwrokyebxcube4rgrc37gsr7.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_23 = async_compile.triton('triton_per_fused_abs_mean_sub_23', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32, 'r': 64},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_23(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 32*r1), xmask, other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e6/ce6wvq2rizpnmo5dp7xwg2wctvkz5ixnsi4nxiw7qsop4e34jzuw.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_24 = async_compile.triton('triton_per_fused_abs_mean_sub_24', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 32},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_24', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_24(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 32
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 32
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rz/crzcrmvfpgbnkmolxbcoyu4q6toj6ejzrhn7sxwekpiexxls7abp.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_12, x_13], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => convolution_5
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => relu_5
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_13, %primals_14, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_25 = async_compile.triton('triton_poi_fused_convolution_relu_25', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_25', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_25(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/u2/cu2r4rvd2kkj3nhmh23nobwebyl6qepjgs4kpsm2ak4tkuecjfx6.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => convolution_5
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => relu_5
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => convolution_6
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => relu_6
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => convolution_7
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => relu_7
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => _low_memory_max_pool2d_with_offsets_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_13, %primals_14, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %primals_15, %primals_16, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %primals_17, %primals_18, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_26 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_26', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_26', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_26(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (256 + x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4352 + x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2r/c2rfxlodks7mn3lj4s3x2viiscg72rlmxpuzywieph7xntbyx6dh.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_55], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => getitem_14, getitem_15
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_14 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_7, 0), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_7, 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_27 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_27', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_27', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_27(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (256 + x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4352 + x0 + 512*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/s4/cs4my3fjomqyehauppeg5scpugcdxznizhkk6lxidzab7vyxudwv.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_28 = async_compile.triton('triton_poi_fused_28', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 131072, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_28', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_28(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 131072
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/s2/cs2vrd5gxsdbowsst5pulsowh7spv425x2fnbq2n34pbq6c6ifjl.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_56, x_57, l1_loss_3], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => sub_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => convolution_5
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => relu_5
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => convolution_6
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => relu_6
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => convolution_7
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => relu_7
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => _low_memory_max_pool2d_with_offsets_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => convolution_8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => relu_8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_24
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_13, %primals_14, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %primals_15, %primals_16, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %primals_17, %primals_18, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %primals_19, %primals_20, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_14, %primals_19, %primals_20, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_1 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lz/clzdsdjn7or24h6k7ufgmxhbprnmzpv7zelvtuxir7uqaxq2eumv.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_30 = async_compile.triton('triton_per_fused_abs_mean_sub_30', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024, 'r': 128},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_30', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_30(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (512*((r2 % 64)) + 32768*((r2 + 128*x0 + 8192*x1) // 32768) + ((((r2 + 128*x0 + 8192*x1) // 64) % 512))), xmask, eviction_policy='evict_last', other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (512*((r2 % 64)) + 32768*((r2 + 128*x0 + 8192*x1) // 32768) + ((((r2 + 128*x0 + 8192*x1) // 64) % 512))), xmask, eviction_policy='evict_last', other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(xmask, tmp4, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.sum(tmp6, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/x6/cx6yo4iqi2xk46tqfeg7hz3cc36gqf5r3mi7okkynyt7efwcvdap.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_31 = async_compile.triton('triton_per_fused_abs_mean_sub_31', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16, 'r': 64},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_31', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_31(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 64*x0), xmask, other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/s4/cs4sjp5phyfcp5uisd5qyjulej2itnhzldrm44zypsixrz6kojgg.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_32 = async_compile.triton('triton_per_fused_abs_mean_sub_32', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 16},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_32', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_32(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/32/c32hukpwmu4idyic6lwjwtiqltrqvyppoydvkk5ssr4mwmkkz4gi.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_33 = async_compile.triton('triton_poi_fused_33', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 262144, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_33', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_33(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 262144
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bm/cbmlevmc4itxajhdukolid6vu3zetplmrlgmy4rpzell7g2ihtff.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, x_22], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => convolution_9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => relu_9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %primals_21, %primals_22, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_34 = async_compile.triton('triton_poi_fused_convolution_relu_34', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_34', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_34(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/si/csimyogqhhrgwcj7o2mw62usgael2vw25lyekbvpc5ef3kb3bn6l.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => convolution_9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => relu_9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => convolution_10
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => relu_10
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => convolution_11
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => relu_11
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => _low_memory_max_pool2d_with_offsets_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %primals_21, %primals_22, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %primals_23, %primals_24, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %primals_25, %primals_26, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_35 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_35', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_35', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_35(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 512) % 4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (512 + x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4608 + x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oh/coh2tlbl5htcuahe3dw7bdzthwo353qcsltqj4qewzwdyt5s5bvp.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_64], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => getitem_16, getitem_17
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_16 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_8, 0), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_8, 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_36 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_36', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_36', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_36(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 512) % 4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (512 + x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4608 + x0 + 1024*x1 + 8192*x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3m/c3mohudbadgdj2apmr6sfqz3ttw7vxqpgrgz7zylcaqcycezwpcq.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_65], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => convolution_9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => relu_9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => convolution_10
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => relu_10
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => convolution_11
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => relu_11
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => _low_memory_max_pool2d_with_offsets_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => convolution_12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_65 => convolution_28
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %primals_21, %primals_22, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %primals_23, %primals_24, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %primals_25, %primals_26, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_12 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %primals_27, %primals_28, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_16, %primals_27, %primals_28, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_37 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_37', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_37', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_37(in_out_ptr0, in_out_ptr1, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_out_ptr1 + (x2), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 + tmp1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp4, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7x/c7xpujlycdzvp65rbz364nnthbdsivfwrzey7e5662czey4e47x7.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_4 => abs_5, mean_4, sub_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => relu_12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_28
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_28, %relu_12), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_5 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_5,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_relu_sub_38 = async_compile.triton('triton_per_fused_abs_mean_relu_sub_38', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256, 'r': 128},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_relu_sub_38', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_relu_sub_38(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (8*x0 + 512*((r2 % 16)) + 8192*x1 + 8192*((r2 + 128*x0) // 8192) + (r2 // 16)), xmask, eviction_policy='evict_last', other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (8*x0 + 512*((r2 % 16)) + 8192*x1 + 8192*((r2 + 128*x0) // 8192) + (r2 // 16)), xmask, eviction_policy='evict_last', other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1, 1], 0, tl.int32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp1, tmp3)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp2 - tmp4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl_math.abs(tmp5)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.where(xmask, tmp7, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.sum(tmp9, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp10, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bs/cbsh37vlwtix4sesebbivgr54adgw65nlc226ww6rleiav2pq5ly.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_4 => abs_5, mean_4, sub_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => relu_12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_28
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_28, %relu_12), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_5 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_5,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_relu_sub_39 = async_compile.triton('triton_per_fused_abs_mean_relu_sub_39', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 64},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_relu_sub_39', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_relu_sub_39(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 64*x0), xmask, other=0.0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2v/c2vocbiwb52gvt4oxxnc7xscnmbdmhirrlbvgjpghbvp4ns2f7lw.py
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss, mul, loss, l1_loss_1, mul_1, loss_1, l1_loss_2, mul_2, loss_2, l1_loss_3, mul_3, loss_3, l1_loss_4, mul_4, loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean, aten.mul, aten.add]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_4 => abs_5, mean_4, sub_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss => add
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_1 => add_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_2 => add_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_3 => add_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_4 => add_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul => mul
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_1 => mul_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_2 => mul_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_3 => mul_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_4 => mul_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => relu_12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_28
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean, 0.03125), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul, 0), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_1, 0.0625), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add, %mul_1), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_2, 0.125), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_1, %mul_2), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_3, 0.25), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2, %mul_3), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_28, %relu_12), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_5 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_4,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_5,), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_4, 1.0), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3, %mul_4), kwargs = {})
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_add_mean_mul_relu_sub_40 = async_compile.triton('triton_per_fused_abs_add_mean_mul_relu_sub_40', '''
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 4},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': (5,)}, 'cls': 'AttrsDescriptor'})]},
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_add_mean_mul_relu_sub_40', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_add_mean_mul_relu_sub_40(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.load(in_out_ptr0 + (0))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, 1])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.load(in_ptr1 + (0))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.broadcast_to(tmp12, [XBLOCK, 1])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr2 + (0))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.broadcast_to(tmp19, [XBLOCK, 1])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr3 + (0))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.broadcast_to(tmp26, [XBLOCK, 1])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1048576.0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 / tmp6
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = 0.03125
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp7 * tmp8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = 0.0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 524288.0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 / tmp14
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = 0.0625
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp11 + tmp17
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = 262144.0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 / tmp21
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = 0.125
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp22 * tmp23
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp18 + tmp24
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = 131072.0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tmp27 / tmp28
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = 0.25
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp29 * tmp30
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp25 + tmp31
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = 32768.0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp3 / tmp33
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = 1.0
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp32 + tmp36
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.debug_barrier()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp37, None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34 = args
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_1, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_2, (64, 3, 3, 3), (27, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_3, (64, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_4, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_5, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_6, (64, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_7, (128, 64, 3, 3), (576, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_8, (128, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_9, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_10, (128, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_11, (256, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_12, (256, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_13, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_14, (256, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_15, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_16, (256, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_17, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_18, (256, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_19, (512, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_20, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_21, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_22, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_23, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_24, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_25, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_26, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_27, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_28, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_29, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_30, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_31, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_32, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_33, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_34, (512, ), (1, ))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = empty_strided_cuda((64, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_0.run(primals_2, buf1, 192, 9, grid=grid(192, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_2
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_1.run(primals_5, buf2, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_5
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_2.run(primals_1, buf0, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_1
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_2.run(primals_4, buf14, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_4
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_3.run(primals_7, buf3, 8192, 9, grid=grid(8192, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_7
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_4.run(primals_9, buf4, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_9
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = empty_strided_cuda((256, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_5.run(primals_11, buf5, 32768, 9, grid=grid(32768, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_11
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_13, buf6, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_13
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_15, buf7, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_15
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_17, buf8, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_17
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = extern_kernels.convolution(buf14, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf15, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf14
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_37], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = extern_kernels.convolution(buf0, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf45, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = buf15; del buf15  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = buf45; del buf45  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf97 = empty_strided_cuda((4, 64, 64, 64), (262144, 1, 4096, 64), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x, x_1, x_37, x_38, l1_loss], Original ATen: [aten.convolution, aten.relu, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_sgn_sub_7.run(buf16, buf46, primals_3, buf97, 1048576, grid=grid(1048576), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_3
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf79 = empty_strided_cuda((128, 64), (1, 128), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_8.run(buf46, buf16, buf79, 8192, 128, grid=grid(8192), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf80 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_9.run(buf79, buf80, 128, 64, grid=grid(128), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf79
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf81 = empty_strided_cuda((), (), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_10.run(buf80, buf81, 1, 128, grid=grid(1), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf80
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = extern_kernels.convolution(buf16, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf17, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = buf17; del buf17  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf18, primals_6, 1048576, grid=grid(1048576), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = empty_strided_cuda((4, 64, 32, 32), (65536, 1, 2048, 64), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3, x_4], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_12.run(buf18, buf19, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf18
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3, x_4, x_5], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = extern_kernels.convolution(buf19, buf3, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf20, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_39], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = extern_kernels.convolution(buf46, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf47, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = buf47; del buf47  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_39, x_40], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf48, primals_6, 1048576, grid=grid(1048576), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_6
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = buf19; del buf19  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = empty_strided_cuda((4, 64, 32, 32), (65536, 1, 2048, 64), torch.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_41], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_13.run(buf48, buf49, buf50, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_42], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = extern_kernels.convolution(buf49, buf3, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf51, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = buf20; del buf20  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = buf51; del buf51  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf96 = empty_strided_cuda((4, 128, 32, 32), (131072, 1, 4096, 128), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3, x_4, x_5, x_6, x_42, x_43, l1_loss_1], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14.run(buf21, buf52, primals_8, buf96, 524288, grid=grid(524288), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_8
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf82 = empty_strided_cuda((64, 64), (1, 64), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_15.run(buf52, buf21, buf82, 4096, 128, grid=grid(4096), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf83 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_16.run(buf82, buf83, 64, 64, grid=grid(64), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf82
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf84 = empty_strided_cuda((), (), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_17.run(buf83, buf84, 1, 64, grid=grid(1), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf83
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = extern_kernels.convolution(buf21, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf22, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf21
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = buf22; del buf22  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_18.run(buf23, primals_10, 524288, grid=grid(524288), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = empty_strided_cuda((4, 128, 16, 16), (32768, 1, 2048, 128), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8, x_9], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_19.run(buf23, buf24, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf23
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8, x_9, x_10], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf24, buf5, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_44], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = extern_kernels.convolution(buf52, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf53, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = buf53; del buf53  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_44, x_45], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_18.run(buf54, primals_10, 524288, grid=grid(524288), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_10
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = buf24; del buf24  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = empty_strided_cuda((4, 128, 16, 16), (32768, 1, 2048, 128), torch.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_46], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_20.run(buf54, buf55, buf56, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_47], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = extern_kernels.convolution(buf55, buf5, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf57, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = buf25; del buf25  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = buf57; del buf57  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf95 = empty_strided_cuda((4, 256, 16, 16), (65536, 1, 4096, 256), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8, x_9, x_10, x_11, x_47, x_48, l1_loss_2], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21.run(buf26, buf58, primals_12, buf95, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_12
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf85 = empty_strided_cuda((32, 64), (1, 32), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_22.run(buf58, buf26, buf85, 2048, 128, grid=grid(2048), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf86 = empty_strided_cuda((32, ), (1, ), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_23.run(buf85, buf86, 32, 64, grid=grid(32), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf85
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf87 = empty_strided_cuda((), (), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_24.run(buf86, buf87, 1, 32, grid=grid(1), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf86
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = extern_kernels.convolution(buf26, buf6, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf27, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf26
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = buf27; del buf27  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf28, primals_14, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = extern_kernels.convolution(buf28, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf29, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf28
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = buf29; del buf29  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf30, primals_16, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = extern_kernels.convolution(buf30, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf31, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf30
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = buf31; del buf31  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf32, primals_18, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = empty_strided_cuda((4, 256, 8, 8), (16384, 1, 2048, 256), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_26.run(buf32, buf33, 65536, grid=grid(65536), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf32
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_49], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf59 = extern_kernels.convolution(buf58, buf6, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf59, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf60 = buf59; del buf59  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_49, x_50], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf60, primals_14, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_14
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_51], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf61 = extern_kernels.convolution(buf60, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf61, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf62 = buf61; del buf61  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_51, x_52], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf62, primals_16, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_16
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_53], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf63 = extern_kernels.convolution(buf62, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf63, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf64 = buf63; del buf63  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_53, x_54], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf64, primals_18, 262144, grid=grid(262144), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_18
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf65 = empty_strided_cuda((4, 256, 8, 8), (16384, 1, 2048, 256), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf66 = empty_strided_cuda((4, 256, 8, 8), (16384, 1, 2048, 256), torch.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_55], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_27.run(buf64, buf65, buf66, 65536, grid=grid(65536), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = empty_strided_cuda((512, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_28.run(primals_19, buf9, 131072, 9, grid=grid(131072, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_19
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = extern_kernels.convolution(buf33, buf9, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf34, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf33
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_56], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf67 = extern_kernels.convolution(buf65, buf9, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf67, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = buf34; del buf34  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf68 = buf67; del buf67  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf94 = empty_strided_cuda((4, 512, 8, 8), (32768, 1, 4096, 512), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_56, x_57, l1_loss_3], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29.run(buf35, buf68, primals_20, buf94, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_20
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf88 = empty_strided_cuda((16, 64), (64, 1), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_30.run(buf68, buf35, buf88, 1024, 128, grid=grid(1024), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf89 = empty_strided_cuda((16, ), (1, ), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_31.run(buf88, buf89, 16, 64, grid=grid(16), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf88
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf90 = empty_strided_cuda((), (), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_32.run(buf89, buf90, 1, 16, grid=grid(1), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf89
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_21, buf10, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_21
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = extern_kernels.convolution(buf35, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf36, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf35
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf36; del buf36  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf37, primals_22, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_58], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf69 = extern_kernels.convolution(buf68, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf69, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf70 = buf69; del buf69  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_58, x_59], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf70, primals_22, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_22
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_23, buf11, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_23
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = extern_kernels.convolution(buf37, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf38, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf37
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = buf38; del buf38  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf39, primals_24, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_60], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf71 = extern_kernels.convolution(buf70, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf71, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf72 = buf71; del buf71  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_60, x_61], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf72, primals_24, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_24
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_25, buf12, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_25
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = extern_kernels.convolution(buf39, buf12, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf40, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf39
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = buf40; del buf40  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf41, primals_26, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_35.run(buf41, buf42, 32768, grid=grid(32768), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf41
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_62], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf73 = extern_kernels.convolution(buf72, buf12, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf73, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf74 = buf73; del buf73  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_62, x_63], Original ATen: [aten.convolution, aten.relu]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf74, primals_26, 131072, grid=grid(131072), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_26
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf75 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf76 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.int8)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_64], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_36.run(buf74, buf75, buf76, 32768, grid=grid(32768), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_27, buf13, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_27
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = extern_kernels.convolution(buf42, buf13, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf43, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf42
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_65], Original ATen: [aten.convolution]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf77 = extern_kernels.convolution(buf75, buf13, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf77, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = buf43; del buf43  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf78 = buf77; del buf77  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_65], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_37.run(buf44, buf78, primals_28, 32768, grid=grid(32768), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_28
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf91 = empty_strided_cuda((4, 64), (64, 1), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_relu_sub_38.run(buf78, buf44, buf91, 256, 128, grid=grid(256), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf92 = empty_strided_cuda((4, ), (1, ), torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_relu_sub_39.run(buf91, buf92, 4, 64, grid=grid(4), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf91
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf98 = buf81; del buf81  # reuse
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss, mul, loss, l1_loss_1, mul_1, loss_1, l1_loss_2, mul_2, loss_2, l1_loss_3, mul_3, loss_3, l1_loss_4, mul_4, loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean, aten.mul, aten.add]
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_add_mean_mul_relu_sub_40.run(buf98, buf92, buf84, buf87, buf90, 1, 4, grid=grid(1), stream=stream0)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf84
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf87
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf90
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf92
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf98, buf0, buf1, buf2, buf3, buf4, buf5, buf6, buf7, buf8, buf9, buf10, buf11, buf12, buf13, buf44, buf46, buf48, buf49, buf50, buf52, buf54, buf55, buf56, buf58, buf60, buf62, buf64, buf65, buf66, buf68, buf70, buf72, buf74, buf75, buf76, buf78, buf94, buf95, buf96, buf97, )
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_2 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_3 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_4 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_5 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_6 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_7 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_8 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_9 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_10 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_11 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_12 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_13 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_14 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_15 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_16 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_17 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_18 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_19 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_20 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_21 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_22 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_23 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_24 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_25 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_26 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_27 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_28 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_29 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_30 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_31 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_32 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_33 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_34 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34])
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 13:40:28.478000 1894003 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:40:28.526000 1894003 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/wb/cwbrwj6ud6i35b3vdgeuidviu6dowrsewhzj5zj463jdbj7g4uwa.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['16_forward']
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/es/ceskliounr4qjtgyincvttn5ejgkizg3qcqw3ksye66pyixuv4ke.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_0 = async_compile.triton('triton_poi_fused_0', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_0(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 192
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vl/cvluqfigqu7hr34s4j3x5s6h2cgckevd74d3xjlnratfe63esdkw.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_1 = async_compile.triton('triton_poi_fused_1', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 4096, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_1(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 4096
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/h2/ch2ss523eeiiqvpckq6n3yddxgicasrxf4mgdffwogieocds47rs.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_2 = async_compile.triton('triton_poi_fused_2', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 4096}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_2(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 4096*y3), ymask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 12288*y1), tmp0, ymask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/z5/cz5lcpzem5jshoxsyxcxgxhiha6q7ktzqnt2hpqcbwodal3x5j3j.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_3 = async_compile.triton('triton_poi_fused_3', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 8192, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_3(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 8192
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/v2/cv2pmewnv75qopjeemipmicxycwgwldxplrujnsdidwoepu6aupv.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_4 = async_compile.triton('triton_poi_fused_4', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16384, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_4(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 16384
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3y/c3ybaagrpyprvu4qucwd5owykjor76dxa5rtm4m76njylkiiywna.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_5 = async_compile.triton('triton_poi_fused_5', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 32768, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_5(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 32768
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xz/cxzcrugq4kcwxq7htwrwvbkq7zxo3viqlah4bvlf6slq5i3eb3jh.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_6 = async_compile.triton('triton_poi_fused_6', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 65536, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_6(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 65536
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ji/cjiiii6yj6dav2b5dal6adytjxixn6ucudcxhtpwz2msreh7uxby.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x, x_1, x_37, x_38, l1_loss], Original ATen: [aten.convolution, aten.relu, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => sub
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => convolution
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => relu
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_4, %primals_2, %primals_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_1, %primals_2, %primals_3, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_4 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_sgn_sub_7 = async_compile.triton('triton_poi_fused_convolution_relu_sgn_sub_7', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_sgn_sub_7', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_sgn_sub_7(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ja/cja6rr7syjuu5ejhimstweh2m3zi4aetp23dkoxyy7vlkko4punz.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_8 = async_compile.triton('triton_per_fused_abs_mean_sub_8', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192, 'r': 128},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_8', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_8(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (64*((r2 % 64)) + 4096*((((r2 + 128*x1) // 64) % 64)) + 262144*((r2 + 128*x1 + 8192*x0) // 262144) + ((((r2 + 128*x1 + 8192*x0) // 4096) % 64))), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (64*((r2 % 64)) + 4096*((((r2 + 128*x1) // 64) % 64)) + 262144*((r2 + 128*x1 + 8192*x0) // 262144) + ((((r2 + 128*x1 + 8192*x0) // 4096) % 64))), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.sum(tmp4, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/iw/ciwxkxpg5wuap3e63isdtaqql6h3fwmagm35fteu6xj323puruhq.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_9 = async_compile.triton('triton_per_fused_abs_mean_sub_9', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128, 'r': 64},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_9(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*r1), xmask, other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/pp/cpp5fkbmxbirfjuayra57zhkgbizp72jrjzmntcprlhicdc5fman.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_10 = async_compile.triton('triton_per_fused_abs_mean_sub_10', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 128},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_10', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_10(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ta/ctao2qea3kckvxtzeu2fgyjd2jquye2zlwkxry5dtgkr5dtnqn62.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_2, x_3], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => convolution_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => relu_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_5, %primals_6, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_11 = async_compile.triton('triton_poi_fused_convolution_relu_11', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_11', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_11(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/z5/cz5mzugr4fiklrv6viikqrrc7e4htndthyrl4pz4q2avk6tw4qw5.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_2, x_3, x_4], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => convolution_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => relu_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => _low_memory_max_pool2d_with_offsets
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_5, %primals_6, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_12 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_12', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_12(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (64 + x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4160 + x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/74/c74jrh6t4f5zydxbb5dk7smolt25662oxueejwtz4twluswcmwfq.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_41], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => getitem_10, getitem_11
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_10 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 0), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_13 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_13', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_13(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (64 + x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4160 + x0 + 128*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/el/cel6zosldswsjuopvzsxkryp2jgay4cqhza7cqran5nm4mu75brg.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_2, x_3, x_4, x_5, x_6, x_42, x_43, l1_loss_1], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => sub_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => convolution_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => relu_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => _low_memory_max_pool2d_with_offsets
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_18
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => convolution_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => relu_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_5, %primals_6, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %primals_7, %primals_8, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %primals_7, %primals_8, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_3 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7z/c7z2riyjagigpjkdtnhqland7kuj3oj6y6iutezwztylz7jpjknt.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_15 = async_compile.triton('triton_per_fused_abs_mean_sub_15', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096, 'r': 128},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_15(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (128*((r2 % 32)) + 4096*((((r2 + 128*x1) // 32) % 32)) + 131072*((r2 + 128*x1 + 8192*x0) // 131072) + ((((r2 + 128*x1 + 8192*x0) // 1024) % 128))), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (128*((r2 % 32)) + 4096*((((r2 + 128*x1) // 32) % 32)) + 131072*((r2 + 128*x1 + 8192*x0) // 131072) + ((((r2 + 128*x1 + 8192*x0) // 1024) % 128))), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.sum(tmp4, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/y7/cy7uireqousd5if3ywtjyrf7hxsragvkx3qecvv3dpwbcqnca7ib.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_16 = async_compile.triton('triton_per_fused_abs_mean_sub_16', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64, 'r': 64},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_16(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 64*r1), xmask, other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ti/cti5632gnar4ugu6il5it7iziy6eanpk3mimxskqg7fyxgdc3mav.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_17 = async_compile.triton('triton_per_fused_abs_mean_sub_17', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 64},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_17(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/yj/cyjntm3a4pgzfbhgbaucb7xu5krvxkikyzxckguvac2jfallzg46.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_7, x_8], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => convolution_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => relu_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %primals_9, %primals_10, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_18 = async_compile.triton('triton_poi_fused_convolution_relu_18', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_18', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_18(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xq/cxq4dtx7ekisowvnuzmstjkg4y5fta6huart3brvnctyaz2zveze.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_7, x_8, x_9], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => convolution_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => relu_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => _low_memory_max_pool2d_with_offsets_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %primals_9, %primals_10, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_19 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_19', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_19(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 128) % 16)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (128 + x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4224 + x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ax/caxndsk3jbcbsm5vw4oukxtk5rzx74pkcc7tddegake4ohnuicij.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_46], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => getitem_12, getitem_13
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_12 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_6, 0), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_13 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_6, 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_20 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_20', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_20(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 128) % 16)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (128 + x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4224 + x0 + 256*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/4a/c4aau3ejauar22bbxsq2fvyh7wx6bt4rc52fg7wyt3rfuv4in7oj.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_7, x_8, x_9, x_10, x_11, x_47, x_48, l1_loss_2], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => sub_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => convolution_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => relu_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_20
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => convolution_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => relu_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => _low_memory_max_pool2d_with_offsets_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %primals_9, %primals_10, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %primals_11, %primals_12, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %primals_11, %primals_12, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_2 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/aq/caqotpjvy2cocnuhcu2krmeas7hy4ikt4beygh2f5edl4igpajav.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_22 = async_compile.triton('triton_per_fused_abs_mean_sub_22', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048, 'r': 128},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_22(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 32
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (256*((r2 % 16)) + 4096*((((r2 + 128*x1) // 16) % 16)) + 65536*((r2 + 128*x1 + 8192*x0) // 65536) + ((((r2 + 128*x1 + 8192*x0) // 256) % 256))), xmask, eviction_policy='evict_last', other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (256*((r2 % 16)) + 4096*((((r2 + 128*x1) // 16) % 16)) + 65536*((r2 + 128*x1 + 8192*x0) // 65536) + ((((r2 + 128*x1 + 8192*x0) // 256) % 256))), xmask, eviction_policy='evict_last', other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(xmask, tmp4, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.sum(tmp6, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/nn/cnnkgj5k3ikpvf4rwu3eyrsllx43cwrokyebxcube4rgrc37gsr7.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_23 = async_compile.triton('triton_per_fused_abs_mean_sub_23', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32, 'r': 64},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_23(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 32*r1), xmask, other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/e6/ce6wvq2rizpnmo5dp7xwg2wctvkz5ixnsi4nxiw7qsop4e34jzuw.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_24 = async_compile.triton('triton_per_fused_abs_mean_sub_24', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 32},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_24', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_24(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 32
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 32
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/rz/crzcrmvfpgbnkmolxbcoyu4q6toj6ejzrhn7sxwekpiexxls7abp.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_12, x_13], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => convolution_5
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => relu_5
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_13, %primals_14, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_25 = async_compile.triton('triton_poi_fused_convolution_relu_25', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_25', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_25(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/u2/cu2r4rvd2kkj3nhmh23nobwebyl6qepjgs4kpsm2ak4tkuecjfx6.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => convolution_5
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => relu_5
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => convolution_6
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => relu_6
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => convolution_7
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => relu_7
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => _low_memory_max_pool2d_with_offsets_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_13, %primals_14, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %primals_15, %primals_16, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %primals_17, %primals_18, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_26 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_26', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_26', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_26(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (256 + x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4352 + x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/2r/c2rfxlodks7mn3lj4s3x2viiscg72rlmxpuzywieph7xntbyx6dh.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_55], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => getitem_14, getitem_15
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_14 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_7, 0), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_7, 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_27 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_27', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_27', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_27(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (256 + x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4352 + x0 + 512*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/s4/cs4my3fjomqyehauppeg5scpugcdxznizhkk6lxidzab7vyxudwv.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_28 = async_compile.triton('triton_poi_fused_28', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 131072, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_28', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_28(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 131072
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/s2/cs2vrd5gxsdbowsst5pulsowh7spv425x2fnbq2n34pbq6c6ifjl.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_56, x_57, l1_loss_3], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => sub_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => convolution_5
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => relu_5
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => convolution_6
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => relu_6
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => convolution_7
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => relu_7
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => _low_memory_max_pool2d_with_offsets_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => convolution_8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => relu_8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_24
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_13, %primals_14, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %primals_15, %primals_16, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %primals_17, %primals_18, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %primals_19, %primals_20, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_14, %primals_19, %primals_20, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sign_1 : [num_users=1] = call_function[target=torch.ops.aten.sign.default](args = (%sub_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29(in_out_ptr0, in_out_ptr1, in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_out_ptr1 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp3, tmp6)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7 - tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp3 < tmp8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 < tmp3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11.to(tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp10 - tmp12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13.to(tmp8.dtype)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp7, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp14, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/lz/clzdsdjn7or24h6k7ufgmxhbprnmzpv7zelvtuxir7uqaxq2eumv.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_30 = async_compile.triton('triton_per_fused_abs_mean_sub_30', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024, 'r': 128},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_30', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_30(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (512*((r2 % 64)) + 32768*((r2 + 128*x0 + 8192*x1) // 32768) + ((((r2 + 128*x0 + 8192*x1) // 64) % 512))), xmask, eviction_policy='evict_last', other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (512*((r2 % 64)) + 32768*((r2 + 128*x0 + 8192*x1) // 32768) + ((((r2 + 128*x0 + 8192*x1) // 64) % 512))), xmask, eviction_policy='evict_last', other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl_math.abs(tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.broadcast_to(tmp3, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(xmask, tmp4, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.sum(tmp6, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/x6/cx6yo4iqi2xk46tqfeg7hz3cc36gqf5r3mi7okkynyt7efwcvdap.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_31 = async_compile.triton('triton_per_fused_abs_mean_sub_31', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16, 'r': 64},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_31', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_31(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 64*x0), xmask, other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/s4/cs4sjp5phyfcp5uisd5qyjulej2itnhzldrm44zypsixrz6kojgg.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_sub_32 = async_compile.triton('triton_per_fused_abs_mean_sub_32', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 16},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': (2,)}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_sub_32', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_sub_32(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp3, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/32/c32hukpwmu4idyic6lwjwtiqltrqvyppoydvkk5ssr4mwmkkz4gi.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_33 = async_compile.triton('triton_poi_fused_33', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 262144, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_33', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_33(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 262144
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bm/cbmlevmc4itxajhdukolid6vu3zetplmrlgmy4rpzell7g2ihtff.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, x_22], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => convolution_9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => relu_9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %primals_21, %primals_22, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_34 = async_compile.triton('triton_poi_fused_convolution_relu_34', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_34', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_34(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/si/csimyogqhhrgwcj7o2mw62usgael2vw25lyekbvpc5ef3kb3bn6l.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => convolution_9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => relu_9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => convolution_10
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => relu_10
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => convolution_11
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => relu_11
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => _low_memory_max_pool2d_with_offsets_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %primals_21, %primals_22, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %primals_23, %primals_24, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %primals_25, %primals_26, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_35 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_35', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_35', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_35(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 512) % 4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (512 + x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4608 + x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/oh/coh2tlbl5htcuahe3dw7bdzthwo353qcsltqj4qewzwdyt5s5bvp.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_64], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => getitem_16, getitem_17
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_16 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_8, 0), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_8, 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_36 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_36', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_36', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_36(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 512) % 4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (512 + x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4096 + x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (4608 + x0 + 1024*x1 + 8192*x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp6, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp16, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3m/c3mohudbadgdj2apmr6sfqz3ttw7vxqpgrgz7zylcaqcycezwpcq.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_65], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => convolution_9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => relu_9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => convolution_10
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => relu_10
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => convolution_11
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => relu_11
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => _low_memory_max_pool2d_with_offsets_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => convolution_12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_65 => convolution_28
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %primals_21, %primals_22, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %primals_23, %primals_24, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %primals_25, %primals_26, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_12 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %primals_27, %primals_28, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_16, %primals_27, %primals_28, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_max_pool2d_with_indices_relu_37 = async_compile.triton('triton_poi_fused_convolution_max_pool2d_with_indices_relu_37', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_out_ptr1': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_max_pool2d_with_indices_relu_37', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_max_pool2d_with_indices_relu_37(in_out_ptr0, in_out_ptr1, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_out_ptr1 + (x2), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 + tmp1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x2), tmp4, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7x/c7xpujlycdzvp65rbz364nnthbdsivfwrzey7e5662czey4e47x7.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_4 => abs_5, mean_4, sub_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => relu_12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_28
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_28, %relu_12), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_5 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_5,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_relu_sub_38 = async_compile.triton('triton_per_fused_abs_mean_relu_sub_38', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256, 'r': 128},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_relu_sub_38', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_relu_sub_38(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 128
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r2 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (8*x0 + 512*((r2 % 16)) + 8192*x1 + 8192*((r2 + 128*x0) // 8192) + (r2 // 16)), xmask, eviction_policy='evict_last', other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (8*x0 + 512*((r2 % 16)) + 8192*x1 + 8192*((r2 + 128*x0) // 8192) + (r2 // 16)), xmask, eviction_policy='evict_last', other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1, 1], 0, tl.int32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp1, tmp3)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp2 - tmp4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl_math.abs(tmp5)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.where(xmask, tmp7, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.sum(tmp9, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp10, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bs/cbsh37vlwtix4sesebbivgr54adgw65nlc226ww6rleiav2pq5ly.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_4 => abs_5, mean_4, sub_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => relu_12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_28
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_28, %relu_12), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_5 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_5,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_mean_relu_sub_39 = async_compile.triton('triton_per_fused_abs_mean_relu_sub_39', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 64},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_mean_relu_sub_39', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_mean_relu_sub_39(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 64
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 64*x0), xmask, other=0.0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/2v/c2vocbiwb52gvt4oxxnc7xscnmbdmhirrlbvgjpghbvp4ns2f7lw.py
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss, mul, loss, l1_loss_1, mul_1, loss_1, l1_loss_2, mul_2, loss_2, l1_loss_3, mul_3, loss_3, l1_loss_4, mul_4, loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean, aten.mul, aten.add]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss => abs_1, mean, sub
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_1 => abs_2, mean_1, sub_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_2 => abs_3, mean_2, sub_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_3 => abs_4, mean_3, sub_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   l1_loss_4 => abs_5, mean_4, sub_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss => add
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_1 => add_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_2 => add_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_3 => add_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   loss_4 => add_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul => mul
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_1 => mul_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_2 => mul_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_3 => mul_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_4 => mul_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => relu_12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_28
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_16, %relu), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean, 0.03125), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul, 0), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_18, %relu_2), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_2 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_1,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_1, 0.0625), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add, %mul_1), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_20, %relu_4), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_3 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_2,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_2, 0.125), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_2 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_1, %mul_2), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=2] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_24, %relu_8), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_4 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_3,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_3, 0.25), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_2, %mul_3), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%relu_28, %relu_12), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %abs_5 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%sub_4,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%abs_5,), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mean_4, 1.0), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_4 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_3, %mul_4), kwargs = {})
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_abs_add_mean_mul_relu_sub_40 = async_compile.triton('triton_per_fused_abs_add_mean_mul_relu_sub_40', '''
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1, 'r': 4},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {'xnumel': 1}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': (5,)}, 'cls': 'AttrsDescriptor'})]},
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_abs_add_mean_mul_relu_sub_40', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 1, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_abs_add_mean_mul_relu_sub_40(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r0 = rindex
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.load(in_out_ptr0 + (0))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.broadcast_to(tmp4, [XBLOCK, 1])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.load(in_ptr1 + (0))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.broadcast_to(tmp12, [XBLOCK, 1])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr2 + (0))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.broadcast_to(tmp19, [XBLOCK, 1])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr3 + (0))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.broadcast_to(tmp26, [XBLOCK, 1])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.sum(tmp1, 1)[:, None]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1048576.0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 / tmp6
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = 0.03125
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp7 * tmp8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = 0.0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 524288.0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 / tmp14
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = 0.0625
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp11 + tmp17
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = 262144.0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 / tmp21
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = 0.125
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp22 * tmp23
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp18 + tmp24
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = 131072.0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tmp27 / tmp28
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = 0.25
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp29 * tmp30
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp25 + tmp31
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = 32768.0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp3 / tmp33
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = 1.0
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp32 + tmp36
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.debug_barrier()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (tl.full([XBLOCK, 1], 0, tl.int32)), tmp37, None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34 = args
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_1, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_2, (64, 3, 3, 3), (27, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_3, (64, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_4, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_5, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_6, (64, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_7, (128, 64, 3, 3), (576, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_8, (128, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_9, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_10, (128, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_11, (256, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_12, (256, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_13, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_14, (256, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_15, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_16, (256, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_17, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_18, (256, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_19, (512, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_20, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_21, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_22, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_23, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_24, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_25, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_26, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_27, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_28, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_29, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_30, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_31, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_32, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_33, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_34, (512, ), (1, ))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = empty_strided_cuda((64, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_0.run(primals_2, buf1, 192, 9, grid=grid(192, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_2
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_1.run(primals_5, buf2, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_5
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_2.run(primals_1, buf0, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_1
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_2.run(primals_4, buf14, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_4
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_3.run(primals_7, buf3, 8192, 9, grid=grid(8192, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_7
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_4.run(primals_9, buf4, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_9
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = empty_strided_cuda((256, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_5.run(primals_11, buf5, 32768, 9, grid=grid(32768, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_11
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_13, buf6, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_13
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_15, buf7, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_15
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_17, buf8, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_17
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = extern_kernels.convolution(buf14, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf15, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf14
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_37], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = extern_kernels.convolution(buf0, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf45, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = buf15; del buf15  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = buf45; del buf45  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf97 = empty_strided_cuda((4, 64, 64, 64), (262144, 1, 4096, 64), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x, x_1, x_37, x_38, l1_loss], Original ATen: [aten.convolution, aten.relu, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_sgn_sub_7.run(buf16, buf46, primals_3, buf97, 1048576, grid=grid(1048576), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_3
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf79 = empty_strided_cuda((128, 64), (1, 128), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_8.run(buf46, buf16, buf79, 8192, 128, grid=grid(8192), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf80 = empty_strided_cuda((128, ), (1, ), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_9.run(buf79, buf80, 128, 64, grid=grid(128), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf79
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf81 = empty_strided_cuda((), (), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_10.run(buf80, buf81, 1, 128, grid=grid(1), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf80
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = extern_kernels.convolution(buf16, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf17, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = buf17; del buf17  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf18, primals_6, 1048576, grid=grid(1048576), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = empty_strided_cuda((4, 64, 32, 32), (65536, 1, 2048, 64), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3, x_4], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_12.run(buf18, buf19, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf18
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3, x_4, x_5], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = extern_kernels.convolution(buf19, buf3, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf20, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_39], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = extern_kernels.convolution(buf46, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf47, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = buf47; del buf47  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_39, x_40], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf48, primals_6, 1048576, grid=grid(1048576), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_6
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = buf19; del buf19  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = empty_strided_cuda((4, 64, 32, 32), (65536, 1, 2048, 64), torch.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_41], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_13.run(buf48, buf49, buf50, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_42], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = extern_kernels.convolution(buf49, buf3, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf51, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = buf20; del buf20  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = buf51; del buf51  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf96 = empty_strided_cuda((4, 128, 32, 32), (131072, 1, 4096, 128), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_2, x_3, x_4, x_5, x_6, x_42, x_43, l1_loss_1], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_14.run(buf21, buf52, primals_8, buf96, 524288, grid=grid(524288), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_8
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf82 = empty_strided_cuda((64, 64), (1, 64), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_15.run(buf52, buf21, buf82, 4096, 128, grid=grid(4096), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf83 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_16.run(buf82, buf83, 64, 64, grid=grid(64), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf82
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf84 = empty_strided_cuda((), (), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_1], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_17.run(buf83, buf84, 1, 64, grid=grid(1), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf83
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = extern_kernels.convolution(buf21, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf22, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf21
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = buf22; del buf22  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_18.run(buf23, primals_10, 524288, grid=grid(524288), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = empty_strided_cuda((4, 128, 16, 16), (32768, 1, 2048, 128), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8, x_9], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_19.run(buf23, buf24, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf23
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8, x_9, x_10], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf24, buf5, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_44], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = extern_kernels.convolution(buf52, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf53, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = buf53; del buf53  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_44, x_45], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_18.run(buf54, primals_10, 524288, grid=grid(524288), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_10
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = buf24; del buf24  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = empty_strided_cuda((4, 128, 16, 16), (32768, 1, 2048, 128), torch.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_46], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_20.run(buf54, buf55, buf56, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_47], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = extern_kernels.convolution(buf55, buf5, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf57, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = buf25; del buf25  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = buf57; del buf57  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf95 = empty_strided_cuda((4, 256, 16, 16), (65536, 1, 4096, 256), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_7, x_8, x_9, x_10, x_11, x_47, x_48, l1_loss_2], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_21.run(buf26, buf58, primals_12, buf95, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_12
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf85 = empty_strided_cuda((32, 64), (1, 32), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_22.run(buf58, buf26, buf85, 2048, 128, grid=grid(2048), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf86 = empty_strided_cuda((32, ), (1, ), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_23.run(buf85, buf86, 32, 64, grid=grid(32), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf85
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf87 = empty_strided_cuda((), (), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_2], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_24.run(buf86, buf87, 1, 32, grid=grid(1), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf86
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = extern_kernels.convolution(buf26, buf6, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf27, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf26
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = buf27; del buf27  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf28, primals_14, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = extern_kernels.convolution(buf28, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf29, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf28
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = buf29; del buf29  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf30, primals_16, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = extern_kernels.convolution(buf30, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf31, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf30
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = buf31; del buf31  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf32, primals_18, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = empty_strided_cuda((4, 256, 8, 8), (16384, 1, 2048, 256), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_26.run(buf32, buf33, 65536, grid=grid(65536), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf32
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_49], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf59 = extern_kernels.convolution(buf58, buf6, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf59, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf60 = buf59; del buf59  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_49, x_50], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf60, primals_14, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_14
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_51], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf61 = extern_kernels.convolution(buf60, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf61, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf62 = buf61; del buf61  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_51, x_52], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf62, primals_16, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_16
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_53], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf63 = extern_kernels.convolution(buf62, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf63, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf64 = buf63; del buf63  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_53, x_54], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_25.run(buf64, primals_18, 262144, grid=grid(262144), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_18
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf65 = empty_strided_cuda((4, 256, 8, 8), (16384, 1, 2048, 256), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf66 = empty_strided_cuda((4, 256, 8, 8), (16384, 1, 2048, 256), torch.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_55], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_27.run(buf64, buf65, buf66, 65536, grid=grid(65536), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = empty_strided_cuda((512, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_28.run(primals_19, buf9, 131072, 9, grid=grid(131072, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_19
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = extern_kernels.convolution(buf33, buf9, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf34, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf33
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_56], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf67 = extern_kernels.convolution(buf65, buf9, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf67, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = buf34; del buf34  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf68 = buf67; del buf67  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf94 = empty_strided_cuda((4, 512, 8, 8), (32768, 1, 4096, 512), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_56, x_57, l1_loss_3], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices, aten.sub, aten.sgn]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_sgn_sub_29.run(buf35, buf68, primals_20, buf94, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_20
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf88 = empty_strided_cuda((16, 64), (64, 1), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_30.run(buf68, buf35, buf88, 1024, 128, grid=grid(1024), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf89 = empty_strided_cuda((16, ), (1, ), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_31.run(buf88, buf89, 16, 64, grid=grid(16), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf88
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf90 = empty_strided_cuda((), (), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [l1_loss_3], Original ATen: [aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_sub_32.run(buf89, buf90, 1, 16, grid=grid(1), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf89
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_21, buf10, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_21
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = extern_kernels.convolution(buf35, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf36, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf35
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf36; del buf36  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf37, primals_22, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_58], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf69 = extern_kernels.convolution(buf68, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf69, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf70 = buf69; del buf69  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_58, x_59], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf70, primals_22, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_22
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_23, buf11, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_23
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = extern_kernels.convolution(buf37, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf38, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf37
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = buf38; del buf38  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf39, primals_24, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_60], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf71 = extern_kernels.convolution(buf70, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf71, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf72 = buf71; del buf71  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_60, x_61], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf72, primals_24, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_24
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_25, buf12, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_25
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = extern_kernels.convolution(buf39, buf12, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf40, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf39
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = buf40; del buf40  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf41, primals_26, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_35.run(buf41, buf42, 32768, grid=grid(32768), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf41
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_62], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf73 = extern_kernels.convolution(buf72, buf12, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf73, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf74 = buf73; del buf73  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_62, x_63], Original ATen: [aten.convolution, aten.relu]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_34.run(buf74, primals_26, 131072, grid=grid(131072), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_26
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf75 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf76 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.int8)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_64], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_36.run(buf74, buf75, buf76, 32768, grid=grid(32768), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_33.run(primals_27, buf13, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_27
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = extern_kernels.convolution(buf42, buf13, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf43, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf42
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_65], Original ATen: [aten.convolution]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf77 = extern_kernels.convolution(buf75, buf13, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf77, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = buf43; del buf43  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf78 = buf77; del buf77  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_65], Original ATen: [aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_max_pool2d_with_indices_relu_37.run(buf44, buf78, primals_28, 32768, grid=grid(32768), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_28
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf91 = empty_strided_cuda((4, 64), (64, 1), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_relu_sub_38.run(buf78, buf44, buf91, 256, 128, grid=grid(256), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf92 = empty_strided_cuda((4, ), (1, ), torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_mean_relu_sub_39.run(buf91, buf92, 4, 64, grid=grid(4), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf91
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf98 = buf81; del buf81  # reuse
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_29, x_66, l1_loss, mul, loss, l1_loss_1, mul_1, loss_1, l1_loss_2, mul_2, loss_2, l1_loss_3, mul_3, loss_3, l1_loss_4, mul_4, loss_4], Original ATen: [aten.relu, aten.sub, aten.abs, aten.mean, aten.mul, aten.add]
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_abs_add_mean_mul_relu_sub_40.run(buf98, buf92, buf84, buf87, buf90, 1, 4, grid=grid(1), stream=stream0)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf84
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf87
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf90
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf92
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf98, buf0, buf1, buf2, buf3, buf4, buf5, buf6, buf7, buf8, buf9, buf10, buf11, buf12, buf13, buf44, buf46, buf48, buf49, buf50, buf52, buf54, buf55, buf56, buf58, buf60, buf62, buf64, buf65, buf66, buf68, buf70, buf72, buf74, buf75, buf76, buf78, buf94, buf95, buf96, buf97, )
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_2 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_3 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_4 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_5 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_6 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_7 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_8 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_9 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_10 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_11 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_12 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_13 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_14 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_15 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_16 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_17 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_18 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_19 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_20 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_21 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_22 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_23 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_24 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_25 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_26 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_27 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_28 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_29 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_30 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_31 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_32 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_33 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_34 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34])
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0205 18:30:25.990000 7574 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:30:26.046000 7574 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: inductor_cache/uh/cuhy3r6qiksq5lomhxhhl5vlfkiromjqksuu66fpdu745uwxl76p.py
