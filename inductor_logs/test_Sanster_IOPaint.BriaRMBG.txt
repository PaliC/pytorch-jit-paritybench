V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['6_forward']
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/n4/cn4hrwuln6hsj2n2w475355p5zbjkm3zwbbdzwtg7wvwuvl2c7lo.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hxin], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hxin => convolution
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_1, %primals_2, %primals_3, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_0 = async_compile.triton('triton_poi_fused_convolution_0', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_0(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ps/cpsj56ahxao7bl2knzgijtnohax7ughlnosxgsx6qa4aloq3bj62.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_1, batch_norm, xout], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm => add_1, mul_1, mul_2, sub
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_1 => convolution_1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout => relu
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%convolution, %primals_4, %primals_5, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_1, %unsqueeze_1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, %unsqueeze_3), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1, %unsqueeze_5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2, %unsqueeze_7), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_1,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dd/cdd2luabwlku737gxy2abzzcnddgktmr5frh67kyenen6ygfwxlo.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_2, batch_norm_1, xout_1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_1 => add_3, mul_4, mul_5, sub_1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_2 => convolution_2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_1 => relu_1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_10, %primals_11, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_2, %unsqueeze_9), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1, %unsqueeze_11), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_5 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_4, %unsqueeze_13), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_5, %unsqueeze_15), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_3,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/l2/cl24z6waopzxpf36qejympec5pm32tod47ep3qeggiykfwxilud3.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx => getitem, getitem_1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_3 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_3', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_3(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bv/cbvw7mz32ydhq5pg2uy3mwch33xrtoyxp2bago3o22nxypthq7ok.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_3, batch_norm_2, xout_2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_2 => add_5, mul_7, mul_8, sub_2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_3 => convolution_3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_2 => relu_2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %primals_16, %primals_17, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_3, %unsqueeze_17), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_2, %unsqueeze_19), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_7, %unsqueeze_21), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_5 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_8, %unsqueeze_23), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_5,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/te/cte4gqdyrzaaflsmzvkr7zsamkmw7f3del56dhewyygbqjza576r.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_1], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_1 => getitem_2, getitem_3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_2 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_1, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_1, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_5 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_5', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_5(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/s3/cs3bytq7ptfg7m5pga47bdf4qgcxi647k4butflxcdueihjurv3s.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_4, batch_norm_3, xout_3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_3 => add_7, mul_10, mul_11, sub_3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_4 => convolution_4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_3 => relu_3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %primals_22, %primals_23, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_4, %unsqueeze_25), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_10 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_3, %unsqueeze_27), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_11 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_10, %unsqueeze_29), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_7 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_11, %unsqueeze_31), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_7,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jq/cjqauidmifhowptdb6atpxelzdzfcwojxpoxaav57f4whuydchbh.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_2], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_2 => getitem_4, getitem_5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_4 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_2, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_2, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_7 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_7', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_7(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fk/cfk6462nwe25mxsqvxpld2cgf7az4phgi3o3g7ijjw7r5c5oj672.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_5, batch_norm_4, xout_4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_4 => add_9, mul_13, mul_14, sub_4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_5 => convolution_5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_4 => relu_4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %primals_28, %primals_29, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_5, %unsqueeze_33), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_4, %unsqueeze_35), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_13, %unsqueeze_37), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_14, %unsqueeze_39), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_9,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sj/csjy3rs4vwvfhlnl37fdizoxfahbmwzs4ecrpetvq7mivj6qpdcs.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_3], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_3 => getitem_6, getitem_7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_6 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_3, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_7 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_3, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_9 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_9', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_9(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e4/ce4guxx3nqprzez22pwxdqps7nxkcb6yhw6redpbn3m3iruvrxlp.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_6, batch_norm_5, xout_5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_5 => add_11, mul_16, mul_17, sub_5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_6 => convolution_6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_5 => relu_5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %primals_34, %primals_35, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_5 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_6, %unsqueeze_41), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_16 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_5, %unsqueeze_43), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_17 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_16, %unsqueeze_45), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_11 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_17, %unsqueeze_47), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_11,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hk/chkealec3cvaznzjbsnaihbf6ip6exzkqbzfg2fiym6rocxyygxz.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_4], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_4 => getitem_8, getitem_9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_8 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_4, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_9 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_4, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_11 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_11', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_11(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/24/c24yaahxaotjirvbua5ytcw4pdkouwhrnbdquad2pxcsr47ft5ap.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_7, batch_norm_6, xout_6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_6 => add_13, mul_19, mul_20, sub_6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_7 => convolution_7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_6 => relu_6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %primals_40, %primals_41, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_6 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_7, %unsqueeze_49), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_19 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_6, %unsqueeze_51), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_20 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_19, %unsqueeze_53), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_13 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_20, %unsqueeze_55), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_13,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vy/cvybkhuxoxcmma7ngxlakt6tovr2qzsg3wzprz53y5wzjpyykabm.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_8 => convolution_8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %primals_46, %primals_47, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_13 = async_compile.triton('triton_poi_fused_convolution_13', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_13', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_13(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ki/ckiwfsfgaddbg6fy2xkk4hocx5p5uyddmmpwckdm4ihdo4ckojzn.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_5], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_5 => cat
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_7, %relu_6], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_14 = async_compile.triton('triton_poi_fused_cat_14', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_14(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (32*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (32*x1 + ((-32) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qc/cqccxiwkiljud3bniroeq5rzv7yugfonbqsv65vrfh2zypuogvs2.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => convert_element_type_19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_19 : [num_users=21] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_15 = async_compile.triton('triton_poi_fused__to_copy_15', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_15(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/k7/ck7wg54iui5c4lyvh2we6r5hz5oknw7usc4xqi3qc465so3kj6ev.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => add_19, clamp_max
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_19 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_19, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_19, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_16 = async_compile.triton('triton_poi_fused_add_clamp_16', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_16(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xj/cxjwtsrvz6c4jeilnwn3wtwvchxqzkclfmkdd2bjn2b2zcfuofd4.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => add_18, clamp_max_2, clamp_min, clamp_min_2, convert_element_type_18, iota, mul_27, sub_11, sub_9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (2,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_18 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_18 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_18, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_27 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_9 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_27, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_9, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_11 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min, %convert_element_type_21), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_2 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_11, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_2 : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_2, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hk/chkicmfgtdjr22sjpzexxlgxj3d7vwhyq5rhfq7jxfvh7rrj7zl4.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => _unsafe_index, _unsafe_index_1, add_22, mul_29, sub_12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_8, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_1 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_8, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_12 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_1, %_unsafe_index), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_12, %clamp_max_2), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_22 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index, %mul_29), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_18 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_18', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_18(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ed/ced563w6eutysah4chmsggvmjterfnbhtdbczolzosskf7cdebxj.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_6], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_6 => cat_1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_1 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_24, %relu_5], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_19 = async_compile.triton('triton_poi_fused_cat_19', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_19(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 128*x3), tmp4 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (32*x3 + (x2)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-32) + x2) + 128*x3), tmp30 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fx/cfxbjodzh2dkxqz27xqawrecnl7poaofdbwkyqnqxc2eipjkxcen.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => convert_element_type_25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_25 : [num_users=21] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_2, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_20 = async_compile.triton('triton_poi_fused__to_copy_20', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_20(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hx/chx57dhjee4zplvovoki5ka2gewhg3mae2vag2qwyasia6zt7gfi.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => add_28, clamp_max_4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_28 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_25, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_4 : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_28, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_21 = async_compile.triton('triton_poi_fused_add_clamp_21', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_21(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.minimum(tmp10, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp11, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7f/c7fjia67jmgqw3y6hgjsetmbdjnkpt6rfxxfkmmxqkdbj6udxg2s.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => add_27, clamp_max_6, clamp_min_4, clamp_min_6, convert_element_type_24, iota_2, mul_35, sub_17, sub_19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_2 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (4,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_24 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_2, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_27 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_24, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_35 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_27, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_17 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_35, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_4 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_17, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_4, %convert_element_type_27), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_6 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_19, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_6 : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_6, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qe/cqebg3ezq3pnopm3tipawtkerhmo2seyoelgiarndvw4aoo5fqlm.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => _unsafe_index_4, _unsafe_index_5, add_31, mul_37, sub_20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_4 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_9, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_5 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_9, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_20 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_5, %_unsafe_index_4), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_37 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_20, %clamp_max_6), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_31 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_4, %mul_37), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_23 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_23', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_23(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sz/csz2nkkakcpbe46dun346pdkca4byzakptkzscd2asrpdrebe2za.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_7], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_7 => cat_2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_2 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_33, %relu_4], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_24 = async_compile.triton('triton_poi_fused_cat_24', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_24', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_24(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 512*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 128*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 128*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-32) + x2) + 512*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/em/cemi7um2z3fkueru4f36t7cd35dorztv3ka53pib5rdthnhijj7r.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => convert_element_type_31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_31 : [num_users=17] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_4, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_25 = async_compile.triton('triton_poi_fused__to_copy_25', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_25', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_25(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fp/cfp6jeb7ig365an2aqmqtwrklya4pbiis7x3fedtdoeg2dv7orjb.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => add_37, clamp_max_8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_37 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_31, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_8 : [num_users=15] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_37, 3), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_26 = async_compile.triton('triton_poi_fused_add_clamp_26', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_26', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_26(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 3, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hv/chvli3k2ywfws7qqeojtkyholsq4cpeulqccwr4k527spvtsk6ac.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => add_36, clamp_max_10, clamp_min_10, clamp_min_8, convert_element_type_30, iota_4, mul_43, sub_25, sub_27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_4 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (8,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_30 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_4, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_36 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_30, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_43 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_36, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_25 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_43, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_8 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_25, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_27 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_8, %convert_element_type_33), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_10 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_27, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_10 : [num_users=15] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_10, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vp/cvpg4it72drineydhg34sxzhijf6p7ctuddzvecmibe4ob4pxiaw.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => _unsafe_index_8, _unsafe_index_9, add_40, mul_45, sub_28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_8 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_10, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_9 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_10, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_28 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_9, %_unsafe_index_8), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_45 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_28, %clamp_max_10), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_40 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_8, %mul_45), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_28 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_28', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_28', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_28(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fw/cfwu76k36hc7m66w7n6pz7ohkyh7qwhdndscoklf6ffqbb6tgznb.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_8], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_8 => cat_3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_3 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_42, %relu_3], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_29 = async_compile.triton('triton_poi_fused_cat_29', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_29', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_29(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 2048*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-32) + x2) + 2048*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ka/ckat4dzxkbv6zu5qbb3dmo3b3udf75n2shxy3mms2mwmszj4njyn.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => convert_element_type_37
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_37 : [num_users=13] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_6, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_30 = async_compile.triton('triton_poi_fused__to_copy_30', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_30', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_30(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6w/c6wnohbmkw3hxjgxk2j3rvnq6byg3fop7asafdg4spxmcmgvzhzs.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => add_46, clamp_max_12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_46 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_37, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_12 : [num_users=11] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_46, 7), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_31 = async_compile.triton('triton_poi_fused_add_clamp_31', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_31', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_31(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 7, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/df/cdfsoali4vp7id6olba5cf6a33x5umpcbhtnri6hm7xpn4r6jwuv.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => add_45, clamp_max_14, clamp_min_12, clamp_min_14, convert_element_type_36, iota_6, mul_51, sub_33, sub_35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_6 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (16,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_36 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_6, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_45 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_36, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_51 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_45, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_33 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_51, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_12 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_33, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_35 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_12, %convert_element_type_39), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_14 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_35, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_14 : [num_users=11] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_14, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5g/c5gwfhqnvvcu2mazt7b4vj2pjp7flrhdebumcshl5tgo4pdujeyr.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => _unsafe_index_12, _unsafe_index_13, add_49, mul_53, sub_36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_12 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_11, [None, None, %convert_element_type_37, %convert_element_type_39]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_13 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_11, [None, None, %convert_element_type_37, %clamp_max_13]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_36 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_13, %_unsafe_index_12), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_53 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_36, %clamp_max_14), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_49 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_12, %mul_53), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_33 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_33', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_33', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_33(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zr/czrcn7h7ij7zuxux4mkob6x3vbabreuvbr7vo4cyi6i52ckawg25.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_9], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_9 => cat_4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_4 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_51, %relu_2], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_34 = async_compile.triton('triton_poi_fused_cat_34', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_34', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_34(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 256) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 256*(x2) + 8192*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 8, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 8*tmp10 + 64*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 8*tmp10 + 64*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 256*((-32) + x2) + 8192*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/c3/cc36kii3ooqjvk7wch3emv4bmfx4t7dmlxot7mzwio2onizczn2i.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => convert_element_type_43
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_43 : [num_users=9] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_8, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_35 = async_compile.triton('triton_poi_fused__to_copy_35', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_35', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_35(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/w7/cw77wo73fvmq62s2sbbxmtp454gc2pj6ffvoq6evwhuc47nv2wrx.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => add_55, clamp_max_16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_55 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_43, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_16 : [num_users=7] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_55, 15), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_36 = async_compile.triton('triton_poi_fused_add_clamp_36', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_36', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_36(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 15, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5x/c5xsj2g4rgsnc4wstdbgnonxevb5at2ilfhmvolsqgras7xpefz7.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => add_54, clamp_max_18, clamp_min_16, clamp_min_18, convert_element_type_42, iota_8, mul_59, sub_41, sub_43
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_8 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (32,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_42 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_8, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_54 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_42, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_59 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_54, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_41 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_59, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_16 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_41, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_43 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_16, %convert_element_type_45), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_18 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_43, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_18 : [num_users=7] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_18, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gg/cggltkplr2gbesssmcbqlax7vgojsbucofrzdw7vavuamkp5givs.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => _unsafe_index_16, _unsafe_index_17, add_58, mul_61, sub_44
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_16 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_12, [None, None, %convert_element_type_43, %convert_element_type_45]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_17 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_12, [None, None, %convert_element_type_43, %clamp_max_17]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_44 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_17, %_unsafe_index_16), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_44, %clamp_max_18), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_58 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_16, %mul_61), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_38 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_38', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_38', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_38(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qt/cqtppf2pm5lqre4r75eyyw2tnawntabwl3urbov6nwhxpt2ymoye.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_10], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_10 => cat_5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_5 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_60, %relu_1], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_39 = async_compile.triton('triton_poi_fused_cat_39', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_39', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_39(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 1024) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 1024)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 1024*(x2) + 32768*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 16, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 16*tmp10 + 256*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 16*tmp10 + 256*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 1024*((-32) + x2) + 32768*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gq/cgqpe4itjdx2iaixlelaufylfuxl5kssrqncxcaqanwpqpfemikl.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_14, batch_norm_13, xout_13, hx1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_13 => add_62, mul_65, mul_66, sub_48
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_14 => convolution_14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx1 => add_63
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_13 => relu_13
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_14 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_5, %primals_82, %primals_83, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_48 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_14, %unsqueeze_105), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_65 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_48, %unsqueeze_107), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_66 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_65, %unsqueeze_109), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_62 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_66, %unsqueeze_111), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_13 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_62,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_63 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_13, %relu), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ic/cicmum7lhyk46sryutafwofdwpaxize267xb642pt6nuqkeaq75t.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_11], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_11 => getitem_10, getitem_11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_10 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_41 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_41', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_41', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_41(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sp/csphgofodssoibkjnktbbnkxfw2xuhsu2x2s2pa7u6gesg3qkryi.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_15, batch_norm_14, xout_14], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_14 => add_65, mul_68, mul_69, sub_49
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_15 => convolution_15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_14 => relu_14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_15 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %primals_88, %primals_89, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_49 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_15, %unsqueeze_113), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_68 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_49, %unsqueeze_115), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_69 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_68, %unsqueeze_117), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_65 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_69, %unsqueeze_119), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_14 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_65,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7h/c7hzimjdqyaux6zlzwslkwvu2ljwo5ufgfgtic3p7y4vubigyzjk.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_26, batch_norm_25, xout_25, hx2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_25 => add_115, mul_121, mul_122, sub_88
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_26 => convolution_26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx2 => add_116
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_25 => relu_25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_10, %primals_154, %primals_155, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_88 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_26, %unsqueeze_201), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_121 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_88, %unsqueeze_203), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_122 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_121, %unsqueeze_205), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_115 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_122, %unsqueeze_207), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_115,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_116 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_25, %relu_14), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3h/c3hulvoujd4rg4skthrp6zn5z6llkghsxnctsngitozth3msvi6v.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_21], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_21 => getitem_20, getitem_21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_20 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_10, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_10, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_44 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_44', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_44', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_44(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/o3/co3pnvtugfpykkfw2ag3kbv3hcasdz5nqyiv76qjj25fsbxsypqt.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_27, batch_norm_26, xout_26], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_26 => add_118, mul_124, mul_125, sub_89
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_27 => convolution_27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_26 => relu_26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_20, %primals_160, %primals_161, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_89 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_27, %unsqueeze_209), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_124 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_89, %unsqueeze_211), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_125 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_124, %unsqueeze_213), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_118 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_125, %unsqueeze_215), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_118,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xs/cxs2mcuj2divobeij3hd7vc4zxjlaraofvgivu5ruunabbhvp6ew.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_28, batch_norm_27, xout_27], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_27 => add_120, mul_127, mul_128, sub_90
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_28 => convolution_28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_27 => relu_27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_26, %primals_166, %primals_167, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_90 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_28, %unsqueeze_217), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_127 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_90, %unsqueeze_219), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_128 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_127, %unsqueeze_221), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_120 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_128, %unsqueeze_223), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_27 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_120,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xu/cxuqrtfuvyvng2kpvxr47n4qjkrsdg453xkb65weg32a4fc2m7x4.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_22], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_22 => getitem_22, getitem_23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_22 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_11, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_11, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_47 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_47', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_47', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_47(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6o/c6owx6kdd26w6j2dob2mznfnlva2we7ajxl2kov4hevat7cal7aw.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_29, batch_norm_28, xout_28], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_28 => add_122, mul_130, mul_131, sub_91
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_29 => convolution_29
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_28 => relu_28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_29 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_22, %primals_172, %primals_173, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_91 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_29, %unsqueeze_225), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_130 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_91, %unsqueeze_227), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_131 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_130, %unsqueeze_229), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_122 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_131, %unsqueeze_231), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_122,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5j/c5jfammzrd5mw7rbqbw7fmw55klu3in7jw3a3o6mv2ln3n5rkd46.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_23], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_23 => getitem_24, getitem_25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_24 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_12, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_12, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_49 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_49', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_49', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_49(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mu/cmuid2yzythokzkzobyyasmdl3cmgxbdwwrejehwcdtxemyeri46.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_30, batch_norm_29, xout_29], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_29 => add_124, mul_133, mul_134, sub_92
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_30 => convolution_30
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_29 => relu_29
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_30 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_24, %primals_178, %primals_179, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_92 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_30, %unsqueeze_233), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_133 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_92, %unsqueeze_235), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_134 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_133, %unsqueeze_237), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_124 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_134, %unsqueeze_239), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_29 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_124,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/et/cetjyjmgszeejve5uujd4y7dxz25b5rdswgnq4m5zvt6nfchvmib.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_24], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_24 => getitem_26, getitem_27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_26 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_13, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_13, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_51 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_51', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_51', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_51(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6y/c6yzc3p5s3lhis73kmzbp6ld6yxnpsh57y4hkiyximy4sp4b4wvg.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_31, batch_norm_30, xout_30], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_30 => add_126, mul_136, mul_137, sub_93
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_31 => convolution_31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_30 => relu_30
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_31 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_26, %primals_184, %primals_185, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_93 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_31, %unsqueeze_241), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_136 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_93, %unsqueeze_243), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_137 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_136, %unsqueeze_245), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_126 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_137, %unsqueeze_247), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_30 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_126,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dy/cdynxj5e3hzsqwau7x4mnh4mrvqjse2qfinnebrksmfykewo4ip4.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_32], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_32 => convolution_32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_32 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_30, %primals_190, %primals_191, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_53 = async_compile.triton('triton_poi_fused_convolution_53', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_53', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_53(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bz/cbzkmfuxaxg3ghfgg5vyblgt5xpwuqdkkuclytlzvn5qipnjaddm.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_25], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_25 => cat_11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_11 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_31, %relu_30], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_54 = async_compile.triton('triton_poi_fused_cat_54', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_54', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_54(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 128
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (64*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (64*x1 + ((-64) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jf/cjfkyye2ztm2ilgvvdnrxc5ywv4b7lww5rdmlanl6x4zbz66udar.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_9], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_9 => _unsafe_index_36, _unsafe_index_37, add_135, mul_146, sub_99
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_36 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_32, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_37 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_32, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_99 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_37, %_unsafe_index_36), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_146 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_99, %clamp_max_2), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_135 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_36, %mul_146), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_55 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_55', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_55', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_55(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/z2/cz2etme3o6ldjjnqd6qcomb2w5wkul7hsmjlx3yodprriozw2jdc.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_26], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_26 => cat_12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_12 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_137, %relu_29], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_56 = async_compile.triton('triton_poi_fused_cat_56', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_56', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_56(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 256*x3), tmp4 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (64*x3 + (x2)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-64) + x2) + 256*x3), tmp30 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vs/cvsint74kx3dbtntzypne3da7p4ari3kd5w642xv4wjn7hh6vunh.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_10], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_10 => _unsafe_index_40, _unsafe_index_41, add_144, mul_154, sub_107
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_40 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_33, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_41 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_33, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_107 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_41, %_unsafe_index_40), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_154 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_107, %clamp_max_6), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_144 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_40, %mul_154), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_57 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_57', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_57', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_57(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/v4/cv42hpt5cwkg4j3vmi3dmuzfwnenybxqlzmydfja3h2yg5zvfb7v.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_27], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_27 => cat_13
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_13 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_146, %relu_28], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_58 = async_compile.triton('triton_poi_fused_cat_58', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_58', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_58(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 1024*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-64) + x2) + 1024*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/g2/cg24uf24eb3yarnhupxidnj6bjqc5u52hn7zm4chtdh4rbalwt4w.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_11], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_11 => _unsafe_index_44, _unsafe_index_45, add_153, mul_162, sub_115
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_44 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_34, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_45 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_34, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_115 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_45, %_unsafe_index_44), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_162 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_115, %clamp_max_10), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_153 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_44, %mul_162), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_59 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_59', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_59', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_59(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/b7/cb7eqfpswkfcmxhxgsxxuz5wf6ryf2zbkjf56a5nqzc545iplgff.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_28], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_28 => cat_14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_14 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_155, %relu_27], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_60 = async_compile.triton('triton_poi_fused_cat_60', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_60', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_60(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 4096*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-64) + x2) + 4096*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fq/cfqohs3m2ag2annqfm2sjuj5antkf2pdifkpp6nxthgx2ryzsgg6.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_36, batch_norm_35, xout_35, hx3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_35 => add_157, mul_166, mul_167, sub_119
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_36 => convolution_36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx3 => add_158
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_35 => relu_35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_36 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_14, %primals_214, %primals_215, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_119 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_36, %unsqueeze_281), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_166 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_119, %unsqueeze_283), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_167 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_166, %unsqueeze_285), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_157 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_167, %unsqueeze_287), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_35 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_157,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_158 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_35, %relu_26), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bq/cbqcoaunyj3zpfycfw27mxpvgis2moialoorqsja4e6vnnsnee3o.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_29], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_29 => getitem_28, getitem_29
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_28 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_14, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_14, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_62 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_62', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_62', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_62(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sk/cskhbw7vfjjh2d22twzswlm6vvdxme5l7oj5m452xdubx3b37rgl.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_37, batch_norm_36, xout_36], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_36 => add_160, mul_169, mul_170, sub_120
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_37 => convolution_37
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_36 => relu_36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_37 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_28, %primals_220, %primals_221, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_120 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_37, %unsqueeze_289), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_169 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_120, %unsqueeze_291), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_170 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_169, %unsqueeze_293), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_160 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_170, %unsqueeze_295), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_36 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_160,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tb/ctboq77ecoz2fj3hdbyjsq7vggtn7xtx5lqpb47eidqwrtqgy62u.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_38, batch_norm_37, xout_37], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_37 => add_162, mul_172, mul_173, sub_121
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_38 => convolution_38
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_37 => relu_37
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_38 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_36, %primals_226, %primals_227, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_121 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_38, %unsqueeze_297), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_172 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_121, %unsqueeze_299), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_173 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_172, %unsqueeze_301), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_162 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_173, %unsqueeze_303), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_37 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_162,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ek/cek4g3o2inknzfobdzxdhf5ce2n22nhbkn35gpajdgq6i5tpnweu.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_30], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_30 => getitem_30, getitem_31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_30 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_15, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_31 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_15, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_65 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_65', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_65', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_65(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ob/cobr4hvo5fiscpoe2cuiqs5kixwvphidpbinmezqq5cwb5kmgf3z.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_39, batch_norm_38, xout_38], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_38 => add_164, mul_175, mul_176, sub_122
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_39 => convolution_39
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_38 => relu_38
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_39 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_30, %primals_232, %primals_233, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_122 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_39, %unsqueeze_305), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_175 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_122, %unsqueeze_307), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_176 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_175, %unsqueeze_309), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_164 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_176, %unsqueeze_311), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_38 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_164,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dc/cdcvhcurqyyzal6xf5plx2onzjxt3affbfmhylv3cqbnxjwhyoyj.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_31], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_31 => getitem_32, getitem_33
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_32 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_16, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_33 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_16, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_67 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_67', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_67', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_67(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7o/c7oi3fswpqzqffukuesj65nghup6sucpigyqyzyjegq32lyr7rtl.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_40, batch_norm_39, xout_39], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_39 => add_166, mul_178, mul_179, sub_123
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_40 => convolution_40
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_39 => relu_39
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_40 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_32, %primals_238, %primals_239, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_123 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_40, %unsqueeze_313), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_178 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_123, %unsqueeze_315), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_179 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_178, %unsqueeze_317), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_166 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_179, %unsqueeze_319), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_39 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_166,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ut/cutpzdmdqefhfygber23sie67pq32lphpsow4q7dcgge5pxaahgz.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_41], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_41 => convolution_41
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_41 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_39, %primals_244, %primals_245, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_69 = async_compile.triton('triton_poi_fused_convolution_69', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_69', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_69(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5r/c5rmnztxebd5trylw3qjvlp5miywfs4autvpmbsf4pzenp2rp25u.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_32], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_32 => cat_15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_15 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_40, %relu_39], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_70 = async_compile.triton('triton_poi_fused_cat_70', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_70', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_70(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (128*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 256, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (128*x1 + ((-128) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qr/cqrsn3ptiawxz37vskkznhzmztx535eb774mkqfqebc6jvj4yerp.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_12], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_12 => _unsafe_index_48, _unsafe_index_49, add_175, mul_188, sub_129
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_48 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_41, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_49 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_41, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_129 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_49, %_unsafe_index_48), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_188 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_129, %clamp_max_2), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_175 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_48, %mul_188), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_71 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_71', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_71', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_71(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4p/c4pmuey3w75elfd3zuqs75bqb3a73yomyk3tlxmg4d262otiqltr.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_33], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_33 => cat_16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_16 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_177, %relu_38], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_72 = async_compile.triton('triton_poi_fused_cat_72', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_72', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_72(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 512*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (128*x3 + (x2)), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 256, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-128) + x2) + 512*x3), tmp30, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kx/ckxya6kfzrdrhgv2w3adtmsuj5phzeygieg7ew5g44h4osz2nxn7.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_13], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_13 => _unsafe_index_52, _unsafe_index_53, add_184, mul_196, sub_137
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_52 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_42, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_53 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_42, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_137 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_53, %_unsafe_index_52), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_196 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_137, %clamp_max_6), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_184 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_52, %mul_196), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_73 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_73', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_73', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_73(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ch/cchek4m3mywf74mr7ybxjcu76po3hlseddln5kjqc4uqzxd5ubae.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_34], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_34 => cat_17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_17 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_186, %relu_37], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_74 = async_compile.triton('triton_poi_fused_cat_74', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_74', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_74(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 2048*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 256, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-128) + x2) + 2048*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sm/csmjx3atuu5sftxrdp3m7nnsln3y3ac5trgrbnrq5vckwxvz5lbo.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_44, batch_norm_43, xout_43, hx4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_43 => add_188, mul_200, mul_201, sub_141
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_44 => convolution_44
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx4 => add_189
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_43 => relu_43
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_44 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_17, %primals_262, %primals_263, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_141 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_44, %unsqueeze_345), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_200 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_141, %unsqueeze_347), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_201 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_200, %unsqueeze_349), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_188 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_201, %unsqueeze_351), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_43 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_188,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_189 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_43, %relu_36), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/cy/ccywaxv2dpmb2xj6ejlrih3ytcwjy6qwnprn3wqbo4b3xcqi3456.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_35], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_35 => getitem_34, getitem_35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_34 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_17, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_35 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_17, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_76 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_76', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_76', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_76(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ql/cqlokdim54hh32hg5cqid524ijmsf7j3epsslcevcfidwrpv2uz4.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_45, batch_norm_44, xout_44], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_44 => add_191, mul_203, mul_204, sub_142
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_45 => convolution_45
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_44 => relu_44
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_45 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_34, %primals_268, %primals_269, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_142 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_45, %unsqueeze_353), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_203 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_142, %unsqueeze_355), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_204 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_203, %unsqueeze_357), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_191 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_204, %unsqueeze_359), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_44 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_191,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qp/cqpsv26ouhkihp4dof4bznz4rjiwblntvaanzsy6gmujn5gl6cnm.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_46, batch_norm_45, xout_45], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_45 => add_193, mul_206, mul_207, sub_143
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_46 => convolution_46
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_45 => relu_45
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_46 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_44, %primals_274, %primals_275, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_143 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_46, %unsqueeze_361), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_206 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_143, %unsqueeze_363), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_207 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_206, %unsqueeze_365), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_193 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_207, %unsqueeze_367), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_45 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_193,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ym/cymqvkhflj3dcsiu6krnjnm2kjlyglggoa7pet6xfuf4euvh7az7.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_49], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_49 => convolution_49
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_49 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_47, %primals_292, %primals_293, [1, 1], [8, 8], [8, 8], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_79 = async_compile.triton('triton_poi_fused_convolution_79', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_79', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_79(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xy/cxywizj77bjqe4jnlfbcf57uhvwtdo3flm2geclbbghlmk3o43u3.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_36], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_36 => cat_18
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_18 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_48, %relu_47], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_80 = async_compile.triton('triton_poi_fused_cat_80', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_80', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_80(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 256, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x0 + 4*(x1) + 1024*x2), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 512, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (x0 + 4*((-256) + x1) + 1024*x2), tmp25, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp29, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6t/c6t2cntwhd4y3wy2ycapcqjqa7atm2yiwcdurdqzi6xfj4bmaesm.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_52, batch_norm_51, xout_51, hx5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_51 => add_205, mul_224, mul_225, sub_149
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_52 => convolution_52
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx5 => add_206
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_51 => relu_51
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_52 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_20, %primals_310, %primals_311, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_149 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_52, %unsqueeze_409), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_224 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_149, %unsqueeze_411), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_225 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_224, %unsqueeze_413), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_205 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_225, %unsqueeze_415), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_51 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_205,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_206 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_51, %relu_44), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3c/c3cfjghqtcivsvfh7ylxmc72w7ytciui7tuvempoigj6xxn2uy4w.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_39], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_39 => getitem_36, getitem_37
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_36 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_18, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_37 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_18, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_82 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_82', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_82', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_82(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jm/cjmimlrzjavp5s6bzifh6ysvkcsmcwcav2mzwodvmbq6hqpa2rp4.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_53, batch_norm_52, xout_52], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_52 => add_208, mul_227, mul_228, sub_150
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_53 => convolution_53
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_52 => relu_52
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_53 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_36, %primals_316, %primals_317, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_150 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_53, %unsqueeze_417), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_227 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_150, %unsqueeze_419), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_228 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_227, %unsqueeze_421), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_208 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_228, %unsqueeze_423), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_52 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_208,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/uz/cuztlvtnpmsfgc3lhicly6fjketxsxbbcpcx4yuek7lgedhuy2gm.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_54, batch_norm_53, xout_53], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_53 => add_210, mul_230, mul_231, sub_151
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_54 => convolution_54
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_53 => relu_53
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_54 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_52, %primals_322, %primals_323, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_151 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_54, %unsqueeze_425), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_230 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_151, %unsqueeze_427), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_231 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_230, %unsqueeze_429), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_210 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_231, %unsqueeze_431), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_53 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_210,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/te/cterkwxbs2p6ivwxu6pxrbvf43mskkrj7cfloxapyxjl6xvd3652.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_57], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_57 => convolution_57
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_57 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_55, %primals_340, %primals_341, [1, 1], [8, 8], [8, 8], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_85 = async_compile.triton('triton_poi_fused_convolution_85', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_85', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_85(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jq/cjqpyffgwbduc6btfnay4y2x2y5tps5bibyfca7ltrdzwgggf42k.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_40], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_40 => cat_21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_21 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_56, %relu_55], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_86 = async_compile.triton('triton_poi_fused_cat_86', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_86', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_86(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 256, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (256*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 512, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (256*x1 + ((-256) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/r6/cr6wg72mr5fklln334qmj53ibkokmvnkd4bwwfa7sgytqpvu2zix.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_60, batch_norm_59, xout_59, hx6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_59 => add_222, mul_248, mul_249, sub_157
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_60 => convolution_60
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx6 => add_223
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_59 => relu_59
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_60 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_23, %primals_358, %primals_359, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_157 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_60, %unsqueeze_473), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_248 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_157, %unsqueeze_475), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_249 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_248, %unsqueeze_477), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_222 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_249, %unsqueeze_479), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_59 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_222,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_223 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_59, %relu_52), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp21, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ow/cowtxvt4bzcohqrg4cwcihar3bifphb7otlnx3tuff27eafdceh7.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_14], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_14 => _unsafe_index_56, _unsafe_index_57, add_228, mul_252, sub_161
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_56 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_223, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_57 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_223, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_161 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_57, %_unsafe_index_56), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_252 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_161, %clamp_max_2), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_228 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_56, %mul_252), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_88 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_88', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_88', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_88(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mc/cmckloig7mkrvttumjufsnusoejqoe2ymplsgmlyk57q3klnj2tn.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_43], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_43 => cat_24
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_24 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_230, %add_206], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_89 = async_compile.triton('triton_poi_fused_cat_89', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_89', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_89(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 1024)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 512, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 2048*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (512*x3 + (x2)), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 1024, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-512) + x2) + 2048*x3), tmp30, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sq/csqqn5oq4tptcrflnblkfkow3smkzod7tjtaoarnwscdkgs7dhil.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_15], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_15 => _unsafe_index_60, _unsafe_index_61, add_252, mul_281, sub_176
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_60 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_247, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_61 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_247, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_176 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_61, %_unsafe_index_60), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_281 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_176, %clamp_max_6), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_252 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_60, %mul_281), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_90 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_90', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_90', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_90(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ac/cacadiy36ql5utfmrhwbgsdxqe2xgtatvjoiumxmpeyapchuk3c7.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_47], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_47 => cat_28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_28 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_254, %add_189], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_91 = async_compile.triton('triton_poi_fused_cat_91', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_91', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_91(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 1024)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 512, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 8192*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 1024, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-512) + x2) + 8192*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7n/c7ngc6rurngorexwcscqy24tplaeeagcvzzoknyoitz6fh34glyd.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_69, batch_norm_68, xout_68], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_68 => add_256, mul_285, mul_286, sub_180
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_69 => convolution_69
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_68 => relu_68
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_69 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_28, %primals_412, %primals_413, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_180 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_69, %unsqueeze_545), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_285 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_180, %unsqueeze_547), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_286 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_285, %unsqueeze_549), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_256 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_286, %unsqueeze_551), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_68 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_256,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7u/c7uuq5mt2ue2sas5opo3tjjpveefug2qfl6652g36zth66suhb5g.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_76, batch_norm_75, xout_75, hx4d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_75 => add_284, mul_316, mul_317, sub_201
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_76 => convolution_76
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx4d => add_285
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_75 => relu_75
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_76 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_31, %primals_454, %primals_455, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_201 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_76, %unsqueeze_601), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_316 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_201, %unsqueeze_603), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_317 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_316, %unsqueeze_605), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_284 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_317, %unsqueeze_607), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_75 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_284,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_285 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_75, %relu_68), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/r5/cr5dt5ddfparo3pswkcvvtfzxb3zuofgqrambfacpvljsmvvpzgd.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_18], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_18 => _unsafe_index_72, _unsafe_index_73, add_290, mul_320, sub_205
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_72 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_285, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_73 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_285, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_205 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_73, %_unsafe_index_72), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_320 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_205, %clamp_max_10), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_290 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_72, %mul_320), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_94 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_94', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_94', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_94(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/u2/cu2nbpgfyii777z7fqeyzsmuc6kq32uqtggwnoh3emfnoovlrn42.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_53], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_53 => cat_32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_32 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_292, %add_158], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_95 = async_compile.triton('triton_poi_fused_cat_95', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_95', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_95(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 512)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 256, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 16384*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 512, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-256) + x2) + 16384*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/za/czawambcozfqvd5ttqz25dv73e54fpmn2fo3b4ztlqbljkyyabey.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_77, batch_norm_76, xout_76], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_76 => add_294, mul_324, mul_325, sub_209
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_77 => convolution_77
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_76 => relu_76
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_77 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_32, %primals_460, %primals_461, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_209 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_77, %unsqueeze_609), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_324 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_209, %unsqueeze_611), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_325 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_324, %unsqueeze_613), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_294 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_325, %unsqueeze_615), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_76 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_294,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/do/cdo663hmrcaid557kmkht4cc36pfuiyxmiwqhdiytghxwvtacf6z.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_86, batch_norm_85, xout_85, hx3d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_85 => add_333, mul_366, mul_367, sub_239
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_86 => convolution_86
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx3d => add_334
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_85 => relu_85
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_86 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_36, %primals_514, %primals_515, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_239 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_86, %unsqueeze_681), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_366 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_239, %unsqueeze_683), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_367 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_366, %unsqueeze_685), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_333 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_367, %unsqueeze_687), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_85 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_333,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_334 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_85, %relu_76), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ez/cezbt6oidldwae4nsiks7z4mgfftcmud6vcxwxnikbn3fe3s2eiy.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_22], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_22 => _unsafe_index_88, _unsafe_index_89, add_339, mul_370, sub_243
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_88 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_334, [None, None, %convert_element_type_37, %convert_element_type_39]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_89 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_334, [None, None, %convert_element_type_37, %clamp_max_13]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_243 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_89, %_unsafe_index_88), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_370 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_243, %clamp_max_14), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_339 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_88, %mul_370), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_98 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_98', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_98', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_98(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/z7/cz74gctem4yluwu3isr6f3azaiiarp7ruvdql6ozvrlgvd5bxw3s.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_61], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_61 => cat_37
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_37 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_341, %add_116], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_99 = async_compile.triton('triton_poi_fused_cat_99', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_99', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_99(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 256) % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 256*(x2) + 32768*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 8, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 8*tmp10 + 64*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 8*tmp10 + 64*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 256, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 256*((-128) + x2) + 32768*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xl/cxlwatlvdgwwd32sz6rwigzvjfqzp5zbos5uemi5zdd4xpsnnnsz.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_87, batch_norm_86, xout_86], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_86 => add_343, mul_374, mul_375, sub_247
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_87 => convolution_87
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_86 => relu_86
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_87 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_37, %primals_520, %primals_521, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_247 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_87, %unsqueeze_689), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_374 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_247, %unsqueeze_691), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_375 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_374, %unsqueeze_693), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_343 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_375, %unsqueeze_695), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_86 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_343,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vo/cvoim6mrpwyax5fdmfktpoftii5azib6q2sjlqe6zmmnbi27yee6.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_98, batch_norm_97, xout_97, hx2d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_97 => add_393, mul_427, mul_428, sub_286
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_98 => convolution_98
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx2d => add_394
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_97 => relu_97
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_98 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_42, %primals_586, %primals_587, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_286 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_98, %unsqueeze_777), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_427 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_286, %unsqueeze_779), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_428 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_427, %unsqueeze_781), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_393 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_428, %unsqueeze_783), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_97 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_393,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_394 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_97, %relu_86), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sm/csmh27hfzbxzsrdocsurozs3zrbmlicpeuhl5dvepy3efionxtxv.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_27], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_27 => _unsafe_index_108, _unsafe_index_109, add_399, mul_431, sub_290
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_108 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_394, [None, None, %convert_element_type_43, %convert_element_type_45]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_109 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_394, [None, None, %convert_element_type_43, %clamp_max_17]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_290 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_109, %_unsafe_index_108), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_431 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_290, %clamp_max_18), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_399 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_108, %mul_431), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_102 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_102', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_102', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_102(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dx/cdxc4o3tbo2lnhpprrzer2w4hdcssfuvn4w3q3hdm257frvbltpb.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_71], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_71 => cat_43
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_43 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_401, %add_63], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_103 = async_compile.triton('triton_poi_fused_cat_103', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_103', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_103(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 1024) % 128)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 1024)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 1024*(x2) + 65536*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 16, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 16*tmp10 + 256*(x2) + 16384*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 16*tmp10 + 256*(x2) + 16384*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 128, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 1024*((-64) + x2) + 65536*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ib/cib2a4nl2kp5blhle7utvozbkoutzgiwy3qgr4dfzcfnhrb57fkf.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_100, batch_norm_99, xout_99], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_99 => add_405, mul_438, mul_439, sub_295
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_100 => convolution_100
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_99 => relu_99
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_100 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_98, %primals_598, %primals_599, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_295 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_100, %unsqueeze_793), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_438 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_295, %unsqueeze_795), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_439 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_438, %unsqueeze_797), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_405 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_439, %unsqueeze_799), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_99 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_405,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/x5/cx5spaym3yd4hbtwbhzjfnbgt6rdmmzfkupn4j5tpkydchg5c6j6.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_72], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_72 => getitem_56, getitem_57
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_56 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_28, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_57 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_28, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_105 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_105', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_105', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_105(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yv/cyvewtlmmwy6llhzhmvaz3zx5jlxohjy5233d3oiz7aqgtitkkux.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_101, batch_norm_100, xout_100], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_100 => add_407, mul_441, mul_442, sub_296
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_101 => convolution_101
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_100 => relu_100
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_101 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_56, %primals_604, %primals_605, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_296 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_101, %unsqueeze_801), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_441 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_296, %unsqueeze_803), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_442 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_441, %unsqueeze_805), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_407 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_442, %unsqueeze_807), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_100 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_407,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/b6/cb6qzybl7sqrou3pakbagoskarqvukytibw5phfvirvj3x43cjqe.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_73], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_73 => getitem_58, getitem_59
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_58 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_29, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_59 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_29, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_107 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_107', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_107', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_107(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/s3/cs3c5yadwc4lfhzi6acdrvjxoz6odivcakwwmgp5q4ovdiygdeen.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_102, batch_norm_101, xout_101], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_101 => add_409, mul_444, mul_445, sub_297
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_102 => convolution_102
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_101 => relu_101
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_102 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_58, %primals_610, %primals_611, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_297 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_102, %unsqueeze_809), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_444 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_297, %unsqueeze_811), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_445 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_444, %unsqueeze_813), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_409 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_445, %unsqueeze_815), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_101 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_409,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xt/cxtykhece7d4hwkyd5e2qi25ff7fwbda2dzcglvyoema2cqriovu.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_74], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_74 => getitem_60, getitem_61
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_60 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_30, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_61 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_30, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_109 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_109', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_109', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_109(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ga/cgablznykyrpieim3ycde46igievgk2d25uhe545da4777s4zicr.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_103, batch_norm_102, xout_102], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_102 => add_411, mul_447, mul_448, sub_298
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_103 => convolution_103
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_102 => relu_102
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_103 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_60, %primals_616, %primals_617, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_298 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_103, %unsqueeze_817), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_447 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_298, %unsqueeze_819), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_448 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_447, %unsqueeze_821), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_411 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_448, %unsqueeze_823), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_102 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_411,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/to/ctoetwdrio5vyg7gydmb7mff54wpzndlq72jlzpaijaqower2glg.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_75], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_75 => getitem_62, getitem_63
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_62 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_31, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_63 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_31, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_111 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_111', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_111', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_111(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qm/cqmonjsoyybfabwiaze5pc2cbe6boimjoutjn4y56553ilfaop5k.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_104, batch_norm_103, xout_103], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_103 => add_413, mul_450, mul_451, sub_299
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_104 => convolution_104
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_103 => relu_103
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_104 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_62, %primals_622, %primals_623, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_299 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_104, %unsqueeze_825), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_450 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_299, %unsqueeze_827), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_451 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_450, %unsqueeze_829), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_413 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_451, %unsqueeze_831), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_103 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_413,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2h/c2hhu7evwklmnmrgpiczixql3pncl3zhbodmpbfiawatskvde4en.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_76], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_76 => getitem_64, getitem_65
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_64 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_32, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_65 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_32, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_113 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_113', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_113', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_113(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ea/ceahagj5yuy4n43ii3lcgoiitfnhoyy3izo5e7uuudqrluepzay3.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_105, batch_norm_104, xout_104], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_104 => add_415, mul_453, mul_454, sub_300
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_105 => convolution_105
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_104 => relu_104
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_105 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_64, %primals_628, %primals_629, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_300 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_105, %unsqueeze_833), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_453 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_300, %unsqueeze_835), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_454 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_453, %unsqueeze_837), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_415 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_454, %unsqueeze_839), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_104 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_415,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vo/cvoidv53r7op5l7jaaf23wtmxslujsv425ezovqnj5pgjwc34ykj.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_106], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_106 => convolution_106
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_106 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_104, %primals_634, %primals_635, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_115 = async_compile.triton('triton_poi_fused_convolution_115', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_115', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_115(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5s/c5sdj7gbnczcm4p5y5s5jbcvfixansb2h2rwyideg6dwn4qjwdzc.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_77], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_77 => cat_44
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_44 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_105, %relu_104], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_116 = async_compile.triton('triton_poi_fused_cat_116', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_116', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_116(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (16*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (16*x1 + ((-16) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/t2/ct2vdoibxw7tphi4f5nbgzsirbrueny5ygjort4nndiaud5js45k.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_28], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_28 => _unsafe_index_112, _unsafe_index_113, add_424, mul_463, sub_306
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_112 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_106, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_113 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_106, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_306 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_113, %_unsafe_index_112), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_463 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_306, %clamp_max_2), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_424 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_112, %mul_463), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_117 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_117', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_117', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_117(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fc/cfcuyonmfdqa7x6kte7ncyeqopon5jhgkdccmgaipen3wj2ohx5v.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_78], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_78 => cat_45
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_45 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_426, %relu_103], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_118 = async_compile.triton('triton_poi_fused_cat_118', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_118', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_118(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 128
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 64*x3), tmp4 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (16*x3 + (x2)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-16) + x2) + 64*x3), tmp30 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pg/cpgf654z32gjsipbpjmxbn5o5ebaembv4uudg3rm7gfn3f2k2bjt.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_29], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_29 => _unsafe_index_116, _unsafe_index_117, add_433, mul_471, sub_314
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_116 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_107, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_117 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_107, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_314 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_117, %_unsafe_index_116), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_471 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_314, %clamp_max_6), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_433 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_116, %mul_471), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_119 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_119', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_119', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_119(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fk/cfkcn3tpbpyyjwb24xgl7jkzog5xa4rhphmihmk6lrgomvmfp2xp.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_79], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_79 => cat_46
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_46 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_435, %relu_102], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_120 = async_compile.triton('triton_poi_fused_cat_120', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_120', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_120(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 512
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 256*x3), tmp4 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 64*x3), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 64*x3), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-16) + x2) + 256*x3), tmp31 & xmask, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3d/c3duare2mhd6l3pk5gkovqnl5hepyjbh76mazymqo5uzaxcw3lqp.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_30], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_30 => _unsafe_index_120, _unsafe_index_121, add_442, mul_479, sub_322
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_120 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_108, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_121 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_108, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_322 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_121, %_unsafe_index_120), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_479 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_322, %clamp_max_10), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_442 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_120, %mul_479), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_121 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_121', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_121', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_121(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xn/cxnoh53bznxai55m2tsinm2cf4exmef3c5i46hy47vg4bmkjwtsu.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_80], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_80 => cat_47
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_47 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_444, %relu_101], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_122 = async_compile.triton('triton_poi_fused_cat_122', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_122', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_122(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 2048
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 1024*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-16) + x2) + 1024*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ra/cragqqzzr4bkptao5x5cdhfemlgdhtyqgkfqvcshm2pep7mfbsnw.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_31], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_31 => _unsafe_index_124, _unsafe_index_125, add_451, mul_487, sub_330
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_124 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_109, [None, None, %convert_element_type_37, %convert_element_type_39]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_125 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_109, [None, None, %convert_element_type_37, %clamp_max_13]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_330 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_125, %_unsafe_index_124), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_487 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_330, %clamp_max_14), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_451 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_124, %mul_487), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_123 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_123', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_123', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_123(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 256
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4k/c4k2qvzjx6lrqhfttd3skwsyewjm325afkkd2ueqdi7uiiamfo3f.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_81], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_81 => cat_48
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_48 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_453, %relu_100], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_124 = async_compile.triton('triton_poi_fused_cat_124', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_124', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_124(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 256) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 8192
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 256)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 256*(x2) + 4096*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 8, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 8*tmp10 + 64*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 8*tmp10 + 64*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 256*((-16) + x2) + 4096*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vx/cvxpcifgroy43sopuvg3usjkgo4uy74m224u55rj4jcnmtz4zm7k.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_32], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_32 => _unsafe_index_128, _unsafe_index_129, add_460, mul_495, sub_338
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_128 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_110, [None, None, %convert_element_type_43, %convert_element_type_45]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_129 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_110, [None, None, %convert_element_type_43, %clamp_max_17]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_338 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_129, %_unsafe_index_128), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_495 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_338, %clamp_max_18), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_460 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_128, %mul_495), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_125 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_125', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_125', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_125(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 1024
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gv/cgvwhb5vinranxn5mpmpxup2zymuqgkvvgerb327y65muqhu44xa.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_82], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_82 => cat_49
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_49 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_462, %relu_99], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_126 = async_compile.triton('triton_poi_fused_cat_126', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_126', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_126(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 1024) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32768
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 1024)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 1024*(x2) + 16384*x3), tmp4, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 16, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 16*tmp10 + 256*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 16*tmp10 + 256*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 1024*((-16) + x2) + 16384*x3), tmp31, other=0.0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/mz/cmzspsfl53lkq62tmsqmf6sckigextfto7f3tvsimjyfvv4dj2nn.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => convert_element_type_357
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_357 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_66, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_127 = async_compile.triton('triton_poi_fused__to_copy_127', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_127', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_127(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/es/cesdunyfxafe6zyboivt3qaqikghgwtzxqvnjew5rctul5es34we.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_467, clamp_max_132
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_467 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_357, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_132 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_467, 31), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_128 = async_compile.triton('triton_poi_fused_add_clamp_128', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_128', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_128(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 31, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/k3/ck3bnkb5r4b2tteb2e7zgyoiqnhnho5l5k4secwfhb4tj7mpdctj.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, clamp_max_134, clamp_min_132, clamp_min_134, convert_element_type_356, iota_66, mul_501, sub_343, sub_345
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_501 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_343 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_501, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_132 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_343, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_345 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_132, %convert_element_type_359), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_134 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_345, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_134 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_134, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2w/c2wrr6zlq74z5x4unjhnaujit5k3aeh2zd62av6semagglqfpfau.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d1, src_33, sigmoid], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d1 => convolution_113
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid => sigmoid
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => _unsafe_index_132, _unsafe_index_133, _unsafe_index_134, _unsafe_index_135, add_470, add_471, add_472, mul_503, mul_504, mul_505, sub_346, sub_347, sub_349
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_113 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_465, %primals_676, %primals_677, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_132 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %convert_element_type_357, %convert_element_type_359]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_133 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %convert_element_type_357, %clamp_max_133]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_134 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %clamp_max_132, %convert_element_type_359]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_135 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %clamp_max_132, %clamp_max_133]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_346 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_133, %_unsafe_index_132), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_503 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_346, %clamp_max_134), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_470 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_132, %mul_503), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_347 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_135, %_unsafe_index_134), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_504 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_347, %clamp_max_134), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_471 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_134, %mul_504), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_349 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_471, %add_470), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_505 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_349, %clamp_max_135), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_472 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_470, %mul_505), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_472,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 32, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 32*tmp4 + 1024*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 32*tmp4 + 1024*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 32*tmp26 + 1024*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 32*tmp26 + 1024*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rb/crbuyax4embruyhcvq5hy2rvnj26umvcres3sa6ocoep42hgkfb2.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => convert_element_type_361
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_361 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_68, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_131 = async_compile.triton('triton_poi_fused__to_copy_131', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_131', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_131(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kh/ckhtyudy7v45qsas6xldlwk6nl222qyqz3bu7ukb4ul4ffxjmalf.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => add_474, clamp_max_136
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_474 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_361, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_136 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_474, 15), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_132 = async_compile.triton('triton_poi_fused_add_clamp_132', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_132', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_132(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 15, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2o/c2o3uak3a7w2nbijof52m6aqhvbn3niieuwba3sch3h6gorqbq5r.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_34], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => clamp_max_138, clamp_min_136, clamp_min_138, mul_506, sub_350, sub_352
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_506 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.25), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_350 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_506, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_136 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_350, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_352 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_136, %convert_element_type_363), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_138 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_352, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_138 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_138, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.25
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yf/cyfvaljkvh73e6dbfegqyqohlf3og2ljubkvgmucr6z6or3fefkl.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d2, src_34, sigmoid_1], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d2 => convolution_114
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_1 => sigmoid_1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => _unsafe_index_136, _unsafe_index_137, _unsafe_index_138, _unsafe_index_139, add_477, add_478, add_479, mul_508, mul_509, mul_510, sub_353, sub_354, sub_356
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_114 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_394, %primals_678, %primals_679, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_136 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %convert_element_type_361, %convert_element_type_363]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_137 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %convert_element_type_361, %clamp_max_137]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_138 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %clamp_max_136, %convert_element_type_363]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_139 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %clamp_max_136, %clamp_max_137]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_353 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_137, %_unsafe_index_136), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_508 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_353, %clamp_max_138), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_477 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_136, %mul_508), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_354 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_139, %_unsafe_index_138), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_509 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_354, %clamp_max_138), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_478 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_138, %mul_509), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_356 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_478, %add_477), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_510 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_356, %clamp_max_139), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_479 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_477, %mul_510), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_1 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_479,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 16*tmp26 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 16*tmp26 + 256*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ta/cta46pwyza5zmhitgcwvyy5lkzwf5chm3c4ssita7ddpppru27xh.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => convert_element_type_365
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_365 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_70, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_135 = async_compile.triton('triton_poi_fused__to_copy_135', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_135', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_135(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.125
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fl/cflwhyulkpdpbxbqp2ffxmzppmh2xayg4p5vc7c4oco2huznerxc.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => add_481, clamp_max_140
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_481 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_365, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_140 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_481, 7), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_136 = async_compile.triton('triton_poi_fused_add_clamp_136', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_136', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_136(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.125
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 7, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bj/cbjmo33rd66p5pcj3hbsvbj55aqt2lcw2fh7hximhdhvhnyjiucl.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_35], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => clamp_max_142, clamp_min_140, clamp_min_142, mul_511, sub_357, sub_359
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_511 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.125), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_357 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_511, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_140 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_357, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_359 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_140, %convert_element_type_367), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_142 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_359, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_142 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_142, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.125
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/di/cdifariefpipllqr54rwrlui44h5ntqm7dpnqduxywwwjkclm47d.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d3, src_35, sigmoid_2], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d3 => convolution_115
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_2 => sigmoid_2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => _unsafe_index_140, _unsafe_index_141, _unsafe_index_142, _unsafe_index_143, add_484, add_485, add_486, mul_513, mul_514, mul_515, sub_360, sub_361, sub_363
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_115 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_334, %primals_680, %primals_681, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_140 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %convert_element_type_365, %convert_element_type_367]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_141 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %convert_element_type_365, %clamp_max_141]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_142 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %clamp_max_140, %convert_element_type_367]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_143 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %clamp_max_140, %clamp_max_141]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_360 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_141, %_unsafe_index_140), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_513 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_360, %clamp_max_142), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_484 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_140, %mul_513), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_361 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_143, %_unsafe_index_142), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_514 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_361, %clamp_max_142), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_485 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_142, %mul_514), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_363 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_485, %add_484), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_515 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_363, %clamp_max_143), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_486 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_484, %mul_515), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_2 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_486,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 8*tmp26 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 8*tmp26 + 64*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/c2/cc2voak6ki7wtbvlgzdx4ry4a5aeiiyymq7kiziptxdau4ecsaef.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => convert_element_type_369
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_369 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_72, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_139 = async_compile.triton('triton_poi_fused__to_copy_139', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_139', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_139(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.0625
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zs/czsuirdgops6fhvgbkhacol6tmsikw5iwvk3haevmbr2yyqrzzfi.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => add_488, clamp_max_144
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_488 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_369, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_144 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_488, 3), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_140 = async_compile.triton('triton_poi_fused_add_clamp_140', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_140', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_140(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.0625
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 3, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qj/cqjzdq4y3lz3mc73hw2gjjoqjcwghmak6sbbuxghkoocb4nivocz.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_36], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => clamp_max_146, clamp_min_144, clamp_min_146, mul_516, sub_364, sub_366
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_516 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.0625), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_364 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_516, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_144 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_364, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_366 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_144, %convert_element_type_371), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_146 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_366, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_146 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_146, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.0625
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/se/cseo6slpldphky2ki7a3ymnj73lxs3mroyx2c2ynecbzomj6fhwv.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d4, src_36, sigmoid_3], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d4 => convolution_116
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_3 => sigmoid_3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => _unsafe_index_144, _unsafe_index_145, _unsafe_index_146, _unsafe_index_147, add_491, add_492, add_493, mul_518, mul_519, mul_520, sub_367, sub_368, sub_370
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_116 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_285, %primals_682, %primals_683, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_144 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %convert_element_type_369, %convert_element_type_371]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_145 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %convert_element_type_369, %clamp_max_145]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_146 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %clamp_max_144, %convert_element_type_371]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_147 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %clamp_max_144, %clamp_max_145]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_367 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_145, %_unsafe_index_144), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_518 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_367, %clamp_max_146), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_491 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_144, %mul_518), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_368 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_147, %_unsafe_index_146), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_519 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_368, %clamp_max_146), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_492 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_146, %mul_519), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_370 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_492, %add_491), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_520 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_370, %clamp_max_147), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_493 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_491, %mul_520), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_3 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_493,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 4*tmp26 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 4*tmp26 + 16*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sc/cscz26acw63oloaf5hfmsskmpl3xxpbh5rx3zasbcgbrjiwxxgox.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => convert_element_type_373
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_373 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_74, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_143 = async_compile.triton('triton_poi_fused__to_copy_143', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_143', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_143(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.03125
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bg/cbgfpt44tadejxrekypvmefx3boiowbfaqxggridn35ztwxjpahe.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => add_495, clamp_max_148
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_495 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_373, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_148 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_495, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_144 = async_compile.triton('triton_poi_fused_add_clamp_144', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_144', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_144(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.03125
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp11, tmp10)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vu/cvufgz4mwb4lh5c7skothlo2ussz5cokv4vb6hwynookr6dohabb.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_37], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => clamp_max_150, clamp_min_148, clamp_min_150, mul_521, sub_371, sub_373
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_521 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.03125), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_371 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_521, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_148 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_371, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_373 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_148, %convert_element_type_375), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_150 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_373, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_150 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_150, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.03125
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/w6/cw6n3puovd4ohclbhawhrkr74fdeolopuuw6ynktpld73blofwhu.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d5, src_37, sigmoid_4], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d5 => convolution_117
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_4 => sigmoid_4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => _unsafe_index_148, _unsafe_index_149, _unsafe_index_150, _unsafe_index_151, add_498, add_499, add_500, mul_523, mul_524, mul_525, sub_374, sub_375, sub_377
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_117 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_247, %primals_684, %primals_685, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_148 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %convert_element_type_373, %convert_element_type_375]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_149 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %convert_element_type_373, %clamp_max_149]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_150 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %clamp_max_148, %convert_element_type_375]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_151 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %clamp_max_148, %clamp_max_149]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_374 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_149, %_unsafe_index_148), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_523 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_374, %clamp_max_150), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_498 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_148, %mul_523), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_375 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_151, %_unsafe_index_150), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_524 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_375, %clamp_max_150), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_499 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_150, %mul_524), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_377 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_499, %add_498), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_525 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_377, %clamp_max_151), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_500 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_498, %mul_525), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_4 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_500,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 2*tmp26 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 2*tmp26 + 4*x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/u3/cu3e2qehtz7zpmz4vmlvgk77xgli5nnmahaemvio24ste7pcjcqf.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => convert_element_type_377
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_377 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_76, torch.int64), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_147 = async_compile.triton('triton_poi_fused__to_copy_147', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_147', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_147(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.015625
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/br/cbrapz2ueulb3drb7rvosh77nrpnq5ton4ompp3lrlka2vbljk3y.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => add_502, clamp_max_152
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_502 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_377, 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_152 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_502, 0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_148 = async_compile.triton('triton_poi_fused_add_clamp_148', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_148', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_148(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.015625
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 0, tl.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/u4/cu4pq3tp225oz5loxuplcmihsjglbctewthe3cup6pzwgx5irms2.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_38], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => clamp_max_154, clamp_min_152, clamp_min_154, mul_526, sub_378, sub_380
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_526 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.015625), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_378 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_526, 0.5), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_152 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_378, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_380 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_152, %convert_element_type_379), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_154 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_380, 0.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_154 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_154, 1.0), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.015625
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qn/cqnwm4oznkom5tlbuhy5omly36d2txez7yggvnvvartxbpw3lzpk.py
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d6, src_38, sigmoid_5], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d6 => convolution_118
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_5 => sigmoid_5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => _unsafe_index_152, _unsafe_index_153, _unsafe_index_154, _unsafe_index_155, add_505, add_506, add_507, mul_528, mul_529, mul_530, sub_381, sub_382, sub_384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_118 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_223, %primals_686, %primals_687, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_152 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %convert_element_type_377, %convert_element_type_379]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_153 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %convert_element_type_377, %clamp_max_153]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_154 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %clamp_max_152, %convert_element_type_379]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_155 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %clamp_max_152, %clamp_max_153]), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_381 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_153, %_unsafe_index_152), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_528 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_381, %clamp_max_154), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_505 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_152, %mul_528), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_382 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_155, %_unsafe_index_154), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_529 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_382, %clamp_max_154), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_506 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_154, %mul_529), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_384 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_506, %add_505), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_530 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_384, %clamp_max_155), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_507 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_505, %mul_530), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_5 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_507,), kwargs = {})
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150', '''
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp12 - tmp12
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp17 * tmp18
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp12 + tmp19
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp21 + tmp1
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 < 0
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp23, tmp22, tmp21)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp20 - tmp20
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp20 + tmp27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.sigmoid(tmp28)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp29, None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687 = args
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_1, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_2, (64, 3, 3, 3), (27, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_3, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_4, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_5, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_6, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_7, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_9, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_10, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_11, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_12, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_13, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_14, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_15, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_16, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_17, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_18, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_19, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_20, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_21, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_22, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_23, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_24, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_25, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_26, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_27, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_28, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_29, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_30, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_31, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_32, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_33, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_34, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_35, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_36, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_37, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_38, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_39, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_40, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_41, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_42, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_43, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_44, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_45, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_46, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_47, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_48, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_49, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_50, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_51, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_52, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_53, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_54, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_55, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_56, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_57, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_58, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_59, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_60, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_61, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_62, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_63, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_64, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_65, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_66, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_67, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_68, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_69, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_70, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_71, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_72, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_73, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_74, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_75, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_76, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_77, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_78, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_79, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_80, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_81, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_82, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_83, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_84, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_85, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_86, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_87, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_88, (128, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_89, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_90, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_91, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_92, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_93, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_94, (32, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_95, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_96, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_97, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_98, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_99, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_100, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_101, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_102, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_103, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_104, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_105, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_106, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_107, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_108, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_109, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_110, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_111, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_112, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_113, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_114, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_115, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_116, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_117, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_118, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_119, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_120, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_121, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_122, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_123, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_124, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_125, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_126, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_127, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_128, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_129, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_130, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_131, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_132, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_133, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_134, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_135, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_136, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_137, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_138, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_139, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_140, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_141, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_142, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_143, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_144, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_145, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_146, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_147, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_148, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_149, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_150, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_151, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_152, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_153, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_154, (128, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_155, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_156, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_157, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_158, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_159, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_160, (256, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_161, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_162, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_163, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_164, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_165, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_166, (64, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_167, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_168, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_169, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_170, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_171, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_172, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_173, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_174, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_175, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_176, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_177, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_178, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_179, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_180, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_181, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_182, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_183, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_184, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_185, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_186, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_187, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_188, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_189, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_190, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_191, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_192, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_193, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_194, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_195, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_196, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_197, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_198, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_199, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_200, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_201, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_202, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_203, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_204, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_205, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_206, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_207, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_208, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_209, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_210, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_211, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_212, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_213, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_214, (256, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_215, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_216, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_217, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_218, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_219, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_220, (512, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_221, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_222, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_223, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_224, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_225, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_226, (128, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_227, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_228, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_229, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_230, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_231, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_232, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_233, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_234, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_235, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_236, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_237, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_238, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_239, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_240, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_241, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_242, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_243, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_244, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_245, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_246, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_247, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_248, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_249, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_250, (128, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_251, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_252, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_253, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_254, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_255, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_256, (128, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_257, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_258, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_259, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_260, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_261, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_262, (512, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_263, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_264, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_265, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_266, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_267, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_268, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_269, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_270, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_271, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_272, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_273, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_274, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_275, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_276, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_277, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_278, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_279, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_280, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_281, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_282, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_283, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_284, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_285, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_286, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_287, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_288, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_289, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_290, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_291, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_292, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_293, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_294, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_295, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_296, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_297, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_298, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_299, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_300, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_301, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_302, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_303, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_304, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_305, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_306, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_307, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_308, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_309, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_310, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_311, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_312, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_313, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_314, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_315, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_316, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_317, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_318, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_319, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_320, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_321, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_322, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_323, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_324, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_325, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_326, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_327, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_328, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_329, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_330, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_331, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_332, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_333, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_334, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_335, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_336, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_337, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_338, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_339, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_340, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_341, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_342, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_343, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_344, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_345, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_346, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_347, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_348, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_349, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_350, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_351, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_352, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_353, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_354, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_355, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_356, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_357, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_358, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_359, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_360, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_361, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_362, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_363, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_364, (512, 1024, 3, 3), (9216, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_365, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_366, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_367, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_368, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_369, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_370, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_371, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_372, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_373, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_374, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_375, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_376, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_377, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_378, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_379, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_380, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_381, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_382, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_383, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_384, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_385, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_386, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_387, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_388, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_389, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_390, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_391, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_392, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_393, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_394, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_395, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_396, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_397, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_398, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_399, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_400, (256, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_401, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_402, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_403, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_404, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_405, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_406, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_407, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_408, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_409, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_410, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_411, (512, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_412, (256, 1024, 3, 3), (9216, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_413, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_414, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_415, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_416, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_417, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_418, (128, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_419, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_420, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_421, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_422, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_423, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_424, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_425, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_426, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_427, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_428, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_429, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_430, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_431, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_432, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_433, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_434, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_435, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_436, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_437, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_438, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_439, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_440, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_441, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_442, (128, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_443, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_444, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_445, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_446, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_447, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_448, (128, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_449, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_450, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_451, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_452, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_453, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_454, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_455, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_456, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_457, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_458, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_459, (256, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_460, (128, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_461, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_462, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_463, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_464, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_465, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_466, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_467, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_468, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_469, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_470, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_471, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_472, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_473, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_474, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_475, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_476, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_477, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_478, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_479, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_480, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_481, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_482, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_483, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_484, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_485, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_486, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_487, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_488, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_489, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_490, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_491, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_492, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_493, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_494, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_495, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_496, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_497, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_498, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_499, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_500, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_501, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_502, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_503, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_504, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_505, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_506, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_507, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_508, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_509, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_510, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_511, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_512, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_513, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_514, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_515, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_516, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_517, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_518, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_519, (128, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_520, (64, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_521, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_522, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_523, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_524, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_525, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_526, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_527, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_528, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_529, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_530, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_531, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_532, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_533, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_534, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_535, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_536, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_537, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_538, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_539, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_540, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_541, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_542, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_543, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_544, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_545, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_546, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_547, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_548, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_549, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_550, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_551, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_552, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_553, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_554, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_555, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_556, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_557, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_558, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_559, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_560, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_561, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_562, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_563, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_564, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_565, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_566, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_567, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_568, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_569, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_570, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_571, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_572, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_573, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_574, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_575, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_576, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_577, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_578, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_579, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_580, (32, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_581, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_582, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_583, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_584, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_585, (32, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_586, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_587, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_588, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_589, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_590, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_591, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_592, (64, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_593, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_594, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_595, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_596, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_597, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_598, (16, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_599, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_600, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_601, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_602, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_603, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_604, (16, 16, 3, 3), (144, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_605, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_606, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_607, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_608, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_609, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_610, (16, 16, 3, 3), (144, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_611, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_612, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_613, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_614, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_615, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_616, (16, 16, 3, 3), (144, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_617, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_618, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_619, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_620, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_621, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_622, (16, 16, 3, 3), (144, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_623, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_624, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_625, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_626, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_627, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_628, (16, 16, 3, 3), (144, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_629, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_630, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_631, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_632, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_633, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_634, (16, 16, 3, 3), (144, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_635, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_636, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_637, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_638, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_639, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_640, (16, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_641, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_642, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_643, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_644, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_645, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_646, (16, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_647, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_648, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_649, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_650, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_651, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_652, (16, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_653, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_654, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_655, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_656, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_657, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_658, (16, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_659, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_660, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_661, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_662, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_663, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_664, (16, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_665, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_666, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_667, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_668, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_669, (16, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_670, (64, 32, 3, 3), (288, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_671, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_672, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_673, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_674, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_675, (64, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_676, (1, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_677, (1, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_678, (1, 64, 3, 3), (576, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_679, (1, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_680, (1, 128, 3, 3), (1152, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_681, (1, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_682, (1, 256, 3, 3), (2304, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_683, (1, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_684, (1, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_685, (1, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_686, (1, 512, 3, 3), (4608, 9, 3, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_687, (1, ), (1, ))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hxin], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = extern_kernels.convolution(primals_1, primals_2, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf0, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = buf0; del buf0  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hxin], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_0.run(buf1, primals_3, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_3
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = extern_kernels.convolution(buf1, primals_4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf2, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = buf2; del buf2  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1, batch_norm, xout], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1.run(buf3, primals_5, primals_6, primals_7, primals_8, primals_9, buf4, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_5
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_9
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = extern_kernels.convolution(buf4, primals_10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf5, (4, 32, 32, 32), (32768, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = buf5; del buf5  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((4, 32, 32, 32), (32768, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2, batch_norm_1, xout_1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2.run(buf6, primals_11, primals_12, primals_13, primals_14, primals_15, buf7, 131072, grid=grid(131072), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_11
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_15
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_3.run(buf7, buf8, buf9, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = extern_kernels.convolution(buf8, primals_16, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf10, (4, 32, 16, 16), (8192, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = buf10; del buf10  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3, batch_norm_2, xout_2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf11, primals_17, primals_18, primals_19, primals_20, primals_21, buf12, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_17
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_21
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_1], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5.run(buf12, buf13, buf14, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = extern_kernels.convolution(buf13, primals_22, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf15, (4, 32, 8, 8), (2048, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = buf15; del buf15  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4, batch_norm_3, xout_3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf16, primals_23, primals_24, primals_25, primals_26, primals_27, buf17, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_23
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_27
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_2], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_7.run(buf17, buf18, buf19, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = extern_kernels.convolution(buf18, primals_28, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf20, (4, 32, 4, 4), (512, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = buf20; del buf20  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5, batch_norm_4, xout_4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf21, primals_29, primals_30, primals_31, primals_32, primals_33, buf22, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_29
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_33
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_3], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_9.run(buf22, buf23, buf24, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf23, primals_34, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 32, 2, 2), (128, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = buf25; del buf25  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6, batch_norm_5, xout_5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf26, primals_35, primals_36, primals_37, primals_38, primals_39, buf27, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_35
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_39
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_4], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_11.run(buf27, buf28, buf29, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = extern_kernels.convolution(buf28, primals_40, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf30, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = buf30; del buf30  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7, batch_norm_6, xout_6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf31, primals_41, primals_42, primals_43, primals_44, primals_45, buf32, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_41
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_45
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = extern_kernels.convolution(buf32, primals_46, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf33, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = buf33; del buf33  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_13.run(buf34, primals_47, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_47
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_5], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_14.run(buf34, primals_48, primals_49, primals_50, primals_51, buf32, buf35, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = extern_kernels.convolution(buf35, primals_52, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf36, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf36; del buf36  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 128, 128), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9, batch_norm_8, xout_8], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf37, primals_53, primals_54, primals_55, primals_56, primals_57, buf38, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_53
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = empty_strided_cuda((2, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_15.run(buf39, 2, grid=grid(2), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = empty_strided_cuda((2, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_16.run(buf40, 2, grid=grid(2), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = empty_strided_cuda((2, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_15.run(buf41, 2, grid=grid(2), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = empty_strided_cuda((2, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_16.run(buf42, 2, grid=grid(2), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = empty_strided_cuda((2, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17.run(buf43, 2, grid=grid(2), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_18.run(buf39, buf41, buf38, buf42, buf43, buf44, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = empty_strided_cuda((2, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17.run(buf45, 2, grid=grid(2), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_6], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_19.run(buf44, buf40, buf41, buf38, buf42, buf43, buf45, buf27, buf46, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = extern_kernels.convolution(buf46, primals_58, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf47, (4, 32, 2, 2), (128, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = buf47; del buf47  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = buf44; del buf44  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10, batch_norm_9, xout_9], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf48, primals_59, primals_60, primals_61, primals_62, primals_63, buf49, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_59
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = empty_strided_cuda((4, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_20.run(buf50, 4, grid=grid(4), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = empty_strided_cuda((4, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_21.run(buf51, 4, grid=grid(4), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = empty_strided_cuda((4, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_20.run(buf52, 4, grid=grid(4), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = empty_strided_cuda((4, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_21.run(buf53, 4, grid=grid(4), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = empty_strided_cuda((4, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22.run(buf54, 4, grid=grid(4), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_23.run(buf50, buf52, buf49, buf53, buf54, buf55, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = empty_strided_cuda((4, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22.run(buf56, 4, grid=grid(4), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_7], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_24.run(buf55, buf51, buf52, buf49, buf53, buf54, buf56, buf22, buf57, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = extern_kernels.convolution(buf57, primals_64, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf58, (4, 32, 4, 4), (512, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf59 = buf58; del buf58  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf60 = buf55; del buf55  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11, batch_norm_10, xout_10], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf59, primals_65, primals_66, primals_67, primals_68, primals_69, buf60, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_65
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf61 = empty_strided_cuda((8, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_25.run(buf61, 8, grid=grid(8), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf62 = empty_strided_cuda((8, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_26.run(buf62, 8, grid=grid(8), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf63 = empty_strided_cuda((8, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_25.run(buf63, 8, grid=grid(8), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf64 = empty_strided_cuda((8, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_26.run(buf64, 8, grid=grid(8), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf65 = empty_strided_cuda((8, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27.run(buf65, 8, grid=grid(8), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf66 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_28.run(buf61, buf63, buf60, buf64, buf65, buf66, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf67 = empty_strided_cuda((8, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27.run(buf67, 8, grid=grid(8), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf68 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_8], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_29.run(buf66, buf62, buf63, buf60, buf64, buf65, buf67, buf17, buf68, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf69 = extern_kernels.convolution(buf68, primals_70, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf69, (4, 32, 8, 8), (2048, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf70 = buf69; del buf69  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf71 = buf66; del buf66  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12, batch_norm_11, xout_11], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf70, primals_71, primals_72, primals_73, primals_74, primals_75, buf71, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_71
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf72 = empty_strided_cuda((16, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_30.run(buf72, 16, grid=grid(16), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf73 = empty_strided_cuda((16, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_31.run(buf73, 16, grid=grid(16), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf74 = empty_strided_cuda((16, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_30.run(buf74, 16, grid=grid(16), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf75 = empty_strided_cuda((16, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_31.run(buf75, 16, grid=grid(16), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf76 = empty_strided_cuda((16, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32.run(buf76, 16, grid=grid(16), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf77 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_33.run(buf72, buf74, buf71, buf75, buf76, buf77, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf78 = empty_strided_cuda((16, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32.run(buf78, 16, grid=grid(16), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf79 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_9], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_34.run(buf77, buf73, buf74, buf71, buf75, buf76, buf78, buf12, buf79, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf80 = extern_kernels.convolution(buf79, primals_76, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf80, (4, 32, 16, 16), (8192, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf81 = buf80; del buf80  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf82 = buf77; del buf77  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13, batch_norm_12, xout_12], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf81, primals_77, primals_78, primals_79, primals_80, primals_81, buf82, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_77
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf83 = empty_strided_cuda((32, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_35.run(buf83, 32, grid=grid(32), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf84 = empty_strided_cuda((32, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_36.run(buf84, 32, grid=grid(32), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf85 = empty_strided_cuda((32, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_35.run(buf85, 32, grid=grid(32), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf86 = empty_strided_cuda((32, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_36.run(buf86, 32, grid=grid(32), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf87 = empty_strided_cuda((32, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37.run(buf87, 32, grid=grid(32), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf88 = empty_strided_cuda((4, 32, 32, 32), (32768, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_38.run(buf83, buf85, buf82, buf86, buf87, buf88, 131072, grid=grid(131072), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf89 = empty_strided_cuda((32, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37.run(buf89, 32, grid=grid(32), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf90 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_10], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_39.run(buf88, buf84, buf85, buf82, buf86, buf87, buf89, buf7, buf90, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf91 = extern_kernels.convolution(buf90, primals_82, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf91, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf92 = buf91; del buf91  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf93 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14, batch_norm_13, xout_13, hx1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40.run(buf92, primals_83, primals_84, primals_85, primals_86, primals_87, buf4, buf93, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_83
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf94 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf95 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_11], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_41.run(buf93, buf94, buf95, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf96 = extern_kernels.convolution(buf94, primals_88, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf96, (4, 128, 16, 16), (32768, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf97 = buf96; del buf96  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf98 = reinterpret_tensor(buf88, (4, 128, 16, 16), (32768, 256, 16, 1), 0); del buf88  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15, batch_norm_14, xout_14], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42.run(buf97, primals_89, primals_90, primals_91, primals_92, primals_93, buf98, 131072, grid=grid(131072), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_89
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_93
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf99 = extern_kernels.convolution(buf98, primals_94, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf99, (4, 32, 16, 16), (8192, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf100 = buf99; del buf99  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf101 = buf82; del buf82  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16, batch_norm_15, xout_15], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf100, primals_95, primals_96, primals_97, primals_98, primals_99, buf101, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_95
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_99
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf102 = buf71; del buf71  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf103 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_12], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5.run(buf101, buf102, buf103, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf104 = extern_kernels.convolution(buf102, primals_100, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf104, (4, 32, 8, 8), (2048, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf105 = buf104; del buf104  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf106 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17, batch_norm_16, xout_16], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf105, primals_101, primals_102, primals_103, primals_104, primals_105, buf106, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_101
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_105
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf107 = buf60; del buf60  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf108 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_13], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_7.run(buf106, buf107, buf108, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_18], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf109 = extern_kernels.convolution(buf107, primals_106, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf109, (4, 32, 4, 4), (512, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf110 = buf109; del buf109  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf111 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_18, batch_norm_17, xout_17], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf110, primals_107, primals_108, primals_109, primals_110, primals_111, buf111, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_107
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_111
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf112 = buf49; del buf49  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf113 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_14], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_9.run(buf111, buf112, buf113, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_19], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf114 = extern_kernels.convolution(buf112, primals_112, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf114, (4, 32, 2, 2), (128, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf115 = buf114; del buf114  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf116 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_19, batch_norm_18, xout_18], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf115, primals_113, primals_114, primals_115, primals_116, primals_117, buf116, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_113
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_117
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf117 = reinterpret_tensor(buf38, (4, 32, 1, 1), (32, 1, 1, 1), 0); del buf38  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf118 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_15], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_11.run(buf116, buf117, buf118, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_20], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf119 = extern_kernels.convolution(buf117, primals_118, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf119, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf120 = buf119; del buf119  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf121 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_20, batch_norm_19, xout_19], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf120, primals_119, primals_120, primals_121, primals_122, primals_123, buf121, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_119
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_123
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_21], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf122 = extern_kernels.convolution(buf121, primals_124, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf122, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf123 = buf122; del buf122  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_21], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_13.run(buf123, primals_125, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_125
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf124 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_16], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_14.run(buf123, primals_126, primals_127, primals_128, primals_129, buf121, buf124, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_22], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf125 = extern_kernels.convolution(buf124, primals_130, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf125, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf126 = buf125; del buf125  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf127 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 128, 128), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_22, batch_norm_21, xout_21], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf126, primals_131, primals_132, primals_133, primals_134, primals_135, buf127, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_131
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf128 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_5], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_18.run(buf39, buf41, buf127, buf42, buf43, buf128, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf129 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_17], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_19.run(buf128, buf40, buf41, buf127, buf42, buf43, buf45, buf116, buf129, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_23], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf130 = extern_kernels.convolution(buf129, primals_136, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf130, (4, 32, 2, 2), (128, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf131 = buf130; del buf130  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf132 = buf128; del buf128  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_23, batch_norm_22, xout_22], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf131, primals_137, primals_138, primals_139, primals_140, primals_141, buf132, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_137
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf133 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_6], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_23.run(buf50, buf52, buf132, buf53, buf54, buf133, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf134 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_18], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_24.run(buf133, buf51, buf52, buf132, buf53, buf54, buf56, buf111, buf134, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_24], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf135 = extern_kernels.convolution(buf134, primals_142, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf135, (4, 32, 4, 4), (512, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf136 = buf135; del buf135  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf137 = buf133; del buf133  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_24, batch_norm_23, xout_23], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf136, primals_143, primals_144, primals_145, primals_146, primals_147, buf137, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_143
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf138 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_7], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_28.run(buf61, buf63, buf137, buf64, buf65, buf138, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf139 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_19], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_29.run(buf138, buf62, buf63, buf137, buf64, buf65, buf67, buf106, buf139, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_25], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf140 = extern_kernels.convolution(buf139, primals_148, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf140, (4, 32, 8, 8), (2048, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf141 = buf140; del buf140  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf142 = buf138; del buf138  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_25, batch_norm_24, xout_24], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf141, primals_149, primals_150, primals_151, primals_152, primals_153, buf142, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_149
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf143 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_8], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_33.run(buf72, buf74, buf142, buf75, buf76, buf143, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf144 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_20], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_34.run(buf143, buf73, buf74, buf142, buf75, buf76, buf78, buf101, buf144, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_26], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf145 = extern_kernels.convolution(buf144, primals_154, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf145, (4, 128, 16, 16), (32768, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf146 = buf145; del buf145  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf147 = empty_strided_cuda((4, 128, 16, 16), (32768, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_26, batch_norm_25, xout_25, hx2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43.run(buf146, primals_155, primals_156, primals_157, primals_158, primals_159, buf98, buf147, 131072, grid=grid(131072), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_155
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf148 = reinterpret_tensor(buf143, (4, 128, 8, 8), (8192, 64, 8, 1), 0); del buf143  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf149 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_21], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_44.run(buf147, buf148, buf149, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_27], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf150 = extern_kernels.convolution(buf148, primals_160, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf150, (4, 256, 8, 8), (16384, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf151 = buf150; del buf150  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf152 = empty_strided_cuda((4, 256, 8, 8), (16384, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_27, batch_norm_26, xout_26], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45.run(buf151, primals_161, primals_162, primals_163, primals_164, primals_165, buf152, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_161
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_165
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_28], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf153 = extern_kernels.convolution(buf152, primals_166, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf153, (4, 64, 8, 8), (4096, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf154 = buf153; del buf153  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf155 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_28, batch_norm_27, xout_27], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46.run(buf154, primals_167, primals_168, primals_169, primals_170, primals_171, buf155, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_167
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_171
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf156 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf157 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_22], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_47.run(buf155, buf156, buf157, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_29], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf158 = extern_kernels.convolution(buf156, primals_172, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf158, (4, 64, 4, 4), (1024, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf159 = buf158; del buf158  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf160 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_29, batch_norm_28, xout_28], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf159, primals_173, primals_174, primals_175, primals_176, primals_177, buf160, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_173
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_177
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf161 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf162 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_23], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_49.run(buf160, buf161, buf162, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_30], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf163 = extern_kernels.convolution(buf161, primals_178, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf163, (4, 64, 2, 2), (256, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf164 = buf163; del buf163  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf165 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_30, batch_norm_29, xout_29], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf164, primals_179, primals_180, primals_181, primals_182, primals_183, buf165, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_179
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_183
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf166 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf167 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_24], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_51.run(buf165, buf166, buf167, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_31], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf168 = extern_kernels.convolution(buf166, primals_184, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf168, (4, 64, 1, 1), (64, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf169 = buf168; del buf168  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf170 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_31, batch_norm_30, xout_30], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf169, primals_185, primals_186, primals_187, primals_188, primals_189, buf170, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_185
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_189
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_32], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf171 = extern_kernels.convolution(buf170, primals_190, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf171, (4, 64, 1, 1), (64, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf172 = buf171; del buf171  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_32], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_53.run(buf172, primals_191, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_191
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf173 = reinterpret_tensor(buf132, (4, 128, 1, 1), (128, 1, 1, 1), 0); del buf132  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_25], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_54.run(buf172, primals_192, primals_193, primals_194, primals_195, buf170, buf173, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_33], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf174 = extern_kernels.convolution(buf173, primals_196, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf174, (4, 64, 1, 1), (64, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf175 = buf174; del buf174  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf176 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 256, 256), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_33, batch_norm_32, xout_32], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf175, primals_197, primals_198, primals_199, primals_200, primals_201, buf176, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_197
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf177 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_9], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_55.run(buf39, buf41, buf176, buf42, buf43, buf177, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf178 = reinterpret_tensor(buf137, (4, 128, 2, 2), (512, 4, 2, 1), 0); del buf137  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_26], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_56.run(buf177, buf40, buf41, buf176, buf42, buf43, buf45, buf165, buf178, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_34], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf179 = extern_kernels.convolution(buf178, primals_202, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf179, (4, 64, 2, 2), (256, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf180 = buf179; del buf179  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf181 = buf177; del buf177  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_34, batch_norm_33, xout_33], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf180, primals_203, primals_204, primals_205, primals_206, primals_207, buf181, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_203
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf182 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_10], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_57.run(buf50, buf52, buf181, buf53, buf54, buf182, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf183 = reinterpret_tensor(buf142, (4, 128, 4, 4), (2048, 16, 4, 1), 0); del buf142  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_27], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_58.run(buf182, buf51, buf52, buf181, buf53, buf54, buf56, buf160, buf183, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_35], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf184 = extern_kernels.convolution(buf183, primals_208, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf184, (4, 64, 4, 4), (1024, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf185 = buf184; del buf184  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf186 = buf182; del buf182  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_35, batch_norm_34, xout_34], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf185, primals_209, primals_210, primals_211, primals_212, primals_213, buf186, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_209
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf187 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_11], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_59.run(buf61, buf63, buf186, buf64, buf65, buf187, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf188 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_28], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_60.run(buf187, buf62, buf63, buf186, buf64, buf65, buf67, buf155, buf188, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_36], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf189 = extern_kernels.convolution(buf188, primals_214, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf189, (4, 256, 8, 8), (16384, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf190 = buf189; del buf189  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf191 = empty_strided_cuda((4, 256, 8, 8), (16384, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_36, batch_norm_35, xout_35, hx3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61.run(buf190, primals_215, primals_216, primals_217, primals_218, primals_219, buf152, buf191, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_215
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf192 = reinterpret_tensor(buf187, (4, 256, 4, 4), (4096, 16, 4, 1), 0); del buf187  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf193 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_29], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_62.run(buf191, buf192, buf193, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_37], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf194 = extern_kernels.convolution(buf192, primals_220, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf194, (4, 512, 4, 4), (8192, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf195 = buf194; del buf194  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf196 = empty_strided_cuda((4, 512, 4, 4), (8192, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_37, batch_norm_36, xout_36], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63.run(buf195, primals_221, primals_222, primals_223, primals_224, primals_225, buf196, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_221
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_225
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_38], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf197 = extern_kernels.convolution(buf196, primals_226, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf197, (4, 128, 4, 4), (2048, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf198 = buf197; del buf197  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf199 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_38, batch_norm_37, xout_37], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64.run(buf198, primals_227, primals_228, primals_229, primals_230, primals_231, buf199, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_227
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_231
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf200 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf201 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_30], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_65.run(buf199, buf200, buf201, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_39], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf202 = extern_kernels.convolution(buf200, primals_232, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf202, (4, 128, 2, 2), (512, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf203 = buf202; del buf202  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf204 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_39, batch_norm_38, xout_38], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf203, primals_233, primals_234, primals_235, primals_236, primals_237, buf204, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_233
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_237
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf205 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf206 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_31], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_67.run(buf204, buf205, buf206, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_40], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf207 = extern_kernels.convolution(buf205, primals_238, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf207, (4, 128, 1, 1), (128, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf208 = buf207; del buf207  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf209 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_40, batch_norm_39, xout_39], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf208, primals_239, primals_240, primals_241, primals_242, primals_243, buf209, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_239
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_243
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_41], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf210 = extern_kernels.convolution(buf209, primals_244, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf210, (4, 128, 1, 1), (128, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf211 = buf210; del buf210  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_41], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_69.run(buf211, primals_245, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_245
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf212 = reinterpret_tensor(buf181, (4, 256, 1, 1), (256, 1, 1, 1), 0); del buf181  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_32], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_70.run(buf211, primals_246, primals_247, primals_248, primals_249, buf209, buf212, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_42], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf213 = extern_kernels.convolution(buf212, primals_250, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf213, (4, 128, 1, 1), (128, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf214 = buf213; del buf213  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf215 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 512, 512), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_42, batch_norm_41, xout_41], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf214, primals_251, primals_252, primals_253, primals_254, primals_255, buf215, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_251
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf216 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_12], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_71.run(buf39, buf41, buf215, buf42, buf43, buf216, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf217 = reinterpret_tensor(buf186, (4, 256, 2, 2), (1024, 4, 2, 1), 0); del buf186  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_33], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_72.run(buf216, buf40, buf41, buf215, buf42, buf43, buf45, buf204, buf217, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_43], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf218 = extern_kernels.convolution(buf217, primals_256, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf218, (4, 128, 2, 2), (512, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf219 = buf218; del buf218  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf220 = buf216; del buf216  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_43, batch_norm_42, xout_42], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf219, primals_257, primals_258, primals_259, primals_260, primals_261, buf220, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_257
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf221 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_13], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_73.run(buf50, buf52, buf220, buf53, buf54, buf221, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf222 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_34], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_74.run(buf221, buf51, buf52, buf220, buf53, buf54, buf56, buf199, buf222, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_44], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf223 = extern_kernels.convolution(buf222, primals_262, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf223, (4, 512, 4, 4), (8192, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf224 = buf223; del buf223  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf225 = empty_strided_cuda((4, 512, 4, 4), (8192, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_44, batch_norm_43, xout_43, hx4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75.run(buf224, primals_263, primals_264, primals_265, primals_266, primals_267, buf196, buf225, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_263
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf226 = reinterpret_tensor(buf221, (4, 512, 2, 2), (2048, 4, 2, 1), 0); del buf221  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf227 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_35], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_76.run(buf225, buf226, buf227, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_45], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf228 = extern_kernels.convolution(buf226, primals_268, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf228, (4, 512, 2, 2), (2048, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf229 = buf228; del buf228  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf230 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_45, batch_norm_44, xout_44], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77.run(buf229, primals_269, primals_270, primals_271, primals_272, primals_273, buf230, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_269
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_273
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_46], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf231 = extern_kernels.convolution(buf230, primals_274, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf231, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf232 = buf231; del buf231  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf233 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_46, batch_norm_45, xout_45], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf232, primals_275, primals_276, primals_277, primals_278, primals_279, buf233, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_275
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_279
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_47], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf234 = extern_kernels.convolution(buf233, primals_280, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf234, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf235 = buf234; del buf234  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf236 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_47, batch_norm_46, xout_46], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf235, primals_281, primals_282, primals_283, primals_284, primals_285, buf236, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_281
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_285
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_48], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf237 = extern_kernels.convolution(buf236, primals_286, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf237, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf238 = buf237; del buf237  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf239 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_48, batch_norm_47, xout_47], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf238, primals_287, primals_288, primals_289, primals_290, primals_291, buf239, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_287
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_291
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_49], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf240 = extern_kernels.convolution(buf239, primals_292, stride=(1, 1), padding=(8, 8), dilation=(8, 8), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf240, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf241 = buf240; del buf240  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_49], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf241, primals_293, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_293
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf242 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_36], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf241, primals_294, primals_295, primals_296, primals_297, buf239, buf242, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_50], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf243 = extern_kernels.convolution(buf242, primals_298, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf243, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf244 = buf243; del buf243  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_50], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf244, primals_299, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_299
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf245 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_37], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf244, primals_300, primals_301, primals_302, primals_303, buf236, buf245, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_51], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf246 = extern_kernels.convolution(buf245, primals_304, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf246, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf247 = buf246; del buf246  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_51], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf247, primals_305, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_305
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf248 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_38], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf247, primals_306, primals_307, primals_308, primals_309, buf233, buf248, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_52], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf249 = extern_kernels.convolution(buf248, primals_310, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf249, (4, 512, 2, 2), (2048, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf250 = buf249; del buf249  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf251 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_52, batch_norm_51, xout_51, hx5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81.run(buf250, primals_311, primals_312, primals_313, primals_314, primals_315, buf230, buf251, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_311
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf252 = reinterpret_tensor(buf220, (4, 512, 1, 1), (512, 1, 1, 1), 0); del buf220  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf253 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_39], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_82.run(buf251, buf252, buf253, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_53], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf254 = extern_kernels.convolution(buf252, primals_316, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf254, (4, 512, 1, 1), (512, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf255 = buf254; del buf254  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf256 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_53, batch_norm_52, xout_52], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83.run(buf255, primals_317, primals_318, primals_319, primals_320, primals_321, buf256, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_317
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_321
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_54], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf257 = extern_kernels.convolution(buf256, primals_322, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf257, (4, 256, 1, 1), (256, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf258 = buf257; del buf257  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf259 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_54, batch_norm_53, xout_53], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84.run(buf258, primals_323, primals_324, primals_325, primals_326, primals_327, buf259, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_323
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_327
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_55], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf260 = extern_kernels.convolution(buf259, primals_328, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf260, (4, 256, 1, 1), (256, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf261 = buf260; del buf260  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf262 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_55, batch_norm_54, xout_54], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84.run(buf261, primals_329, primals_330, primals_331, primals_332, primals_333, buf262, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_329
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_333
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_56], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf263 = extern_kernels.convolution(buf262, primals_334, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf263, (4, 256, 1, 1), (256, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf264 = buf263; del buf263  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf265 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_56, batch_norm_55, xout_55], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84.run(buf264, primals_335, primals_336, primals_337, primals_338, primals_339, buf265, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_335
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_339
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_57], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf266 = extern_kernels.convolution(buf265, primals_340, stride=(1, 1), padding=(8, 8), dilation=(8, 8), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf266, (4, 256, 1, 1), (256, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf267 = buf266; del buf266  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_57], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_85.run(buf267, primals_341, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_341
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf268 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_40], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_86.run(buf267, primals_342, primals_343, primals_344, primals_345, buf265, buf268, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_58], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf269 = extern_kernels.convolution(buf268, primals_346, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf269, (4, 256, 1, 1), (256, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf270 = buf269; del buf269  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_58], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_85.run(buf270, primals_347, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_347
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf271 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_41], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_86.run(buf270, primals_348, primals_349, primals_350, primals_351, buf262, buf271, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_59], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf272 = extern_kernels.convolution(buf271, primals_352, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf272, (4, 256, 1, 1), (256, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf273 = buf272; del buf272  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_59], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_85.run(buf273, primals_353, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_353
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf274 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_42], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_86.run(buf273, primals_354, primals_355, primals_356, primals_357, buf259, buf274, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_60], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf275 = extern_kernels.convolution(buf274, primals_358, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf275, (4, 512, 1, 1), (512, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf276 = buf275; del buf275  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf277 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_60, batch_norm_59, xout_59, hx6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87.run(buf276, primals_359, primals_360, primals_361, primals_362, primals_363, buf256, buf277, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_359
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf278 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_14], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_88.run(buf39, buf41, buf277, buf42, buf43, buf278, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf279 = empty_strided_cuda((4, 1024, 2, 2), (4096, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_43], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_89.run(buf278, buf40, buf41, buf277, buf42, buf43, buf45, buf251, buf279, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_61], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf280 = extern_kernels.convolution(buf279, primals_364, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf280, (4, 512, 2, 2), (2048, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf281 = buf280; del buf280  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf282 = buf278; del buf278  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_61, batch_norm_60, xout_60], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77.run(buf281, primals_365, primals_366, primals_367, primals_368, primals_369, buf282, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_365
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_369
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_62], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf283 = extern_kernels.convolution(buf282, primals_370, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf283, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf284 = buf283; del buf283  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf285 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_62, batch_norm_61, xout_61], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf284, primals_371, primals_372, primals_373, primals_374, primals_375, buf285, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_371
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_375
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_63], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf286 = extern_kernels.convolution(buf285, primals_376, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf286, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf287 = buf286; del buf286  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf288 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_63, batch_norm_62, xout_62], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf287, primals_377, primals_378, primals_379, primals_380, primals_381, buf288, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_377
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_381
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_64], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf289 = extern_kernels.convolution(buf288, primals_382, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf289, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf290 = buf289; del buf289  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf291 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_64, batch_norm_63, xout_63], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf290, primals_383, primals_384, primals_385, primals_386, primals_387, buf291, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_383
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_387
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_65], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf292 = extern_kernels.convolution(buf291, primals_388, stride=(1, 1), padding=(8, 8), dilation=(8, 8), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf292, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf293 = buf292; del buf292  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_65], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf293, primals_389, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_389
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf294 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_44], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf293, primals_390, primals_391, primals_392, primals_393, buf291, buf294, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_66], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf295 = extern_kernels.convolution(buf294, primals_394, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf295, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf296 = buf295; del buf295  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_66], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf296, primals_395, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_395
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf297 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_45], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf296, primals_396, primals_397, primals_398, primals_399, buf288, buf297, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_67], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf298 = extern_kernels.convolution(buf297, primals_400, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf298, (4, 256, 2, 2), (1024, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf299 = buf298; del buf298  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_67], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf299, primals_401, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_401
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf300 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_46], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf299, primals_402, primals_403, primals_404, primals_405, buf285, buf300, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_68], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf301 = extern_kernels.convolution(buf300, primals_406, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf301, (4, 512, 2, 2), (2048, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf302 = buf301; del buf301  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf303 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_68, batch_norm_67, xout_67, hx5d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81.run(buf302, primals_407, primals_408, primals_409, primals_410, primals_411, buf282, buf303, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_407
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf304 = empty_strided_cuda((4, 512, 4, 4), (8192, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_15], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_90.run(buf50, buf52, buf303, buf53, buf54, buf304, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf305 = empty_strided_cuda((4, 1024, 4, 4), (16384, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_47], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_91.run(buf304, buf51, buf52, buf303, buf53, buf54, buf56, buf225, buf305, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_69], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf306 = extern_kernels.convolution(buf305, primals_412, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf306, (4, 256, 4, 4), (4096, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf307 = buf306; del buf306  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf308 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_69, batch_norm_68, xout_68], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92.run(buf307, primals_413, primals_414, primals_415, primals_416, primals_417, buf308, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_413
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_417
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_70], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf309 = extern_kernels.convolution(buf308, primals_418, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf309, (4, 128, 4, 4), (2048, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf310 = buf309; del buf309  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf311 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_70, batch_norm_69, xout_69], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64.run(buf310, primals_419, primals_420, primals_421, primals_422, primals_423, buf311, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_419
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_423
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf312 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf313 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_48], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_65.run(buf311, buf312, buf313, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_71], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf314 = extern_kernels.convolution(buf312, primals_424, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf314, (4, 128, 2, 2), (512, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf315 = buf314; del buf314  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf316 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_71, batch_norm_70, xout_70], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf315, primals_425, primals_426, primals_427, primals_428, primals_429, buf316, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_425
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_429
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf317 = reinterpret_tensor(buf215, (4, 128, 1, 1), (128, 1, 1, 1), 0); del buf215  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf318 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_49], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_67.run(buf316, buf317, buf318, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_72], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf319 = extern_kernels.convolution(buf317, primals_430, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf319, (4, 128, 1, 1), (128, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf320 = buf319; del buf319  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf321 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_72, batch_norm_71, xout_71], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf320, primals_431, primals_432, primals_433, primals_434, primals_435, buf321, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_431
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_435
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_73], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf322 = extern_kernels.convolution(buf321, primals_436, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf322, (4, 128, 1, 1), (128, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf323 = buf322; del buf322  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_73], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_69.run(buf323, primals_437, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_437
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf324 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_50], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_70.run(buf323, primals_438, primals_439, primals_440, primals_441, buf321, buf324, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_74], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf325 = extern_kernels.convolution(buf324, primals_442, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf325, (4, 128, 1, 1), (128, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf326 = buf325; del buf325  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf327 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 512, 512), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_74, batch_norm_73, xout_73], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf326, primals_443, primals_444, primals_445, primals_446, primals_447, buf327, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_443
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf328 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_16], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_71.run(buf39, buf41, buf327, buf42, buf43, buf328, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf329 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_51], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_72.run(buf328, buf40, buf41, buf327, buf42, buf43, buf45, buf316, buf329, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_75], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf330 = extern_kernels.convolution(buf329, primals_448, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf330, (4, 128, 2, 2), (512, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf331 = buf330; del buf330  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf332 = buf328; del buf328  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_75, batch_norm_74, xout_74], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf331, primals_449, primals_450, primals_451, primals_452, primals_453, buf332, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_449
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf333 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_17], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_73.run(buf50, buf52, buf332, buf53, buf54, buf333, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf334 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_52], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_74.run(buf333, buf51, buf52, buf332, buf53, buf54, buf56, buf311, buf334, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_76], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf335 = extern_kernels.convolution(buf334, primals_454, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf335, (4, 256, 4, 4), (4096, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf336 = buf335; del buf335  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf337 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_76, batch_norm_75, xout_75, hx4d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93.run(buf336, primals_455, primals_456, primals_457, primals_458, primals_459, buf308, buf337, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_455
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf338 = empty_strided_cuda((4, 256, 8, 8), (16384, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_18], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_94.run(buf61, buf63, buf337, buf64, buf65, buf338, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf339 = empty_strided_cuda((4, 512, 8, 8), (32768, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_53], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_95.run(buf338, buf62, buf63, buf337, buf64, buf65, buf67, buf191, buf339, 131072, grid=grid(131072), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_77], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf340 = extern_kernels.convolution(buf339, primals_460, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf340, (4, 128, 8, 8), (8192, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf341 = buf340; del buf340  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf342 = reinterpret_tensor(buf304, (4, 128, 8, 8), (8192, 64, 8, 1), 0); del buf304  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_77, batch_norm_76, xout_76], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96.run(buf341, primals_461, primals_462, primals_463, primals_464, primals_465, buf342, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_461
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_465
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_78], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf343 = extern_kernels.convolution(buf342, primals_466, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf343, (4, 64, 8, 8), (4096, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf344 = buf343; del buf343  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf345 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_78, batch_norm_77, xout_77], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46.run(buf344, primals_467, primals_468, primals_469, primals_470, primals_471, buf345, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_467
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_471
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf346 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf347 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_54], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_47.run(buf345, buf346, buf347, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_79], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf348 = extern_kernels.convolution(buf346, primals_472, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf348, (4, 64, 4, 4), (1024, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf349 = buf348; del buf348  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf350 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_79, batch_norm_78, xout_78], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf349, primals_473, primals_474, primals_475, primals_476, primals_477, buf350, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_473
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_477
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf351 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf352 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_55], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_49.run(buf350, buf351, buf352, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_80], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf353 = extern_kernels.convolution(buf351, primals_478, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf353, (4, 64, 2, 2), (256, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf354 = buf353; del buf353  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf355 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_80, batch_norm_79, xout_79], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf354, primals_479, primals_480, primals_481, primals_482, primals_483, buf355, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_479
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_483
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf356 = reinterpret_tensor(buf176, (4, 64, 1, 1), (64, 1, 1, 1), 0); del buf176  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf357 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_56], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_51.run(buf355, buf356, buf357, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_81], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf358 = extern_kernels.convolution(buf356, primals_484, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf358, (4, 64, 1, 1), (64, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf359 = buf358; del buf358  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf360 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_81, batch_norm_80, xout_80], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf359, primals_485, primals_486, primals_487, primals_488, primals_489, buf360, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_485
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_489
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_82], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf361 = extern_kernels.convolution(buf360, primals_490, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf361, (4, 64, 1, 1), (64, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf362 = buf361; del buf361  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_82], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_53.run(buf362, primals_491, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_491
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf363 = reinterpret_tensor(buf327, (4, 128, 1, 1), (128, 1, 1, 1), 0); del buf327  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_57], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_54.run(buf362, primals_492, primals_493, primals_494, primals_495, buf360, buf363, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_83], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf364 = extern_kernels.convolution(buf363, primals_496, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf364, (4, 64, 1, 1), (64, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf365 = buf364; del buf364  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf366 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 256, 256), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_83, batch_norm_82, xout_82], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf365, primals_497, primals_498, primals_499, primals_500, primals_501, buf366, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_497
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf367 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_19], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_55.run(buf39, buf41, buf366, buf42, buf43, buf367, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf368 = buf332; del buf332  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_58], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_56.run(buf367, buf40, buf41, buf366, buf42, buf43, buf45, buf355, buf368, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_84], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf369 = extern_kernels.convolution(buf368, primals_502, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf369, (4, 64, 2, 2), (256, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf370 = buf369; del buf369  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf371 = buf367; del buf367  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_84, batch_norm_83, xout_83], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf370, primals_503, primals_504, primals_505, primals_506, primals_507, buf371, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_503
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf372 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_20], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_57.run(buf50, buf52, buf371, buf53, buf54, buf372, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf373 = buf333; del buf333  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_59], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_58.run(buf372, buf51, buf52, buf371, buf53, buf54, buf56, buf350, buf373, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_85], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf374 = extern_kernels.convolution(buf373, primals_508, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf374, (4, 64, 4, 4), (1024, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf375 = buf374; del buf374  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf376 = buf372; del buf372  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_85, batch_norm_84, xout_84], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf375, primals_509, primals_510, primals_511, primals_512, primals_513, buf376, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_509
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf377 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_21], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_59.run(buf61, buf63, buf376, buf64, buf65, buf377, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf378 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_60], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_60.run(buf377, buf62, buf63, buf376, buf64, buf65, buf67, buf345, buf378, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_86], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf379 = extern_kernels.convolution(buf378, primals_514, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf379, (4, 128, 8, 8), (8192, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf380 = buf379; del buf379  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf381 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_86, batch_norm_85, xout_85, hx3d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97.run(buf380, primals_515, primals_516, primals_517, primals_518, primals_519, buf342, buf381, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_515
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf382 = empty_strided_cuda((4, 128, 16, 16), (32768, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_22], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_98.run(buf72, buf74, buf381, buf75, buf76, buf382, 131072, grid=grid(131072), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf383 = empty_strided_cuda((4, 256, 16, 16), (65536, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_61], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_99.run(buf382, buf73, buf74, buf381, buf75, buf76, buf78, buf147, buf383, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_87], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf384 = extern_kernels.convolution(buf383, primals_520, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf384, (4, 64, 16, 16), (16384, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf385 = buf384; del buf384  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf386 = reinterpret_tensor(buf338, (4, 64, 16, 16), (16384, 256, 16, 1), 0); del buf338  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_87, batch_norm_86, xout_86], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100.run(buf385, primals_521, primals_522, primals_523, primals_524, primals_525, buf386, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_521
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_525
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_88], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf387 = extern_kernels.convolution(buf386, primals_526, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf387, (4, 32, 16, 16), (8192, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf388 = buf387; del buf387  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf389 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_88, batch_norm_87, xout_87], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf388, primals_527, primals_528, primals_529, primals_530, primals_531, buf389, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_527
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_531
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf390 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf391 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_62], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5.run(buf389, buf390, buf391, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_89], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf392 = extern_kernels.convolution(buf390, primals_532, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf392, (4, 32, 8, 8), (2048, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf393 = buf392; del buf392  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf394 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_89, batch_norm_88, xout_88], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf393, primals_533, primals_534, primals_535, primals_536, primals_537, buf394, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_533
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_537
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf395 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf396 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_63], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_7.run(buf394, buf395, buf396, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_90], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf397 = extern_kernels.convolution(buf395, primals_538, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf397, (4, 32, 4, 4), (512, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf398 = buf397; del buf397  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf399 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_90, batch_norm_89, xout_89], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf398, primals_539, primals_540, primals_541, primals_542, primals_543, buf399, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_539
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_543
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf400 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf401 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_64], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_9.run(buf399, buf400, buf401, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_91], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf402 = extern_kernels.convolution(buf400, primals_544, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf402, (4, 32, 2, 2), (128, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf403 = buf402; del buf402  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf404 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_91, batch_norm_90, xout_90], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf403, primals_545, primals_546, primals_547, primals_548, primals_549, buf404, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_545
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_549
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf405 = reinterpret_tensor(buf127, (4, 32, 1, 1), (32, 1, 1, 1), 0); del buf127  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf406 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_65], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_11.run(buf404, buf405, buf406, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_92], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf407 = extern_kernels.convolution(buf405, primals_550, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf407, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf408 = buf407; del buf407  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf409 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_92, batch_norm_91, xout_91], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf408, primals_551, primals_552, primals_553, primals_554, primals_555, buf409, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_551
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_555
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_93], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf410 = extern_kernels.convolution(buf409, primals_556, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf410, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf411 = buf410; del buf410  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_93], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_13.run(buf411, primals_557, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_557
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf412 = reinterpret_tensor(buf366, (4, 64, 1, 1), (64, 1, 1, 1), 0); del buf366  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_66], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_14.run(buf411, primals_558, primals_559, primals_560, primals_561, buf409, buf412, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_94], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf413 = extern_kernels.convolution(buf412, primals_562, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf413, (4, 32, 1, 1), (32, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf414 = buf413; del buf413  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf415 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 128, 128), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_94, batch_norm_93, xout_93], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf414, primals_563, primals_564, primals_565, primals_566, primals_567, buf415, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_563
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf416 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_23], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_18.run(buf39, buf41, buf415, buf42, buf43, buf416, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf417 = buf371; del buf371  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_67], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_19.run(buf416, buf40, buf41, buf415, buf42, buf43, buf45, buf404, buf417, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_95], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf418 = extern_kernels.convolution(buf417, primals_568, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf418, (4, 32, 2, 2), (128, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf419 = buf418; del buf418  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf420 = buf416; del buf416  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_95, batch_norm_94, xout_94], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf419, primals_569, primals_570, primals_571, primals_572, primals_573, buf420, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_569
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf421 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_24], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_23.run(buf50, buf52, buf420, buf53, buf54, buf421, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf422 = buf376; del buf376  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_68], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_24.run(buf421, buf51, buf52, buf420, buf53, buf54, buf56, buf399, buf422, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_96], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf423 = extern_kernels.convolution(buf422, primals_574, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf423, (4, 32, 4, 4), (512, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf424 = buf423; del buf423  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf425 = buf421; del buf421  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_96, batch_norm_95, xout_95], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf424, primals_575, primals_576, primals_577, primals_578, primals_579, buf425, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_575
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf426 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_25], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_28.run(buf61, buf63, buf425, buf64, buf65, buf426, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf427 = buf377; del buf377  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_69], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_29.run(buf426, buf62, buf63, buf425, buf64, buf65, buf67, buf394, buf427, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_97], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf428 = extern_kernels.convolution(buf427, primals_580, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf428, (4, 32, 8, 8), (2048, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf429 = buf428; del buf428  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf430 = buf426; del buf426  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_97, batch_norm_96, xout_96], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf429, primals_581, primals_582, primals_583, primals_584, primals_585, buf430, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_581
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf431 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_26], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_33.run(buf72, buf74, buf430, buf75, buf76, buf431, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf432 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_70], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_34.run(buf431, buf73, buf74, buf430, buf75, buf76, buf78, buf389, buf432, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_98], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf433 = extern_kernels.convolution(buf432, primals_586, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf433, (4, 64, 16, 16), (16384, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf434 = buf433; del buf433  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf435 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_98, batch_norm_97, xout_97, hx2d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101.run(buf434, primals_587, primals_588, primals_589, primals_590, primals_591, buf386, buf435, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_587
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf436 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_27], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_102.run(buf83, buf85, buf435, buf86, buf87, buf436, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf437 = empty_strided_cuda((4, 128, 32, 32), (131072, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_71], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_103.run(buf436, buf84, buf85, buf435, buf86, buf87, buf89, buf93, buf437, 524288, grid=grid(524288), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_99], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf438 = extern_kernels.convolution(buf437, primals_592, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf438, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf439 = buf438; del buf438  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf440 = buf436; del buf436  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_99, batch_norm_98, xout_98], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1.run(buf439, primals_593, primals_594, primals_595, primals_596, primals_597, buf440, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_593
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_597
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_100], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf441 = extern_kernels.convolution(buf440, primals_598, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf441, (4, 16, 32, 32), (16384, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf442 = buf441; del buf441  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf443 = empty_strided_cuda((4, 16, 32, 32), (16384, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_100, batch_norm_99, xout_99], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104.run(buf442, primals_599, primals_600, primals_601, primals_602, primals_603, buf443, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_599
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_603
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf444 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf445 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_72], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_105.run(buf443, buf444, buf445, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_101], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf446 = extern_kernels.convolution(buf444, primals_604, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf446, (4, 16, 16, 16), (4096, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf447 = buf446; del buf446  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf448 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_101, batch_norm_100, xout_100], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106.run(buf447, primals_605, primals_606, primals_607, primals_608, primals_609, buf448, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_605
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_609
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf449 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf450 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_73], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_107.run(buf448, buf449, buf450, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_102], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf451 = extern_kernels.convolution(buf449, primals_610, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf451, (4, 16, 8, 8), (1024, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf452 = buf451; del buf451  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf453 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_102, batch_norm_101, xout_101], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108.run(buf452, primals_611, primals_612, primals_613, primals_614, primals_615, buf453, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_611
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_615
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf454 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf455 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_74], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_109.run(buf453, buf454, buf455, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_103], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf456 = extern_kernels.convolution(buf454, primals_616, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf456, (4, 16, 4, 4), (256, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf457 = buf456; del buf456  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf458 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_103, batch_norm_102, xout_102], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110.run(buf457, primals_617, primals_618, primals_619, primals_620, primals_621, buf458, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_617
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_621
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf459 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf460 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_75], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_111.run(buf458, buf459, buf460, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_104], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf461 = extern_kernels.convolution(buf459, primals_622, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf461, (4, 16, 2, 2), (64, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf462 = buf461; del buf461  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf463 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_104, batch_norm_103, xout_103], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112.run(buf462, primals_623, primals_624, primals_625, primals_626, primals_627, buf463, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_623
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_627
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf464 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf465 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 1, 1), torch.int8)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_76], Original ATen: [aten.max_pool2d_with_indices]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_113.run(buf463, buf464, buf465, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_105], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf466 = extern_kernels.convolution(buf464, primals_628, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf466, (4, 16, 1, 1), (16, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf467 = buf466; del buf466  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf468 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_105, batch_norm_104, xout_104], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114.run(buf467, primals_629, primals_630, primals_631, primals_632, primals_633, buf468, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_629
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_633
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_106], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf469 = extern_kernels.convolution(buf468, primals_634, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf469, (4, 16, 1, 1), (16, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf470 = buf469; del buf469  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_106], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_115.run(buf470, primals_635, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_635
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf471 = reinterpret_tensor(buf415, (4, 32, 1, 1), (32, 1, 1, 1), 0); del buf415  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_77], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_116.run(buf470, primals_636, primals_637, primals_638, primals_639, buf468, buf471, 128, grid=grid(128), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_107], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf472 = extern_kernels.convolution(buf471, primals_640, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf472, (4, 16, 1, 1), (16, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf473 = buf472; del buf472  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf474 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 64, 64), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_107, batch_norm_106, xout_106], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114.run(buf473, primals_641, primals_642, primals_643, primals_644, primals_645, buf474, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_641
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf475 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_28], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_117.run(buf39, buf41, buf474, buf42, buf43, buf475, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf476 = buf420; del buf420  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_78], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_118.run(buf475, buf40, buf41, buf474, buf42, buf43, buf45, buf463, buf476, 512, grid=grid(512), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_108], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf477 = extern_kernels.convolution(buf476, primals_646, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf477, (4, 16, 2, 2), (64, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf478 = buf477; del buf477  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf479 = buf475; del buf475  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_108, batch_norm_107, xout_107], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112.run(buf478, primals_647, primals_648, primals_649, primals_650, primals_651, buf479, 256, grid=grid(256), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_647
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf480 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_29], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_119.run(buf50, buf52, buf479, buf53, buf54, buf480, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf481 = buf425; del buf425  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_79], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_120.run(buf480, buf51, buf52, buf479, buf53, buf54, buf56, buf458, buf481, 2048, grid=grid(2048), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf479
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_109], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf482 = extern_kernels.convolution(buf481, primals_652, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf482, (4, 16, 4, 4), (256, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf483 = buf482; del buf482  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf484 = buf480; del buf480  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_109, batch_norm_108, xout_108], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110.run(buf483, primals_653, primals_654, primals_655, primals_656, primals_657, buf484, 1024, grid=grid(1024), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_653
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf485 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_30], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_121.run(buf61, buf63, buf484, buf64, buf65, buf485, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf486 = buf430; del buf430  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_80], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_122.run(buf485, buf62, buf63, buf484, buf64, buf65, buf67, buf453, buf486, 8192, grid=grid(8192), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf484
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_110], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf487 = extern_kernels.convolution(buf486, primals_658, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf487, (4, 16, 8, 8), (1024, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf488 = buf487; del buf487  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf489 = buf485; del buf485  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_110, batch_norm_109, xout_109], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108.run(buf488, primals_659, primals_660, primals_661, primals_662, primals_663, buf489, 4096, grid=grid(4096), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_659
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf490 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_31], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_123.run(buf72, buf74, buf489, buf75, buf76, buf490, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf491 = buf431; del buf431  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_81], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_124.run(buf490, buf73, buf74, buf489, buf75, buf76, buf78, buf448, buf491, 32768, grid=grid(32768), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf489
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_111], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf492 = extern_kernels.convolution(buf491, primals_664, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf492, (4, 16, 16, 16), (4096, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf493 = buf492; del buf492  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf494 = buf490; del buf490  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_111, batch_norm_110, xout_110], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106.run(buf493, primals_665, primals_666, primals_667, primals_668, primals_669, buf494, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_665
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf495 = empty_strided_cuda((4, 16, 32, 32), (16384, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_32], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_125.run(buf83, buf85, buf494, buf86, buf87, buf495, 65536, grid=grid(65536), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf496 = reinterpret_tensor(buf382, (4, 32, 32, 32), (32768, 1024, 32, 1), 0); del buf382  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_82], Original ATen: [aten.cat]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_126.run(buf495, buf84, buf85, buf494, buf86, buf87, buf89, buf443, buf496, 131072, grid=grid(131072), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf495
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_112], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf497 = extern_kernels.convolution(buf496, primals_670, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf497, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf498 = buf497; del buf497  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf499 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_112, batch_norm_111, xout_111, hx1d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40.run(buf498, primals_671, primals_672, primals_673, primals_674, primals_675, buf440, buf499, 262144, grid=grid(262144), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_671
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d1], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf500 = extern_kernels.convolution(buf499, primals_676, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf500, (4, 1, 32, 32), (1024, 1024, 32, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf501 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_127.run(buf501, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf502 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_128.run(buf502, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf503 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_127.run(buf503, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf504 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_128.run(buf504, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf505 = reinterpret_tensor(buf474, (64, ), (1, ), 0); del buf474  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129.run(buf505, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf507 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129.run(buf507, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf506 = reinterpret_tensor(buf494, (4, 1, 64, 64), (4096, 16384, 64, 1), 0); del buf494  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf553 = reinterpret_tensor(buf506, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf506  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d1, src_33, sigmoid], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130.run(buf553, buf501, buf503, buf500, primals_677, buf504, buf505, buf502, buf507, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf500
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_677
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d2], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf509 = extern_kernels.convolution(buf435, primals_678, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf509, (4, 1, 16, 16), (256, 256, 16, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf510 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_131.run(buf510, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf511 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_132.run(buf511, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf512 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_34], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_131.run(buf512, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf513 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_132.run(buf513, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf514 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_34], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133.run(buf514, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf516 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133.run(buf516, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf515 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf554 = reinterpret_tensor(buf515, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf515  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d2, src_34, sigmoid_1], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134.run(buf554, buf510, buf512, buf509, primals_679, buf513, buf514, buf511, buf516, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf509
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_679
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d3], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf518 = extern_kernels.convolution(buf381, primals_680, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf518, (4, 1, 8, 8), (64, 64, 8, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf519 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_135.run(buf519, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf520 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_136.run(buf520, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf521 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_35], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_135.run(buf521, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf522 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_136.run(buf522, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf523 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_35], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137.run(buf523, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf525 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137.run(buf525, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf524 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf555 = reinterpret_tensor(buf524, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf524  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d3, src_35, sigmoid_2], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138.run(buf555, buf519, buf521, buf518, primals_681, buf522, buf523, buf520, buf525, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf518
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_681
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d4], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf527 = extern_kernels.convolution(buf337, primals_682, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf527, (4, 1, 4, 4), (16, 16, 4, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf528 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_139.run(buf528, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf529 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_140.run(buf529, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf530 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_36], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_139.run(buf530, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf531 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_140.run(buf531, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf532 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_36], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141.run(buf532, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf534 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141.run(buf534, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf533 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf556 = reinterpret_tensor(buf533, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf533  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d4, src_36, sigmoid_3], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142.run(buf556, buf528, buf530, buf527, primals_683, buf531, buf532, buf529, buf534, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_683
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d5], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf536 = extern_kernels.convolution(buf303, primals_684, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf536, (4, 1, 2, 2), (4, 4, 2, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf537 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_143.run(buf537, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf538 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_144.run(buf538, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf539 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_37], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_143.run(buf539, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf540 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_144.run(buf540, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf541 = reinterpret_tensor(buf527, (64, ), (1, ), 0); del buf527  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_37], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145.run(buf541, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf543 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145.run(buf543, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf542 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf557 = reinterpret_tensor(buf542, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf542  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d5, src_37, sigmoid_4], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146.run(buf557, buf537, buf539, buf536, primals_685, buf540, buf541, buf538, buf543, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf536
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_685
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d6], Original ATen: [aten.convolution]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf545 = extern_kernels.convolution(buf277, primals_686, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf545, (4, 1, 1, 1), (1, 1, 1, 1))
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf546 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten._to_copy]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_147.run(buf546, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf547 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_148.run(buf547, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf548 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_38], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_147.run(buf548, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf549 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.add, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_148.run(buf549, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf550 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_38], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149.run(buf550, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf552 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.sub, aten.clamp]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149.run(buf552, 64, grid=grid(64), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf551 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf558 = reinterpret_tensor(buf551, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf551  # reuse
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d6, src_38, sigmoid_5], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150.run(buf558, buf546, buf548, buf545, primals_687, buf549, buf550, buf547, buf552, 16384, grid=grid(16384), stream=stream0)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf545
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_687
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf553, buf554, buf555, buf556, buf557, buf558, buf499, buf435, buf381, buf337, buf303, buf277, primals_1, primals_2, primals_4, primals_6, primals_7, primals_8, primals_10, primals_12, primals_13, primals_14, primals_16, primals_18, primals_19, primals_20, primals_22, primals_24, primals_25, primals_26, primals_28, primals_30, primals_31, primals_32, primals_34, primals_36, primals_37, primals_38, primals_40, primals_42, primals_43, primals_44, primals_46, primals_48, primals_49, primals_50, primals_51, primals_52, primals_54, primals_55, primals_56, primals_57, primals_58, primals_60, primals_61, primals_62, primals_63, primals_64, primals_66, primals_67, primals_68, primals_69, primals_70, primals_72, primals_73, primals_74, primals_75, primals_76, primals_78, primals_79, primals_80, primals_81, primals_82, primals_84, primals_85, primals_86, primals_87, primals_88, primals_90, primals_91, primals_92, primals_94, primals_96, primals_97, primals_98, primals_100, primals_102, primals_103, primals_104, primals_106, primals_108, primals_109, primals_110, primals_112, primals_114, primals_115, primals_116, primals_118, primals_120, primals_121, primals_122, primals_124, primals_126, primals_127, primals_128, primals_129, primals_130, primals_132, primals_133, primals_134, primals_135, primals_136, primals_138, primals_139, primals_140, primals_141, primals_142, primals_144, primals_145, primals_146, primals_147, primals_148, primals_150, primals_151, primals_152, primals_153, primals_154, primals_156, primals_157, primals_158, primals_159, primals_160, primals_162, primals_163, primals_164, primals_166, primals_168, primals_169, primals_170, primals_172, primals_174, primals_175, primals_176, primals_178, primals_180, primals_181, primals_182, primals_184, primals_186, primals_187, primals_188, primals_190, primals_192, primals_193, primals_194, primals_195, primals_196, primals_198, primals_199, primals_200, primals_201, primals_202, primals_204, primals_205, primals_206, primals_207, primals_208, primals_210, primals_211, primals_212, primals_213, primals_214, primals_216, primals_217, primals_218, primals_219, primals_220, primals_222, primals_223, primals_224, primals_226, primals_228, primals_229, primals_230, primals_232, primals_234, primals_235, primals_236, primals_238, primals_240, primals_241, primals_242, primals_244, primals_246, primals_247, primals_248, primals_249, primals_250, primals_252, primals_253, primals_254, primals_255, primals_256, primals_258, primals_259, primals_260, primals_261, primals_262, primals_264, primals_265, primals_266, primals_267, primals_268, primals_270, primals_271, primals_272, primals_274, primals_276, primals_277, primals_278, primals_280, primals_282, primals_283, primals_284, primals_286, primals_288, primals_289, primals_290, primals_292, primals_294, primals_295, primals_296, primals_297, primals_298, primals_300, primals_301, primals_302, primals_303, primals_304, primals_306, primals_307, primals_308, primals_309, primals_310, primals_312, primals_313, primals_314, primals_315, primals_316, primals_318, primals_319, primals_320, primals_322, primals_324, primals_325, primals_326, primals_328, primals_330, primals_331, primals_332, primals_334, primals_336, primals_337, primals_338, primals_340, primals_342, primals_343, primals_344, primals_345, primals_346, primals_348, primals_349, primals_350, primals_351, primals_352, primals_354, primals_355, primals_356, primals_357, primals_358, primals_360, primals_361, primals_362, primals_363, primals_364, primals_366, primals_367, primals_368, primals_370, primals_372, primals_373, primals_374, primals_376, primals_378, primals_379, primals_380, primals_382, primals_384, primals_385, primals_386, primals_388, primals_390, primals_391, primals_392, primals_393, primals_394, primals_396, primals_397, primals_398, primals_399, primals_400, primals_402, primals_403, primals_404, primals_405, primals_406, primals_408, primals_409, primals_410, primals_411, primals_412, primals_414, primals_415, primals_416, primals_418, primals_420, primals_421, primals_422, primals_424, primals_426, primals_427, primals_428, primals_430, primals_432, primals_433, primals_434, primals_436, primals_438, primals_439, primals_440, primals_441, primals_442, primals_444, primals_445, primals_446, primals_447, primals_448, primals_450, primals_451, primals_452, primals_453, primals_454, primals_456, primals_457, primals_458, primals_459, primals_460, primals_462, primals_463, primals_464, primals_466, primals_468, primals_469, primals_470, primals_472, primals_474, primals_475, primals_476, primals_478, primals_480, primals_481, primals_482, primals_484, primals_486, primals_487, primals_488, primals_490, primals_492, primals_493, primals_494, primals_495, primals_496, primals_498, primals_499, primals_500, primals_501, primals_502, primals_504, primals_505, primals_506, primals_507, primals_508, primals_510, primals_511, primals_512, primals_513, primals_514, primals_516, primals_517, primals_518, primals_519, primals_520, primals_522, primals_523, primals_524, primals_526, primals_528, primals_529, primals_530, primals_532, primals_534, primals_535, primals_536, primals_538, primals_540, primals_541, primals_542, primals_544, primals_546, primals_547, primals_548, primals_550, primals_552, primals_553, primals_554, primals_556, primals_558, primals_559, primals_560, primals_561, primals_562, primals_564, primals_565, primals_566, primals_567, primals_568, primals_570, primals_571, primals_572, primals_573, primals_574, primals_576, primals_577, primals_578, primals_579, primals_580, primals_582, primals_583, primals_584, primals_585, primals_586, primals_588, primals_589, primals_590, primals_591, primals_592, primals_594, primals_595, primals_596, primals_598, primals_600, primals_601, primals_602, primals_604, primals_606, primals_607, primals_608, primals_610, primals_612, primals_613, primals_614, primals_616, primals_618, primals_619, primals_620, primals_622, primals_624, primals_625, primals_626, primals_628, primals_630, primals_631, primals_632, primals_634, primals_636, primals_637, primals_638, primals_639, primals_640, primals_642, primals_643, primals_644, primals_645, primals_646, primals_648, primals_649, primals_650, primals_651, primals_652, primals_654, primals_655, primals_656, primals_657, primals_658, primals_660, primals_661, primals_662, primals_663, primals_664, primals_666, primals_667, primals_668, primals_669, primals_670, primals_672, primals_673, primals_674, primals_675, primals_676, primals_678, primals_680, primals_682, primals_684, primals_686, buf1, buf3, buf4, buf6, buf7, buf8, buf9, buf11, buf12, buf13, buf14, buf16, buf17, buf18, buf19, buf21, buf22, buf23, buf24, buf26, buf27, buf28, buf29, buf31, buf32, buf34, buf35, buf37, buf39, buf40, buf41, buf42, buf43, buf45, buf46, buf48, buf50, buf51, buf52, buf53, buf54, buf56, buf57, buf59, buf61, buf62, buf63, buf64, buf65, buf67, buf68, buf70, buf72, buf73, buf74, buf75, buf76, buf78, buf79, buf81, buf83, buf84, buf85, buf86, buf87, buf89, buf90, buf92, buf93, buf94, buf95, buf97, buf98, buf100, buf101, buf102, buf103, buf105, buf106, buf107, buf108, buf110, buf111, buf112, buf113, buf115, buf116, buf117, buf118, buf120, buf121, buf123, buf124, buf126, buf129, buf131, buf134, buf136, buf139, buf141, buf144, buf146, buf147, buf148, buf149, buf151, buf152, buf154, buf155, buf156, buf157, buf159, buf160, buf161, buf162, buf164, buf165, buf166, buf167, buf169, buf170, buf172, buf173, buf175, buf178, buf180, buf183, buf185, buf188, buf190, buf191, buf192, buf193, buf195, buf196, buf198, buf199, buf200, buf201, buf203, buf204, buf205, buf206, buf208, buf209, buf211, buf212, buf214, buf217, buf219, buf222, buf224, buf225, buf226, buf227, buf229, buf230, buf232, buf233, buf235, buf236, buf238, buf239, buf241, buf242, buf244, buf245, buf247, buf248, buf250, buf251, buf252, buf253, buf255, buf256, buf258, buf259, buf261, buf262, buf264, buf265, buf267, buf268, buf270, buf271, buf273, buf274, buf276, buf277, buf279, buf281, buf282, buf284, buf285, buf287, buf288, buf290, buf291, buf293, buf294, buf296, buf297, buf299, buf300, buf302, buf303, buf305, buf307, buf308, buf310, buf311, buf312, buf313, buf315, buf316, buf317, buf318, buf320, buf321, buf323, buf324, buf326, buf329, buf331, buf334, buf336, buf337, buf339, buf341, buf342, buf344, buf345, buf346, buf347, buf349, buf350, buf351, buf352, buf354, buf355, buf356, buf357, buf359, buf360, buf362, buf363, buf365, buf368, buf370, buf373, buf375, buf378, buf380, buf381, buf383, buf385, buf386, buf388, buf389, buf390, buf391, buf393, buf394, buf395, buf396, buf398, buf399, buf400, buf401, buf403, buf404, buf405, buf406, buf408, buf409, buf411, buf412, buf414, buf417, buf419, buf422, buf424, buf427, buf429, buf432, buf434, buf435, buf437, buf439, buf440, buf442, buf443, buf444, buf445, buf447, buf448, buf449, buf450, buf452, buf453, buf454, buf455, buf457, buf458, buf459, buf460, buf462, buf463, buf464, buf465, buf467, buf468, buf470, buf471, buf473, buf476, buf478, buf481, buf483, buf486, buf488, buf491, buf493, buf496, buf498, buf499, buf501, buf502, buf503, buf504, buf505, buf507, buf510, buf511, buf512, buf513, buf514, buf516, buf519, buf520, buf521, buf522, buf523, buf525, buf528, buf529, buf530, buf531, buf532, buf534, buf537, buf538, buf539, buf540, buf541, buf543, buf546, buf547, buf548, buf549, buf550, buf552, buf553, buf554, buf555, buf556, buf557, buf558, )
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_2 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_3 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_4 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_5 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_6 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_7 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_10 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_11 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_12 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_13 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_14 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_15 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_16 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_17 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_18 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_19 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_20 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_21 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_22 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_23 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_24 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_25 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_26 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_27 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_28 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_29 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_30 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_31 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_32 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_33 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_34 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_35 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_36 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_37 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_38 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_39 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_40 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_41 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_42 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_43 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_44 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_45 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_46 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_47 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_48 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_49 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_50 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_51 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_52 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_53 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_54 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_55 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_56 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_57 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_58 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_59 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_60 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_61 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_62 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_63 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_64 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_65 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_66 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_67 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_68 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_69 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_70 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_71 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_72 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_73 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_74 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_75 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_76 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_77 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_78 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_79 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_80 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_81 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_82 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_83 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_84 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_85 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_86 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_87 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_88 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_89 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_90 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_91 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_92 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_93 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_94 = rand_strided((32, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_95 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_96 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_97 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_98 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_99 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_100 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_101 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_102 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_103 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_104 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_105 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_106 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_107 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_108 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_109 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_110 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_111 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_112 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_113 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_114 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_115 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_116 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_117 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_118 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_119 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_120 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_121 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_122 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_123 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_124 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_125 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_126 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_127 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_128 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_129 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_130 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_131 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_132 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_133 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_134 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_135 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_136 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_137 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_138 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_139 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_140 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_141 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_142 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_143 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_144 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_145 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_146 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_147 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_148 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_149 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_150 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_151 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_152 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_153 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_154 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_155 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_156 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_157 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_158 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_159 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_160 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_161 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_162 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_163 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_164 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_165 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_166 = rand_strided((64, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_167 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_168 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_169 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_170 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_171 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_172 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_173 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_174 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_175 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_176 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_177 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_178 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_179 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_180 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_181 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_182 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_183 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_184 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_185 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_186 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_187 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_188 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_189 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_190 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_191 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_192 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_193 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_194 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_195 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_196 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_197 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_198 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_199 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_200 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_201 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_202 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_203 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_204 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_205 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_206 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_207 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_208 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_209 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_210 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_211 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_212 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_213 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_214 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_215 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_216 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_217 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_218 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_219 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_220 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_221 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_222 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_223 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_224 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_225 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_226 = rand_strided((128, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_227 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_228 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_229 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_230 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_231 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_232 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_233 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_234 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_235 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_236 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_237 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_238 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_239 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_240 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_241 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_242 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_243 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_244 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_245 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_246 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_247 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_248 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_249 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_250 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_251 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_252 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_253 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_254 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_255 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_256 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_257 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_258 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_259 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_260 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_261 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_262 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_263 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_264 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_265 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_266 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_267 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_268 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_269 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_270 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_271 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_272 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_273 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_274 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_275 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_276 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_277 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_278 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_279 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_280 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_281 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_282 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_283 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_284 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_285 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_286 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_287 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_288 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_289 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_290 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_291 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_292 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_293 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_294 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_295 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_296 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_297 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_298 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_299 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_300 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_301 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_302 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_303 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_304 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_305 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_306 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_307 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_308 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_309 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_310 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_311 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_312 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_313 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_314 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_315 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_316 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_317 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_318 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_319 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_320 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_321 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_322 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_323 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_324 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_325 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_326 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_327 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_328 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_329 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_330 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_331 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_332 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_333 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_334 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_335 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_336 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_337 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_338 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_339 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_340 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_341 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_342 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_343 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_344 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_345 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_346 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_347 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_348 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_349 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_350 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_351 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_352 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_353 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_354 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_355 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_356 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_357 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_358 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_359 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_360 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_361 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_362 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_363 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_364 = rand_strided((512, 1024, 3, 3), (9216, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_365 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_366 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_367 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_368 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_369 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_370 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_371 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_372 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_373 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_374 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_375 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_376 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_377 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_378 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_379 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_380 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_381 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_382 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_383 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_384 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_385 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_386 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_387 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_388 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_389 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_390 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_391 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_392 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_393 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_394 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_395 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_396 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_397 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_398 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_399 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_400 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_401 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_402 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_403 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_404 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_405 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_406 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_407 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_408 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_409 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_410 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_411 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_412 = rand_strided((256, 1024, 3, 3), (9216, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_413 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_414 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_415 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_416 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_417 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_418 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_419 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_420 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_421 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_422 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_423 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_424 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_425 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_426 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_427 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_428 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_429 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_430 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_431 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_432 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_433 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_434 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_435 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_436 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_437 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_438 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_439 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_440 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_441 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_442 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_443 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_444 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_445 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_446 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_447 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_448 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_449 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_450 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_451 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_452 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_453 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_454 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_455 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_456 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_457 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_458 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_459 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_460 = rand_strided((128, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_461 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_462 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_463 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_464 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_465 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_466 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_467 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_468 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_469 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_470 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_471 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_472 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_473 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_474 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_475 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_476 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_477 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_478 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_479 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_480 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_481 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_482 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_483 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_484 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_485 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_486 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_487 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_488 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_489 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_490 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_491 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_492 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_493 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_494 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_495 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_496 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_497 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_498 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_499 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_500 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_501 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_502 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_503 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_504 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_505 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_506 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_507 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_508 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_509 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_510 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_511 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_512 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_513 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_514 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_515 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_516 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_517 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_518 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_519 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_520 = rand_strided((64, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_521 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_522 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_523 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_524 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_525 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_526 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_527 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_528 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_529 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_530 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_531 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_532 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_533 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_534 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_535 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_536 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_537 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_538 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_539 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_540 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_541 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_542 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_543 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_544 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_545 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_546 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_547 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_548 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_549 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_550 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_551 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_552 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_553 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_554 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_555 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_556 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_557 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_558 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_559 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_560 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_561 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_562 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_563 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_564 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_565 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_566 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_567 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_568 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_569 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_570 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_571 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_572 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_573 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_574 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_575 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_576 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_577 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_578 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_579 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_580 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_581 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_582 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_583 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_584 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_585 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_586 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_587 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_588 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_589 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_590 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_591 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_592 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_593 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_594 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_595 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_596 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_597 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_598 = rand_strided((16, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_599 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_600 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_601 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_602 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_603 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_604 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_605 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_606 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_607 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_608 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_609 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_610 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_611 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_612 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_613 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_614 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_615 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_616 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_617 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_618 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_619 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_620 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_621 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_622 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_623 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_624 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_625 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_626 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_627 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_628 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_629 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_630 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_631 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_632 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_633 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_634 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_635 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_636 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_637 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_638 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_639 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_640 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_641 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_642 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_643 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_644 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_645 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_646 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_647 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_648 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_649 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_650 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_651 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_652 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_653 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_654 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_655 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_656 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_657 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_658 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_659 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_660 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_661 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_662 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_663 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_664 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_665 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_666 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_667 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_668 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_669 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_670 = rand_strided((64, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_671 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_672 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_673 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_674 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_675 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_676 = rand_strided((1, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_677 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_678 = rand_strided((1, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_679 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_680 = rand_strided((1, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_681 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_682 = rand_strided((1, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_683 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_684 = rand_strided((1, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_685 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_686 = rand_strided((1, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_687 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687])
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 13:52:54.154000 2390417 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 13:52:54.386000 2390417 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/p3/cp3fngmwyzbe35rnfkvgrxs5y3f5oyvhyibtb26n4dczwjhgux7j.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['6_forward']
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/n4/cn4hrwuln6hsj2n2w475355p5zbjkm3zwbbdzwtg7wvwuvl2c7lo.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hxin], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hxin => convolution
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_1, %primals_2, %primals_3, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_0 = async_compile.triton('triton_poi_fused_convolution_0', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_0(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ps/cpsj56ahxao7bl2knzgijtnohax7ughlnosxgsx6qa4aloq3bj62.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_1, batch_norm, xout], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm => add_1, mul_1, mul_2, sub
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_1 => convolution_1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout => relu
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%convolution, %primals_4, %primals_5, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_1, %unsqueeze_1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, %unsqueeze_3), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_1, %unsqueeze_5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_2, %unsqueeze_7), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_1,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dd/cdd2luabwlku737gxy2abzzcnddgktmr5frh67kyenen6ygfwxlo.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_2, batch_norm_1, xout_1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_1 => add_3, mul_4, mul_5, sub_1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_2 => convolution_2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_1 => relu_1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %primals_10, %primals_11, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_2, %unsqueeze_9), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_1, %unsqueeze_11), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_5 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_4, %unsqueeze_13), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_3 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_5, %unsqueeze_15), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_3,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/l2/cl24z6waopzxpf36qejympec5pm32tod47ep3qeggiykfwxilud3.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx => getitem, getitem_1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_3 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_3', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_3(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bv/cbvw7mz32ydhq5pg2uy3mwch33xrtoyxp2bago3o22nxypthq7ok.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_3, batch_norm_2, xout_2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_2 => add_5, mul_7, mul_8, sub_2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_3 => convolution_3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_2 => relu_2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %primals_16, %primals_17, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_3, %unsqueeze_17), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_2, %unsqueeze_19), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_7, %unsqueeze_21), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_5 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_8, %unsqueeze_23), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_5,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/te/cte4gqdyrzaaflsmzvkr7zsamkmw7f3del56dhewyygbqjza576r.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_1], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_1 => getitem_2, getitem_3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_2 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_1, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_1, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_5 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_5', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_5(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/s3/cs3bytq7ptfg7m5pga47bdf4qgcxi647k4butflxcdueihjurv3s.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_4, batch_norm_3, xout_3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_3 => add_7, mul_10, mul_11, sub_3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_4 => convolution_4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_3 => relu_3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %primals_22, %primals_23, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_4, %unsqueeze_25), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_10 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_3, %unsqueeze_27), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_11 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_10, %unsqueeze_29), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_7 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_11, %unsqueeze_31), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_7,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/jq/cjqauidmifhowptdb6atpxelzdzfcwojxpoxaav57f4whuydchbh.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_2], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_2 => getitem_4, getitem_5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_4 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_2, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_2, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_7 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_7', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_7(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fk/cfk6462nwe25mxsqvxpld2cgf7az4phgi3o3g7ijjw7r5c5oj672.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_5, batch_norm_4, xout_4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_4 => add_9, mul_13, mul_14, sub_4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_5 => convolution_5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_4 => relu_4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %primals_28, %primals_29, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_5, %unsqueeze_33), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_4, %unsqueeze_35), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_13, %unsqueeze_37), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_14, %unsqueeze_39), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_9,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sj/csjy3rs4vwvfhlnl37fdizoxfahbmwzs4ecrpetvq7mivj6qpdcs.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_3], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_3 => getitem_6, getitem_7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_6 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_3, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_7 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_3, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_9 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_9', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_9', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_9(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/e4/ce4guxx3nqprzez22pwxdqps7nxkcb6yhw6redpbn3m3iruvrxlp.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_6, batch_norm_5, xout_5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_5 => add_11, mul_16, mul_17, sub_5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_6 => convolution_6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_5 => relu_5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %primals_34, %primals_35, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_5 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_6, %unsqueeze_41), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_16 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_5, %unsqueeze_43), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_17 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_16, %unsqueeze_45), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_11 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_17, %unsqueeze_47), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_11,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/hk/chkealec3cvaznzjbsnaihbf6ip6exzkqbzfg2fiym6rocxyygxz.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_4], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_4 => getitem_8, getitem_9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_8 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_4, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_9 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_4, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_11 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_11', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_11', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_11(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/24/c24yaahxaotjirvbua5ytcw4pdkouwhrnbdquad2pxcsr47ft5ap.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_7, batch_norm_6, xout_6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_6 => add_13, mul_19, mul_20, sub_6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_7 => convolution_7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_6 => relu_6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %primals_40, %primals_41, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_6 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_7, %unsqueeze_49), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_19 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_6, %unsqueeze_51), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_20 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_19, %unsqueeze_53), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_13 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_20, %unsqueeze_55), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_13,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vy/cvybkhuxoxcmma7ngxlakt6tovr2qzsg3wzprz53y5wzjpyykabm.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_8 => convolution_8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %primals_46, %primals_47, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_13 = async_compile.triton('triton_poi_fused_convolution_13', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_13', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_13(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ki/ckiwfsfgaddbg6fy2xkk4hocx5p5uyddmmpwckdm4ihdo4ckojzn.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_5], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_5 => cat
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_7, %relu_6], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_14 = async_compile.triton('triton_poi_fused_cat_14', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_14', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_14(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (32*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (32*x1 + ((-32) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qc/cqccxiwkiljud3bniroeq5rzv7yugfonbqsv65vrfh2zypuogvs2.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => convert_element_type_19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_19 : [num_users=21] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_15 = async_compile.triton('triton_poi_fused__to_copy_15', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_15(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/k7/ck7wg54iui5c4lyvh2we6r5hz5oknw7usc4xqi3qc465so3kj6ev.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => add_19, clamp_max
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_19 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_19, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_19, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_16 = async_compile.triton('triton_poi_fused_add_clamp_16', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_16(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xj/cxjwtsrvz6c4jeilnwn3wtwvchxqzkclfmkdd2bjn2b2zcfuofd4.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => add_18, clamp_max_2, clamp_min, clamp_min_2, convert_element_type_18, iota, mul_27, sub_11, sub_9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (2,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_18 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_18 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_18, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_27 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_9 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_27, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_9, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_11 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min, %convert_element_type_21), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_2 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_11, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_2 : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_2, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/hk/chkicmfgtdjr22sjpzexxlgxj3d7vwhyq5rhfq7jxfvh7rrj7zl4.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src => _unsafe_index, _unsafe_index_1, add_22, mul_29, sub_12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_8, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_1 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_8, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_12 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_1, %_unsafe_index), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_12, %clamp_max_2), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_22 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index, %mul_29), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_18 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_18', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_18(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ed/ced563w6eutysah4chmsggvmjterfnbhtdbczolzosskf7cdebxj.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_6], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_6 => cat_1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_1 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_24, %relu_5], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_19 = async_compile.triton('triton_poi_fused_cat_19', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_19(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 128*x3), tmp4 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (32*x3 + (x2)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-32) + x2) + 128*x3), tmp30 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fx/cfxbjodzh2dkxqz27xqawrecnl7poaofdbwkyqnqxc2eipjkxcen.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => convert_element_type_25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_25 : [num_users=21] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_2, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_20 = async_compile.triton('triton_poi_fused__to_copy_20', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_20(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/hx/chx57dhjee4zplvovoki5ka2gewhg3mae2vag2qwyasia6zt7gfi.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => add_28, clamp_max_4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_28 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_25, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_4 : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_28, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_21 = async_compile.triton('triton_poi_fused_add_clamp_21', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_21(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.minimum(tmp10, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp11, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7f/c7fjia67jmgqw3y6hgjsetmbdjnkpt6rfxxfkmmxqkdbj6udxg2s.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => add_27, clamp_max_6, clamp_min_4, clamp_min_6, convert_element_type_24, iota_2, mul_35, sub_17, sub_19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_2 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (4,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_24 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_2, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_27 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_24, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_35 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_27, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_17 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_35, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_4 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_17, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_4, %convert_element_type_27), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_6 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_19, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_6 : [num_users=19] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_6, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qe/cqebg3ezq3pnopm3tipawtkerhmo2seyoelgiarndvw4aoo5fqlm.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_1 => _unsafe_index_4, _unsafe_index_5, add_31, mul_37, sub_20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_4 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_9, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_5 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_9, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_20 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_5, %_unsafe_index_4), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_37 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_20, %clamp_max_6), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_31 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_4, %mul_37), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_23 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_23', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_23(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sz/csz2nkkakcpbe46dun346pdkca4byzakptkzscd2asrpdrebe2za.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_7], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_7 => cat_2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_2 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_33, %relu_4], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_24 = async_compile.triton('triton_poi_fused_cat_24', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_24', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_24(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 512*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 128*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 128*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-32) + x2) + 512*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/em/cemi7um2z3fkueru4f36t7cd35dorztv3ka53pib5rdthnhijj7r.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => convert_element_type_31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_31 : [num_users=17] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_4, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_25 = async_compile.triton('triton_poi_fused__to_copy_25', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_25', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_25(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fp/cfp6jeb7ig365an2aqmqtwrklya4pbiis7x3fedtdoeg2dv7orjb.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => add_37, clamp_max_8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_37 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_31, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_8 : [num_users=15] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_37, 3), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_26 = async_compile.triton('triton_poi_fused_add_clamp_26', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_26', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_26(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 3, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/hv/chvli3k2ywfws7qqeojtkyholsq4cpeulqccwr4k527spvtsk6ac.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => add_36, clamp_max_10, clamp_min_10, clamp_min_8, convert_element_type_30, iota_4, mul_43, sub_25, sub_27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_4 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (8,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_30 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_4, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_36 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_30, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_43 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_36, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_25 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_43, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_8 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_25, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_27 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_8, %convert_element_type_33), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_10 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_27, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_10 : [num_users=15] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_10, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0,), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vp/cvpg4it72drineydhg34sxzhijf6p7ctuddzvecmibe4ob4pxiaw.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_2 => _unsafe_index_8, _unsafe_index_9, add_40, mul_45, sub_28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_8 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_10, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_9 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_10, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_28 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_9, %_unsafe_index_8), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_45 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_28, %clamp_max_10), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_40 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_8, %mul_45), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_28 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_28', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_28', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_28(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fw/cfwu76k36hc7m66w7n6pz7ohkyh7qwhdndscoklf6ffqbb6tgznb.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_8], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_8 => cat_3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_3 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_42, %relu_3], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_29 = async_compile.triton('triton_poi_fused_cat_29', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_29', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_29(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 2048*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-32) + x2) + 2048*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ka/ckat4dzxkbv6zu5qbb3dmo3b3udf75n2shxy3mms2mwmszj4njyn.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => convert_element_type_37
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_37 : [num_users=13] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_6, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_30 = async_compile.triton('triton_poi_fused__to_copy_30', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_30', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_30(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/6w/c6wnohbmkw3hxjgxk2j3rvnq6byg3fop7asafdg4spxmcmgvzhzs.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => add_46, clamp_max_12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_46 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_37, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_12 : [num_users=11] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_46, 7), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_31 = async_compile.triton('triton_poi_fused_add_clamp_31', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_31', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_31(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 7, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/df/cdfsoali4vp7id6olba5cf6a33x5umpcbhtnri6hm7xpn4r6jwuv.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => add_45, clamp_max_14, clamp_min_12, clamp_min_14, convert_element_type_36, iota_6, mul_51, sub_33, sub_35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_6 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (16,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_36 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_6, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_45 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_36, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_51 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_45, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_33 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_51, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_12 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_33, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_35 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_12, %convert_element_type_39), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_14 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_35, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_14 : [num_users=11] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_14, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5g/c5gwfhqnvvcu2mazt7b4vj2pjp7flrhdebumcshl5tgo4pdujeyr.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_3 => _unsafe_index_12, _unsafe_index_13, add_49, mul_53, sub_36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_12 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_11, [None, None, %convert_element_type_37, %convert_element_type_39]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_13 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_11, [None, None, %convert_element_type_37, %clamp_max_13]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_36 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_13, %_unsafe_index_12), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_53 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_36, %clamp_max_14), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_49 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_12, %mul_53), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_33 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_33', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_33', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_33(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/zr/czrcn7h7ij7zuxux4mkob6x3vbabreuvbr7vo4cyi6i52ckawg25.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_9], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_9 => cat_4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_4 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_51, %relu_2], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_34 = async_compile.triton('triton_poi_fused_cat_34', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_34', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_34(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 256) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 256*(x2) + 8192*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 8, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 8*tmp10 + 64*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 8*tmp10 + 64*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 256*((-32) + x2) + 8192*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/c3/cc36kii3ooqjvk7wch3emv4bmfx4t7dmlxot7mzwio2onizczn2i.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => convert_element_type_43
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_43 : [num_users=9] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_8, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_35 = async_compile.triton('triton_poi_fused__to_copy_35', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_35', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_35(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/w7/cw77wo73fvmq62s2sbbxmtp454gc2pj6ffvoq6evwhuc47nv2wrx.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => add_55, clamp_max_16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_55 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_43, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_16 : [num_users=7] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_55, 15), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_36 = async_compile.triton('triton_poi_fused_add_clamp_36', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_36', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_36(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 15, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5x/c5xsj2g4rgsnc4wstdbgnonxevb5at2ilfhmvolsqgras7xpefz7.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => add_54, clamp_max_18, clamp_min_16, clamp_min_18, convert_element_type_42, iota_8, mul_59, sub_41, sub_43
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_8 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (32,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_42 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_8, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_54 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_42, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_59 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_54, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_41 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_59, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_16 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_41, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_43 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_16, %convert_element_type_45), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_18 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_43, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_18 : [num_users=7] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_18, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/gg/cggltkplr2gbesssmcbqlax7vgojsbucofrzdw7vavuamkp5givs.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_4 => _unsafe_index_16, _unsafe_index_17, add_58, mul_61, sub_44
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_16 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_12, [None, None, %convert_element_type_43, %convert_element_type_45]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_17 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_12, [None, None, %convert_element_type_43, %clamp_max_17]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_44 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_17, %_unsafe_index_16), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_44, %clamp_max_18), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_58 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_16, %mul_61), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_38 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_38', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_38', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_38(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qt/cqtppf2pm5lqre4r75eyyw2tnawntabwl3urbov6nwhxpt2ymoye.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_10], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_10 => cat_5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_5 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_60, %relu_1], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_39 = async_compile.triton('triton_poi_fused_cat_39', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_39', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_39(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 1024) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 1024)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 1024*(x2) + 32768*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 16, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 16*tmp10 + 256*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 16*tmp10 + 256*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 1024*((-32) + x2) + 32768*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/gq/cgqpe4itjdx2iaixlelaufylfuxl5kssrqncxcaqanwpqpfemikl.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_14, batch_norm_13, xout_13, hx1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_13 => add_62, mul_65, mul_66, sub_48
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_14 => convolution_14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx1 => add_63
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_13 => relu_13
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_14 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_5, %primals_82, %primals_83, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_48 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_14, %unsqueeze_105), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_65 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_48, %unsqueeze_107), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_66 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_65, %unsqueeze_109), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_62 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_66, %unsqueeze_111), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_13 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_62,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_63 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_13, %relu), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ic/cicmum7lhyk46sryutafwofdwpaxize267xb642pt6nuqkeaq75t.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_11], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_11 => getitem_10, getitem_11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_10 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_5, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_41 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_41', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_41', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_41(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sp/csphgofodssoibkjnktbbnkxfw2xuhsu2x2s2pa7u6gesg3qkryi.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_15, batch_norm_14, xout_14], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_14 => add_65, mul_68, mul_69, sub_49
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_15 => convolution_15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_14 => relu_14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_15 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %primals_88, %primals_89, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_49 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_15, %unsqueeze_113), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_68 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_49, %unsqueeze_115), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_69 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_68, %unsqueeze_117), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_65 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_69, %unsqueeze_119), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_14 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_65,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7h/c7hzimjdqyaux6zlzwslkwvu2ljwo5ufgfgtic3p7y4vubigyzjk.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_26, batch_norm_25, xout_25, hx2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_25 => add_115, mul_121, mul_122, sub_88
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_26 => convolution_26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx2 => add_116
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_25 => relu_25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_10, %primals_154, %primals_155, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_88 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_26, %unsqueeze_201), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_121 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_88, %unsqueeze_203), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_122 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_121, %unsqueeze_205), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_115 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_122, %unsqueeze_207), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_115,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_116 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_25, %relu_14), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3h/c3hulvoujd4rg4skthrp6zn5z6llkghsxnctsngitozth3msvi6v.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_21], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_21 => getitem_20, getitem_21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_20 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_10, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_10, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_44 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_44', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_44', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_44(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/o3/co3pnvtugfpykkfw2ag3kbv3hcasdz5nqyiv76qjj25fsbxsypqt.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_27, batch_norm_26, xout_26], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_26 => add_118, mul_124, mul_125, sub_89
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_27 => convolution_27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_26 => relu_26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_20, %primals_160, %primals_161, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_89 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_27, %unsqueeze_209), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_124 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_89, %unsqueeze_211), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_125 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_124, %unsqueeze_213), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_118 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_125, %unsqueeze_215), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_118,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xs/cxs2mcuj2divobeij3hd7vc4zxjlaraofvgivu5ruunabbhvp6ew.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_28, batch_norm_27, xout_27], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_27 => add_120, mul_127, mul_128, sub_90
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_28 => convolution_28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_27 => relu_27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_26, %primals_166, %primals_167, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_90 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_28, %unsqueeze_217), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_127 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_90, %unsqueeze_219), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_128 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_127, %unsqueeze_221), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_120 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_128, %unsqueeze_223), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_27 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_120,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xu/cxuqrtfuvyvng2kpvxr47n4qjkrsdg453xkb65weg32a4fc2m7x4.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_22], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_22 => getitem_22, getitem_23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_22 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_11, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_11, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_47 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_47', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_47', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_47(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/6o/c6owx6kdd26w6j2dob2mznfnlva2we7ajxl2kov4hevat7cal7aw.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_29, batch_norm_28, xout_28], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_28 => add_122, mul_130, mul_131, sub_91
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_29 => convolution_29
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_28 => relu_28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_29 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_22, %primals_172, %primals_173, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_91 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_29, %unsqueeze_225), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_130 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_91, %unsqueeze_227), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_131 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_130, %unsqueeze_229), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_122 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_131, %unsqueeze_231), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_122,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5j/c5jfammzrd5mw7rbqbw7fmw55klu3in7jw3a3o6mv2ln3n5rkd46.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_23], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_23 => getitem_24, getitem_25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_24 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_12, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_12, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_49 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_49', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_49', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_49(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/mu/cmuid2yzythokzkzobyyasmdl3cmgxbdwwrejehwcdtxemyeri46.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_30, batch_norm_29, xout_29], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_29 => add_124, mul_133, mul_134, sub_92
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_30 => convolution_30
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_29 => relu_29
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_30 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_24, %primals_178, %primals_179, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_92 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_30, %unsqueeze_233), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_133 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_92, %unsqueeze_235), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_134 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_133, %unsqueeze_237), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_124 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_134, %unsqueeze_239), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_29 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_124,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/et/cetjyjmgszeejve5uujd4y7dxz25b5rdswgnq4m5zvt6nfchvmib.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_24], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_24 => getitem_26, getitem_27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_26 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_13, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_13, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_51 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_51', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_51', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_51(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/6y/c6yzc3p5s3lhis73kmzbp6ld6yxnpsh57y4hkiyximy4sp4b4wvg.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_31, batch_norm_30, xout_30], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_30 => add_126, mul_136, mul_137, sub_93
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_31 => convolution_31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_30 => relu_30
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_31 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_26, %primals_184, %primals_185, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_93 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_31, %unsqueeze_241), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_136 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_93, %unsqueeze_243), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_137 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_136, %unsqueeze_245), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_126 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_137, %unsqueeze_247), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_30 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_126,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dy/cdynxj5e3hzsqwau7x4mnh4mrvqjse2qfinnebrksmfykewo4ip4.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_32], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_32 => convolution_32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_32 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_30, %primals_190, %primals_191, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_53 = async_compile.triton('triton_poi_fused_convolution_53', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_53', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_53(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bz/cbzkmfuxaxg3ghfgg5vyblgt5xpwuqdkkuclytlzvn5qipnjaddm.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_25], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_25 => cat_11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_11 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_31, %relu_30], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_54 = async_compile.triton('triton_poi_fused_cat_54', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_54', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_54(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 128
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (64*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (64*x1 + ((-64) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/jf/cjfkyye2ztm2ilgvvdnrxc5ywv4b7lww5rdmlanl6x4zbz66udar.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_9], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_9 => _unsafe_index_36, _unsafe_index_37, add_135, mul_146, sub_99
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_36 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_32, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_37 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_32, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_99 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_37, %_unsafe_index_36), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_146 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_99, %clamp_max_2), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_135 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_36, %mul_146), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_55 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_55', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_55', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_55(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/z2/cz2etme3o6ldjjnqd6qcomb2w5wkul7hsmjlx3yodprriozw2jdc.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_26], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_26 => cat_12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_12 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_137, %relu_29], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_56 = async_compile.triton('triton_poi_fused_cat_56', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_56', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_56(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 256*x3), tmp4 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (64*x3 + (x2)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-64) + x2) + 256*x3), tmp30 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vs/cvsint74kx3dbtntzypne3da7p4ari3kd5w642xv4wjn7hh6vunh.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_10], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_10 => _unsafe_index_40, _unsafe_index_41, add_144, mul_154, sub_107
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_40 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_33, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_41 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_33, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_107 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_41, %_unsafe_index_40), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_154 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_107, %clamp_max_6), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_144 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_40, %mul_154), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_57 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_57', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_57', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_57(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/v4/cv42hpt5cwkg4j3vmi3dmuzfwnenybxqlzmydfja3h2yg5zvfb7v.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_27], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_27 => cat_13
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_13 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_146, %relu_28], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_58 = async_compile.triton('triton_poi_fused_cat_58', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_58', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_58(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 1024*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-64) + x2) + 1024*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/g2/cg24uf24eb3yarnhupxidnj6bjqc5u52hn7zm4chtdh4rbalwt4w.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_11], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_11 => _unsafe_index_44, _unsafe_index_45, add_153, mul_162, sub_115
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_44 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_34, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_45 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_34, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_115 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_45, %_unsafe_index_44), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_162 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_115, %clamp_max_10), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_153 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_44, %mul_162), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_59 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_59', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_59', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_59(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/b7/cb7eqfpswkfcmxhxgsxxuz5wf6ryf2zbkjf56a5nqzc545iplgff.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_28], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_28 => cat_14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_14 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_155, %relu_27], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_60 = async_compile.triton('triton_poi_fused_cat_60', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_60', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_60(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 4096*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-64) + x2) + 4096*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fq/cfqohs3m2ag2annqfm2sjuj5antkf2pdifkpp6nxthgx2ryzsgg6.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_36, batch_norm_35, xout_35, hx3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_35 => add_157, mul_166, mul_167, sub_119
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_36 => convolution_36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx3 => add_158
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_35 => relu_35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_36 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_14, %primals_214, %primals_215, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_119 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_36, %unsqueeze_281), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_166 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_119, %unsqueeze_283), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_167 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_166, %unsqueeze_285), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_157 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_167, %unsqueeze_287), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_35 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_157,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_158 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_35, %relu_26), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bq/cbqcoaunyj3zpfycfw27mxpvgis2moialoorqsja4e6vnnsnee3o.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_29], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_29 => getitem_28, getitem_29
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_28 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_14, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_14, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_62 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_62', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_62', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_62(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sk/cskhbw7vfjjh2d22twzswlm6vvdxme5l7oj5m452xdubx3b37rgl.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_37, batch_norm_36, xout_36], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_36 => add_160, mul_169, mul_170, sub_120
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_37 => convolution_37
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_36 => relu_36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_37 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_28, %primals_220, %primals_221, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_120 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_37, %unsqueeze_289), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_169 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_120, %unsqueeze_291), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_170 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_169, %unsqueeze_293), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_160 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_170, %unsqueeze_295), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_36 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_160,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/tb/ctboq77ecoz2fj3hdbyjsq7vggtn7xtx5lqpb47eidqwrtqgy62u.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_38, batch_norm_37, xout_37], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_37 => add_162, mul_172, mul_173, sub_121
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_38 => convolution_38
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_37 => relu_37
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_38 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_36, %primals_226, %primals_227, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_121 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_38, %unsqueeze_297), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_172 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_121, %unsqueeze_299), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_173 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_172, %unsqueeze_301), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_162 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_173, %unsqueeze_303), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_37 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_162,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ek/cek4g3o2inknzfobdzxdhf5ce2n22nhbkn35gpajdgq6i5tpnweu.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_30], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_30 => getitem_30, getitem_31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_30 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_15, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_31 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_15, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_65 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_65', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_65', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_65(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ob/cobr4hvo5fiscpoe2cuiqs5kixwvphidpbinmezqq5cwb5kmgf3z.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_39, batch_norm_38, xout_38], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_38 => add_164, mul_175, mul_176, sub_122
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_39 => convolution_39
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_38 => relu_38
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_39 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_30, %primals_232, %primals_233, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_122 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_39, %unsqueeze_305), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_175 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_122, %unsqueeze_307), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_176 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_175, %unsqueeze_309), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_164 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_176, %unsqueeze_311), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_38 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_164,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dc/cdcvhcurqyyzal6xf5plx2onzjxt3affbfmhylv3cqbnxjwhyoyj.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_31], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_31 => getitem_32, getitem_33
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_32 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_16, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_33 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_16, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_67 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_67', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_67', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_67(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7o/c7oi3fswpqzqffukuesj65nghup6sucpigyqyzyjegq32lyr7rtl.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_40, batch_norm_39, xout_39], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_39 => add_166, mul_178, mul_179, sub_123
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_40 => convolution_40
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_39 => relu_39
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_40 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_32, %primals_238, %primals_239, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_123 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_40, %unsqueeze_313), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_178 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_123, %unsqueeze_315), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_179 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_178, %unsqueeze_317), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_166 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_179, %unsqueeze_319), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_39 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_166,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ut/cutpzdmdqefhfygber23sie67pq32lphpsow4q7dcgge5pxaahgz.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_41], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_41 => convolution_41
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_41 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_39, %primals_244, %primals_245, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_69 = async_compile.triton('triton_poi_fused_convolution_69', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_69', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_69(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5r/c5rmnztxebd5trylw3qjvlp5miywfs4autvpmbsf4pzenp2rp25u.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_32], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_32 => cat_15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_15 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_40, %relu_39], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_70 = async_compile.triton('triton_poi_fused_cat_70', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_70', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_70(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (128*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 256, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (128*x1 + ((-128) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qr/cqrsn3ptiawxz37vskkznhzmztx535eb774mkqfqebc6jvj4yerp.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_12], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_12 => _unsafe_index_48, _unsafe_index_49, add_175, mul_188, sub_129
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_48 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_41, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_49 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_41, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_129 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_49, %_unsafe_index_48), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_188 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_129, %clamp_max_2), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_175 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_48, %mul_188), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_71 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_71', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_71', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_71(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/4p/c4pmuey3w75elfd3zuqs75bqb3a73yomyk3tlxmg4d262otiqltr.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_33], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_33 => cat_16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_16 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_177, %relu_38], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_72 = async_compile.triton('triton_poi_fused_cat_72', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_72', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_72(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 512*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (128*x3 + (x2)), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 256, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-128) + x2) + 512*x3), tmp30, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/kx/ckxya6kfzrdrhgv2w3adtmsuj5phzeygieg7ew5g44h4osz2nxn7.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_13], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_13 => _unsafe_index_52, _unsafe_index_53, add_184, mul_196, sub_137
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_52 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_42, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_53 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_42, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_137 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_53, %_unsafe_index_52), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_196 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_137, %clamp_max_6), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_184 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_52, %mul_196), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_73 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_73', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_73', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_73(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ch/cchek4m3mywf74mr7ybxjcu76po3hlseddln5kjqc4uqzxd5ubae.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_34], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_34 => cat_17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_17 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_186, %relu_37], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_74 = async_compile.triton('triton_poi_fused_cat_74', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_74', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_74(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 2048*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 512*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 256, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-128) + x2) + 2048*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sm/csmjx3atuu5sftxrdp3m7nnsln3y3ac5trgrbnrq5vckwxvz5lbo.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_44, batch_norm_43, xout_43, hx4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_43 => add_188, mul_200, mul_201, sub_141
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_44 => convolution_44
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx4 => add_189
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_43 => relu_43
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_44 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_17, %primals_262, %primals_263, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_141 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_44, %unsqueeze_345), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_200 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_141, %unsqueeze_347), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_201 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_200, %unsqueeze_349), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_188 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_201, %unsqueeze_351), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_43 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_188,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_189 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_43, %relu_36), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/cy/ccywaxv2dpmb2xj6ejlrih3ytcwjy6qwnprn3wqbo4b3xcqi3456.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_35], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_35 => getitem_34, getitem_35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_34 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_17, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_35 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_17, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_76 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_76', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_76', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_76(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ql/cqlokdim54hh32hg5cqid524ijmsf7j3epsslcevcfidwrpv2uz4.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_45, batch_norm_44, xout_44], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_44 => add_191, mul_203, mul_204, sub_142
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_45 => convolution_45
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_44 => relu_44
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_45 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_34, %primals_268, %primals_269, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_142 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_45, %unsqueeze_353), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_203 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_142, %unsqueeze_355), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_204 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_203, %unsqueeze_357), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_191 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_204, %unsqueeze_359), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_44 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_191,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qp/cqpsv26ouhkihp4dof4bznz4rjiwblntvaanzsy6gmujn5gl6cnm.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_46, batch_norm_45, xout_45], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_45 => add_193, mul_206, mul_207, sub_143
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_46 => convolution_46
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_45 => relu_45
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_46 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_44, %primals_274, %primals_275, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_143 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_46, %unsqueeze_361), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_206 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_143, %unsqueeze_363), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_207 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_206, %unsqueeze_365), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_193 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_207, %unsqueeze_367), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_45 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_193,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ym/cymqvkhflj3dcsiu6krnjnm2kjlyglggoa7pet6xfuf4euvh7az7.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_49], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_49 => convolution_49
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_49 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_47, %primals_292, %primals_293, [1, 1], [8, 8], [8, 8], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_79 = async_compile.triton('triton_poi_fused_convolution_79', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_79', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_79(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xy/cxywizj77bjqe4jnlfbcf57uhvwtdo3flm2geclbbghlmk3o43u3.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_36], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_36 => cat_18
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_18 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_48, %relu_47], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_80 = async_compile.triton('triton_poi_fused_cat_80', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_80', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_80(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 256, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x0 + 4*(x1) + 1024*x2), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 512, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (x0 + 4*((-256) + x1) + 1024*x2), tmp25, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp29, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/6t/c6t2cntwhd4y3wy2ycapcqjqa7atm2yiwcdurdqzi6xfj4bmaesm.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_52, batch_norm_51, xout_51, hx5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_51 => add_205, mul_224, mul_225, sub_149
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_52 => convolution_52
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx5 => add_206
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_51 => relu_51
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_52 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_20, %primals_310, %primals_311, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_149 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_52, %unsqueeze_409), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_224 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_149, %unsqueeze_411), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_225 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_224, %unsqueeze_413), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_205 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_225, %unsqueeze_415), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_51 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_205,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_206 : [num_users=3] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_51, %relu_44), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3c/c3cfjghqtcivsvfh7ylxmc72w7ytciui7tuvempoigj6xxn2uy4w.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_39], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_39 => getitem_36, getitem_37
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_36 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_18, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_37 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_18, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_82 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_82', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_82', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_82(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/jm/cjmimlrzjavp5s6bzifh6ysvkcsmcwcav2mzwodvmbq6hqpa2rp4.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_53, batch_norm_52, xout_52], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_52 => add_208, mul_227, mul_228, sub_150
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_53 => convolution_53
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_52 => relu_52
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_53 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_36, %primals_316, %primals_317, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_150 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_53, %unsqueeze_417), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_227 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_150, %unsqueeze_419), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_228 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_227, %unsqueeze_421), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_208 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_228, %unsqueeze_423), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_52 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_208,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/uz/cuztlvtnpmsfgc3lhicly6fjketxsxbbcpcx4yuek7lgedhuy2gm.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_54, batch_norm_53, xout_53], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_53 => add_210, mul_230, mul_231, sub_151
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_54 => convolution_54
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_53 => relu_53
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_54 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_52, %primals_322, %primals_323, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_151 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_54, %unsqueeze_425), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_230 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_151, %unsqueeze_427), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_231 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_230, %unsqueeze_429), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_210 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_231, %unsqueeze_431), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_53 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_210,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/te/cterkwxbs2p6ivwxu6pxrbvf43mskkrj7cfloxapyxjl6xvd3652.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_57], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_57 => convolution_57
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_57 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_55, %primals_340, %primals_341, [1, 1], [8, 8], [8, 8], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_85 = async_compile.triton('triton_poi_fused_convolution_85', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_85', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_85(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/jq/cjqpyffgwbduc6btfnay4y2x2y5tps5bibyfca7ltrdzwgggf42k.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_40], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_40 => cat_21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_21 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_56, %relu_55], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_86 = async_compile.triton('triton_poi_fused_cat_86', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_86', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_86(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 256, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (256*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 512, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (256*x1 + ((-256) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/r6/cr6wg72mr5fklln334qmj53ibkokmvnkd4bwwfa7sgytqpvu2zix.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_60, batch_norm_59, xout_59, hx6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_59 => add_222, mul_248, mul_249, sub_157
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_60 => convolution_60
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx6 => add_223
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_59 => relu_59
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_60 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_23, %primals_358, %primals_359, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_157 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_60, %unsqueeze_473), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_248 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_157, %unsqueeze_475), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_249 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_248, %unsqueeze_477), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_222 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_249, %unsqueeze_479), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_59 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_222,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_223 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_59, %relu_52), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp21, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ow/cowtxvt4bzcohqrg4cwcihar3bifphb7otlnx3tuff27eafdceh7.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_14], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_14 => _unsafe_index_56, _unsafe_index_57, add_228, mul_252, sub_161
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_56 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_223, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_57 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_223, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_161 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_57, %_unsafe_index_56), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_252 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_161, %clamp_max_2), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_228 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_56, %mul_252), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_88 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_88', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_88', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_88(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/mc/cmckloig7mkrvttumjufsnusoejqoe2ymplsgmlyk57q3klnj2tn.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_43], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_43 => cat_24
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_24 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_230, %add_206], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_89 = async_compile.triton('triton_poi_fused_cat_89', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_89', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_89(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 1024)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 512, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 2048*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (512*x3 + (x2)), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 1024, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-512) + x2) + 2048*x3), tmp30, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sq/csqqn5oq4tptcrflnblkfkow3smkzod7tjtaoarnwscdkgs7dhil.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_15], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_15 => _unsafe_index_60, _unsafe_index_61, add_252, mul_281, sub_176
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_60 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_247, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_61 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_247, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_176 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_61, %_unsafe_index_60), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_281 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_176, %clamp_max_6), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_252 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_60, %mul_281), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_90 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_90', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_90', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_90(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ac/cacadiy36ql5utfmrhwbgsdxqe2xgtatvjoiumxmpeyapchuk3c7.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_47], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_47 => cat_28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_28 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_254, %add_189], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_91 = async_compile.triton('triton_poi_fused_cat_91', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_91', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_91(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 1024)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 512, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 8192*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 2048*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 1024, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-512) + x2) + 8192*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7n/c7ngc6rurngorexwcscqy24tplaeeagcvzzoknyoitz6fh34glyd.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_69, batch_norm_68, xout_68], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_68 => add_256, mul_285, mul_286, sub_180
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_69 => convolution_69
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_68 => relu_68
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_69 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_28, %primals_412, %primals_413, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_180 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_69, %unsqueeze_545), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_285 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_180, %unsqueeze_547), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_286 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_285, %unsqueeze_549), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_256 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_286, %unsqueeze_551), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_68 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_256,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7u/c7uuq5mt2ue2sas5opo3tjjpveefug2qfl6652g36zth66suhb5g.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_76, batch_norm_75, xout_75, hx4d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_75 => add_284, mul_316, mul_317, sub_201
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_76 => convolution_76
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx4d => add_285
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_75 => relu_75
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_76 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_31, %primals_454, %primals_455, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_201 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_76, %unsqueeze_601), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_316 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_201, %unsqueeze_603), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_317 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_316, %unsqueeze_605), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_284 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_317, %unsqueeze_607), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_75 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_284,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_285 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_75, %relu_68), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/r5/cr5dt5ddfparo3pswkcvvtfzxb3zuofgqrambfacpvljsmvvpzgd.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_18], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_18 => _unsafe_index_72, _unsafe_index_73, add_290, mul_320, sub_205
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_72 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_285, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_73 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_285, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_205 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_73, %_unsafe_index_72), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_320 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_205, %clamp_max_10), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_290 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_72, %mul_320), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_94 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_94', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_94', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_94(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/u2/cu2nbpgfyii777z7fqeyzsmuc6kq32uqtggwnoh3emfnoovlrn42.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_53], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_53 => cat_32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_32 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_292, %add_158], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_95 = async_compile.triton('triton_poi_fused_cat_95', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_95', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_95(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 512)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 256, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 16384*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 512, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-256) + x2) + 16384*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/za/czawambcozfqvd5ttqz25dv73e54fpmn2fo3b4ztlqbljkyyabey.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_77, batch_norm_76, xout_76], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_76 => add_294, mul_324, mul_325, sub_209
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_77 => convolution_77
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_76 => relu_76
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_77 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_32, %primals_460, %primals_461, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_209 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_77, %unsqueeze_609), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_324 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_209, %unsqueeze_611), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_325 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_324, %unsqueeze_613), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_294 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_325, %unsqueeze_615), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_76 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_294,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/do/cdo663hmrcaid557kmkht4cc36pfuiyxmiwqhdiytghxwvtacf6z.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_86, batch_norm_85, xout_85, hx3d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_85 => add_333, mul_366, mul_367, sub_239
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_86 => convolution_86
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx3d => add_334
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_85 => relu_85
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_86 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_36, %primals_514, %primals_515, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_239 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_86, %unsqueeze_681), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_366 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_239, %unsqueeze_683), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_367 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_366, %unsqueeze_685), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_333 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_367, %unsqueeze_687), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_85 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_333,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_334 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_85, %relu_76), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ez/cezbt6oidldwae4nsiks7z4mgfftcmud6vcxwxnikbn3fe3s2eiy.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_22], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_22 => _unsafe_index_88, _unsafe_index_89, add_339, mul_370, sub_243
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_88 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_334, [None, None, %convert_element_type_37, %convert_element_type_39]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_89 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_334, [None, None, %convert_element_type_37, %clamp_max_13]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_243 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_89, %_unsafe_index_88), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_370 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_243, %clamp_max_14), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_339 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_88, %mul_370), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_98 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_98', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_98', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_98(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/z7/cz74gctem4yluwu3isr6f3azaiiarp7ruvdql6ozvrlgvd5bxw3s.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_61], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_61 => cat_37
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_37 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_341, %add_116], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_99 = async_compile.triton('triton_poi_fused_cat_99', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_99', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_99(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 256) % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 256*(x2) + 32768*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 8, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 8*tmp10 + 64*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 8*tmp10 + 64*(x2) + 8192*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 256, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 256*((-128) + x2) + 32768*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xl/cxlwatlvdgwwd32sz6rwigzvjfqzp5zbos5uemi5zdd4xpsnnnsz.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_87, batch_norm_86, xout_86], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_86 => add_343, mul_374, mul_375, sub_247
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_87 => convolution_87
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_86 => relu_86
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_87 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_37, %primals_520, %primals_521, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_247 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_87, %unsqueeze_689), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_374 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_247, %unsqueeze_691), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_375 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_374, %unsqueeze_693), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_343 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_375, %unsqueeze_695), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_86 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_343,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vo/cvoim6mrpwyax5fdmfktpoftii5azib6q2sjlqe6zmmnbi27yee6.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_98, batch_norm_97, xout_97, hx2d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_97 => add_393, mul_427, mul_428, sub_286
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_98 => convolution_98
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx2d => add_394
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_97 => relu_97
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_98 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%cat_42, %primals_586, %primals_587, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_286 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_98, %unsqueeze_777), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_427 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_286, %unsqueeze_779), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_428 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_427, %unsqueeze_781), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_393 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_428, %unsqueeze_783), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_97 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%add_393,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_394 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%relu_97, %relu_86), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 + tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp21, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sm/csmh27hfzbxzsrdocsurozs3zrbmlicpeuhl5dvepy3efionxtxv.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_27], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_27 => _unsafe_index_108, _unsafe_index_109, add_399, mul_431, sub_290
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_108 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_394, [None, None, %convert_element_type_43, %convert_element_type_45]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_109 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%add_394, [None, None, %convert_element_type_43, %clamp_max_17]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_290 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_109, %_unsafe_index_108), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_431 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_290, %clamp_max_18), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_399 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_108, %mul_431), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_102 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_102', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_102', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_102(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dx/cdxc4o3tbo2lnhpprrzer2w4hdcssfuvn4w3q3hdm257frvbltpb.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_71], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_71 => cat_43
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_43 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_401, %add_63], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_103 = async_compile.triton('triton_poi_fused_cat_103', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_103', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_103(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 1024) % 128)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 1024)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 64, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 1024*(x2) + 65536*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 16, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 16*tmp10 + 256*(x2) + 16384*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 16*tmp10 + 256*(x2) + 16384*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 128, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 1024*((-64) + x2) + 65536*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ib/cib2a4nl2kp5blhle7utvozbkoutzgiwy3qgr4dfzcfnhrb57fkf.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_100, batch_norm_99, xout_99], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_99 => add_405, mul_438, mul_439, sub_295
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_100 => convolution_100
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_99 => relu_99
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_100 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_98, %primals_598, %primals_599, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_295 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_100, %unsqueeze_793), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_438 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_295, %unsqueeze_795), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_439 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_438, %unsqueeze_797), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_405 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_439, %unsqueeze_799), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_99 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_405,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 1024) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/x5/cx5spaym3yd4hbtwbhzjfnbgt6rdmmzfkupn4j5tpkydchg5c6j6.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_72], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_72 => getitem_56, getitem_57
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_56 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_28, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_57 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_28, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_105 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_105', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_105', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_105(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x0 + 64*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/yv/cyvewtlmmwy6llhzhmvaz3zx5jlxohjy5233d3oiz7aqgtitkkux.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_101, batch_norm_100, xout_100], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_100 => add_407, mul_441, mul_442, sub_296
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_101 => convolution_101
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_100 => relu_100
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_101 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_56, %primals_604, %primals_605, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_296 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_101, %unsqueeze_801), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_441 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_296, %unsqueeze_803), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_442 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_441, %unsqueeze_805), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_407 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_442, %unsqueeze_807), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_100 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_407,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/b6/cb6qzybl7sqrou3pakbagoskarqvukytibw5phfvirvj3x43cjqe.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_73], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_73 => getitem_58, getitem_59
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_58 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_29, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_59 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_29, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_107 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_107', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_107', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_107(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x0 + 32*x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/s3/cs3c5yadwc4lfhzi6acdrvjxoz6odivcakwwmgp5q4ovdiygdeen.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_102, batch_norm_101, xout_101], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_101 => add_409, mul_444, mul_445, sub_297
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_102 => convolution_102
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_101 => relu_101
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_102 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_58, %primals_610, %primals_611, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_297 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_102, %unsqueeze_809), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_444 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_297, %unsqueeze_811), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_445 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_444, %unsqueeze_813), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_409 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_445, %unsqueeze_815), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_101 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_409,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xt/cxtykhece7d4hwkyd5e2qi25ff7fwbda2dzcglvyoema2cqriovu.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_74], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_74 => getitem_60, getitem_61
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_60 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_30, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_61 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_30, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_109 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_109', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_109', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_109(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x0 + 16*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ga/cgablznykyrpieim3ycde46igievgk2d25uhe545da4777s4zicr.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_103, batch_norm_102, xout_102], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_102 => add_411, mul_447, mul_448, sub_298
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_103 => convolution_103
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_102 => relu_102
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_103 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_60, %primals_616, %primals_617, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_298 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_103, %unsqueeze_817), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_447 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_298, %unsqueeze_819), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_448 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_447, %unsqueeze_821), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_411 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_448, %unsqueeze_823), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_102 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_411,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/to/ctoetwdrio5vyg7gydmb7mff54wpzndlq72jlzpaijaqower2glg.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_75], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_75 => getitem_62, getitem_63
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_62 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_31, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_63 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_31, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_111 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_111', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_111', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_111(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (4 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (5 + 2*x0 + 8*x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qm/cqmonjsoyybfabwiaze5pc2cbe6boimjoutjn4y56553ilfaop5k.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_104, batch_norm_103, xout_103], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_103 => add_413, mul_450, mul_451, sub_299
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_104 => convolution_104
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_103 => relu_103
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_104 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_62, %primals_622, %primals_623, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_299 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_104, %unsqueeze_825), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_450 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_299, %unsqueeze_827), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_451 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_450, %unsqueeze_829), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_413 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_451, %unsqueeze_831), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_103 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_413,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x3), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/2h/c2hhu7evwklmnmrgpiczixql3pncl3zhbodmpbfiawatskvde4en.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_76], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_76 => getitem_64, getitem_65
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_64 : [num_users=2] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_32, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %getitem_65 : [num_users=1] = call_function[target=operator.getitem](args = (%_low_memory_max_pool2d_with_offsets_32, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_max_pool2d_with_indices_113 = async_compile.triton('triton_poi_fused_max_pool2d_with_indices_113', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*i8', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_113', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_max_pool2d_with_indices_113(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 4*x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp1 > tmp0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.full([1], 1, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 0, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp7, tmp8, tmp9)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp3 > tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 2, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp11, tmp12, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp5 > tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.full([1], 3, tl.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp14, tmp15, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp6, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp16, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ea/ceahagj5yuy4n43ii3lcgoiitfnhoyy3izo5e7uuudqrluepzay3.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_105, batch_norm_104, xout_104], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   batch_norm_104 => add_415, mul_453, mul_454, sub_300
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_105 => convolution_105
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   xout_104 => relu_104
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_105 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_64, %primals_628, %primals_629, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_300 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%convolution_105, %unsqueeze_833), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_453 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_300, %unsqueeze_835), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_454 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_453, %unsqueeze_837), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_415 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_454, %unsqueeze_839), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_104 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%add_415,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114 = async_compile.triton('triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 - tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 + tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = libdevice.sqrt(tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 / tmp8
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp4 * tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = triton_helpers.maximum(tmp18, tmp17)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp19, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vo/cvoidv53r7op5l7jaaf23wtmxslujsv425ezovqnj5pgjwc34ykj.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_106], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_106 => convolution_106
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_106 : [num_users=2] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_104, %primals_634, %primals_635, [1, 1], [2, 2], [2, 2], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_115 = async_compile.triton('triton_poi_fused_convolution_115', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_115', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_115(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp2, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5s/c5sdj7gbnczcm4p5y5s5jbcvfixansb2h2rwyideg6dwn4qjwdzc.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_77], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_77 => cat_44
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_44 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%relu_105, %relu_104], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_116 = async_compile.triton('triton_poi_fused_cat_116', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_116', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 6, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_116(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = xindex // 32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (16*x1 + (x0)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 - tmp6
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1e-05
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = libdevice.sqrt(tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp12 / tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 * tmp14
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp7 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 * tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp18 + tmp19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.full([1], 0, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = triton_helpers.maximum(tmp21, tmp20)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.full(tmp22.shape, 0.0, tmp22.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp4, tmp22, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp0 < tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.load(in_ptr5 + (16*x1 + ((-16) + x0)), tmp25 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp24, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp29, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/t2/ct2vdoibxw7tphi4f5nbgzsirbrueny5ygjort4nndiaud5js45k.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_28], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_28 => _unsafe_index_112, _unsafe_index_113, add_424, mul_463, sub_306
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_112 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_106, [None, None, %convert_element_type_19, %convert_element_type_21]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_113 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_106, [None, None, %convert_element_type_19, %clamp_max_1]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_306 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_113, %_unsafe_index_112), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_463 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_306, %clamp_max_2), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_424 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_112, %mul_463), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_117 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_117', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 256}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_117', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_117(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp9 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp14 * tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 + tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp17, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fc/cfcuyonmfdqa7x6kte7ncyeqopon5jhgkdccmgaipen3wj2ohx5v.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_78], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_78 => cat_45
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_45 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_426, %relu_103], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_118 = async_compile.triton('triton_poi_fused_cat_118', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 512}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_118', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_118(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 4) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 128
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 2) % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 2)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 4*(x2) + 64*x3), tmp4 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (16*x3 + (x2)), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp15 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp20 * tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp15 + tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tmp24 * tmp25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp5 + tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.full(tmp27.shape, 0.0, tmp27.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.where(tmp4, tmp27, tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp0 < tmp31
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tl.load(in_ptr7 + (x4 + 4*((-16) + x2) + 64*x3), tmp30 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.where(tmp4, tmp29, tmp33)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp34, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/pg/cpgf654z32gjsipbpjmxbn5o5ebaembv4uudg3rm7gfn3f2k2bjt.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_29], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_29 => _unsafe_index_116, _unsafe_index_117, add_433, mul_471, sub_314
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_116 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_107, [None, None, %convert_element_type_25, %convert_element_type_27]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_117 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_107, [None, None, %convert_element_type_25, %clamp_max_5]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_314 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_117, %_unsafe_index_116), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_471 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_314, %clamp_max_6), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_433 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_116, %mul_471), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_119 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_119', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1024}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_119', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_119(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 2*tmp4 + 4*x2), xmask, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fk/cfkcn3tpbpyyjwb24xgl7jkzog5xa4rhphmihmk6lrgomvmfp2xp.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_79], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_79 => cat_46
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_46 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_435, %relu_102], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_120 = async_compile.triton('triton_poi_fused_cat_120', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2048}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_120', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_120(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 16) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 512
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 4) % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 4)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 16*(x2) + 256*x3), tmp4 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 2*tmp10 + 4*(x2) + 64*x3), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 2*tmp10 + 4*(x2) + 64*x3), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4 & xmask, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 16*((-16) + x2) + 256*x3), tmp31 & xmask, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3d/c3duare2mhd6l3pk5gkovqnl5hepyjbh76mazymqo5uzaxcw3lqp.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_30], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_30 => _unsafe_index_120, _unsafe_index_121, add_442, mul_479, sub_322
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_120 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_108, [None, None, %convert_element_type_31, %convert_element_type_33]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_121 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_108, [None, None, %convert_element_type_31, %clamp_max_9]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_322 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_121, %_unsafe_index_120), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_479 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_322, %clamp_max_10), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_442 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_120, %mul_479), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_121 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_121', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4096}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_121', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_121(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xn/cxnoh53bznxai55m2tsinm2cf4exmef3c5i46hy47vg4bmkjwtsu.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_80], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_80 => cat_47
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_47 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_444, %relu_101], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_122 = async_compile.triton('triton_poi_fused_cat_122', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_122', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_122(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 64) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 2048
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 8) % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 64*(x2) + 1024*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 4*tmp10 + 16*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 4*tmp10 + 16*(x2) + 256*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 64*((-16) + x2) + 1024*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ra/cragqqzzr4bkptao5x5cdhfemlgdhtyqgkfqvcshm2pep7mfbsnw.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_31], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_31 => _unsafe_index_124, _unsafe_index_125, add_451, mul_487, sub_330
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_124 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_109, [None, None, %convert_element_type_37, %convert_element_type_39]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_125 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_109, [None, None, %convert_element_type_37, %clamp_max_13]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_330 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_125, %_unsafe_index_124), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_487 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_330, %clamp_max_14), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_451 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_124, %mul_487), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_123 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_123', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_123', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_123(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 256
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/4k/c4k2qvzjx6lrqhfttd3skwsyewjm325afkkd2ueqdi7uiiamfo3f.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_81], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_81 => cat_48
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_48 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_453, %relu_100], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_124 = async_compile.triton('triton_poi_fused_cat_124', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_124', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_124(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 256) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 8192
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 256)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 16) % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 256*(x2) + 4096*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 8, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 8*tmp10 + 64*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 8*tmp10 + 64*(x2) + 1024*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 256*((-16) + x2) + 4096*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vx/cvxpcifgroy43sopuvg3usjkgo4uy74m224u55rj4jcnmtz4zm7k.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_32], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_32 => _unsafe_index_128, _unsafe_index_129, add_460, mul_495, sub_338
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_128 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_110, [None, None, %convert_element_type_43, %convert_element_type_45]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_129 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%relu_110, [None, None, %convert_element_type_43, %clamp_max_17]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_338 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_129, %_unsafe_index_128), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_495 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_338, %clamp_max_18), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_460 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_128, %mul_495), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_mul_sub_125 = async_compile.triton('triton_poi_fused__unsafe_index_add_mul_sub_125', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*i64', 'in_ptr4': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_mul_sub_125', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_mul_sub_125(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 1024
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp10 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(tmp12, tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.load(in_ptr2 + (tmp13 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp14 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp15 * tmp16
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp9 + tmp17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x4), tmp18, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/gv/cgvwhb5vinranxn5mpmpxup2zymuqgkvvgerb327y65muqhu44xa.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [hx_82], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   hx_82 => cat_49
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat_49 : [num_users=2] = call_function[target=torch.ops.aten.cat.default](args = ([%add_462, %relu_99], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_cat_126 = async_compile.triton('triton_poi_fused_cat_126', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*i64', 'in_ptr2': '*i64', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_cat_126', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_cat_126(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = ((xindex // 1024) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32768
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x4 = (xindex % 1024)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 32) % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 16, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (x4 + 1024*(x2) + 16384*x3), tmp4, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.load(in_ptr1 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.full([XBLOCK], 16, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp6 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.where(tmp9, tmp8, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.load(in_ptr2 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tmp11 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.where(tmp13, tmp12, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tl.load(in_ptr3 + (tmp14 + 16*tmp10 + 256*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.load(in_ptr4 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp16 + tmp7
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp16 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tl.where(tmp18, tmp17, tmp16)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr3 + (tmp19 + 16*tmp10 + 256*(x2) + 4096*x3), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp20 - tmp15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tl.load(in_ptr5 + (x0), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 * tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp15 + tmp23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp24 - tmp5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr6 + (x1), tmp4, eviction_policy='evict_last', other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp5 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.full(tmp28.shape, 0.0, tmp28.dtype)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tl.where(tmp4, tmp28, tmp29)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp0 >= tmp3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.full([1], 32, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp0 < tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tl.load(in_ptr7 + (x4 + 1024*((-16) + x2) + 16384*x3), tmp31, other=0.0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.where(tmp4, tmp30, tmp34)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x5), tmp35, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/mz/cmzspsfl53lkq62tmsqmf6sckigextfto7f3tvsimjyfvv4dj2nn.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => convert_element_type_357
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_357 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_66, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_127 = async_compile.triton('triton_poi_fused__to_copy_127', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_127', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_127(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp8, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/es/cesdunyfxafe6zyboivt3qaqikghgwtzxqvnjew5rctul5es34we.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_467, clamp_max_132
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_467 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_357, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_132 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_467, 31), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_128 = async_compile.triton('triton_poi_fused_add_clamp_128', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_128', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_128(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 + tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.full([1], 31, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp10, tmp11)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/k3/ck3bnkb5r4b2tteb2e7zgyoiqnhnho5l5k4secwfhb4tj7mpdctj.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, clamp_max_134, clamp_min_132, clamp_min_134, convert_element_type_356, iota_66, mul_501, sub_343, sub_345
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_501 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_343 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_501, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_132 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_343, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_345 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_132, %convert_element_type_359), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_134 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_345, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_134 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_134, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp3 * tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp4 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = triton_helpers.maximum(tmp5, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp7.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp7 - tmp9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = triton_helpers.maximum(tmp10, tmp6)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/2w/c2wrr6zlq74z5x4unjhnaujit5k3aeh2zd62av6semagglqfpfau.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d1, src_33, sigmoid], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d1 => convolution_113
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid => sigmoid
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => _unsafe_index_132, _unsafe_index_133, _unsafe_index_134, _unsafe_index_135, add_470, add_471, add_472, mul_503, mul_504, mul_505, sub_346, sub_347, sub_349
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_113 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_465, %primals_676, %primals_677, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_132 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %convert_element_type_357, %convert_element_type_359]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_133 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %convert_element_type_357, %clamp_max_133]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_134 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %clamp_max_132, %convert_element_type_359]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_135 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_113, [None, None, %clamp_max_132, %clamp_max_133]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_346 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_133, %_unsafe_index_132), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_503 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_346, %clamp_max_134), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_470 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_132, %mul_503), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_347 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_135, %_unsafe_index_134), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_504 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_347, %clamp_max_134), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_471 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_134, %mul_504), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_349 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_471, %add_470), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_505 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_349, %clamp_max_135), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_472 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_470, %mul_505), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_472,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 32, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 32*tmp4 + 1024*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 32*tmp4 + 1024*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 32*tmp26 + 1024*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 32*tmp26 + 1024*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/rb/crbuyax4embruyhcvq5hy2rvnj26umvcres3sa6ocoep42hgkfb2.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => convert_element_type_361
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_361 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_68, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_131 = async_compile.triton('triton_poi_fused__to_copy_131', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_131', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_131(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/kh/ckhtyudy7v45qsas6xldlwk6nl222qyqz3bu7ukb4ul4ffxjmalf.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => add_474, clamp_max_136
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_474 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_361, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_136 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_474, 15), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_132 = async_compile.triton('triton_poi_fused_add_clamp_132', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_132', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_132(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 15, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/2o/c2o3uak3a7w2nbijof52m6aqhvbn3niieuwba3sch3h6gorqbq5r.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_34], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => clamp_max_138, clamp_min_136, clamp_min_138, mul_506, sub_350, sub_352
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_506 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.25), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_350 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_506, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_136 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_350, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_352 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_136, %convert_element_type_363), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_138 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_352, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_138 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_138, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.25
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/yf/cyfvaljkvh73e6dbfegqyqohlf3og2ljubkvgmucr6z6or3fefkl.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d2, src_34, sigmoid_1], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d2 => convolution_114
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_1 => sigmoid_1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_34 => _unsafe_index_136, _unsafe_index_137, _unsafe_index_138, _unsafe_index_139, add_477, add_478, add_479, mul_508, mul_509, mul_510, sub_353, sub_354, sub_356
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_114 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_394, %primals_678, %primals_679, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_136 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %convert_element_type_361, %convert_element_type_363]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_137 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %convert_element_type_361, %clamp_max_137]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_138 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %clamp_max_136, %convert_element_type_363]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_139 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_114, [None, None, %clamp_max_136, %clamp_max_137]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_353 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_137, %_unsafe_index_136), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_508 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_353, %clamp_max_138), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_477 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_136, %mul_508), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_354 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_139, %_unsafe_index_138), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_509 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_354, %clamp_max_138), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_478 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_138, %mul_509), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_356 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_478, %add_477), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_510 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_356, %clamp_max_139), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_479 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_477, %mul_510), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_1 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_479,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 16, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 16*tmp4 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 16*tmp26 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 16*tmp26 + 256*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ta/cta46pwyza5zmhitgcwvyy5lkzwf5chm3c4ssita7ddpppru27xh.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => convert_element_type_365
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_365 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_70, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_135 = async_compile.triton('triton_poi_fused__to_copy_135', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_135', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_135(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.125
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fl/cflwhyulkpdpbxbqp2ffxmzppmh2xayg4p5vc7c4oco2huznerxc.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => add_481, clamp_max_140
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_481 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_365, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_140 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_481, 7), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_136 = async_compile.triton('triton_poi_fused_add_clamp_136', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_136', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_136(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.125
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 7, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bj/cbjmo33rd66p5pcj3hbsvbj55aqt2lcw2fh7hximhdhvhnyjiucl.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_35], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => clamp_max_142, clamp_min_140, clamp_min_142, mul_511, sub_357, sub_359
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_511 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.125), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_357 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_511, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_140 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_357, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_359 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_140, %convert_element_type_367), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_142 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_359, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_142 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_142, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.125
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/di/cdifariefpipllqr54rwrlui44h5ntqm7dpnqduxywwwjkclm47d.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d3, src_35, sigmoid_2], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d3 => convolution_115
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_2 => sigmoid_2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_35 => _unsafe_index_140, _unsafe_index_141, _unsafe_index_142, _unsafe_index_143, add_484, add_485, add_486, mul_513, mul_514, mul_515, sub_360, sub_361, sub_363
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_115 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_334, %primals_680, %primals_681, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_140 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %convert_element_type_365, %convert_element_type_367]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_141 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %convert_element_type_365, %clamp_max_141]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_142 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %clamp_max_140, %convert_element_type_367]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_143 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_115, [None, None, %clamp_max_140, %clamp_max_141]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_360 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_141, %_unsafe_index_140), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_513 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_360, %clamp_max_142), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_484 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_140, %mul_513), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_361 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_143, %_unsafe_index_142), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_514 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_361, %clamp_max_142), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_485 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_142, %mul_514), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_363 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_485, %add_484), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_515 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_363, %clamp_max_143), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_486 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_484, %mul_515), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_2 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_486,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 8, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 8*tmp4 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 8*tmp26 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 8*tmp26 + 64*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/c2/cc2voak6ki7wtbvlgzdx4ry4a5aeiiyymq7kiziptxdau4ecsaef.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => convert_element_type_369
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_369 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_72, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_139 = async_compile.triton('triton_poi_fused__to_copy_139', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_139', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_139(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.0625
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/zs/czsuirdgops6fhvgbkhacol6tmsikw5iwvk3haevmbr2yyqrzzfi.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => add_488, clamp_max_144
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_488 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_369, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_144 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_488, 3), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_140 = async_compile.triton('triton_poi_fused_add_clamp_140', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_140', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_140(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.0625
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 3, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qj/cqjzdq4y3lz3mc73hw2gjjoqjcwghmak6sbbuxghkoocb4nivocz.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_36], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => clamp_max_146, clamp_min_144, clamp_min_146, mul_516, sub_364, sub_366
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_516 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.0625), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_364 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_516, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_144 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_364, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_366 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_144, %convert_element_type_371), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_146 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_366, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_146 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_146, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.0625
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/se/cseo6slpldphky2ki7a3ymnj73lxs3mroyx2c2ynecbzomj6fhwv.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d4, src_36, sigmoid_3], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d4 => convolution_116
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_3 => sigmoid_3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_36 => _unsafe_index_144, _unsafe_index_145, _unsafe_index_146, _unsafe_index_147, add_491, add_492, add_493, mul_518, mul_519, mul_520, sub_367, sub_368, sub_370
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_116 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_285, %primals_682, %primals_683, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_144 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %convert_element_type_369, %convert_element_type_371]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_145 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %convert_element_type_369, %clamp_max_145]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_146 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %clamp_max_144, %convert_element_type_371]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_147 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_116, [None, None, %clamp_max_144, %clamp_max_145]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_367 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_145, %_unsafe_index_144), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_518 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_367, %clamp_max_146), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_491 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_144, %mul_518), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_368 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_147, %_unsafe_index_146), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_519 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_368, %clamp_max_146), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_492 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_146, %mul_519), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_370 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_492, %add_491), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_520 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_370, %clamp_max_147), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_493 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_491, %mul_520), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_3 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_493,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 4, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 4*tmp4 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 4*tmp26 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 4*tmp26 + 16*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sc/cscz26acw63oloaf5hfmsskmpl3xxpbh5rx3zasbcgbrjiwxxgox.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => convert_element_type_373
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_373 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_74, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_143 = async_compile.triton('triton_poi_fused__to_copy_143', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_143', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_143(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.03125
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bg/cbgfpt44tadejxrekypvmefx3boiowbfaqxggridn35ztwxjpahe.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => add_495, clamp_max_148
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_495 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_373, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_148 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_495, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_144 = async_compile.triton('triton_poi_fused_add_clamp_144', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_144', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_144(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.03125
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.minimum(tmp11, tmp10)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vu/cvufgz4mwb4lh5c7skothlo2ussz5cokv4vb6hwynookr6dohabb.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_37], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => clamp_max_150, clamp_min_148, clamp_min_150, mul_521, sub_371, sub_373
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_521 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.03125), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_371 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_521, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_148 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_371, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_373 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_148, %convert_element_type_375), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_150 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_373, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_150 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_150, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.03125
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/w6/cw6n3puovd4ohclbhawhrkr74fdeolopuuw6ynktpld73blofwhu.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d5, src_37, sigmoid_4], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d5 => convolution_117
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_4 => sigmoid_4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_37 => _unsafe_index_148, _unsafe_index_149, _unsafe_index_150, _unsafe_index_151, add_498, add_499, add_500, mul_523, mul_524, mul_525, sub_374, sub_375, sub_377
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_117 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_247, %primals_684, %primals_685, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_148 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %convert_element_type_373, %convert_element_type_375]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_149 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %convert_element_type_373, %clamp_max_149]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_150 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %clamp_max_148, %convert_element_type_375]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_151 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_117, [None, None, %clamp_max_148, %clamp_max_149]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_374 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_149, %_unsafe_index_148), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_523 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_374, %clamp_max_150), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_498 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_148, %mul_523), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_375 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_151, %_unsafe_index_150), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_524 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_375, %clamp_max_150), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_499 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_150, %mul_524), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_377 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_499, %add_498), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_525 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_377, %clamp_max_151), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_500 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_498, %mul_525), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_4 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_500,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 2, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (tmp8 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tl.load(in_ptr2 + (tmp16 + 2*tmp4 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tmp17 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 - tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tmp19 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp12 + tmp21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tmp23 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp23 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.where(tmp25, tmp24, tmp23)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tl.load(in_ptr2 + (tmp8 + 2*tmp26 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp27 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.load(in_ptr2 + (tmp16 + 2*tmp26 + 4*x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp30 = tmp29 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp31 = tmp30 - tmp28
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tmp31 * tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp33 = tmp28 + tmp32
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = tmp33 - tmp22
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp34 * tmp35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = tmp22 + tmp36
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tl.sigmoid(tmp37)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp38, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/u3/cu3e2qehtz7zpmz4vmlvgk77xgli5nnmahaemvio24ste7pcjcqf.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => convert_element_type_377
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_377 : [num_users=5] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%view_76, torch.int64), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_147 = async_compile.triton('triton_poi_fused__to_copy_147', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_147', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_147(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.015625
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp9, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/br/cbrapz2ueulb3drb7rvosh77nrpnq5ton4ompp3lrlka2vbljk3y.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => add_502, clamp_max_152
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_502 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_377, 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_152 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%add_502, 0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_148 = async_compile.triton('triton_poi_fused_add_clamp_148', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*i64', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_148', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_148(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.015625
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.full([1], 1, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp9 + tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tl.full([1], 0, tl.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = triton_helpers.minimum(tmp11, tmp12)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp13, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/u4/cu4pq3tp225oz5loxuplcmihsjglbctewthe3cup6pzwgx5irms2.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [src_33, src_38], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_33 => add_466, convert_element_type_356, iota_66
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => clamp_max_154, clamp_min_152, clamp_min_154, mul_526, sub_378, sub_380
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %iota_66 : [num_users=1] = call_function[target=torch.ops.prims.iota.default](args = (64,), kwargs = {start: 0, step: 1, dtype: torch.int64, device: cuda:0, requires_grad: False})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convert_element_type_356 : [num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%iota_66, torch.float32), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_466 : [num_users=6] = call_function[target=torch.ops.aten.add.Tensor](args = (%convert_element_type_356, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_526 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_466, 0.015625), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_378 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_526, 0.5), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_152 : [num_users=3] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_378, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_380 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%clamp_min_152, %convert_element_type_379), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_154 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_380, 0.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_max_154 : [num_users=3] = call_function[target=torch.ops.aten.clamp_max.default](args = (%clamp_min_154, 1.0), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149 = async_compile.triton('triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 64}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = x0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tmp0.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = 0.5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 + tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 0.015625
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 - tmp2
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tmp8.to(tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9.to(tl.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tmp8 - tmp10
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = triton_helpers.maximum(tmp11, tmp7)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = 1.0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = triton_helpers.minimum(tmp12, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp14, xmask)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qn/cqnwm4oznkom5tlbuhy5omly36d2txez7yggvnvvartxbpw3lzpk.py
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [d6, src_38, sigmoid_5], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   d6 => convolution_118
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sigmoid_5 => sigmoid_5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   src_38 => _unsafe_index_152, _unsafe_index_153, _unsafe_index_154, _unsafe_index_155, add_505, add_506, add_507, mul_528, mul_529, mul_530, sub_381, sub_382, sub_384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_118 : [num_users=4] = call_function[target=torch.ops.aten.convolution.default](args = (%add_223, %primals_686, %primals_687, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_152 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %convert_element_type_377, %convert_element_type_379]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_153 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %convert_element_type_377, %clamp_max_153]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_154 : [num_users=2] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %clamp_max_152, %convert_element_type_379]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_unsafe_index_155 : [num_users=1] = call_function[target=torch.ops.aten._unsafe_index.Tensor](args = (%convolution_118, [None, None, %clamp_max_152, %clamp_max_153]), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_381 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_153, %_unsafe_index_152), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_528 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_381, %clamp_max_154), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_505 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_152, %mul_528), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_382 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%_unsafe_index_155, %_unsafe_index_154), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_529 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_382, %clamp_max_154), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_506 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%_unsafe_index_154, %mul_529), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_384 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_506, %add_505), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_530 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub_384, %clamp_max_155), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_507 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add_505, %mul_530), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sigmoid_5 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%add_507,), kwargs = {})
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150 = async_compile.triton('triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150', '''
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*i64', 'in_ptr1': '*i64', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*i64', 'in_ptr5': '*fp32', 'in_ptr6': '*i64', 'in_ptr7': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, xnumel, XBLOCK : tl.constexpr):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex // 4096
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.load(in_ptr2 + (x2), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (0))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK])
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp21 = tl.load(in_ptr6 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp26 = tl.load(in_ptr7 + (x1), None, eviction_policy='evict_last')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.full([XBLOCK], 1, tl.int32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp0 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.where(tmp3, tmp2, tmp0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp5 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp5 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(tmp7, tmp6, tmp5)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp9 + tmp11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tmp13 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = tmp13 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tl.where(tmp15, tmp14, tmp13)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp12 - tmp12
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp17 * tmp18
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp12 + tmp19
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp22 = tmp21 + tmp1
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp23 = tmp21 < 0
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.where(tmp23, tmp22, tmp21)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp25 = tmp20 - tmp20
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp27 = tmp25 * tmp26
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tmp20 + tmp27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp29 = tl.sigmoid(tmp28)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x3), tmp29, None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687 = args
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_1, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_2, (64, 3, 3, 3), (27, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_3, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_4, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_5, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_6, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_7, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_8, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_9, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_10, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_11, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_12, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_13, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_14, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_15, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_16, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_17, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_18, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_19, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_20, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_21, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_22, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_23, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_24, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_25, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_26, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_27, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_28, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_29, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_30, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_31, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_32, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_33, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_34, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_35, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_36, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_37, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_38, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_39, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_40, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_41, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_42, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_43, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_44, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_45, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_46, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_47, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_48, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_49, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_50, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_51, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_52, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_53, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_54, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_55, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_56, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_57, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_58, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_59, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_60, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_61, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_62, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_63, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_64, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_65, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_66, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_67, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_68, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_69, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_70, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_71, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_72, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_73, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_74, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_75, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_76, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_77, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_78, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_79, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_80, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_81, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_82, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_83, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_84, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_85, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_86, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_87, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_88, (128, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_89, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_90, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_91, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_92, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_93, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_94, (32, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_95, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_96, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_97, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_98, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_99, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_100, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_101, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_102, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_103, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_104, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_105, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_106, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_107, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_108, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_109, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_110, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_111, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_112, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_113, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_114, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_115, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_116, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_117, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_118, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_119, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_120, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_121, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_122, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_123, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_124, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_125, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_126, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_127, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_128, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_129, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_130, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_131, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_132, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_133, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_134, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_135, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_136, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_137, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_138, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_139, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_140, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_141, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_142, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_143, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_144, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_145, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_146, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_147, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_148, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_149, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_150, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_151, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_152, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_153, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_154, (128, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_155, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_156, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_157, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_158, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_159, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_160, (256, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_161, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_162, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_163, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_164, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_165, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_166, (64, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_167, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_168, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_169, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_170, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_171, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_172, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_173, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_174, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_175, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_176, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_177, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_178, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_179, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_180, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_181, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_182, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_183, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_184, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_185, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_186, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_187, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_188, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_189, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_190, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_191, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_192, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_193, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_194, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_195, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_196, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_197, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_198, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_199, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_200, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_201, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_202, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_203, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_204, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_205, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_206, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_207, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_208, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_209, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_210, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_211, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_212, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_213, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_214, (256, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_215, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_216, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_217, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_218, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_219, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_220, (512, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_221, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_222, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_223, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_224, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_225, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_226, (128, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_227, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_228, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_229, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_230, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_231, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_232, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_233, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_234, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_235, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_236, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_237, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_238, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_239, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_240, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_241, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_242, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_243, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_244, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_245, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_246, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_247, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_248, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_249, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_250, (128, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_251, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_252, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_253, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_254, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_255, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_256, (128, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_257, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_258, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_259, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_260, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_261, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_262, (512, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_263, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_264, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_265, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_266, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_267, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_268, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_269, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_270, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_271, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_272, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_273, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_274, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_275, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_276, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_277, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_278, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_279, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_280, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_281, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_282, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_283, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_284, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_285, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_286, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_287, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_288, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_289, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_290, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_291, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_292, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_293, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_294, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_295, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_296, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_297, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_298, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_299, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_300, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_301, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_302, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_303, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_304, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_305, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_306, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_307, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_308, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_309, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_310, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_311, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_312, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_313, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_314, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_315, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_316, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_317, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_318, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_319, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_320, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_321, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_322, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_323, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_324, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_325, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_326, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_327, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_328, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_329, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_330, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_331, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_332, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_333, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_334, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_335, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_336, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_337, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_338, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_339, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_340, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_341, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_342, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_343, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_344, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_345, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_346, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_347, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_348, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_349, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_350, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_351, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_352, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_353, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_354, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_355, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_356, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_357, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_358, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_359, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_360, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_361, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_362, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_363, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_364, (512, 1024, 3, 3), (9216, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_365, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_366, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_367, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_368, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_369, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_370, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_371, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_372, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_373, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_374, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_375, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_376, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_377, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_378, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_379, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_380, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_381, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_382, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_383, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_384, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_385, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_386, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_387, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_388, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_389, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_390, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_391, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_392, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_393, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_394, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_395, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_396, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_397, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_398, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_399, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_400, (256, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_401, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_402, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_403, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_404, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_405, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_406, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_407, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_408, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_409, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_410, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_411, (512, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_412, (256, 1024, 3, 3), (9216, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_413, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_414, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_415, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_416, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_417, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_418, (128, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_419, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_420, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_421, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_422, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_423, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_424, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_425, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_426, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_427, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_428, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_429, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_430, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_431, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_432, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_433, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_434, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_435, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_436, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_437, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_438, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_439, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_440, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_441, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_442, (128, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_443, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_444, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_445, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_446, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_447, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_448, (128, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_449, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_450, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_451, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_452, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_453, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_454, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_455, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_456, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_457, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_458, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_459, (256, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_460, (128, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_461, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_462, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_463, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_464, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_465, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_466, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_467, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_468, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_469, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_470, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_471, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_472, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_473, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_474, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_475, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_476, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_477, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_478, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_479, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_480, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_481, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_482, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_483, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_484, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_485, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_486, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_487, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_488, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_489, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_490, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_491, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_492, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_493, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_494, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_495, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_496, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_497, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_498, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_499, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_500, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_501, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_502, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_503, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_504, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_505, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_506, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_507, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_508, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_509, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_510, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_511, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_512, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_513, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_514, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_515, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_516, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_517, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_518, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_519, (128, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_520, (64, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_521, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_522, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_523, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_524, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_525, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_526, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_527, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_528, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_529, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_530, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_531, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_532, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_533, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_534, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_535, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_536, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_537, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_538, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_539, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_540, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_541, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_542, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_543, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_544, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_545, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_546, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_547, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_548, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_549, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_550, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_551, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_552, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_553, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_554, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_555, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_556, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_557, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_558, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_559, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_560, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_561, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_562, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_563, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_564, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_565, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_566, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_567, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_568, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_569, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_570, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_571, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_572, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_573, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_574, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_575, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_576, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_577, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_578, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_579, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_580, (32, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_581, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_582, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_583, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_584, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_585, (32, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_586, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_587, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_588, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_589, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_590, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_591, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_592, (64, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_593, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_594, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_595, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_596, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_597, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_598, (16, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_599, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_600, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_601, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_602, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_603, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_604, (16, 16, 3, 3), (144, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_605, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_606, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_607, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_608, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_609, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_610, (16, 16, 3, 3), (144, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_611, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_612, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_613, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_614, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_615, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_616, (16, 16, 3, 3), (144, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_617, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_618, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_619, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_620, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_621, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_622, (16, 16, 3, 3), (144, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_623, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_624, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_625, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_626, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_627, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_628, (16, 16, 3, 3), (144, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_629, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_630, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_631, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_632, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_633, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_634, (16, 16, 3, 3), (144, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_635, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_636, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_637, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_638, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_639, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_640, (16, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_641, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_642, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_643, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_644, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_645, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_646, (16, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_647, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_648, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_649, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_650, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_651, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_652, (16, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_653, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_654, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_655, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_656, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_657, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_658, (16, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_659, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_660, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_661, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_662, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_663, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_664, (16, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_665, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_666, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_667, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_668, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_669, (16, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_670, (64, 32, 3, 3), (288, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_671, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_672, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_673, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_674, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_675, (64, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_676, (1, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_677, (1, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_678, (1, 64, 3, 3), (576, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_679, (1, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_680, (1, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_681, (1, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_682, (1, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_683, (1, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_684, (1, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_685, (1, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_686, (1, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_687, (1, ), (1, ))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hxin], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = extern_kernels.convolution(primals_1, primals_2, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf0, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = buf0; del buf0  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hxin], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_0.run(buf1, primals_3, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_3
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = extern_kernels.convolution(buf1, primals_4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf2, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = buf2; del buf2  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1, batch_norm, xout], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1.run(buf3, primals_5, primals_6, primals_7, primals_8, primals_9, buf4, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_5
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_9
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = extern_kernels.convolution(buf4, primals_10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf5, (4, 32, 32, 32), (32768, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = buf5; del buf5  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((4, 32, 32, 32), (32768, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2, batch_norm_1, xout_1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_2.run(buf6, primals_11, primals_12, primals_13, primals_14, primals_15, buf7, 131072, grid=grid(131072), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_11
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_15
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_3.run(buf7, buf8, buf9, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = extern_kernels.convolution(buf8, primals_16, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf10, (4, 32, 16, 16), (8192, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = buf10; del buf10  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3, batch_norm_2, xout_2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf11, primals_17, primals_18, primals_19, primals_20, primals_21, buf12, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_17
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_21
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_1], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5.run(buf12, buf13, buf14, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = extern_kernels.convolution(buf13, primals_22, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf15, (4, 32, 8, 8), (2048, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = buf15; del buf15  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4, batch_norm_3, xout_3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf16, primals_23, primals_24, primals_25, primals_26, primals_27, buf17, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_23
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_27
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_2], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_7.run(buf17, buf18, buf19, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = extern_kernels.convolution(buf18, primals_28, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf20, (4, 32, 4, 4), (512, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = buf20; del buf20  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5, batch_norm_4, xout_4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf21, primals_29, primals_30, primals_31, primals_32, primals_33, buf22, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_29
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_33
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_3], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_9.run(buf22, buf23, buf24, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf23, primals_34, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 32, 2, 2), (128, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = buf25; del buf25  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6, batch_norm_5, xout_5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf26, primals_35, primals_36, primals_37, primals_38, primals_39, buf27, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_35
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_39
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_4], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_11.run(buf27, buf28, buf29, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = extern_kernels.convolution(buf28, primals_40, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf30, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = buf30; del buf30  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7, batch_norm_6, xout_6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf31, primals_41, primals_42, primals_43, primals_44, primals_45, buf32, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_41
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_45
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = extern_kernels.convolution(buf32, primals_46, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf33, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = buf33; del buf33  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_13.run(buf34, primals_47, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_47
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_5], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_14.run(buf34, primals_48, primals_49, primals_50, primals_51, buf32, buf35, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = extern_kernels.convolution(buf35, primals_52, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf36, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf36; del buf36  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 128, 128), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9, batch_norm_8, xout_8], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf37, primals_53, primals_54, primals_55, primals_56, primals_57, buf38, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_53
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = empty_strided_cuda((2, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_15.run(buf39, 2, grid=grid(2), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = empty_strided_cuda((2, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_16.run(buf40, 2, grid=grid(2), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = empty_strided_cuda((2, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_15.run(buf41, 2, grid=grid(2), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = empty_strided_cuda((2, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_16.run(buf42, 2, grid=grid(2), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = empty_strided_cuda((2, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17.run(buf43, 2, grid=grid(2), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_18.run(buf39, buf41, buf38, buf42, buf43, buf44, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = empty_strided_cuda((2, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_17.run(buf45, 2, grid=grid(2), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_6], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_19.run(buf44, buf40, buf41, buf38, buf42, buf43, buf45, buf27, buf46, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = extern_kernels.convolution(buf46, primals_58, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf47, (4, 32, 2, 2), (128, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = buf47; del buf47  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = buf44; del buf44  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10, batch_norm_9, xout_9], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf48, primals_59, primals_60, primals_61, primals_62, primals_63, buf49, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_59
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = empty_strided_cuda((4, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_20.run(buf50, 4, grid=grid(4), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = empty_strided_cuda((4, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_21.run(buf51, 4, grid=grid(4), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = empty_strided_cuda((4, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_20.run(buf52, 4, grid=grid(4), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = empty_strided_cuda((4, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_21.run(buf53, 4, grid=grid(4), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = empty_strided_cuda((4, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22.run(buf54, 4, grid=grid(4), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_23.run(buf50, buf52, buf49, buf53, buf54, buf55, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = empty_strided_cuda((4, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_1], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_22.run(buf56, 4, grid=grid(4), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_7], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_24.run(buf55, buf51, buf52, buf49, buf53, buf54, buf56, buf22, buf57, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = extern_kernels.convolution(buf57, primals_64, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf58, (4, 32, 4, 4), (512, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf59 = buf58; del buf58  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf60 = buf55; del buf55  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11, batch_norm_10, xout_10], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf59, primals_65, primals_66, primals_67, primals_68, primals_69, buf60, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_65
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf61 = empty_strided_cuda((8, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_25.run(buf61, 8, grid=grid(8), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf62 = empty_strided_cuda((8, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_26.run(buf62, 8, grid=grid(8), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf63 = empty_strided_cuda((8, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_25.run(buf63, 8, grid=grid(8), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf64 = empty_strided_cuda((8, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_26.run(buf64, 8, grid=grid(8), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf65 = empty_strided_cuda((8, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27.run(buf65, 8, grid=grid(8), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf66 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_28.run(buf61, buf63, buf60, buf64, buf65, buf66, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf67 = empty_strided_cuda((8, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_2], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_27.run(buf67, 8, grid=grid(8), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf68 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_8], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_29.run(buf66, buf62, buf63, buf60, buf64, buf65, buf67, buf17, buf68, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf69 = extern_kernels.convolution(buf68, primals_70, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf69, (4, 32, 8, 8), (2048, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf70 = buf69; del buf69  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf71 = buf66; del buf66  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12, batch_norm_11, xout_11], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf70, primals_71, primals_72, primals_73, primals_74, primals_75, buf71, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_71
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf72 = empty_strided_cuda((16, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_30.run(buf72, 16, grid=grid(16), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf73 = empty_strided_cuda((16, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_31.run(buf73, 16, grid=grid(16), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf74 = empty_strided_cuda((16, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_30.run(buf74, 16, grid=grid(16), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf75 = empty_strided_cuda((16, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_31.run(buf75, 16, grid=grid(16), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf76 = empty_strided_cuda((16, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32.run(buf76, 16, grid=grid(16), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf77 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_33.run(buf72, buf74, buf71, buf75, buf76, buf77, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf78 = empty_strided_cuda((16, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_3], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_32.run(buf78, 16, grid=grid(16), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf79 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_9], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_34.run(buf77, buf73, buf74, buf71, buf75, buf76, buf78, buf12, buf79, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf80 = extern_kernels.convolution(buf79, primals_76, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf80, (4, 32, 16, 16), (8192, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf81 = buf80; del buf80  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf82 = buf77; del buf77  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13, batch_norm_12, xout_12], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf81, primals_77, primals_78, primals_79, primals_80, primals_81, buf82, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_77
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf83 = empty_strided_cuda((32, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_35.run(buf83, 32, grid=grid(32), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf84 = empty_strided_cuda((32, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_36.run(buf84, 32, grid=grid(32), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf85 = empty_strided_cuda((32, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_35.run(buf85, 32, grid=grid(32), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf86 = empty_strided_cuda((32, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_36.run(buf86, 32, grid=grid(32), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf87 = empty_strided_cuda((32, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37.run(buf87, 32, grid=grid(32), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf88 = empty_strided_cuda((4, 32, 32, 32), (32768, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_38.run(buf83, buf85, buf82, buf86, buf87, buf88, 131072, grid=grid(131072), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf89 = empty_strided_cuda((32, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_4], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_37.run(buf89, 32, grid=grid(32), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf90 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_10], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_39.run(buf88, buf84, buf85, buf82, buf86, buf87, buf89, buf7, buf90, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf91 = extern_kernels.convolution(buf90, primals_82, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf91, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf92 = buf91; del buf91  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf93 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14, batch_norm_13, xout_13, hx1], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40.run(buf92, primals_83, primals_84, primals_85, primals_86, primals_87, buf4, buf93, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_83
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf94 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf95 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_11], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_41.run(buf93, buf94, buf95, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf96 = extern_kernels.convolution(buf94, primals_88, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf96, (4, 128, 16, 16), (32768, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf97 = buf96; del buf96  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf98 = reinterpret_tensor(buf88, (4, 128, 16, 16), (32768, 256, 16, 1), 0); del buf88  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15, batch_norm_14, xout_14], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_42.run(buf97, primals_89, primals_90, primals_91, primals_92, primals_93, buf98, 131072, grid=grid(131072), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_89
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_93
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf99 = extern_kernels.convolution(buf98, primals_94, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf99, (4, 32, 16, 16), (8192, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf100 = buf99; del buf99  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf101 = buf82; del buf82  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16, batch_norm_15, xout_15], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf100, primals_95, primals_96, primals_97, primals_98, primals_99, buf101, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_95
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_99
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf102 = buf71; del buf71  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf103 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_12], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5.run(buf101, buf102, buf103, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf104 = extern_kernels.convolution(buf102, primals_100, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf104, (4, 32, 8, 8), (2048, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf105 = buf104; del buf104  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf106 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17, batch_norm_16, xout_16], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf105, primals_101, primals_102, primals_103, primals_104, primals_105, buf106, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_101
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_105
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf107 = buf60; del buf60  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf108 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_13], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_7.run(buf106, buf107, buf108, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_18], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf109 = extern_kernels.convolution(buf107, primals_106, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf109, (4, 32, 4, 4), (512, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf110 = buf109; del buf109  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf111 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_18, batch_norm_17, xout_17], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf110, primals_107, primals_108, primals_109, primals_110, primals_111, buf111, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_107
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_111
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf112 = buf49; del buf49  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf113 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_14], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_9.run(buf111, buf112, buf113, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_19], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf114 = extern_kernels.convolution(buf112, primals_112, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf114, (4, 32, 2, 2), (128, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf115 = buf114; del buf114  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf116 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_19, batch_norm_18, xout_18], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf115, primals_113, primals_114, primals_115, primals_116, primals_117, buf116, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_113
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_117
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf117 = reinterpret_tensor(buf38, (4, 32, 1, 1), (32, 1, 1, 1), 0); del buf38  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf118 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_15], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_11.run(buf116, buf117, buf118, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_20], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf119 = extern_kernels.convolution(buf117, primals_118, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf119, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf120 = buf119; del buf119  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf121 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_20, batch_norm_19, xout_19], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf120, primals_119, primals_120, primals_121, primals_122, primals_123, buf121, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_119
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_123
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_21], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf122 = extern_kernels.convolution(buf121, primals_124, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf122, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf123 = buf122; del buf122  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_21], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_13.run(buf123, primals_125, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_125
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf124 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_16], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_14.run(buf123, primals_126, primals_127, primals_128, primals_129, buf121, buf124, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_22], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf125 = extern_kernels.convolution(buf124, primals_130, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf125, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf126 = buf125; del buf125  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf127 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 128, 128), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_22, batch_norm_21, xout_21], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf126, primals_131, primals_132, primals_133, primals_134, primals_135, buf127, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_131
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf128 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_5], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_18.run(buf39, buf41, buf127, buf42, buf43, buf128, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf129 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_17], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_19.run(buf128, buf40, buf41, buf127, buf42, buf43, buf45, buf116, buf129, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_23], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf130 = extern_kernels.convolution(buf129, primals_136, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf130, (4, 32, 2, 2), (128, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf131 = buf130; del buf130  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf132 = buf128; del buf128  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_23, batch_norm_22, xout_22], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf131, primals_137, primals_138, primals_139, primals_140, primals_141, buf132, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_137
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf133 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_6], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_23.run(buf50, buf52, buf132, buf53, buf54, buf133, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf134 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_18], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_24.run(buf133, buf51, buf52, buf132, buf53, buf54, buf56, buf111, buf134, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_24], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf135 = extern_kernels.convolution(buf134, primals_142, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf135, (4, 32, 4, 4), (512, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf136 = buf135; del buf135  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf137 = buf133; del buf133  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_24, batch_norm_23, xout_23], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf136, primals_143, primals_144, primals_145, primals_146, primals_147, buf137, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_143
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf138 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_7], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_28.run(buf61, buf63, buf137, buf64, buf65, buf138, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf139 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_19], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_29.run(buf138, buf62, buf63, buf137, buf64, buf65, buf67, buf106, buf139, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_25], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf140 = extern_kernels.convolution(buf139, primals_148, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf140, (4, 32, 8, 8), (2048, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf141 = buf140; del buf140  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf142 = buf138; del buf138  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_25, batch_norm_24, xout_24], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf141, primals_149, primals_150, primals_151, primals_152, primals_153, buf142, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_149
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf143 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_8], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_33.run(buf72, buf74, buf142, buf75, buf76, buf143, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf144 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_20], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_34.run(buf143, buf73, buf74, buf142, buf75, buf76, buf78, buf101, buf144, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_26], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf145 = extern_kernels.convolution(buf144, primals_154, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf145, (4, 128, 16, 16), (32768, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf146 = buf145; del buf145  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf147 = empty_strided_cuda((4, 128, 16, 16), (32768, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_26, batch_norm_25, xout_25, hx2], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_43.run(buf146, primals_155, primals_156, primals_157, primals_158, primals_159, buf98, buf147, 131072, grid=grid(131072), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_155
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf148 = reinterpret_tensor(buf143, (4, 128, 8, 8), (8192, 64, 8, 1), 0); del buf143  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf149 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_21], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_44.run(buf147, buf148, buf149, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_27], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf150 = extern_kernels.convolution(buf148, primals_160, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf150, (4, 256, 8, 8), (16384, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf151 = buf150; del buf150  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf152 = empty_strided_cuda((4, 256, 8, 8), (16384, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_27, batch_norm_26, xout_26], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_45.run(buf151, primals_161, primals_162, primals_163, primals_164, primals_165, buf152, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_161
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_165
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_28], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf153 = extern_kernels.convolution(buf152, primals_166, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf153, (4, 64, 8, 8), (4096, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf154 = buf153; del buf153  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf155 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_28, batch_norm_27, xout_27], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46.run(buf154, primals_167, primals_168, primals_169, primals_170, primals_171, buf155, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_167
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_171
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf156 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf157 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_22], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_47.run(buf155, buf156, buf157, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_29], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf158 = extern_kernels.convolution(buf156, primals_172, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf158, (4, 64, 4, 4), (1024, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf159 = buf158; del buf158  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf160 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_29, batch_norm_28, xout_28], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf159, primals_173, primals_174, primals_175, primals_176, primals_177, buf160, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_173
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_177
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf161 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf162 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_23], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_49.run(buf160, buf161, buf162, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_30], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf163 = extern_kernels.convolution(buf161, primals_178, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf163, (4, 64, 2, 2), (256, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf164 = buf163; del buf163  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf165 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_30, batch_norm_29, xout_29], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf164, primals_179, primals_180, primals_181, primals_182, primals_183, buf165, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_179
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_183
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf166 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf167 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_24], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_51.run(buf165, buf166, buf167, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_31], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf168 = extern_kernels.convolution(buf166, primals_184, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf168, (4, 64, 1, 1), (64, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf169 = buf168; del buf168  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf170 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_31, batch_norm_30, xout_30], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf169, primals_185, primals_186, primals_187, primals_188, primals_189, buf170, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_185
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_189
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_32], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf171 = extern_kernels.convolution(buf170, primals_190, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf171, (4, 64, 1, 1), (64, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf172 = buf171; del buf171  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_32], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_53.run(buf172, primals_191, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_191
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf173 = reinterpret_tensor(buf132, (4, 128, 1, 1), (128, 1, 1, 1), 0); del buf132  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_25], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_54.run(buf172, primals_192, primals_193, primals_194, primals_195, buf170, buf173, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_33], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf174 = extern_kernels.convolution(buf173, primals_196, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf174, (4, 64, 1, 1), (64, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf175 = buf174; del buf174  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf176 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 256, 256), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_33, batch_norm_32, xout_32], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf175, primals_197, primals_198, primals_199, primals_200, primals_201, buf176, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_197
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf177 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_9], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_55.run(buf39, buf41, buf176, buf42, buf43, buf177, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf178 = reinterpret_tensor(buf137, (4, 128, 2, 2), (512, 4, 2, 1), 0); del buf137  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_26], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_56.run(buf177, buf40, buf41, buf176, buf42, buf43, buf45, buf165, buf178, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_34], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf179 = extern_kernels.convolution(buf178, primals_202, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf179, (4, 64, 2, 2), (256, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf180 = buf179; del buf179  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf181 = buf177; del buf177  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_34, batch_norm_33, xout_33], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf180, primals_203, primals_204, primals_205, primals_206, primals_207, buf181, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_203
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf182 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_10], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_57.run(buf50, buf52, buf181, buf53, buf54, buf182, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf183 = reinterpret_tensor(buf142, (4, 128, 4, 4), (2048, 16, 4, 1), 0); del buf142  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_27], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_58.run(buf182, buf51, buf52, buf181, buf53, buf54, buf56, buf160, buf183, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_35], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf184 = extern_kernels.convolution(buf183, primals_208, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf184, (4, 64, 4, 4), (1024, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf185 = buf184; del buf184  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf186 = buf182; del buf182  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_35, batch_norm_34, xout_34], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf185, primals_209, primals_210, primals_211, primals_212, primals_213, buf186, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_209
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf187 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_11], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_59.run(buf61, buf63, buf186, buf64, buf65, buf187, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf188 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_28], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_60.run(buf187, buf62, buf63, buf186, buf64, buf65, buf67, buf155, buf188, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_36], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf189 = extern_kernels.convolution(buf188, primals_214, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf189, (4, 256, 8, 8), (16384, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf190 = buf189; del buf189  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf191 = empty_strided_cuda((4, 256, 8, 8), (16384, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_36, batch_norm_35, xout_35, hx3], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_61.run(buf190, primals_215, primals_216, primals_217, primals_218, primals_219, buf152, buf191, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_215
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf192 = reinterpret_tensor(buf187, (4, 256, 4, 4), (4096, 16, 4, 1), 0); del buf187  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf193 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_29], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_62.run(buf191, buf192, buf193, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_37], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf194 = extern_kernels.convolution(buf192, primals_220, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf194, (4, 512, 4, 4), (8192, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf195 = buf194; del buf194  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf196 = empty_strided_cuda((4, 512, 4, 4), (8192, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_37, batch_norm_36, xout_36], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_63.run(buf195, primals_221, primals_222, primals_223, primals_224, primals_225, buf196, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_221
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_225
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_38], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf197 = extern_kernels.convolution(buf196, primals_226, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf197, (4, 128, 4, 4), (2048, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf198 = buf197; del buf197  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf199 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_38, batch_norm_37, xout_37], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64.run(buf198, primals_227, primals_228, primals_229, primals_230, primals_231, buf199, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_227
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_231
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf200 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf201 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_30], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_65.run(buf199, buf200, buf201, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_39], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf202 = extern_kernels.convolution(buf200, primals_232, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf202, (4, 128, 2, 2), (512, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf203 = buf202; del buf202  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf204 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_39, batch_norm_38, xout_38], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf203, primals_233, primals_234, primals_235, primals_236, primals_237, buf204, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_233
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_237
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf205 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf206 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_31], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_67.run(buf204, buf205, buf206, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_40], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf207 = extern_kernels.convolution(buf205, primals_238, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf207, (4, 128, 1, 1), (128, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf208 = buf207; del buf207  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf209 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_40, batch_norm_39, xout_39], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf208, primals_239, primals_240, primals_241, primals_242, primals_243, buf209, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_239
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_243
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_41], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf210 = extern_kernels.convolution(buf209, primals_244, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf210, (4, 128, 1, 1), (128, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf211 = buf210; del buf210  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_41], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_69.run(buf211, primals_245, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_245
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf212 = reinterpret_tensor(buf181, (4, 256, 1, 1), (256, 1, 1, 1), 0); del buf181  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_32], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_70.run(buf211, primals_246, primals_247, primals_248, primals_249, buf209, buf212, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_42], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf213 = extern_kernels.convolution(buf212, primals_250, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf213, (4, 128, 1, 1), (128, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf214 = buf213; del buf213  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf215 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 512, 512), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_42, batch_norm_41, xout_41], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf214, primals_251, primals_252, primals_253, primals_254, primals_255, buf215, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_251
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf216 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_12], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_71.run(buf39, buf41, buf215, buf42, buf43, buf216, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf217 = reinterpret_tensor(buf186, (4, 256, 2, 2), (1024, 4, 2, 1), 0); del buf186  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_33], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_72.run(buf216, buf40, buf41, buf215, buf42, buf43, buf45, buf204, buf217, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_43], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf218 = extern_kernels.convolution(buf217, primals_256, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf218, (4, 128, 2, 2), (512, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf219 = buf218; del buf218  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf220 = buf216; del buf216  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_43, batch_norm_42, xout_42], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf219, primals_257, primals_258, primals_259, primals_260, primals_261, buf220, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_257
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf221 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_13], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_73.run(buf50, buf52, buf220, buf53, buf54, buf221, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf222 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_34], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_74.run(buf221, buf51, buf52, buf220, buf53, buf54, buf56, buf199, buf222, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_44], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf223 = extern_kernels.convolution(buf222, primals_262, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf223, (4, 512, 4, 4), (8192, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf224 = buf223; del buf223  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf225 = empty_strided_cuda((4, 512, 4, 4), (8192, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_44, batch_norm_43, xout_43, hx4], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_75.run(buf224, primals_263, primals_264, primals_265, primals_266, primals_267, buf196, buf225, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_263
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf226 = reinterpret_tensor(buf221, (4, 512, 2, 2), (2048, 4, 2, 1), 0); del buf221  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf227 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_35], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_76.run(buf225, buf226, buf227, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_45], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf228 = extern_kernels.convolution(buf226, primals_268, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf228, (4, 512, 2, 2), (2048, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf229 = buf228; del buf228  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf230 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_45, batch_norm_44, xout_44], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77.run(buf229, primals_269, primals_270, primals_271, primals_272, primals_273, buf230, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_269
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_273
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_46], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf231 = extern_kernels.convolution(buf230, primals_274, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf231, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf232 = buf231; del buf231  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf233 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_46, batch_norm_45, xout_45], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf232, primals_275, primals_276, primals_277, primals_278, primals_279, buf233, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_275
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_279
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_47], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf234 = extern_kernels.convolution(buf233, primals_280, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf234, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf235 = buf234; del buf234  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf236 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_47, batch_norm_46, xout_46], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf235, primals_281, primals_282, primals_283, primals_284, primals_285, buf236, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_281
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_285
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_48], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf237 = extern_kernels.convolution(buf236, primals_286, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf237, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf238 = buf237; del buf237  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf239 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_48, batch_norm_47, xout_47], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf238, primals_287, primals_288, primals_289, primals_290, primals_291, buf239, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_287
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_291
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_49], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf240 = extern_kernels.convolution(buf239, primals_292, stride=(1, 1), padding=(8, 8), dilation=(8, 8), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf240, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf241 = buf240; del buf240  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_49], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf241, primals_293, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_293
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf242 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_36], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf241, primals_294, primals_295, primals_296, primals_297, buf239, buf242, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_50], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf243 = extern_kernels.convolution(buf242, primals_298, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf243, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf244 = buf243; del buf243  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_50], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf244, primals_299, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_299
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf245 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_37], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf244, primals_300, primals_301, primals_302, primals_303, buf236, buf245, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_51], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf246 = extern_kernels.convolution(buf245, primals_304, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf246, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf247 = buf246; del buf246  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_51], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf247, primals_305, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_305
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf248 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_38], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf247, primals_306, primals_307, primals_308, primals_309, buf233, buf248, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_52], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf249 = extern_kernels.convolution(buf248, primals_310, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf249, (4, 512, 2, 2), (2048, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf250 = buf249; del buf249  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf251 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_52, batch_norm_51, xout_51, hx5], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81.run(buf250, primals_311, primals_312, primals_313, primals_314, primals_315, buf230, buf251, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_311
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf252 = reinterpret_tensor(buf220, (4, 512, 1, 1), (512, 1, 1, 1), 0); del buf220  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf253 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_39], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_82.run(buf251, buf252, buf253, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_53], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf254 = extern_kernels.convolution(buf252, primals_316, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf254, (4, 512, 1, 1), (512, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf255 = buf254; del buf254  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf256 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_53, batch_norm_52, xout_52], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_83.run(buf255, primals_317, primals_318, primals_319, primals_320, primals_321, buf256, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_317
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_321
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_54], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf257 = extern_kernels.convolution(buf256, primals_322, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf257, (4, 256, 1, 1), (256, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf258 = buf257; del buf257  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf259 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_54, batch_norm_53, xout_53], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84.run(buf258, primals_323, primals_324, primals_325, primals_326, primals_327, buf259, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_323
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_327
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_55], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf260 = extern_kernels.convolution(buf259, primals_328, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf260, (4, 256, 1, 1), (256, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf261 = buf260; del buf260  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf262 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_55, batch_norm_54, xout_54], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84.run(buf261, primals_329, primals_330, primals_331, primals_332, primals_333, buf262, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_329
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_333
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_56], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf263 = extern_kernels.convolution(buf262, primals_334, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf263, (4, 256, 1, 1), (256, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf264 = buf263; del buf263  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf265 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_56, batch_norm_55, xout_55], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_84.run(buf264, primals_335, primals_336, primals_337, primals_338, primals_339, buf265, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_335
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_339
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_57], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf266 = extern_kernels.convolution(buf265, primals_340, stride=(1, 1), padding=(8, 8), dilation=(8, 8), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf266, (4, 256, 1, 1), (256, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf267 = buf266; del buf266  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_57], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_85.run(buf267, primals_341, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_341
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf268 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_40], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_86.run(buf267, primals_342, primals_343, primals_344, primals_345, buf265, buf268, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_58], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf269 = extern_kernels.convolution(buf268, primals_346, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf269, (4, 256, 1, 1), (256, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf270 = buf269; del buf269  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_58], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_85.run(buf270, primals_347, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_347
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf271 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_41], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_86.run(buf270, primals_348, primals_349, primals_350, primals_351, buf262, buf271, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_59], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf272 = extern_kernels.convolution(buf271, primals_352, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf272, (4, 256, 1, 1), (256, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf273 = buf272; del buf272  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_59], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_85.run(buf273, primals_353, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_353
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf274 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_42], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_86.run(buf273, primals_354, primals_355, primals_356, primals_357, buf259, buf274, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_60], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf275 = extern_kernels.convolution(buf274, primals_358, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf275, (4, 512, 1, 1), (512, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf276 = buf275; del buf275  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf277 = empty_strided_cuda((4, 512, 1, 1), (512, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_60, batch_norm_59, xout_59, hx6], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_87.run(buf276, primals_359, primals_360, primals_361, primals_362, primals_363, buf256, buf277, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_359
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf278 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_14], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_88.run(buf39, buf41, buf277, buf42, buf43, buf278, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf279 = empty_strided_cuda((4, 1024, 2, 2), (4096, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_43], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_89.run(buf278, buf40, buf41, buf277, buf42, buf43, buf45, buf251, buf279, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_61], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf280 = extern_kernels.convolution(buf279, primals_364, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf280, (4, 512, 2, 2), (2048, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf281 = buf280; del buf280  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf282 = buf278; del buf278  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_61, batch_norm_60, xout_60], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_77.run(buf281, primals_365, primals_366, primals_367, primals_368, primals_369, buf282, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_365
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_369
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_62], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf283 = extern_kernels.convolution(buf282, primals_370, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf283, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf284 = buf283; del buf283  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf285 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_62, batch_norm_61, xout_61], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf284, primals_371, primals_372, primals_373, primals_374, primals_375, buf285, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_371
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_375
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_63], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf286 = extern_kernels.convolution(buf285, primals_376, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf286, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf287 = buf286; del buf286  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf288 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_63, batch_norm_62, xout_62], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf287, primals_377, primals_378, primals_379, primals_380, primals_381, buf288, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_377
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_381
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_64], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf289 = extern_kernels.convolution(buf288, primals_382, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf289, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf290 = buf289; del buf289  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf291 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_64, batch_norm_63, xout_63], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_78.run(buf290, primals_383, primals_384, primals_385, primals_386, primals_387, buf291, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_383
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_387
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_65], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf292 = extern_kernels.convolution(buf291, primals_388, stride=(1, 1), padding=(8, 8), dilation=(8, 8), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf292, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf293 = buf292; del buf292  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_65], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf293, primals_389, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_389
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf294 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_44], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf293, primals_390, primals_391, primals_392, primals_393, buf291, buf294, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_66], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf295 = extern_kernels.convolution(buf294, primals_394, stride=(1, 1), padding=(4, 4), dilation=(4, 4), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf295, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf296 = buf295; del buf295  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_66], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf296, primals_395, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_395
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf297 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_45], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf296, primals_396, primals_397, primals_398, primals_399, buf288, buf297, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_67], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf298 = extern_kernels.convolution(buf297, primals_400, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf298, (4, 256, 2, 2), (1024, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf299 = buf298; del buf298  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_67], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_79.run(buf299, primals_401, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_401
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf300 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_46], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_80.run(buf299, primals_402, primals_403, primals_404, primals_405, buf285, buf300, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_68], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf301 = extern_kernels.convolution(buf300, primals_406, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf301, (4, 512, 2, 2), (2048, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf302 = buf301; del buf301  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf303 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_68, batch_norm_67, xout_67, hx5d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_81.run(buf302, primals_407, primals_408, primals_409, primals_410, primals_411, buf282, buf303, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_407
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf304 = empty_strided_cuda((4, 512, 4, 4), (8192, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_15], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_90.run(buf50, buf52, buf303, buf53, buf54, buf304, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf305 = empty_strided_cuda((4, 1024, 4, 4), (16384, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_47], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_91.run(buf304, buf51, buf52, buf303, buf53, buf54, buf56, buf225, buf305, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_69], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf306 = extern_kernels.convolution(buf305, primals_412, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf306, (4, 256, 4, 4), (4096, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf307 = buf306; del buf306  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf308 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_69, batch_norm_68, xout_68], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_92.run(buf307, primals_413, primals_414, primals_415, primals_416, primals_417, buf308, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_413
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_417
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_70], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf309 = extern_kernels.convolution(buf308, primals_418, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf309, (4, 128, 4, 4), (2048, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf310 = buf309; del buf309  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf311 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_70, batch_norm_69, xout_69], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_64.run(buf310, primals_419, primals_420, primals_421, primals_422, primals_423, buf311, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_419
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_423
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf312 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf313 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_48], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_65.run(buf311, buf312, buf313, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_71], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf314 = extern_kernels.convolution(buf312, primals_424, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf314, (4, 128, 2, 2), (512, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf315 = buf314; del buf314  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf316 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_71, batch_norm_70, xout_70], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf315, primals_425, primals_426, primals_427, primals_428, primals_429, buf316, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_425
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_429
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf317 = reinterpret_tensor(buf215, (4, 128, 1, 1), (128, 1, 1, 1), 0); del buf215  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf318 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_49], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_67.run(buf316, buf317, buf318, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_72], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf319 = extern_kernels.convolution(buf317, primals_430, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf319, (4, 128, 1, 1), (128, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf320 = buf319; del buf319  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf321 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_72, batch_norm_71, xout_71], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf320, primals_431, primals_432, primals_433, primals_434, primals_435, buf321, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_431
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_435
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_73], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf322 = extern_kernels.convolution(buf321, primals_436, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf322, (4, 128, 1, 1), (128, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf323 = buf322; del buf322  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_73], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_69.run(buf323, primals_437, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_437
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf324 = empty_strided_cuda((4, 256, 1, 1), (256, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_50], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_70.run(buf323, primals_438, primals_439, primals_440, primals_441, buf321, buf324, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_74], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf325 = extern_kernels.convolution(buf324, primals_442, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf325, (4, 128, 1, 1), (128, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf326 = buf325; del buf325  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf327 = empty_strided_cuda((4, 128, 1, 1), (128, 1, 512, 512), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_74, batch_norm_73, xout_73], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_68.run(buf326, primals_443, primals_444, primals_445, primals_446, primals_447, buf327, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_443
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf328 = empty_strided_cuda((4, 128, 2, 2), (512, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_16], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_71.run(buf39, buf41, buf327, buf42, buf43, buf328, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf329 = empty_strided_cuda((4, 256, 2, 2), (1024, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_51], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_72.run(buf328, buf40, buf41, buf327, buf42, buf43, buf45, buf316, buf329, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_75], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf330 = extern_kernels.convolution(buf329, primals_448, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf330, (4, 128, 2, 2), (512, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf331 = buf330; del buf330  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf332 = buf328; del buf328  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_75, batch_norm_74, xout_74], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_66.run(buf331, primals_449, primals_450, primals_451, primals_452, primals_453, buf332, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_449
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf333 = empty_strided_cuda((4, 128, 4, 4), (2048, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_17], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_73.run(buf50, buf52, buf332, buf53, buf54, buf333, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf334 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_52], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_74.run(buf333, buf51, buf52, buf332, buf53, buf54, buf56, buf311, buf334, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_76], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf335 = extern_kernels.convolution(buf334, primals_454, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf335, (4, 256, 4, 4), (4096, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf336 = buf335; del buf335  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf337 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_76, batch_norm_75, xout_75, hx4d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_93.run(buf336, primals_455, primals_456, primals_457, primals_458, primals_459, buf308, buf337, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_455
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf338 = empty_strided_cuda((4, 256, 8, 8), (16384, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_18], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_94.run(buf61, buf63, buf337, buf64, buf65, buf338, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf339 = empty_strided_cuda((4, 512, 8, 8), (32768, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_53], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_95.run(buf338, buf62, buf63, buf337, buf64, buf65, buf67, buf191, buf339, 131072, grid=grid(131072), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_77], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf340 = extern_kernels.convolution(buf339, primals_460, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf340, (4, 128, 8, 8), (8192, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf341 = buf340; del buf340  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf342 = reinterpret_tensor(buf304, (4, 128, 8, 8), (8192, 64, 8, 1), 0); del buf304  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_77, batch_norm_76, xout_76], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_96.run(buf341, primals_461, primals_462, primals_463, primals_464, primals_465, buf342, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_461
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_465
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_78], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf343 = extern_kernels.convolution(buf342, primals_466, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf343, (4, 64, 8, 8), (4096, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf344 = buf343; del buf343  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf345 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_78, batch_norm_77, xout_77], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_46.run(buf344, primals_467, primals_468, primals_469, primals_470, primals_471, buf345, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_467
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_471
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf346 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf347 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_54], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_47.run(buf345, buf346, buf347, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_79], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf348 = extern_kernels.convolution(buf346, primals_472, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf348, (4, 64, 4, 4), (1024, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf349 = buf348; del buf348  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf350 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_79, batch_norm_78, xout_78], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf349, primals_473, primals_474, primals_475, primals_476, primals_477, buf350, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_473
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_477
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf351 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf352 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_55], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_49.run(buf350, buf351, buf352, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_80], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf353 = extern_kernels.convolution(buf351, primals_478, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf353, (4, 64, 2, 2), (256, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf354 = buf353; del buf353  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf355 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_80, batch_norm_79, xout_79], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf354, primals_479, primals_480, primals_481, primals_482, primals_483, buf355, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_479
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_483
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf356 = reinterpret_tensor(buf176, (4, 64, 1, 1), (64, 1, 1, 1), 0); del buf176  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf357 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_56], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_51.run(buf355, buf356, buf357, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_81], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf358 = extern_kernels.convolution(buf356, primals_484, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf358, (4, 64, 1, 1), (64, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf359 = buf358; del buf358  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf360 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_81, batch_norm_80, xout_80], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf359, primals_485, primals_486, primals_487, primals_488, primals_489, buf360, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_485
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_489
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_82], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf361 = extern_kernels.convolution(buf360, primals_490, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf361, (4, 64, 1, 1), (64, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf362 = buf361; del buf361  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_82], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_53.run(buf362, primals_491, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_491
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf363 = reinterpret_tensor(buf327, (4, 128, 1, 1), (128, 1, 1, 1), 0); del buf327  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_57], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_54.run(buf362, primals_492, primals_493, primals_494, primals_495, buf360, buf363, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_83], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf364 = extern_kernels.convolution(buf363, primals_496, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf364, (4, 64, 1, 1), (64, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf365 = buf364; del buf364  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf366 = empty_strided_cuda((4, 64, 1, 1), (64, 1, 256, 256), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_83, batch_norm_82, xout_82], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_52.run(buf365, primals_497, primals_498, primals_499, primals_500, primals_501, buf366, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_497
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf367 = empty_strided_cuda((4, 64, 2, 2), (256, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_19], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_55.run(buf39, buf41, buf366, buf42, buf43, buf367, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf368 = buf332; del buf332  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_58], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_56.run(buf367, buf40, buf41, buf366, buf42, buf43, buf45, buf355, buf368, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_84], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf369 = extern_kernels.convolution(buf368, primals_502, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf369, (4, 64, 2, 2), (256, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf370 = buf369; del buf369  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf371 = buf367; del buf367  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_84, batch_norm_83, xout_83], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_50.run(buf370, primals_503, primals_504, primals_505, primals_506, primals_507, buf371, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_503
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf372 = empty_strided_cuda((4, 64, 4, 4), (1024, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_20], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_57.run(buf50, buf52, buf371, buf53, buf54, buf372, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf373 = buf333; del buf333  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_59], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_58.run(buf372, buf51, buf52, buf371, buf53, buf54, buf56, buf350, buf373, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_85], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf374 = extern_kernels.convolution(buf373, primals_508, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf374, (4, 64, 4, 4), (1024, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf375 = buf374; del buf374  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf376 = buf372; del buf372  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_85, batch_norm_84, xout_84], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_48.run(buf375, primals_509, primals_510, primals_511, primals_512, primals_513, buf376, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_509
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf377 = empty_strided_cuda((4, 64, 8, 8), (4096, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_21], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_59.run(buf61, buf63, buf376, buf64, buf65, buf377, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf378 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_60], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_60.run(buf377, buf62, buf63, buf376, buf64, buf65, buf67, buf345, buf378, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_86], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf379 = extern_kernels.convolution(buf378, primals_514, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf379, (4, 128, 8, 8), (8192, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf380 = buf379; del buf379  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf381 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_86, batch_norm_85, xout_85, hx3d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_97.run(buf380, primals_515, primals_516, primals_517, primals_518, primals_519, buf342, buf381, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_515
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf382 = empty_strided_cuda((4, 128, 16, 16), (32768, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_22], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_98.run(buf72, buf74, buf381, buf75, buf76, buf382, 131072, grid=grid(131072), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf383 = empty_strided_cuda((4, 256, 16, 16), (65536, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_61], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_99.run(buf382, buf73, buf74, buf381, buf75, buf76, buf78, buf147, buf383, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_87], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf384 = extern_kernels.convolution(buf383, primals_520, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf384, (4, 64, 16, 16), (16384, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf385 = buf384; del buf384  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf386 = reinterpret_tensor(buf338, (4, 64, 16, 16), (16384, 256, 16, 1), 0); del buf338  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_87, batch_norm_86, xout_86], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_100.run(buf385, primals_521, primals_522, primals_523, primals_524, primals_525, buf386, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_521
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_525
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_88], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf387 = extern_kernels.convolution(buf386, primals_526, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf387, (4, 32, 16, 16), (8192, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf388 = buf387; del buf387  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf389 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_88, batch_norm_87, xout_87], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_4.run(buf388, primals_527, primals_528, primals_529, primals_530, primals_531, buf389, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_527
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_531
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf390 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf391 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_62], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_5.run(buf389, buf390, buf391, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_89], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf392 = extern_kernels.convolution(buf390, primals_532, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf392, (4, 32, 8, 8), (2048, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf393 = buf392; del buf392  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf394 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_89, batch_norm_88, xout_88], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf393, primals_533, primals_534, primals_535, primals_536, primals_537, buf394, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_533
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_537
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf395 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf396 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_63], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_7.run(buf394, buf395, buf396, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_90], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf397 = extern_kernels.convolution(buf395, primals_538, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf397, (4, 32, 4, 4), (512, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf398 = buf397; del buf397  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf399 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_90, batch_norm_89, xout_89], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf398, primals_539, primals_540, primals_541, primals_542, primals_543, buf399, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_539
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_543
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf400 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf401 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_64], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_9.run(buf399, buf400, buf401, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_91], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf402 = extern_kernels.convolution(buf400, primals_544, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf402, (4, 32, 2, 2), (128, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf403 = buf402; del buf402  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf404 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_91, batch_norm_90, xout_90], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf403, primals_545, primals_546, primals_547, primals_548, primals_549, buf404, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_545
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_549
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf405 = reinterpret_tensor(buf127, (4, 32, 1, 1), (32, 1, 1, 1), 0); del buf127  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf406 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_65], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_11.run(buf404, buf405, buf406, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_92], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf407 = extern_kernels.convolution(buf405, primals_550, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf407, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf408 = buf407; del buf407  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf409 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_92, batch_norm_91, xout_91], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf408, primals_551, primals_552, primals_553, primals_554, primals_555, buf409, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_551
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_555
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_93], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf410 = extern_kernels.convolution(buf409, primals_556, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf410, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf411 = buf410; del buf410  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_93], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_13.run(buf411, primals_557, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_557
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf412 = reinterpret_tensor(buf366, (4, 64, 1, 1), (64, 1, 1, 1), 0); del buf366  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_66], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_14.run(buf411, primals_558, primals_559, primals_560, primals_561, buf409, buf412, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_94], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf413 = extern_kernels.convolution(buf412, primals_562, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf413, (4, 32, 1, 1), (32, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf414 = buf413; del buf413  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf415 = empty_strided_cuda((4, 32, 1, 1), (32, 1, 128, 128), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_94, batch_norm_93, xout_93], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_12.run(buf414, primals_563, primals_564, primals_565, primals_566, primals_567, buf415, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_563
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf416 = empty_strided_cuda((4, 32, 2, 2), (128, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_23], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_18.run(buf39, buf41, buf415, buf42, buf43, buf416, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf417 = buf371; del buf371  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_67], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_19.run(buf416, buf40, buf41, buf415, buf42, buf43, buf45, buf404, buf417, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_95], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf418 = extern_kernels.convolution(buf417, primals_568, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf418, (4, 32, 2, 2), (128, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf419 = buf418; del buf418  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf420 = buf416; del buf416  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_95, batch_norm_94, xout_94], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_10.run(buf419, primals_569, primals_570, primals_571, primals_572, primals_573, buf420, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_569
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf421 = empty_strided_cuda((4, 32, 4, 4), (512, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_24], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_23.run(buf50, buf52, buf420, buf53, buf54, buf421, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf422 = buf376; del buf376  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_68], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_24.run(buf421, buf51, buf52, buf420, buf53, buf54, buf56, buf399, buf422, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_96], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf423 = extern_kernels.convolution(buf422, primals_574, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf423, (4, 32, 4, 4), (512, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf424 = buf423; del buf423  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf425 = buf421; del buf421  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_96, batch_norm_95, xout_95], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_8.run(buf424, primals_575, primals_576, primals_577, primals_578, primals_579, buf425, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_575
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf426 = empty_strided_cuda((4, 32, 8, 8), (2048, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_25], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_28.run(buf61, buf63, buf425, buf64, buf65, buf426, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf427 = buf377; del buf377  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_69], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_29.run(buf426, buf62, buf63, buf425, buf64, buf65, buf67, buf394, buf427, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_97], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf428 = extern_kernels.convolution(buf427, primals_580, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf428, (4, 32, 8, 8), (2048, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf429 = buf428; del buf428  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf430 = buf426; del buf426  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_97, batch_norm_96, xout_96], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_6.run(buf429, primals_581, primals_582, primals_583, primals_584, primals_585, buf430, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_581
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf431 = empty_strided_cuda((4, 32, 16, 16), (8192, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_26], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_33.run(buf72, buf74, buf430, buf75, buf76, buf431, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf432 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_70], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_34.run(buf431, buf73, buf74, buf430, buf75, buf76, buf78, buf389, buf432, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_98], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf433 = extern_kernels.convolution(buf432, primals_586, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf433, (4, 64, 16, 16), (16384, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf434 = buf433; del buf433  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf435 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_98, batch_norm_97, xout_97, hx2d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_101.run(buf434, primals_587, primals_588, primals_589, primals_590, primals_591, buf386, buf435, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_587
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf436 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_27], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_102.run(buf83, buf85, buf435, buf86, buf87, buf436, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf437 = empty_strided_cuda((4, 128, 32, 32), (131072, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_71], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_103.run(buf436, buf84, buf85, buf435, buf86, buf87, buf89, buf93, buf437, 524288, grid=grid(524288), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_99], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf438 = extern_kernels.convolution(buf437, primals_592, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf438, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf439 = buf438; del buf438  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf440 = buf436; del buf436  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_99, batch_norm_98, xout_98], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_1.run(buf439, primals_593, primals_594, primals_595, primals_596, primals_597, buf440, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_593
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_597
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_100], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf441 = extern_kernels.convolution(buf440, primals_598, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf441, (4, 16, 32, 32), (16384, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf442 = buf441; del buf441  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf443 = empty_strided_cuda((4, 16, 32, 32), (16384, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_100, batch_norm_99, xout_99], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_104.run(buf442, primals_599, primals_600, primals_601, primals_602, primals_603, buf443, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_599
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_603
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf444 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf445 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_72], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_105.run(buf443, buf444, buf445, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_101], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf446 = extern_kernels.convolution(buf444, primals_604, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf446, (4, 16, 16, 16), (4096, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf447 = buf446; del buf446  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf448 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_101, batch_norm_100, xout_100], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106.run(buf447, primals_605, primals_606, primals_607, primals_608, primals_609, buf448, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_605
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_609
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf449 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf450 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_73], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_107.run(buf448, buf449, buf450, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_102], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf451 = extern_kernels.convolution(buf449, primals_610, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf451, (4, 16, 8, 8), (1024, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf452 = buf451; del buf451  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf453 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_102, batch_norm_101, xout_101], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108.run(buf452, primals_611, primals_612, primals_613, primals_614, primals_615, buf453, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_611
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_615
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf454 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf455 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_74], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_109.run(buf453, buf454, buf455, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_103], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf456 = extern_kernels.convolution(buf454, primals_616, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf456, (4, 16, 4, 4), (256, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf457 = buf456; del buf456  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf458 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_103, batch_norm_102, xout_102], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110.run(buf457, primals_617, primals_618, primals_619, primals_620, primals_621, buf458, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_617
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_621
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf459 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf460 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_75], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_111.run(buf458, buf459, buf460, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_104], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf461 = extern_kernels.convolution(buf459, primals_622, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf461, (4, 16, 2, 2), (64, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf462 = buf461; del buf461  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf463 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_104, batch_norm_103, xout_103], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112.run(buf462, primals_623, primals_624, primals_625, primals_626, primals_627, buf463, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_623
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_627
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf464 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf465 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 1, 1), torch.int8)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_76], Original ATen: [aten.max_pool2d_with_indices]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_max_pool2d_with_indices_113.run(buf463, buf464, buf465, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_105], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf466 = extern_kernels.convolution(buf464, primals_628, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf466, (4, 16, 1, 1), (16, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf467 = buf466; del buf466  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf468 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_105, batch_norm_104, xout_104], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114.run(buf467, primals_629, primals_630, primals_631, primals_632, primals_633, buf468, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_629
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_633
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_106], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf469 = extern_kernels.convolution(buf468, primals_634, stride=(1, 1), padding=(2, 2), dilation=(2, 2), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf469, (4, 16, 1, 1), (16, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf470 = buf469; del buf469  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_106], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_115.run(buf470, primals_635, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_635
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf471 = reinterpret_tensor(buf415, (4, 32, 1, 1), (32, 1, 1, 1), 0); del buf415  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_77], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_116.run(buf470, primals_636, primals_637, primals_638, primals_639, buf468, buf471, 128, grid=grid(128), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_107], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf472 = extern_kernels.convolution(buf471, primals_640, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf472, (4, 16, 1, 1), (16, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf473 = buf472; del buf472  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf474 = empty_strided_cuda((4, 16, 1, 1), (16, 1, 64, 64), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_107, batch_norm_106, xout_106], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_114.run(buf473, primals_641, primals_642, primals_643, primals_644, primals_645, buf474, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_641
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf475 = empty_strided_cuda((4, 16, 2, 2), (64, 4, 2, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_28], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_117.run(buf39, buf41, buf474, buf42, buf43, buf475, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf476 = buf420; del buf420  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_78], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_118.run(buf475, buf40, buf41, buf474, buf42, buf43, buf45, buf463, buf476, 512, grid=grid(512), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_108], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf477 = extern_kernels.convolution(buf476, primals_646, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf477, (4, 16, 2, 2), (64, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf478 = buf477; del buf477  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf479 = buf475; del buf475  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_108, batch_norm_107, xout_107], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_112.run(buf478, primals_647, primals_648, primals_649, primals_650, primals_651, buf479, 256, grid=grid(256), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_647
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf480 = empty_strided_cuda((4, 16, 4, 4), (256, 16, 4, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_29], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_119.run(buf50, buf52, buf479, buf53, buf54, buf480, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf481 = buf425; del buf425  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_79], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_120.run(buf480, buf51, buf52, buf479, buf53, buf54, buf56, buf458, buf481, 2048, grid=grid(2048), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf479
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_109], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf482 = extern_kernels.convolution(buf481, primals_652, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf482, (4, 16, 4, 4), (256, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf483 = buf482; del buf482  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf484 = buf480; del buf480  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_109, batch_norm_108, xout_108], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_110.run(buf483, primals_653, primals_654, primals_655, primals_656, primals_657, buf484, 1024, grid=grid(1024), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_653
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf485 = empty_strided_cuda((4, 16, 8, 8), (1024, 64, 8, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_30], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_121.run(buf61, buf63, buf484, buf64, buf65, buf485, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf486 = buf430; del buf430  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_80], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_122.run(buf485, buf62, buf63, buf484, buf64, buf65, buf67, buf453, buf486, 8192, grid=grid(8192), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf484
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_110], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf487 = extern_kernels.convolution(buf486, primals_658, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf487, (4, 16, 8, 8), (1024, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf488 = buf487; del buf487  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf489 = buf485; del buf485  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_110, batch_norm_109, xout_109], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_108.run(buf488, primals_659, primals_660, primals_661, primals_662, primals_663, buf489, 4096, grid=grid(4096), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_659
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf490 = empty_strided_cuda((4, 16, 16, 16), (4096, 256, 16, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_31], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_123.run(buf72, buf74, buf489, buf75, buf76, buf490, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf491 = buf431; del buf431  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_81], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_124.run(buf490, buf73, buf74, buf489, buf75, buf76, buf78, buf448, buf491, 32768, grid=grid(32768), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf489
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_111], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf492 = extern_kernels.convolution(buf491, primals_664, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf492, (4, 16, 16, 16), (4096, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf493 = buf492; del buf492  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf494 = buf490; del buf490  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_111, batch_norm_110, xout_110], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_convolution_relu_106.run(buf493, primals_665, primals_666, primals_667, primals_668, primals_669, buf494, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_665
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf495 = empty_strided_cuda((4, 16, 32, 32), (16384, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_32], Original ATen: [aten._unsafe_index, aten.sub, aten.mul, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_mul_sub_125.run(buf83, buf85, buf494, buf86, buf87, buf495, 65536, grid=grid(65536), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf496 = reinterpret_tensor(buf382, (4, 32, 32, 32), (32768, 1024, 32, 1), 0); del buf382  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [hx_82], Original ATen: [aten.cat]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_cat_126.run(buf495, buf84, buf85, buf494, buf86, buf87, buf89, buf443, buf496, 131072, grid=grid(131072), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf495
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_112], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf497 = extern_kernels.convolution(buf496, primals_670, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf497, (4, 64, 32, 32), (65536, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf498 = buf497; del buf497  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf499 = empty_strided_cuda((4, 64, 32, 32), (65536, 1024, 32, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_112, batch_norm_111, xout_111, hx1d], Original ATen: [aten.convolution, aten._native_batch_norm_legit_no_training, aten.relu, aten.add]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__native_batch_norm_legit_no_training_add_convolution_relu_40.run(buf498, primals_671, primals_672, primals_673, primals_674, primals_675, buf440, buf499, 262144, grid=grid(262144), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_671
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d1], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf500 = extern_kernels.convolution(buf499, primals_676, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf500, (4, 1, 32, 32), (1024, 1024, 32, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf501 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_127.run(buf501, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf502 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_128.run(buf502, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf503 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_127.run(buf503, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf504 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_128.run(buf504, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf505 = reinterpret_tensor(buf474, (64, ), (1, ), 0); del buf474  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129.run(buf505, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf507 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_129.run(buf507, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf506 = reinterpret_tensor(buf494, (4, 1, 64, 64), (4096, 16384, 64, 1), 0); del buf494  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf553 = reinterpret_tensor(buf506, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf506  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d1, src_33, sigmoid], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_130.run(buf553, buf501, buf503, buf500, primals_677, buf504, buf505, buf502, buf507, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf500
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_677
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d2], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf509 = extern_kernels.convolution(buf435, primals_678, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf509, (4, 1, 16, 16), (256, 256, 16, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf510 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_131.run(buf510, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf511 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_132.run(buf511, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf512 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_34], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_131.run(buf512, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf513 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_132.run(buf513, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf514 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_34], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133.run(buf514, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf516 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_34], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_133.run(buf516, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf515 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf554 = reinterpret_tensor(buf515, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf515  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d2, src_34, sigmoid_1], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_134.run(buf554, buf510, buf512, buf509, primals_679, buf513, buf514, buf511, buf516, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf509
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_679
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d3], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf518 = extern_kernels.convolution(buf381, primals_680, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf518, (4, 1, 8, 8), (64, 64, 8, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf519 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_135.run(buf519, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf520 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_136.run(buf520, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf521 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_35], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_135.run(buf521, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf522 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_136.run(buf522, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf523 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_35], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137.run(buf523, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf525 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_35], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_137.run(buf525, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf524 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf555 = reinterpret_tensor(buf524, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf524  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d3, src_35, sigmoid_2], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_138.run(buf555, buf519, buf521, buf518, primals_681, buf522, buf523, buf520, buf525, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf518
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_681
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d4], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf527 = extern_kernels.convolution(buf337, primals_682, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf527, (4, 1, 4, 4), (16, 16, 4, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf528 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_139.run(buf528, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf529 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_140.run(buf529, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf530 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_36], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_139.run(buf530, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf531 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_140.run(buf531, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf532 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_36], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141.run(buf532, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf534 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_36], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_141.run(buf534, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf533 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf556 = reinterpret_tensor(buf533, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf533  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d4, src_36, sigmoid_3], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_142.run(buf556, buf528, buf530, buf527, primals_683, buf531, buf532, buf529, buf534, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_683
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d5], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf536 = extern_kernels.convolution(buf303, primals_684, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf536, (4, 1, 2, 2), (4, 4, 2, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf537 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_143.run(buf537, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf538 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_144.run(buf538, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf539 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_37], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_143.run(buf539, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf540 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_144.run(buf540, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf541 = reinterpret_tensor(buf527, (64, ), (1, ), 0); del buf527  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_37], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145.run(buf541, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf543 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_37], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_145.run(buf543, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf542 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf557 = reinterpret_tensor(buf542, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf542  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d5, src_37, sigmoid_4], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_146.run(buf557, buf537, buf539, buf536, primals_685, buf540, buf541, buf538, buf543, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf536
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_685
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d6], Original ATen: [aten.convolution]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf545 = extern_kernels.convolution(buf277, primals_686, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf545, (4, 1, 1, 1), (1, 1, 1, 1))
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf546 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten._to_copy]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_147.run(buf546, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf547 = empty_strided_cuda((64, 1), (1, 1), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_148.run(buf547, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf548 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_38], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_147.run(buf548, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf549 = empty_strided_cuda((64, ), (1, ), torch.int64)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.add, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_148.run(buf549, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf550 = empty_strided_cuda((64, ), (1, ), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_33, src_38], Original ATen: [aten.arange, aten._to_copy, aten.add, aten.mul, aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149.run(buf550, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf552 = empty_strided_cuda((64, 1), (1, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [src_38], Original ATen: [aten.sub, aten.clamp]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__to_copy_add_arange_clamp_mul_sub_149.run(buf552, 64, grid=grid(64), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf551 = empty_strided_cuda((4, 1, 64, 64), (4096, 16384, 64, 1), torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf558 = reinterpret_tensor(buf551, (4, 1, 64, 64), (4096, 4096, 64, 1), 0); del buf551  # reuse
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [d6, src_38, sigmoid_5], Original ATen: [aten.convolution, aten._unsafe_index, aten.sub, aten.mul, aten.add, aten.sigmoid]
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused__unsafe_index_add_convolution_mul_sigmoid_sub_150.run(buf558, buf546, buf548, buf545, primals_687, buf549, buf550, buf547, buf552, 16384, grid=grid(16384), stream=stream0)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf545
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_687
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf553, buf554, buf555, buf556, buf557, buf558, buf499, buf435, buf381, buf337, buf303, buf277, primals_1, primals_2, primals_4, primals_6, primals_7, primals_8, primals_10, primals_12, primals_13, primals_14, primals_16, primals_18, primals_19, primals_20, primals_22, primals_24, primals_25, primals_26, primals_28, primals_30, primals_31, primals_32, primals_34, primals_36, primals_37, primals_38, primals_40, primals_42, primals_43, primals_44, primals_46, primals_48, primals_49, primals_50, primals_51, primals_52, primals_54, primals_55, primals_56, primals_57, primals_58, primals_60, primals_61, primals_62, primals_63, primals_64, primals_66, primals_67, primals_68, primals_69, primals_70, primals_72, primals_73, primals_74, primals_75, primals_76, primals_78, primals_79, primals_80, primals_81, primals_82, primals_84, primals_85, primals_86, primals_87, primals_88, primals_90, primals_91, primals_92, primals_94, primals_96, primals_97, primals_98, primals_100, primals_102, primals_103, primals_104, primals_106, primals_108, primals_109, primals_110, primals_112, primals_114, primals_115, primals_116, primals_118, primals_120, primals_121, primals_122, primals_124, primals_126, primals_127, primals_128, primals_129, primals_130, primals_132, primals_133, primals_134, primals_135, primals_136, primals_138, primals_139, primals_140, primals_141, primals_142, primals_144, primals_145, primals_146, primals_147, primals_148, primals_150, primals_151, primals_152, primals_153, primals_154, primals_156, primals_157, primals_158, primals_159, primals_160, primals_162, primals_163, primals_164, primals_166, primals_168, primals_169, primals_170, primals_172, primals_174, primals_175, primals_176, primals_178, primals_180, primals_181, primals_182, primals_184, primals_186, primals_187, primals_188, primals_190, primals_192, primals_193, primals_194, primals_195, primals_196, primals_198, primals_199, primals_200, primals_201, primals_202, primals_204, primals_205, primals_206, primals_207, primals_208, primals_210, primals_211, primals_212, primals_213, primals_214, primals_216, primals_217, primals_218, primals_219, primals_220, primals_222, primals_223, primals_224, primals_226, primals_228, primals_229, primals_230, primals_232, primals_234, primals_235, primals_236, primals_238, primals_240, primals_241, primals_242, primals_244, primals_246, primals_247, primals_248, primals_249, primals_250, primals_252, primals_253, primals_254, primals_255, primals_256, primals_258, primals_259, primals_260, primals_261, primals_262, primals_264, primals_265, primals_266, primals_267, primals_268, primals_270, primals_271, primals_272, primals_274, primals_276, primals_277, primals_278, primals_280, primals_282, primals_283, primals_284, primals_286, primals_288, primals_289, primals_290, primals_292, primals_294, primals_295, primals_296, primals_297, primals_298, primals_300, primals_301, primals_302, primals_303, primals_304, primals_306, primals_307, primals_308, primals_309, primals_310, primals_312, primals_313, primals_314, primals_315, primals_316, primals_318, primals_319, primals_320, primals_322, primals_324, primals_325, primals_326, primals_328, primals_330, primals_331, primals_332, primals_334, primals_336, primals_337, primals_338, primals_340, primals_342, primals_343, primals_344, primals_345, primals_346, primals_348, primals_349, primals_350, primals_351, primals_352, primals_354, primals_355, primals_356, primals_357, primals_358, primals_360, primals_361, primals_362, primals_363, primals_364, primals_366, primals_367, primals_368, primals_370, primals_372, primals_373, primals_374, primals_376, primals_378, primals_379, primals_380, primals_382, primals_384, primals_385, primals_386, primals_388, primals_390, primals_391, primals_392, primals_393, primals_394, primals_396, primals_397, primals_398, primals_399, primals_400, primals_402, primals_403, primals_404, primals_405, primals_406, primals_408, primals_409, primals_410, primals_411, primals_412, primals_414, primals_415, primals_416, primals_418, primals_420, primals_421, primals_422, primals_424, primals_426, primals_427, primals_428, primals_430, primals_432, primals_433, primals_434, primals_436, primals_438, primals_439, primals_440, primals_441, primals_442, primals_444, primals_445, primals_446, primals_447, primals_448, primals_450, primals_451, primals_452, primals_453, primals_454, primals_456, primals_457, primals_458, primals_459, primals_460, primals_462, primals_463, primals_464, primals_466, primals_468, primals_469, primals_470, primals_472, primals_474, primals_475, primals_476, primals_478, primals_480, primals_481, primals_482, primals_484, primals_486, primals_487, primals_488, primals_490, primals_492, primals_493, primals_494, primals_495, primals_496, primals_498, primals_499, primals_500, primals_501, primals_502, primals_504, primals_505, primals_506, primals_507, primals_508, primals_510, primals_511, primals_512, primals_513, primals_514, primals_516, primals_517, primals_518, primals_519, primals_520, primals_522, primals_523, primals_524, primals_526, primals_528, primals_529, primals_530, primals_532, primals_534, primals_535, primals_536, primals_538, primals_540, primals_541, primals_542, primals_544, primals_546, primals_547, primals_548, primals_550, primals_552, primals_553, primals_554, primals_556, primals_558, primals_559, primals_560, primals_561, primals_562, primals_564, primals_565, primals_566, primals_567, primals_568, primals_570, primals_571, primals_572, primals_573, primals_574, primals_576, primals_577, primals_578, primals_579, primals_580, primals_582, primals_583, primals_584, primals_585, primals_586, primals_588, primals_589, primals_590, primals_591, primals_592, primals_594, primals_595, primals_596, primals_598, primals_600, primals_601, primals_602, primals_604, primals_606, primals_607, primals_608, primals_610, primals_612, primals_613, primals_614, primals_616, primals_618, primals_619, primals_620, primals_622, primals_624, primals_625, primals_626, primals_628, primals_630, primals_631, primals_632, primals_634, primals_636, primals_637, primals_638, primals_639, primals_640, primals_642, primals_643, primals_644, primals_645, primals_646, primals_648, primals_649, primals_650, primals_651, primals_652, primals_654, primals_655, primals_656, primals_657, primals_658, primals_660, primals_661, primals_662, primals_663, primals_664, primals_666, primals_667, primals_668, primals_669, primals_670, primals_672, primals_673, primals_674, primals_675, primals_676, primals_678, primals_680, primals_682, primals_684, primals_686, buf1, buf3, buf4, buf6, buf7, buf8, buf9, buf11, buf12, buf13, buf14, buf16, buf17, buf18, buf19, buf21, buf22, buf23, buf24, buf26, buf27, buf28, buf29, buf31, buf32, buf34, buf35, buf37, buf39, buf40, buf41, buf42, buf43, buf45, buf46, buf48, buf50, buf51, buf52, buf53, buf54, buf56, buf57, buf59, buf61, buf62, buf63, buf64, buf65, buf67, buf68, buf70, buf72, buf73, buf74, buf75, buf76, buf78, buf79, buf81, buf83, buf84, buf85, buf86, buf87, buf89, buf90, buf92, buf93, buf94, buf95, buf97, buf98, buf100, buf101, buf102, buf103, buf105, buf106, buf107, buf108, buf110, buf111, buf112, buf113, buf115, buf116, buf117, buf118, buf120, buf121, buf123, buf124, buf126, buf129, buf131, buf134, buf136, buf139, buf141, buf144, buf146, buf147, buf148, buf149, buf151, buf152, buf154, buf155, buf156, buf157, buf159, buf160, buf161, buf162, buf164, buf165, buf166, buf167, buf169, buf170, buf172, buf173, buf175, buf178, buf180, buf183, buf185, buf188, buf190, buf191, buf192, buf193, buf195, buf196, buf198, buf199, buf200, buf201, buf203, buf204, buf205, buf206, buf208, buf209, buf211, buf212, buf214, buf217, buf219, buf222, buf224, buf225, buf226, buf227, buf229, buf230, buf232, buf233, buf235, buf236, buf238, buf239, buf241, buf242, buf244, buf245, buf247, buf248, buf250, buf251, buf252, buf253, buf255, buf256, buf258, buf259, buf261, buf262, buf264, buf265, buf267, buf268, buf270, buf271, buf273, buf274, buf276, buf277, buf279, buf281, buf282, buf284, buf285, buf287, buf288, buf290, buf291, buf293, buf294, buf296, buf297, buf299, buf300, buf302, buf303, buf305, buf307, buf308, buf310, buf311, buf312, buf313, buf315, buf316, buf317, buf318, buf320, buf321, buf323, buf324, buf326, buf329, buf331, buf334, buf336, buf337, buf339, buf341, buf342, buf344, buf345, buf346, buf347, buf349, buf350, buf351, buf352, buf354, buf355, buf356, buf357, buf359, buf360, buf362, buf363, buf365, buf368, buf370, buf373, buf375, buf378, buf380, buf381, buf383, buf385, buf386, buf388, buf389, buf390, buf391, buf393, buf394, buf395, buf396, buf398, buf399, buf400, buf401, buf403, buf404, buf405, buf406, buf408, buf409, buf411, buf412, buf414, buf417, buf419, buf422, buf424, buf427, buf429, buf432, buf434, buf435, buf437, buf439, buf440, buf442, buf443, buf444, buf445, buf447, buf448, buf449, buf450, buf452, buf453, buf454, buf455, buf457, buf458, buf459, buf460, buf462, buf463, buf464, buf465, buf467, buf468, buf470, buf471, buf473, buf476, buf478, buf481, buf483, buf486, buf488, buf491, buf493, buf496, buf498, buf499, buf501, buf502, buf503, buf504, buf505, buf507, buf510, buf511, buf512, buf513, buf514, buf516, buf519, buf520, buf521, buf522, buf523, buf525, buf528, buf529, buf530, buf531, buf532, buf534, buf537, buf538, buf539, buf540, buf541, buf543, buf546, buf547, buf548, buf549, buf550, buf552, buf553, buf554, buf555, buf556, buf557, buf558, )
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_2 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_3 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_4 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_5 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_6 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_7 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_10 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_11 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_12 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_13 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_14 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_15 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_16 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_17 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_18 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_19 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_20 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_21 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_22 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_23 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_24 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_25 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_26 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_27 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_28 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_29 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_30 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_31 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_32 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_33 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_34 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_35 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_36 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_37 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_38 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_39 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_40 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_41 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_42 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_43 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_44 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_45 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_46 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_47 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_48 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_49 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_50 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_51 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_52 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_53 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_54 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_55 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_56 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_57 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_58 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_59 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_60 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_61 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_62 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_63 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_64 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_65 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_66 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_67 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_68 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_69 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_70 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_71 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_72 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_73 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_74 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_75 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_76 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_77 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_78 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_79 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_80 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_81 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_82 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_83 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_84 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_85 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_86 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_87 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_88 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_89 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_90 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_91 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_92 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_93 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_94 = rand_strided((32, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_95 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_96 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_97 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_98 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_99 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_100 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_101 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_102 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_103 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_104 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_105 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_106 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_107 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_108 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_109 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_110 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_111 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_112 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_113 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_114 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_115 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_116 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_117 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_118 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_119 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_120 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_121 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_122 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_123 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_124 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_125 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_126 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_127 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_128 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_129 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_130 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_131 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_132 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_133 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_134 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_135 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_136 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_137 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_138 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_139 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_140 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_141 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_142 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_143 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_144 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_145 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_146 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_147 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_148 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_149 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_150 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_151 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_152 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_153 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_154 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_155 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_156 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_157 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_158 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_159 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_160 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_161 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_162 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_163 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_164 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_165 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_166 = rand_strided((64, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_167 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_168 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_169 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_170 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_171 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_172 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_173 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_174 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_175 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_176 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_177 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_178 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_179 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_180 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_181 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_182 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_183 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_184 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_185 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_186 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_187 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_188 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_189 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_190 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_191 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_192 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_193 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_194 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_195 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_196 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_197 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_198 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_199 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_200 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_201 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_202 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_203 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_204 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_205 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_206 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_207 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_208 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_209 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_210 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_211 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_212 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_213 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_214 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_215 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_216 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_217 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_218 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_219 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_220 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_221 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_222 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_223 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_224 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_225 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_226 = rand_strided((128, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_227 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_228 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_229 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_230 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_231 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_232 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_233 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_234 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_235 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_236 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_237 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_238 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_239 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_240 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_241 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_242 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_243 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_244 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_245 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_246 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_247 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_248 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_249 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_250 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_251 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_252 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_253 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_254 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_255 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_256 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_257 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_258 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_259 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_260 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_261 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_262 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_263 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_264 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_265 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_266 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_267 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_268 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_269 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_270 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_271 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_272 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_273 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_274 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_275 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_276 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_277 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_278 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_279 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_280 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_281 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_282 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_283 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_284 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_285 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_286 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_287 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_288 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_289 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_290 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_291 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_292 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_293 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_294 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_295 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_296 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_297 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_298 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_299 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_300 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_301 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_302 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_303 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_304 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_305 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_306 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_307 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_308 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_309 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_310 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_311 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_312 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_313 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_314 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_315 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_316 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_317 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_318 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_319 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_320 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_321 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_322 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_323 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_324 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_325 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_326 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_327 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_328 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_329 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_330 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_331 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_332 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_333 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_334 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_335 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_336 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_337 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_338 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_339 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_340 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_341 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_342 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_343 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_344 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_345 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_346 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_347 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_348 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_349 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_350 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_351 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_352 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_353 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_354 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_355 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_356 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_357 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_358 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_359 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_360 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_361 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_362 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_363 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_364 = rand_strided((512, 1024, 3, 3), (9216, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_365 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_366 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_367 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_368 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_369 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_370 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_371 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_372 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_373 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_374 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_375 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_376 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_377 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_378 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_379 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_380 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_381 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_382 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_383 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_384 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_385 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_386 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_387 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_388 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_389 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_390 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_391 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_392 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_393 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_394 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_395 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_396 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_397 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_398 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_399 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_400 = rand_strided((256, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_401 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_402 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_403 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_404 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_405 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_406 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_407 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_408 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_409 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_410 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_411 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_412 = rand_strided((256, 1024, 3, 3), (9216, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_413 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_414 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_415 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_416 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_417 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_418 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_419 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_420 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_421 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_422 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_423 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_424 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_425 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_426 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_427 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_428 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_429 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_430 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_431 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_432 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_433 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_434 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_435 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_436 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_437 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_438 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_439 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_440 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_441 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_442 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_443 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_444 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_445 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_446 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_447 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_448 = rand_strided((128, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_449 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_450 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_451 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_452 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_453 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_454 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_455 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_456 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_457 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_458 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_459 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_460 = rand_strided((128, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_461 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_462 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_463 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_464 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_465 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_466 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_467 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_468 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_469 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_470 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_471 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_472 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_473 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_474 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_475 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_476 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_477 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_478 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_479 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_480 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_481 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_482 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_483 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_484 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_485 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_486 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_487 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_488 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_489 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_490 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_491 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_492 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_493 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_494 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_495 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_496 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_497 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_498 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_499 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_500 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_501 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_502 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_503 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_504 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_505 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_506 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_507 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_508 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_509 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_510 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_511 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_512 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_513 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_514 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_515 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_516 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_517 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_518 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_519 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_520 = rand_strided((64, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_521 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_522 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_523 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_524 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_525 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_526 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_527 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_528 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_529 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_530 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_531 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_532 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_533 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_534 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_535 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_536 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_537 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_538 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_539 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_540 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_541 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_542 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_543 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_544 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_545 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_546 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_547 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_548 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_549 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_550 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_551 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_552 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_553 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_554 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_555 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_556 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_557 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_558 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_559 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_560 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_561 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_562 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_563 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_564 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_565 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_566 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_567 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_568 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_569 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_570 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_571 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_572 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_573 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_574 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_575 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_576 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_577 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_578 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_579 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_580 = rand_strided((32, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_581 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_582 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_583 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_584 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_585 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_586 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_587 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_588 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_589 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_590 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_591 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_592 = rand_strided((64, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_593 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_594 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_595 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_596 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_597 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_598 = rand_strided((16, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_599 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_600 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_601 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_602 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_603 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_604 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_605 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_606 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_607 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_608 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_609 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_610 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_611 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_612 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_613 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_614 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_615 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_616 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_617 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_618 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_619 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_620 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_621 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_622 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_623 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_624 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_625 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_626 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_627 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_628 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_629 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_630 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_631 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_632 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_633 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_634 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_635 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_636 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_637 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_638 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_639 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_640 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_641 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_642 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_643 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_644 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_645 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_646 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_647 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_648 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_649 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_650 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_651 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_652 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_653 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_654 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_655 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_656 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_657 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_658 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_659 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_660 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_661 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_662 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_663 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_664 = rand_strided((16, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_665 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_666 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_667 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_668 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_669 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_670 = rand_strided((64, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_671 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_672 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_673 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_674 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_675 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_676 = rand_strided((1, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_677 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_678 = rand_strided((1, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_679 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_680 = rand_strided((1, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_681 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_682 = rand_strided((1, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_683 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_684 = rand_strided((1, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_685 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_686 = rand_strided((1, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_687 = rand_strided((1, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, primals_441, primals_442, primals_443, primals_444, primals_445, primals_446, primals_447, primals_448, primals_449, primals_450, primals_451, primals_452, primals_453, primals_454, primals_455, primals_456, primals_457, primals_458, primals_459, primals_460, primals_461, primals_462, primals_463, primals_464, primals_465, primals_466, primals_467, primals_468, primals_469, primals_470, primals_471, primals_472, primals_473, primals_474, primals_475, primals_476, primals_477, primals_478, primals_479, primals_480, primals_481, primals_482, primals_483, primals_484, primals_485, primals_486, primals_487, primals_488, primals_489, primals_490, primals_491, primals_492, primals_493, primals_494, primals_495, primals_496, primals_497, primals_498, primals_499, primals_500, primals_501, primals_502, primals_503, primals_504, primals_505, primals_506, primals_507, primals_508, primals_509, primals_510, primals_511, primals_512, primals_513, primals_514, primals_515, primals_516, primals_517, primals_518, primals_519, primals_520, primals_521, primals_522, primals_523, primals_524, primals_525, primals_526, primals_527, primals_528, primals_529, primals_530, primals_531, primals_532, primals_533, primals_534, primals_535, primals_536, primals_537, primals_538, primals_539, primals_540, primals_541, primals_542, primals_543, primals_544, primals_545, primals_546, primals_547, primals_548, primals_549, primals_550, primals_551, primals_552, primals_553, primals_554, primals_555, primals_556, primals_557, primals_558, primals_559, primals_560, primals_561, primals_562, primals_563, primals_564, primals_565, primals_566, primals_567, primals_568, primals_569, primals_570, primals_571, primals_572, primals_573, primals_574, primals_575, primals_576, primals_577, primals_578, primals_579, primals_580, primals_581, primals_582, primals_583, primals_584, primals_585, primals_586, primals_587, primals_588, primals_589, primals_590, primals_591, primals_592, primals_593, primals_594, primals_595, primals_596, primals_597, primals_598, primals_599, primals_600, primals_601, primals_602, primals_603, primals_604, primals_605, primals_606, primals_607, primals_608, primals_609, primals_610, primals_611, primals_612, primals_613, primals_614, primals_615, primals_616, primals_617, primals_618, primals_619, primals_620, primals_621, primals_622, primals_623, primals_624, primals_625, primals_626, primals_627, primals_628, primals_629, primals_630, primals_631, primals_632, primals_633, primals_634, primals_635, primals_636, primals_637, primals_638, primals_639, primals_640, primals_641, primals_642, primals_643, primals_644, primals_645, primals_646, primals_647, primals_648, primals_649, primals_650, primals_651, primals_652, primals_653, primals_654, primals_655, primals_656, primals_657, primals_658, primals_659, primals_660, primals_661, primals_662, primals_663, primals_664, primals_665, primals_666, primals_667, primals_668, primals_669, primals_670, primals_671, primals_672, primals_673, primals_674, primals_675, primals_676, primals_677, primals_678, primals_679, primals_680, primals_681, primals_682, primals_683, primals_684, primals_685, primals_686, primals_687])
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0205 18:42:45.888000 409561 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:42:46.203000 409561 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: inductor_cache/aa/caaarztkgp6om6w7ux5ny7wmax3nxp5b5zuakcy6ydvppvmvve3v.py
