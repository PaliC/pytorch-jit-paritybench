V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['0_forward']
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3h/c3hpecenggnrxcqg3nyshgwbawgb3vfvl2axvlomnkql4xptnmer.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_0 = async_compile.triton('triton_poi_fused_0', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 64, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_0(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 48
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/34/c3464zi6weokoq52acp66gfau3o5qak3htxz7oaxxip4nrnowu4j.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_1 = async_compile.triton('triton_poi_fused_1', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_1(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 16)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 16
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 16*x2 + 144*y1), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gh/cgh2jwhmivwex37rgxcgpkrwuyqokuuysiey7tggntzwz3irn567.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_2 = async_compile.triton('triton_poi_fused_2', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_2(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 16)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 16
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 16*x2 + 144*y1), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/aa/caaphy6jmftxbj3ckdql3butbwcqp5ayaf2ivjs3siifg2jq4ar4.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_3 = async_compile.triton('triton_poi_fused_3', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_3(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 32
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 32*x2 + 288*y1), tmp0, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rc/crc2com54urx7z2tsxr75g43wnsxg2w4vbfptuzmfylwsh36jxft.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_4 = async_compile.triton('triton_poi_fused_4', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 8192, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_4(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 8192
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bu/cbuy56fby4itmxwcn5644vhxoovupz2o7uniixicmdxc743yz2lc.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_5 = async_compile.triton('triton_poi_fused_5', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 4096, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_5(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 4096
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zr/czrz3h4gfrwirhghfb7czlmzw3jvt6jlsicvus3iz3xul6aoogke.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_6 = async_compile.triton('triton_poi_fused_6', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_6(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 32
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 32*x2 + 288*y1), tmp0, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5h/c5h3w6gwxhogr3yzo6wir5aocnxuz35eu6w2vuvb5zjzdu4ih2tb.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_7 = async_compile.triton('triton_poi_fused_7', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 4096}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_7(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 4096*y3), ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 12288*y1), tmp0, ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5w/c5wwdwygmv6zxqnhrv3c3oalone6mqpaza3tmly2tz7fofdym34x.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d, img], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d => convolution
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img => relu
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_3, %primals_1, %primals_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_8 = async_compile.triton('triton_poi_fused_convolution_relu_8', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_8(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/tf/ctff5dgfpuwireresr75haiunzab75tjbqgyf2njd2ohej2whgcd.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_2, img_2], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_2 => convolution_2
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_2 => relu_2
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %primals_6, %primals_7, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_9 = async_compile.triton('triton_poi_fused_convolution_relu_9', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_9(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/he/cheys6bcnsxybg5lb7p75vmtsxvhoi3aw3cch5syc7dvoio2sqby.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_5, img_5], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_5 => convolution_5
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_5 => relu_5
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_12, %primals_13, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_10 = async_compile.triton('triton_poi_fused_convolution_relu_10', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_10(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/c5/cc5tl23q4twnksdbdkzwiix6vgjybvzusrjfihlu4h7xg3dsat7m.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_8, img_8], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_8 => convolution_8
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_8 => relu_8
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_7, %primals_18, %primals_19, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_11 = async_compile.triton('triton_poi_fused_convolution_relu_11', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_11', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_11(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hw/chwq7bysete6hctxjhurqwutdcgbkgdd645vx6hpqk2j5uqjvfof.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_12 = async_compile.triton('triton_poi_fused_12', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16384, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_12(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 16384
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/by/cbyrmr4zrmukofnpcjae3qqikfo53ocdfxdrhqr6g6yeir66d3m5.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_13 = async_compile.triton('triton_poi_fused_13', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 32768, 'x': 32}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_13(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 32768
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 25
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 25*y3), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 3200*y1), tmp0, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/5v/c5vj3scydovosiobqxte25uutkcipoalvyhmyig2tihkjsrpsk4f.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_11, img_11], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_11 => convolution_11
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_11 => relu_11
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %primals_24, %primals_25, [2, 2], [2, 2], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_14 = async_compile.triton('triton_poi_fused_convolution_relu_14', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_14', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_14(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ma/cma4jv7jfnpfotnwjeq6zid7fux6rrqe5ndyuxueapmpiji4gihl.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_15 = async_compile.triton('triton_poi_fused_15', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 65536, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_15(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 65536
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/e5/ce5gpqtqdkpp52srqiir6drhvqk6mnzt5zu2slfjdhupghpfdz2v.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_16 = async_compile.triton('triton_poi_fused_16', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 131072, 'x': 32}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_16(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 131072
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 25
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 25*y3), xmask & ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 6400*y1), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ni/cnigrqm4uk47ym6wwybxc4u7lmn4qxdpn23fvit4jut67kon35js.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_14, img_14], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_14 => convolution_14
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_14 => relu_14
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_13, %primals_30, %primals_31, [2, 2], [2, 2], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_14 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_14,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_17 = async_compile.triton('triton_poi_fused_convolution_relu_17', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_17', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_17(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4s/c4sves5vd2jgb7aoai3njpzonwocktkci5v6wkqm22dkvmfwxkza.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_18 = async_compile.triton('triton_poi_fused_18', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 262144, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_18(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 262144
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pt/cptyg4gv34l5wir7yyumbtiiv65dcvzxrn3iywtp27uqc3drmvvi.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_17, img_17], Original ATen: [aten.convolution, aten.relu, aten.threshold_backward]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_17 => convolution_17
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_17 => relu_17
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_16, %primals_36, %primals_37, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %le : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_17, 0), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_threshold_backward_19 = async_compile.triton('triton_poi_fused_convolution_relu_threshold_backward_19', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_threshold_backward_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_threshold_backward_19(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp4 <= tmp5
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6n/c6np4jznpzojund2ye4ipvx7hnsccetc7lz7qcpfgbz7opw3wa2x.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_17, img_17, img5], Original ATen: [aten.convolution, aten.relu, aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_17 => convolution_17
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img5 => squeeze_3
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_17 => relu_17
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_16, %primals_36, %primals_37, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze_3 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_17,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_squeeze_20 = async_compile.triton('triton_poi_fused_convolution_relu_squeeze_20', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 4}, tile_hint=TileHint.DEFAULT,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_squeeze_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_squeeze_20(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 2048*y1), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 4*y3), tmp4, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/md/cmd457kqhrdmzi3wk72kcnkbby3zhft66wiou73b5zeswrkklhz2.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [img4], Original ATen: [aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img4 => squeeze_2
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze_2 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_13,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_squeeze_21 = async_compile.triton('triton_poi_fused_squeeze_21', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_squeeze_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_squeeze_21(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 256*x2 + 4096*y1), xmask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 16*y3), tmp0, xmask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fw/cfwtrrgjpji4ngr7ah7dokjak32v26edu2dd4syxzyvtnfuqviyh.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [img3], Original ATen: [aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img3 => squeeze_1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_10,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_squeeze_22 = async_compile.triton('triton_poi_fused_squeeze_22', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 64}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_squeeze_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_squeeze_22(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 128*x2 + 8192*y1), xmask & ymask, eviction_policy='evict_last')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 64*y3), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jh/cjhaa4chhbuaoc2trb7fxvgfhxfkuziajehvflrspm6rszx3leuy.py
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [img2], Original ATen: [aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img2 => squeeze
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_7,), kwargs = {})
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_squeeze_23 = async_compile.triton('triton_poi_fused_squeeze_23', '''
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 256}, tile_hint=TileHint.SQUARE,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_squeeze_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_squeeze_23(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 64*x2 + 16384*y1), xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 256*y3), tmp0, xmask & ymask)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37 = args
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_1, (16, 3, 3, 3), (27, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_2, (16, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_3, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_4, (16, 16, 3, 3), (144, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_5, (16, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_6, (32, 16, 3, 3), (144, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_7, (32, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_8, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_9, (32, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_10, (32, 32, 3, 3), (288, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_11, (32, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_12, (64, 32, 3, 3), (288, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_13, (64, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_14, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_15, (64, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_16, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_17, (64, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_18, (128, 64, 3, 3), (576, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_19, (128, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_20, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_21, (128, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_22, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_23, (128, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_24, (256, 128, 5, 5), (3200, 25, 5, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_25, (256, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_26, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_27, (256, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_28, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_29, (256, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_30, (512, 256, 5, 5), (6400, 25, 5, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_31, (512, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_32, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_33, (512, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_34, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_35, (512, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_36, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_37, (512, ), (1, ))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = empty_strided_cuda((16, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_0.run(primals_1, buf0, 48, 9, grid=grid(48, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_1
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = empty_strided_cuda((16, 16, 3, 3), (144, 1, 48, 16), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_1.run(primals_4, buf2, 256, 9, grid=grid(256, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_4
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = empty_strided_cuda((32, 16, 3, 3), (144, 1, 48, 16), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_2.run(primals_6, buf3, 512, 9, grid=grid(512, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_6
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((32, 32, 3, 3), (288, 1, 96, 32), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_3.run(primals_8, buf4, 1024, 9, grid=grid(1024, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_8
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = empty_strided_cuda((32, 32, 3, 3), (288, 1, 96, 32), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_3.run(primals_10, buf5, 1024, 9, grid=grid(1024, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_10
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_4.run(primals_18, buf9, 8192, 9, grid=grid(8192, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_18
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_5.run(primals_16, buf8, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_16
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_5.run(primals_14, buf7, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_14
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = empty_strided_cuda((64, 32, 3, 3), (288, 1, 96, 32), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_12, buf6, 2048, 9, grid=grid(2048, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_12
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_7.run(primals_3, buf1, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_3
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = extern_kernels.convolution(buf1, buf0, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf19, (4, 16, 64, 64), (65536, 1, 1024, 16))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = buf19; del buf19  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d, img], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_8.run(buf20, primals_2, 262144, grid=grid(262144), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_2
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = extern_kernels.convolution(buf20, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf21, (4, 16, 64, 64), (65536, 1, 1024, 16))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = buf21; del buf21  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1, img_1], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_8.run(buf22, primals_5, 262144, grid=grid(262144), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_5
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = extern_kernels.convolution(buf22, buf3, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf23, (4, 32, 32, 32), (32768, 1, 1024, 32))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = buf23; del buf23  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2, img_2], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_9.run(buf24, primals_7, 131072, grid=grid(131072), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_7
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf24, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 32, 32, 32), (32768, 1, 1024, 32))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = buf25; del buf25  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3, img_3], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_9.run(buf26, primals_9, 131072, grid=grid(131072), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_9
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = extern_kernels.convolution(buf26, buf5, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf27, (4, 32, 32, 32), (32768, 1, 1024, 32))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = buf27; del buf27  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4, img_4], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_9.run(buf28, primals_11, 131072, grid=grid(131072), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_11
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = extern_kernels.convolution(buf28, buf6, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf29, (4, 64, 16, 16), (16384, 1, 1024, 64))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = buf29; del buf29  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5, img_5], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_10.run(buf30, primals_13, 65536, grid=grid(65536), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_13
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = extern_kernels.convolution(buf30, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf31, (4, 64, 16, 16), (16384, 1, 1024, 64))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = buf31; del buf31  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6, img_6], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_10.run(buf32, primals_15, 65536, grid=grid(65536), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_15
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = extern_kernels.convolution(buf32, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf33, (4, 64, 16, 16), (16384, 1, 1024, 64))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = buf33; del buf33  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7, img_7], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_10.run(buf34, primals_17, 65536, grid=grid(65536), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_17
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = extern_kernels.convolution(buf34, buf9, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf36, (4, 128, 8, 8), (8192, 1, 1024, 128))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf36; del buf36  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8, img_8], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf37, primals_19, 32768, grid=grid(32768), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_19
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_12.run(primals_20, buf10, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_20
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = extern_kernels.convolution(buf37, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf38, (4, 128, 8, 8), (8192, 1, 1024, 128))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = buf38; del buf38  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9, img_9], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf39, primals_21, 32768, grid=grid(32768), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_21
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_12.run(primals_22, buf11, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_22
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = extern_kernels.convolution(buf39, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf40, (4, 128, 8, 8), (8192, 1, 1024, 128))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = buf40; del buf40  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10, img_10], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf41, primals_23, 32768, grid=grid(32768), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_23
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = empty_strided_cuda((256, 128, 5, 5), (3200, 1, 640, 128), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_13.run(primals_24, buf12, 32768, 25, grid=grid(32768, 25), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_24
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = extern_kernels.convolution(buf41, buf12, stride=(2, 2), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf43, (4, 256, 4, 4), (4096, 1, 1024, 256))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = buf43; del buf43  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11, img_11], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_14.run(buf44, primals_25, 16384, grid=grid(16384), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_25
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_15.run(primals_26, buf13, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_26
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = extern_kernels.convolution(buf44, buf13, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf45, (4, 256, 4, 4), (4096, 1, 1024, 256))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = buf45; del buf45  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12, img_12], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_14.run(buf46, primals_27, 16384, grid=grid(16384), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_27
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_15.run(primals_28, buf14, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_28
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = extern_kernels.convolution(buf46, buf14, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf47, (4, 256, 4, 4), (4096, 1, 1024, 256))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = buf47; del buf47  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13, img_13], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_14.run(buf48, primals_29, 16384, grid=grid(16384), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_29
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = empty_strided_cuda((512, 256, 5, 5), (6400, 1, 1280, 256), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_16.run(primals_30, buf15, 131072, 25, grid=grid(131072, 25), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_30
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = extern_kernels.convolution(buf48, buf15, stride=(2, 2), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf50, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = buf50; del buf50  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14, img_14], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_17.run(buf51, primals_31, 8192, grid=grid(8192), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_31
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_18.run(primals_32, buf16, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_32
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = extern_kernels.convolution(buf51, buf16, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf52, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = buf52; del buf52  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15, img_15], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_17.run(buf53, primals_33, 8192, grid=grid(8192), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_33
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_18.run(primals_34, buf17, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_34
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = extern_kernels.convolution(buf53, buf17, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf54, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = buf54; del buf54  # reuse
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16, img_16], Original ATen: [aten.convolution, aten.relu]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_17.run(buf55, primals_35, 8192, grid=grid(8192), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_35
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_18.run(primals_36, buf18, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_36
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17], Original ATen: [aten.convolution]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = extern_kernels.convolution(buf55, buf18, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf56, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = empty_strided_cuda((4, 512, 2, 2), (2048, 1, 1024, 512), torch.bool)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17, img_17], Original ATen: [aten.convolution, aten.relu, aten.threshold_backward]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_threshold_backward_19.run(buf56, primals_37, buf58, 8192, grid=grid(8192), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17, img_17, img5], Original ATen: [aten.convolution, aten.relu, aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_squeeze_20.run(buf56, primals_37, buf57, 2048, 4, grid=grid(2048, 4), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf56
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_37
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [img4], Original ATen: [aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_squeeze_21.run(buf48, buf49, 1024, 16, grid=grid(1024, 16), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [img3], Original ATen: [aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_squeeze_22.run(buf41, buf42, 512, 64, grid=grid(512, 64), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [img2], Original ATen: [aten.squeeze]
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_squeeze_23.run(buf34, buf35, 256, 256, grid=grid(256, 256), stream=stream0)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf35, buf42, buf49, buf57, buf0, buf1, buf2, buf3, buf4, buf5, buf6, buf7, buf8, buf9, buf10, buf11, buf12, buf13, buf14, buf15, buf16, buf17, buf18, buf20, buf22, buf24, buf26, buf28, buf30, buf32, buf34, buf37, buf39, buf41, buf44, buf46, buf48, buf51, buf53, buf55, buf58, )
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1 = rand_strided((16, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_2 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_3 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_4 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_5 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_6 = rand_strided((32, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_7 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_8 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_9 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_10 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_11 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_12 = rand_strided((64, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_13 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_14 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_15 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_16 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_17 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_18 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_19 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_20 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_21 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_22 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_23 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_24 = rand_strided((256, 128, 5, 5), (3200, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_25 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_26 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_27 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_28 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_29 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_30 = rand_strided((512, 256, 5, 5), (6400, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_31 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_32 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_33 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_34 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_35 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_36 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_37 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37])
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 14:07:47.621000 3190652 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 14:07:47.657000 3190652 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/el/celromqo4sautssigdw7mctwcuvgnqzjifxvgugitqmosiem2k3j.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['0_forward']
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3h/c3hpecenggnrxcqg3nyshgwbawgb3vfvl2axvlomnkql4xptnmer.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_0 = async_compile.triton('triton_poi_fused_0', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 64, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_0(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 48
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/34/c3464zi6weokoq52acp66gfau3o5qak3htxz7oaxxip4nrnowu4j.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_1 = async_compile.triton('triton_poi_fused_1', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_1(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 16)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 16
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 16*x2 + 144*y1), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/gh/cgh2jwhmivwex37rgxcgpkrwuyqokuuysiey7tggntzwz3irn567.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_2 = async_compile.triton('triton_poi_fused_2', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_2', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_2(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 16)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 16
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 16*x2 + 144*y1), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/aa/caaphy6jmftxbj3ckdql3butbwcqp5ayaf2ivjs3siifg2jq4ar4.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_3 = async_compile.triton('triton_poi_fused_3', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_3', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_3(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 32
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 32*x2 + 288*y1), tmp0, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/rc/crc2com54urx7z2tsxr75g43wnsxg2w4vbfptuzmfylwsh36jxft.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_4 = async_compile.triton('triton_poi_fused_4', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 8192, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_4', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_4(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 8192
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bu/cbuy56fby4itmxwcn5644vhxoovupz2o7uniixicmdxc743yz2lc.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_5 = async_compile.triton('triton_poi_fused_5', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 4096, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_5', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_5(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 4096
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/zr/czrz3h4gfrwirhghfb7czlmzw3jvt6jlsicvus3iz3xul6aoogke.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_6 = async_compile.triton('triton_poi_fused_6', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_6', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_6(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 32
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 32*x2 + 288*y1), tmp0, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5h/c5h3w6gwxhogr3yzo6wir5aocnxuz35eu6w2vuvb5zjzdu4ih2tb.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_7 = async_compile.triton('triton_poi_fused_7', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 4096}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_7', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_7(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 4096*y3), ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 12288*y1), tmp0, ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5w/c5wwdwygmv6zxqnhrv3c3oalone6mqpaza3tmly2tz7fofdym34x.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d, img], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d => convolution
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img => relu
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%primals_3, %primals_1, %primals_2, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_8 = async_compile.triton('triton_poi_fused_convolution_relu_8', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_8', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_8(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 16)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/tf/ctff5dgfpuwireresr75haiunzab75tjbqgyf2njd2ohej2whgcd.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_2, img_2], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_2 => convolution_2
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_2 => relu_2
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_1, %primals_6, %primals_7, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_9 = async_compile.triton('triton_poi_fused_convolution_relu_9', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_9(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/he/cheys6bcnsxybg5lb7p75vmtsxvhoi3aw3cch5syc7dvoio2sqby.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_5, img_5], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_5 => convolution_5
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_5 => relu_5
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %primals_12, %primals_13, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_10 = async_compile.triton('triton_poi_fused_convolution_relu_10', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_10', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_10(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/c5/cc5tl23q4twnksdbdkzwiix6vgjybvzusrjfihlu4h7xg3dsat7m.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_8, img_8], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_8 => convolution_8
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_8 => relu_8
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_7, %primals_18, %primals_19, [2, 2], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_11 = async_compile.triton('triton_poi_fused_convolution_relu_11', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_11', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_11(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/hw/chwq7bysete6hctxjhurqwutdcgbkgdd645vx6hpqk2j5uqjvfof.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_12 = async_compile.triton('triton_poi_fused_12', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16384, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_12', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_12(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 16384
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/by/cbyrmr4zrmukofnpcjae3qqikfo53ocdfxdrhqr6g6yeir66d3m5.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_13 = async_compile.triton('triton_poi_fused_13', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 32768, 'x': 32}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_13', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_13(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 32768
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 25
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 25*y3), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 3200*y1), tmp0, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/5v/c5vj3scydovosiobqxte25uutkcipoalvyhmyig2tihkjsrpsk4f.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_11, img_11], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_11 => convolution_11
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_11 => relu_11
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %primals_24, %primals_25, [2, 2], [2, 2], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_14 = async_compile.triton('triton_poi_fused_convolution_relu_14', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_14', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_14(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ma/cma4jv7jfnpfotnwjeq6zid7fux6rrqe5ndyuxueapmpiji4gihl.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_15 = async_compile.triton('triton_poi_fused_15', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 65536, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_15', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_15(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 65536
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/e5/ce5gpqtqdkpp52srqiir6drhvqk6mnzt5zu2slfjdhupghpfdz2v.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_16 = async_compile.triton('triton_poi_fused_16', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 131072, 'x': 32}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_16', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_16(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 131072
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 25
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 25*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 6400*y1), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ni/cnigrqm4uk47ym6wwybxc4u7lmn4qxdpn23fvit4jut67kon35js.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_14, img_14], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_14 => convolution_14
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_14 => relu_14
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_13, %primals_30, %primals_31, [2, 2], [2, 2], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_14 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_14,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_17 = async_compile.triton('triton_poi_fused_convolution_relu_17', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_17', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_17(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/4s/c4sves5vd2jgb7aoai3njpzonwocktkci5v6wkqm22dkvmfwxkza.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_18 = async_compile.triton('triton_poi_fused_18', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 262144, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_18', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_18(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 262144
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/pt/cptyg4gv34l5wir7yyumbtiiv65dcvzxrn3iywtp27uqc3drmvvi.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_17, img_17], Original ATen: [aten.convolution, aten.relu, aten.threshold_backward]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_17 => convolution_17
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_17 => relu_17
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_16, %primals_36, %primals_37, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %le : [num_users=1] = call_function[target=torch.ops.aten.le.Scalar](args = (%relu_17, 0), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_threshold_backward_19 = async_compile.triton('triton_poi_fused_convolution_relu_threshold_backward_19', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8192}, 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*i1', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_threshold_backward_19', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_threshold_backward_19(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8192
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2), None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp4 <= tmp5
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp6, None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/6n/c6np4jznpzojund2ye4ipvx7hnsccetc7lz7qcpfgbz7opw3wa2x.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [conv2d_17, img_17, img5], Original ATen: [aten.convolution, aten.relu, aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   conv2d_17 => convolution_17
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img5 => squeeze_3
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img_17 => relu_17
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_16, %primals_36, %primals_37, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=2] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze_3 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_17,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_relu_squeeze_20 = async_compile.triton('triton_poi_fused_convolution_relu_squeeze_20', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 4}, tile_hint=TileHint.DEFAULT,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_relu_squeeze_20', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_relu_squeeze_20(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 2048*y1), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 4*y3), tmp4, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/md/cmd457kqhrdmzi3wk72kcnkbby3zhft66wiou73b5zeswrkklhz2.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [img4], Original ATen: [aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img4 => squeeze_2
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze_2 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_13,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_squeeze_21 = async_compile.triton('triton_poi_fused_squeeze_21', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_squeeze_21', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_squeeze_21(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 256*x2 + 4096*y1), xmask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 16*y3), tmp0, xmask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fw/cfwtrrgjpji4ngr7ah7dokjak32v26edu2dd4syxzyvtnfuqviyh.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [img3], Original ATen: [aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img3 => squeeze_1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze_1 : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_10,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_squeeze_22 = async_compile.triton('triton_poi_fused_squeeze_22', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 64}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_squeeze_22', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_squeeze_22(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 128*x2 + 8192*y1), xmask & ymask, eviction_policy='evict_last')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 64*y3), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/jh/cjhaa4chhbuaoc2trb7fxvgfhxfkuziajehvflrspm6rszx3leuy.py
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [img2], Original ATen: [aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   img2 => squeeze
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %squeeze : [num_users=1] = call_function[target=torch.ops.aten.squeeze.default](args = (%relu_7,), kwargs = {})
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_squeeze_23 = async_compile.triton('triton_poi_fused_squeeze_23', '''
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 256}, tile_hint=TileHint.SQUARE,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_squeeze_23', 'mutated_arg_names': [], 'optimize_mem': False, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_squeeze_23(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 64*x2 + 16384*y1), xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 256*y3), tmp0, xmask & ymask)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37 = args
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_1, (16, 3, 3, 3), (27, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_2, (16, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_3, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_4, (16, 16, 3, 3), (144, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_5, (16, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_6, (32, 16, 3, 3), (144, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_7, (32, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_8, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_9, (32, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_10, (32, 32, 3, 3), (288, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_11, (32, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_12, (64, 32, 3, 3), (288, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_13, (64, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_14, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_15, (64, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_16, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_17, (64, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_18, (128, 64, 3, 3), (576, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_19, (128, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_20, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_21, (128, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_22, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_23, (128, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_24, (256, 128, 5, 5), (3200, 25, 5, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_25, (256, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_26, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_27, (256, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_28, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_29, (256, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_30, (512, 256, 5, 5), (6400, 25, 5, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_31, (512, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_32, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_33, (512, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_34, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_35, (512, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_36, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(primals_37, (512, ), (1, ))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = empty_strided_cuda((16, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_0.run(primals_1, buf0, 48, 9, grid=grid(48, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_1
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = empty_strided_cuda((16, 16, 3, 3), (144, 1, 48, 16), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_1.run(primals_4, buf2, 256, 9, grid=grid(256, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_4
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = empty_strided_cuda((32, 16, 3, 3), (144, 1, 48, 16), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_2.run(primals_6, buf3, 512, 9, grid=grid(512, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_6
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((32, 32, 3, 3), (288, 1, 96, 32), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_3.run(primals_8, buf4, 1024, 9, grid=grid(1024, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_8
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = empty_strided_cuda((32, 32, 3, 3), (288, 1, 96, 32), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_3.run(primals_10, buf5, 1024, 9, grid=grid(1024, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_10
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_4.run(primals_18, buf9, 8192, 9, grid=grid(8192, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_18
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_5.run(primals_16, buf8, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_16
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_5.run(primals_14, buf7, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_14
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = empty_strided_cuda((64, 32, 3, 3), (288, 1, 96, 32), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_6.run(primals_12, buf6, 2048, 9, grid=grid(2048, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_12
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_7.run(primals_3, buf1, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_3
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = extern_kernels.convolution(buf1, buf0, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf19, (4, 16, 64, 64), (65536, 1, 1024, 16))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = buf19; del buf19  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d, img], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_8.run(buf20, primals_2, 262144, grid=grid(262144), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_2
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = extern_kernels.convolution(buf20, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf21, (4, 16, 64, 64), (65536, 1, 1024, 16))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = buf21; del buf21  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_1, img_1], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_8.run(buf22, primals_5, 262144, grid=grid(262144), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_5
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = extern_kernels.convolution(buf22, buf3, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf23, (4, 32, 32, 32), (32768, 1, 1024, 32))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = buf23; del buf23  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_2, img_2], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_9.run(buf24, primals_7, 131072, grid=grid(131072), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_7
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf24, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 32, 32, 32), (32768, 1, 1024, 32))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = buf25; del buf25  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_3, img_3], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_9.run(buf26, primals_9, 131072, grid=grid(131072), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_9
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = extern_kernels.convolution(buf26, buf5, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf27, (4, 32, 32, 32), (32768, 1, 1024, 32))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = buf27; del buf27  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_4, img_4], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_9.run(buf28, primals_11, 131072, grid=grid(131072), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_11
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = extern_kernels.convolution(buf28, buf6, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf29, (4, 64, 16, 16), (16384, 1, 1024, 64))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = buf29; del buf29  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_5, img_5], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_10.run(buf30, primals_13, 65536, grid=grid(65536), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_13
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = extern_kernels.convolution(buf30, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf31, (4, 64, 16, 16), (16384, 1, 1024, 64))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = buf31; del buf31  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_6, img_6], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_10.run(buf32, primals_15, 65536, grid=grid(65536), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_15
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = extern_kernels.convolution(buf32, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf33, (4, 64, 16, 16), (16384, 1, 1024, 64))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = buf33; del buf33  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_7, img_7], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_10.run(buf34, primals_17, 65536, grid=grid(65536), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_17
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = extern_kernels.convolution(buf34, buf9, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf36, (4, 128, 8, 8), (8192, 1, 1024, 128))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf36; del buf36  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_8, img_8], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf37, primals_19, 32768, grid=grid(32768), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_19
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_12.run(primals_20, buf10, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_20
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = extern_kernels.convolution(buf37, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf38, (4, 128, 8, 8), (8192, 1, 1024, 128))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = buf38; del buf38  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_9, img_9], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf39, primals_21, 32768, grid=grid(32768), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_21
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_12.run(primals_22, buf11, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_22
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = extern_kernels.convolution(buf39, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf40, (4, 128, 8, 8), (8192, 1, 1024, 128))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = buf40; del buf40  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_10, img_10], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_11.run(buf41, primals_23, 32768, grid=grid(32768), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_23
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = empty_strided_cuda((256, 128, 5, 5), (3200, 1, 640, 128), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_13.run(primals_24, buf12, 32768, 25, grid=grid(32768, 25), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_24
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = extern_kernels.convolution(buf41, buf12, stride=(2, 2), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf43, (4, 256, 4, 4), (4096, 1, 1024, 256))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = buf43; del buf43  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_11, img_11], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_14.run(buf44, primals_25, 16384, grid=grid(16384), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_25
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_15.run(primals_26, buf13, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_26
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = extern_kernels.convolution(buf44, buf13, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf45, (4, 256, 4, 4), (4096, 1, 1024, 256))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = buf45; del buf45  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_12, img_12], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_14.run(buf46, primals_27, 16384, grid=grid(16384), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_27
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_15.run(primals_28, buf14, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_28
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = extern_kernels.convolution(buf46, buf14, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf47, (4, 256, 4, 4), (4096, 1, 1024, 256))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = buf47; del buf47  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_13, img_13], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_14.run(buf48, primals_29, 16384, grid=grid(16384), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_29
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = empty_strided_cuda((512, 256, 5, 5), (6400, 1, 1280, 256), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_16.run(primals_30, buf15, 131072, 25, grid=grid(131072, 25), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_30
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = extern_kernels.convolution(buf48, buf15, stride=(2, 2), padding=(2, 2), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf50, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = buf50; del buf50  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_14, img_14], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_17.run(buf51, primals_31, 8192, grid=grid(8192), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_31
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_18.run(primals_32, buf16, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_32
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = extern_kernels.convolution(buf51, buf16, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf52, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = buf52; del buf52  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_15, img_15], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_17.run(buf53, primals_33, 8192, grid=grid(8192), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_33
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_18.run(primals_34, buf17, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_34
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = extern_kernels.convolution(buf53, buf17, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf54, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = buf54; del buf54  # reuse
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_16, img_16], Original ATen: [aten.convolution, aten.relu]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_17.run(buf55, primals_35, 8192, grid=grid(8192), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_35
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_18.run(primals_36, buf18, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_36
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17], Original ATen: [aten.convolution]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = extern_kernels.convolution(buf55, buf18, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf56, (4, 512, 2, 2), (2048, 1, 1024, 512))
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = empty_strided_cuda((4, 512, 2, 2), (2048, 1, 1024, 512), torch.bool)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17, img_17], Original ATen: [aten.convolution, aten.relu, aten.threshold_backward]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_threshold_backward_19.run(buf56, primals_37, buf58, 8192, grid=grid(8192), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = empty_strided_cuda((4, 512, 2, 2), (2048, 4, 2, 1), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [conv2d_17, img_17, img5], Original ATen: [aten.convolution, aten.relu, aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_relu_squeeze_20.run(buf56, primals_37, buf57, 2048, 4, grid=grid(2048, 4), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf56
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del primals_37
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = empty_strided_cuda((4, 256, 4, 4), (4096, 16, 4, 1), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [img4], Original ATen: [aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_squeeze_21.run(buf48, buf49, 1024, 16, grid=grid(1024, 16), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = empty_strided_cuda((4, 128, 8, 8), (8192, 64, 8, 1), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [img3], Original ATen: [aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_squeeze_22.run(buf41, buf42, 512, 64, grid=grid(512, 64), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = empty_strided_cuda((4, 64, 16, 16), (16384, 256, 16, 1), torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [img2], Original ATen: [aten.squeeze]
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_squeeze_23.run(buf34, buf35, 256, 256, grid=grid(256, 256), stream=stream0)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf35, buf42, buf49, buf57, buf0, buf1, buf2, buf3, buf4, buf5, buf6, buf7, buf8, buf9, buf10, buf11, buf12, buf13, buf14, buf15, buf16, buf17, buf18, buf20, buf22, buf24, buf26, buf28, buf30, buf32, buf34, buf37, buf39, buf41, buf44, buf46, buf48, buf51, buf53, buf55, buf58, )
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_1 = rand_strided((16, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_2 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_3 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_4 = rand_strided((16, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_5 = rand_strided((16, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_6 = rand_strided((32, 16, 3, 3), (144, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_7 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_8 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_9 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_10 = rand_strided((32, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_11 = rand_strided((32, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_12 = rand_strided((64, 32, 3, 3), (288, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_13 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_14 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_15 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_16 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_17 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_18 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_19 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_20 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_21 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_22 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_23 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_24 = rand_strided((256, 128, 5, 5), (3200, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_25 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_26 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_27 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_28 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_29 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_30 = rand_strided((512, 256, 5, 5), (6400, 25, 5, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_31 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_32 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_33 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_34 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_35 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_36 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     primals_37 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37])
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0205 18:57:08.758000 816045 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 18:57:08.788000 816045 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: inductor_cache/nh/cnh3wbgdkj2hg2su6ceolmhgmbiuxofxmlwgoim26w2iu6sf2xvl.py
