V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['6_inference']
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4u/c4uphk3fqlj6q7n67bpi7eytulvyt7qomgbbaq7oo22qmpn4mxtm.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones_2], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones_2 => full_default_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_10 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 128, 128], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_0 = async_compile.triton('triton_poi_fused_ones_0', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_0(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ae/caezwt3dazloz6k5qlrlf2btuoq3t2jffhdyjxdg2kdfn4gpc6oh.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16384, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 16384
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/lx/clxoagskmjx5qordpcuqhf5cmcss3cct52b3w7porwml3uigcntv.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 8192, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 8192
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/rr/crrkolhzwcxnb7fcwtjvvn2euallcs5uu2tul4tymmeil3psm7ci.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, sub_1, x_36, x_37, x_38, x_39], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_3 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_3', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 4096, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_3(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 4096
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/it/citnzpf6ukmbpkqrzwbjhz467f2dfgroknt742n6byzqdy2totcn.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, sub_1, x_36, x_37], Original ATen: [aten.sub, aten.div, aten.convolution]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_sub_4 = async_compile.triton('triton_poi_fused_convolution_div_sub_4', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_sub_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_sub_4(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 192
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/hv/chvlqtgbvtew2pkavtfmpmi2no4jyfczetydksthpgitvsj363ma.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x], Original ATen: [aten.sub, aten.div]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_div_sub_5 = async_compile.triton('triton_poi_fused_div_sub_5', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 4096}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_div_sub_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_div_sub_5(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 4096*y3), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 / tmp3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 12288*y1), tmp4, ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kg/ckg3urqn2dd4lzcaeoagf5gwyuvefbhaoswn2vlc24b7t6e7iqun.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_6 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_6', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_6', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_6(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/vw/cvw3al4oi5lzxpvwkqmaimlwmwbsg6ra2yoxuflcvapxe6gx5zwq.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_7 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_7', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 4096}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_7(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 64*x2 + 262144*y1), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 4096*y3), tmp4, ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oe/coexrasmurz46jvg3thc4m26acaei6nrroxm5bcg5mrtl432vbj3.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 1024}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (64 + 2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (65 + 2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x5 + 65536*y1), tmp6, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/4o/c4o7i3qjuppjqidahaxm5bzhq5xsldnnx7gdtefwxw2pfhdofq5r.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yk/cykebbth7kjxomqdyv637d4zebpzjwyo35iom6nuk35ytcsomf5h.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 1024}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 128*x2 + 131072*y1), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 1024*y3), tmp4, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7y/c7yplctydqvomwece7vi6vev2reakycwxse7sfybcqvpusutldeu.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat_2, mul_21, mul_22], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_21 => mul_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_22 => mul_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat_2 => repeat_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat_2 : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_9, [4, 1, 1]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_24 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_14, %repeat_2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_25 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_14, %repeat_2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_11 = async_compile.triton('triton_poi_fused_mul_repeat_11', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_11', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_11(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 128) % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ya/cyavguuiwrhd25nm3uvga4imk3csx5sr4eadqg6xvitmio4xy6ew.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp_2, add_8, mul_23, dcov_8, dcov_9, dcov_10, add_9, dcov_11], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_8 => add_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_9 => add_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_10 => mul_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_11 => sqrt_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_8 => sub_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_9 => clamp_min_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp_2 => full_default_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_23 => mul_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_11 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 6.103515625e-05), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_8 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_15, %bmm_16), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_26 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_14, 2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_8 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_26), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_2 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_8, 0.0), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_27 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_11, %clamp_min_2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_27, 1e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt_3 : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_9,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 6.103515625e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qt/cqttxpins755lmba6tmii3pj7otftg3ydsrszivx2c7m5vofjaru.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36], Original ATen: [aten.sub, aten.div]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_div_sub_13 = async_compile.triton('triton_poi_fused_div_sub_13', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 262144}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_div_sub_13', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_div_sub_13(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 262144*y3), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 / tmp3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 786432*y1), tmp4, ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/l4/cl4fabuq6fs3hvjklqmspp23uc4cidamix2dan7tmfvziu3o6f6r.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_14 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_14', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 67108864}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_14', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_14(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 67108864
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/nc/cnc2kqqwvia5gdxbjjyl44vjfwzilknjvxg26ecvyrrj6ndx4cxu.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_15 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_15', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 262144}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_15(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 64*x2 + 16777216*y1), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 262144*y3), tmp4, ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pq/cpqgx3pqeahxytpbugniotlx23eddvrfgqdj7j6uh47lplu3t6xy.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 65536}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (512 + 2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (513 + 2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x5 + 4194304*y1), tmp6, ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/kd/ckd2ryfdtkv44wiawkdredaf6zz4dlmxkchlcugqhh7vsxkeoa2t.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 33554432}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 33554432
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/f7/cf7y4k57xzogbyfip75pq7x3nb6vyyho6z3oellxx3zu3ulxetws.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 65536}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 128*x2 + 8388608*y1), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 65536*y3), tmp4, ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/c4/cc4cxnivmqnkcuni2wbcuxq5h6gsvxt3dhyelkngo5rb6fen6wm4.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_1 => sum_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_1 => sum_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_1 => sum_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_2 => add_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_3 => add_13
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_25 => mul_28
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_26 => mul_29
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_27 => mul_30
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_33 => mul_37
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_34 => mul_38
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_35 => mul_39
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_36 => mul_40
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_37 => mul_41
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_38 => mul_42
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_10 => sub_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_12 => sub_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_13 => sub_13
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_9 => sub_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_28 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_17, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_9 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_3, %mul_28), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_18, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_10 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_9, %mul_29), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_30 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_20, 6.103515625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_10 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_10, %mul_30), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_37 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_24, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_12 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_4, %mul_37), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_38 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_25, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_13 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_12, %mul_38), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_39 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_27, 6.103515625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_13 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_13, %mul_39), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_40 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_13), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_40, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_41 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_10), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_41, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_42 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_13, %add_13), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_42, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_sub_sum_19 = async_compile.triton('triton_red_fused_add_mul_sub_sum_19', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8, 'r': 8192},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_sub_sum_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_sub_sum_19(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8192
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.0078125
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 6.103515625e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp24, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp28, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp32, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/7i/c7i667oq44lt437lh7ijd2fawdbunfuyskqyecrkmgjsq6sf3bka.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_1 => sum_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_1 => sum_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_1 => sum_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_2 => add_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_3 => add_13
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_25 => mul_28
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_26 => mul_29
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_27 => mul_30
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_33 => mul_37
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_34 => mul_38
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_35 => mul_39
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_36 => mul_40
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_37 => mul_41
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_38 => mul_42
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_10 => sub_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_12 => sub_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_13 => sub_13
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_9 => sub_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_28 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_17, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_9 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_3, %mul_28), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_18, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_10 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_9, %mul_29), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_30 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_20, 6.103515625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_10 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_10, %mul_30), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_37 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_24, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_12 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_4, %mul_37), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_38 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_25, 0.0078125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_13 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_12, %mul_38), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_39 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_27, 6.103515625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_13 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_13, %mul_39), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_40 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_13), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_40, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_41 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_10), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_41, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_42 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_13, %add_13), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_42, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_add_mul_stack_sub_sum_20 = async_compile.triton('triton_per_fused_add_mul_stack_sub_sum_20', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 2},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_mul_stack_sub_sum_20', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_add_mul_stack_sub_sum_20(in_ptr0, in_ptr1, in_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 2*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r1 + 2*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r1 + 2*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = 1e-06
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp4 + tmp15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 * tmp14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = libdevice.sqrt(tmp17)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 + tmp15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp16 / tmp19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp20, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3d/c3dszbnfxhi6mel6ylwm373o7ssxzdwapx23km72gkryrizfnos4.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones_4], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones_4 => full_default_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_18 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 256, 256], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_21 = async_compile.triton('triton_poi_fused_ones_21', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_21', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_21(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/fb/cfbfjntq4hakpxqf6minwds45mpckhrqfpwwt4a5gz3ac6kbhipf.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 32768, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 32768
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/qz/cqzqjh3cssqlrg3q6nteutfqekzvtg6ienxjosjp2iqpnhkg5u66.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 256}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 16)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x5 + 32768*y1), tmp6, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/m5/cm5eye3svuxtcojajpyhrwjumbwskmumotob4poekvcw4loxbxhw.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/yu/cyuwsgmljehmqabc46hh6ayd7hjjpfuxeghzw2fevssdtnp5frs7.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 65536, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 65536
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/iq/ciqrgfh3kg3cweeo4nonbgz2ovljh67er5v5mtavgsx3fbu7732h.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 256}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 256*x2 + 65536*y1), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 256*y3), tmp4, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/de/cderbz5kj3xmpm4orwj22mb6gtcjwcyoq52wsa3jbwxk4cmmjp3d.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat_4, mul_41, mul_42], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_41 => mul_46
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_42 => mul_47
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat_4 => repeat_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat_4 : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_17, [4, 1, 1]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_46 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_28, %repeat_4), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_47 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_28, %repeat_4), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_27 = async_compile.triton('triton_poi_fused_mul_repeat_27', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_27', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_27(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/oe/coeu43v4eqkl2bcv5x5j22rh2m66ut2qyz5blbe62bbbozwoonc5.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp_4, add_16, mul_43, dcov_16, dcov_17, dcov_18, add_17, dcov_19], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_16 => add_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_17 => add_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_16 => sub_14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_17 => clamp_min_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_18 => mul_49
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_19 => sqrt_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp_4 => full_default_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_43 => mul_48
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_19 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 1.5258788153005298e-05), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_16 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_29, %bmm_30), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_28, 2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_14 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_16, %mul_48), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_4 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_14, 0.0), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_19, %clamp_min_4), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_17 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_49, 1e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt_6 : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1.5258788153005298e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gf/cgfz7srtyuyeeomnsa4yhd6zqdc34f2pgh6onmkvq6qkwenoz6kc.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 16384}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (256 + 2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (257 + 2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x5 + 2097152*y1), tmp6, ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/wf/cwfcn7tcxurfr72bvpgseejdtfxdfo5kts5zmljjdif5labx6hal.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16777216}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16777216
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/j3/cj3tlvpfpun2rpl557cio53halkqpeo3ggqidzc7xtmy37zlkldj.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 16384}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 256*x2 + 4194304*y1), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 16384*y3), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ez/cezmhvk5s7xoyhie6dxetwtwoe7cjgjsxcwb2w6er46rg6nvod7x.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_2 => sum_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_2 => sum_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_2 => sum_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_4 => add_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_5 => add_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_45 => mul_50
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_46 => mul_51
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_47 => mul_52
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_53 => mul_59
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_54 => mul_60
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_55 => mul_61
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_56 => mul_62
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_57 => mul_63
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_58 => mul_64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_15 => sub_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_16 => sub_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_18 => sub_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_19 => sub_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_31, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_15 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_6, %mul_50), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_51 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_32, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_16 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_15, %mul_51), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_52 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_34, 1.52587890625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_18 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_16, %mul_52), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_59 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_38, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_18 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_7, %mul_59), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_60 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_39, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_18, %mul_60), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_41, 1.52587890625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_21 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_19, %mul_61), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_62 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_21), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_62, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_63 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_18), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_63, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_64 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_21, %add_21), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_64, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_sub_sum_32 = async_compile.triton('triton_red_fused_add_mul_sub_sum_32', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32, 'r': 8192},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_sub_sum_32', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_sub_sum_32(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8192
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.00390625
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 1.52587890625e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp24, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp28, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp32, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/sb/csbuxprofcvghtgzfrp4xmdzagkjd3mcy2dvptvxj6vyh3y2ajxb.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_2 => sum_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_2 => sum_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_2 => sum_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_4 => add_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_5 => add_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_45 => mul_50
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_46 => mul_51
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_47 => mul_52
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_53 => mul_59
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_54 => mul_60
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_55 => mul_61
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_56 => mul_62
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_57 => mul_63
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_58 => mul_64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_15 => sub_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_16 => sub_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_18 => sub_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_19 => sub_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_31, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_15 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_6, %mul_50), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_51 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_32, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_16 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_15, %mul_51), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_52 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_34, 1.52587890625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_18 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_16, %mul_52), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_59 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_38, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_18 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_7, %mul_59), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_60 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_39, 0.00390625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_18, %mul_60), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_41, 1.52587890625e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_21 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_19, %mul_61), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_62 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_21), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_62, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_63 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_18), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_63, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_64 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_21, %add_21), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_64, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_add_mul_stack_sub_sum_33 = async_compile.triton('triton_per_fused_add_mul_stack_sub_sum_33', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 8},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_mul_stack_sub_sum_33', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_add_mul_stack_sub_sum_33(in_ptr0, in_ptr1, in_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 8*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r1 + 8*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r1 + 8*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = 1e-06
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp4 + tmp15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 * tmp14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = libdevice.sqrt(tmp17)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 + tmp15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp16 / tmp19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp20, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gv/cgvq2m3a77v6ovwh3kuhctq7izkxf2j2z7obpp7jefmi6lhip4bx.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones_6], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones_6 => full_default_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_26 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 512, 512], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_34 = async_compile.triton('triton_poi_fused_ones_34', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_34', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_34(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dd/cdd2pjizwfvgzygimhruablz7j3fyjg2hmwcvu2pvoh74hr6ugvk.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 64}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 8)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x5 + 16384*y1), tmp6, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/gv/cgvliqgeblmyvvq4txz4cidrumc52utjlek5xhrszvuruudcsndk.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 131072, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 131072
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/we/cwetxl3zgnau4mu3vmiiffnls6utrqt6rrtwkca7sozek4ms7sem.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dr/cdryd4bhxduj7a5d4caqlfiuoezkuunlirso453zffifkusvmtwm.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 262144, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 262144
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xw/cxwqnu5wptxcgkurc4idyth6wqeasp45qtklkdo4usbs7pcm3i75.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 64}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 32768*y1), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 64*y3), tmp4, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/jq/cjq3tdkgwqp6lmb7rpnpk25pjyyte23l4n5y5swniymbkqwa4ek7.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat_6, mul_61, mul_62], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_61 => mul_68
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_62 => mul_69
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat_6 => repeat_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat_6 : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_25, [4, 1, 1]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_68 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_42, %repeat_6), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_69 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_42, %repeat_6), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_40 = async_compile.triton('triton_poi_fused_mul_repeat_40', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_40', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_40(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 512) % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/i5/ci5b6abj7wh464v2wb27hjpwbuia43p7k2ik7rmehfeonlsivou2.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp_6, add_24, mul_63, dcov_24, dcov_25, dcov_26, add_25, dcov_27], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_24 => add_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_25 => add_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_24 => sub_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_25 => clamp_min_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_26 => mul_71
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_27 => sqrt_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp_6 => full_default_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_63 => mul_70
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_27 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 3.8146970382513246e-06), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_24 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_43, %bmm_44), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_70 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_42, 2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_20 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_24, %mul_70), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_6 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_20, 0.0), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_71 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_27, %clamp_min_6), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_25 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_71, 1e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt_9 : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_25,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 3.8146970382513246e-06
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/bu/cbud6knn2y57dh6roes5adenyj2xgidzxpiespagnlfnac7v5ozn.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 4096}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (128 + 2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (129 + 2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x5 + 1048576*y1), tmp6, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3y/c3y7rwqc3zy2j325hdmu3cbeugafb4sdgmoop5zz3gj73ndc6ksk.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8388608}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8388608
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3v/c3vmfrr47ib3in7qtnqueopr5e3r33dfnlpystxdgnh2q4pz24st.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 4096}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 2097152*y1), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 4096*y3), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/2y/c2ybj64mlp5tjh6ti234lxsypxiza2du3cwgmx5trawkkmxzeole.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_3 => sum_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_3 => sum_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_3 => sum_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_6 => add_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_7 => add_29
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_65 => mul_72
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_66 => mul_73
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_67 => mul_74
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_73 => mul_81
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_74 => mul_82
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_75 => mul_83
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_76 => mul_84
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_77 => mul_85
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_78 => mul_86
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_21 => sub_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_22 => sub_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_24 => sub_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_25 => sub_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_72 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_45, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_21 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_9, %mul_72), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_73 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_46, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_22 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_21, %mul_73), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_74 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_48, 3.814697265625e-06), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_26 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_22, %mul_74), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_81 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_52, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_24 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_10, %mul_81), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_82 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_53, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_25 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_24, %mul_82), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_83 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_55, 3.814697265625e-06), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_29 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_25, %mul_83), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_84 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_29), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_84, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_85 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_26), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_85, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_86 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_29, %add_29), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_86, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_sub_sum_45 = async_compile.triton('triton_red_fused_add_mul_sub_sum_45', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128, 'r': 8192},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_sub_sum_45', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_sub_sum_45(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8192
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.001953125
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 3.814697265625e-06
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp24, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp28, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp32, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/ey/cey6iyfm3blcmlde3ozyjijfch4nbn75g24rzqtxem6houm2gyra.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_3 => sum_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_3 => sum_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_3 => sum_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_6 => add_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_7 => add_29
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_65 => mul_72
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_66 => mul_73
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_67 => mul_74
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_73 => mul_81
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_74 => mul_82
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_75 => mul_83
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_76 => mul_84
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_77 => mul_85
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_78 => mul_86
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_21 => sub_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_22 => sub_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_24 => sub_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_25 => sub_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_72 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_45, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_21 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_9, %mul_72), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_73 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_46, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_22 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_21, %mul_73), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_74 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_48, 3.814697265625e-06), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_26 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_22, %mul_74), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_81 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_52, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_24 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_10, %mul_81), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_82 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_53, 0.001953125), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_25 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_24, %mul_82), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_83 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_55, 3.814697265625e-06), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_29 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_25, %mul_83), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_84 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_29), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_84, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_85 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_26), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_85, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_86 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_29, %add_29), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_86, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_add_mul_stack_sub_sum_46 = async_compile.triton('triton_per_fused_add_mul_stack_sub_sum_46', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 32},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_mul_stack_sub_sum_46', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_add_mul_stack_sub_sum_46(in_ptr0, in_ptr1, in_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 32
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 32
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 32*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r1 + 32*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r1 + 32*x0), xmask, other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = 1e-06
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp4 + tmp15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 * tmp14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = libdevice.sqrt(tmp17)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 + tmp15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp16 / tmp19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp20, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/m7/cm7fdwguvl4tbclhou7kdty2ysawnkfdgvjywfuzspan2spodll6.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => _low_memory_max_pool2d_with_offsets_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 16}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x5 + 8192*y1), tmp6, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dc/cdcwjwxtlkqhgilrullqxguy5yoiubhrqtj3etz3qwd7xszqowks.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => _low_memory_max_pool2d_with_offsets_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => convolution_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_30 => relu_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/3w/c3wgjrcacagsfwc5u2ooonww3c3mdfuebwucn6cg5k3yvax6lpln.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => _low_memory_max_pool2d_with_offsets_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => convolution_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_30 => relu_12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_31 => convolution_13
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_32 => relu_13
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_33 => convolution_14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_34 => relu_14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_35 => convolution_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_12, %arg30_1, %arg31_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_13 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_13,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_13, %arg32_1, %arg33_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_14 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_14,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_15 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_14, %arg34_1, %arg35_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 8192*y1), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 16*y3), tmp2, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xz/cxzan4jsydudlfxx2x2pktpcbwczrpzjzb65ih6ycn6c454dlzsv.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => _low_memory_max_pool2d_with_offsets_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_7 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_26, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 1024}, tile_hint=TileHint.SQUARE,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (64 + 2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (65 + 2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x5 + 524288*y1), tmp6, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/xd/cxdnrwaxqamyw7ilopuzxobmhk3qjevkalgv3arfx3qmx5czzc3p.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => _low_memory_max_pool2d_with_offsets_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_65 => convolution_28
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_7 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_26, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_14, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_27 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2097152}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2097152
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/pu/cpurrsc5vq4nye5jwox3u7t6jxacoj2yeqkdwkkzgv3uqttiy6ll.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => _low_memory_max_pool2d_with_offsets_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_65 => convolution_28
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_67 => convolution_29
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_68 => relu_28
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_69 => convolution_30
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_70 => relu_29
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_71 => convolution_31
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_7 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_26, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_14, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_27 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_29 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_27, %arg30_1, %arg31_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_29,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_30 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_28, %arg32_1, %arg33_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_29 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_30,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_31 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_29, %arg34_1, %arg35_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 1024}, tile_hint=TileHint.DEFAULT,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 524288*y1), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 1024*y3), tmp2, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/dr/cdrrshtd55lt32vwfihidtwi4x4nt4vc3necjrvl7gyzqbovemvo.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones => full_default_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_2 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 64, 64], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_53 = async_compile.triton('triton_poi_fused_ones_53', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_53', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_53(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/i7/ci723w6y6bcn5vp5k6uwp5diwjrvkwb3ervxtcpuspptiyyqbl5e.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat, mul_1, mul_2], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_1 => mul_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_2 => mul_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat => repeat
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_1, [4, 1, 1]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm, %repeat), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm, %repeat), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_54 = async_compile.triton('triton_poi_fused_mul_repeat_54', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_54', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_54(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/as/casrn6v36ztvaeh2jdy3pfla4d2rqup6to7wtndj25uspy2nrvoh.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp, add, mul_3, dcov, dcov_1, dcov_2, add_1, dcov_3], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add => add
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_1 => add_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov => sub_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_1 => clamp_min
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_2 => mul_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_3 => sqrt
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp => full_default_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_3 => mul_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_3 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 0.000244140625), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_1, %bmm_2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm, 2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add, %mul_4), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_2, 0.0), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_5 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_3, %clamp_min), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_5, 1e-05), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_1,), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 0.000244140625
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/6n/c6n2vcodxy72aebth35l3zhk73tn4gqcqbglj6lknyqgua4d3xsv.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_5, sub_3, mul_6, sub_4, mul_7, dcdm, mul_13, sub_6, mul_14, sub_7, mul_15, dcdm_1, mul_16, Gamma_XY, mul_17, Gamma_XX, mul_18, Gamma_YY, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX => sum_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY => sum_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY => sum_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm => add_2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_1 => add_5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_13 => mul_15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_14 => mul_16
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_15 => mul_17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_16 => mul_18
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_17 => mul_19
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_18 => mul_20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_5 => mul_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_6 => mul_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_7 => mul_8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_3 => sub_3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_4 => sub_4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_6 => sub_6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_7 => sub_7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_6 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_3, 0.015625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt, %mul_6), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_4, 0.015625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_3, %mul_7), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_6, 0.000244140625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_2 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_4, %mul_8), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_10, 0.015625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_6 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_1, %mul_15), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_16 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_11, 0.015625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_7 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_6, %mul_16), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_17 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_13, 0.000244140625), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_5 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_7, %mul_17), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_18 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2, %add_5), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_18, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_19 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2, %add_2), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_19, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_20 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_5, %add_5), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_20, [1, 2]), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_stack_sub_sum_56 = async_compile.triton('triton_red_fused_add_mul_stack_sub_sum_56', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 4096},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 10), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_stack_sub_sum_56', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_stack_sub_sum_56(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 4096
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.015625
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 0.000244140625
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = 1e-06
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tmp24 + tmp34
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp28 * tmp32
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = libdevice.sqrt(tmp36)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tmp37 + tmp34
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp39 = tmp35 / tmp38
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp39, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: /tmp/torchinductor_sahanp/zq/czqm4qmckoybde6vhytq3zp4e62222goty27y3cbs2gkx25w63po.py
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mean, score], Original ATen: [aten.mean, aten.rsub]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mean => mean
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   score => sub_32
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%cat, [1], True), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_32 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mean), kwargs = {})
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mean_rsub_57 = async_compile.triton('triton_poi_fused_mean_rsub_57', '''
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mean_rsub_57', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mean_rsub_57(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (5*x0), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 5*x0), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 5*x0), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 5*x0), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.load(in_ptr0 + (4 + 5*x0), xmask, eviction_policy='evict_last')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 + tmp3
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp4 + tmp5
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 5.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 / tmp9
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 - tmp10
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1 = args
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg0_1, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg1_1, (4, 3, 512, 512), (786432, 262144, 512, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg2_1, (1, 3, 1, 1), (3, 1, 1, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg3_1, (1, 3, 1, 1), (3, 1, 1, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg4_1, (64, 3, 3, 3), (27, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg5_1, (64, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg6_1, (64, 64, 3, 3), (576, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg7_1, (64, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg8_1, (128, 64, 3, 3), (576, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg9_1, (128, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg10_1, (128, 128, 3, 3), (1152, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg11_1, (128, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg12_1, (256, 128, 3, 3), (1152, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg13_1, (256, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg14_1, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg15_1, (256, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg16_1, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg17_1, (256, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg18_1, (256, 256, 3, 3), (2304, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg19_1, (256, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg20_1, (512, 256, 3, 3), (2304, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg21_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg22_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg23_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg24_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg25_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg26_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg27_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg28_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg29_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg30_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg31_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg32_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg33_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg34_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg35_1, (512, ), (1, ))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf106 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_2], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_0.run(buf106, 65536, grid=grid(65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1.run(arg10_1, buf11, buf51, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg10_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2.run(arg8_1, buf8, buf48, 8192, 9, grid=grid(8192, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg8_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, sub_1, x_36, x_37, x_38, x_39], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_3.run(arg6_1, buf4, buf44, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg6_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = empty_strided_cuda((64, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = empty_strided_cuda((64, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, sub_1, x_36, x_37], Original ATen: [aten.sub, aten.div, aten.convolution]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_sub_4.run(arg4_1, buf1, buf41, 192, 9, grid=grid(192, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg4_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x], Original ATen: [aten.sub, aten.div]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_div_sub_5.run(arg0_1, arg2_1, arg3_1, buf0, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg0_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1], Original ATen: [aten.sub, aten.div, aten.convolution]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = extern_kernels.convolution(buf0, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf2, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf0
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = buf2; del buf2  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_6.run(buf3, arg5_1, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = extern_kernels.convolution(buf3, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf5, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf4
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = reinterpret_tensor(buf3, (4, 64, 64, 64), (262144, 4096, 64, 1), 0); del buf3  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_7.run(buf5, arg7_1, buf6, 256, 4096, grid=grid(256, 4096), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((4, 64, 32, 32), (65536, 1, 2048, 64), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8.run(buf6, buf7, 256, 1024, grid=grid(256, 1024), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = extern_kernels.convolution(buf7, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf9, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf8
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = buf9; del buf9  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9.run(buf10, arg9_1, 524288, grid=grid(524288), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = extern_kernels.convolution(buf10, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf12, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf11
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = reinterpret_tensor(buf10, (4, 128, 32, 32), (131072, 1024, 32, 1), 0); del buf10  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10.run(buf12, arg11_1, buf13, 512, 1024, grid=grid(512, 1024), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf12
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf105 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_2], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf13, (4, 128, 1024), (131072, 1024, 1), 0), reinterpret_tensor(buf13, (4, 1024, 128), (131072, 1, 1024), 0), out=buf105)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf107 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf109 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_2, mul_21, mul_22], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_11.run(buf105, buf107, buf109, 65536, grid=grid(65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf108 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_2, repeat_2, mul_21, bmm_15], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf106, buf107, out=buf108)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf110 = buf107; del buf107  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_2, mul_22, bmm_16], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf109, buf106, out=buf110)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf111 = buf108; del buf108  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_2, add_8, mul_23, dcov_8, dcov_9, dcov_10, add_9, dcov_11], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12.run(buf111, buf110, buf105, 65536, grid=grid(65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf112 = buf110; del buf110  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_17], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf111, buf106, out=buf112)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf113 = buf105; del buf105  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_18], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf106, buf111, out=buf113)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf114 = buf109; del buf109  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_19], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf106, buf111, out=buf114)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf115 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_20], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf114, buf106, out=buf115)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf117 = buf114; del buf114  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_3], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_0.run(buf117, 65536, grid=grid(65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = empty_strided_cuda((4, 3, 512, 512), (786432, 1, 1536, 3), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36], Original ATen: [aten.sub, aten.div]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_div_sub_13.run(arg1_1, arg2_1, arg3_1, buf40, 12, 262144, grid=grid(12, 262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg1_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg2_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg3_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37], Original ATen: [aten.sub, aten.div, aten.convolution]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = extern_kernels.convolution(buf40, buf41, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf42, (4, 64, 512, 512), (16777216, 1, 32768, 64))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf40
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf41
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = buf42; del buf42  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_14.run(buf43, arg5_1, 67108864, grid=grid(67108864), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg5_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = extern_kernels.convolution(buf43, buf44, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf45, (4, 64, 512, 512), (16777216, 1, 32768, 64))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf44
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = reinterpret_tensor(buf43, (4, 64, 512, 512), (16777216, 262144, 512, 1), 0); del buf43  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_15.run(buf45, arg7_1, buf46, 256, 262144, grid=grid(256, 262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg7_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf45
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = empty_strided_cuda((4, 64, 256, 256), (4194304, 1, 16384, 64), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16.run(buf46, buf47, 256, 65536, grid=grid(256, 65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = extern_kernels.convolution(buf47, buf48, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf49, (4, 128, 256, 256), (8388608, 1, 32768, 128))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf47
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf48
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = buf49; del buf49  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17.run(buf50, arg9_1, 33554432, grid=grid(33554432), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg9_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = extern_kernels.convolution(buf50, buf51, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf52, (4, 128, 256, 256), (8388608, 1, 32768, 128))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf51
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = reinterpret_tensor(buf50, (4, 128, 256, 256), (8388608, 65536, 256, 1), 0); del buf50  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18.run(buf52, arg11_1, buf53, 512, 65536, grid=grid(512, 65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg11_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf52
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf116 = buf106; del buf106  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_3], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf53, (4, 128, 65536), (8388608, 65536, 1), 0), reinterpret_tensor(buf53, (4, 65536, 128), (8388608, 1, 65536), 0), out=buf116)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf118 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf120 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_3, mul_29, mul_30], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_11.run(buf116, buf118, buf120, 65536, grid=grid(65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf119 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_3, repeat_3, mul_29, bmm_22], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf117, buf118, out=buf119)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf121 = buf118; del buf118  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_3, mul_30, bmm_23], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf120, buf117, out=buf121)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf122 = buf119; del buf119  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_3, add_11, mul_31, dcov_12, dcov_13, dcov_14, add_12, dcov_15], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12.run(buf122, buf121, buf116, 65536, grid=grid(65536), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf123 = buf121; del buf121  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_24], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf122, buf117, out=buf123)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf124 = buf116; del buf116  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_25], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf117, buf122, out=buf124)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf125 = buf120; del buf120  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_26], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf117, buf122, out=buf125)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf126 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_27], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf125, buf117, out=buf126)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf117
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf125
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf127 = empty_strided_cuda((4, 2), (2, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf129 = empty_strided_cuda((4, 2), (2, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf131 = empty_strided_cuda((4, 2), (2, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_19.run(buf111, buf112, buf113, buf115, buf122, buf123, buf124, buf126, buf127, buf129, buf131, 8, 8192, grid=grid(8), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf111
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf112
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf113
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf115
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf122
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf123
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf124
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf248 = empty_strided_cuda((4, 5), (5, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf244 = reinterpret_tensor(buf248, (4, 1), (5, 1), 1)  # alias
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_20.run(buf127, buf129, buf131, buf244, 4, 2, grid=grid(4), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf127
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf129
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf131
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf134 = reinterpret_tensor(buf7, (4, 256, 256), (65536, 256, 1), 0); del buf7  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_4], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_21.run(buf134, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = empty_strided_cuda((256, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = empty_strided_cuda((256, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22.run(arg12_1, buf15, buf55, 32768, 9, grid=grid(32768, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg12_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((4, 128, 16, 16), (32768, 1, 2048, 128), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23.run(buf13, buf14, 512, 256, grid=grid(512, 256), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf13
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = extern_kernels.convolution(buf14, buf15, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf16, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf14
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf15
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = buf16; del buf16  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24.run(buf17, arg13_1, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25.run(arg14_1, buf18, buf58, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg14_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = extern_kernels.convolution(buf17, buf18, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf19, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = buf19; del buf19  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24.run(buf20, arg15_1, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = buf18; del buf18  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf61 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25.run(arg16_1, buf21, buf61, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg16_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = extern_kernels.convolution(buf20, buf21, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf22, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = buf22; del buf22  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24.run(buf23, arg17_1, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = buf21; del buf21  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf64 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25.run(arg18_1, buf24, buf64, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg18_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf23, buf24, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf24
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = reinterpret_tensor(buf23, (4, 256, 16, 16), (65536, 256, 16, 1), 0); del buf23  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26.run(buf25, arg19_1, buf26, 1024, 256, grid=grid(1024, 256), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf133 = reinterpret_tensor(buf25, (4, 256, 256), (65536, 256, 1), 0); del buf25  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_4], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf26, (4, 256, 256), (65536, 256, 1), 0), reinterpret_tensor(buf26, (4, 256, 256), (65536, 1, 256), 0), out=buf133)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf135 = reinterpret_tensor(buf20, (4, 256, 256), (65536, 256, 1), 0); del buf20  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf137 = reinterpret_tensor(buf17, (4, 256, 256), (65536, 256, 1), 0); del buf17  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_4, mul_41, mul_42], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_27.run(buf133, buf135, buf137, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf136 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_4, repeat_4, mul_41, bmm_29], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf134, buf135, out=buf136)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf138 = buf135; del buf135  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_4, mul_42, bmm_30], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf137, buf134, out=buf138)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf139 = buf136; del buf136  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_4, add_16, mul_43, dcov_16, dcov_17, dcov_18, add_17, dcov_19], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28.run(buf139, buf138, buf133, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf140 = buf138; del buf138  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_31], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf139, buf134, out=buf140)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf141 = buf133; del buf133  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_32], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf134, buf139, out=buf141)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf142 = buf137; del buf137  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_33], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf134, buf139, out=buf142)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf143 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_34], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf142, buf134, out=buf143)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf145 = buf142; del buf142  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_5], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_21.run(buf145, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = empty_strided_cuda((4, 128, 128, 128), (2097152, 1, 16384, 128), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29.run(buf53, buf54, 512, 16384, grid=grid(512, 16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf53
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = extern_kernels.convolution(buf54, buf55, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf56, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf54
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf55
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = buf56; del buf56  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30.run(buf57, arg13_1, 16777216, grid=grid(16777216), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg13_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf59 = extern_kernels.convolution(buf57, buf58, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf59, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf57
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf58
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf60 = buf59; del buf59  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30.run(buf60, arg15_1, 16777216, grid=grid(16777216), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg15_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf62 = extern_kernels.convolution(buf60, buf61, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf62, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf60
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf61
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf63 = buf62; del buf62  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30.run(buf63, arg17_1, 16777216, grid=grid(16777216), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg17_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf65 = extern_kernels.convolution(buf63, buf64, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf65, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf64
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf66 = reinterpret_tensor(buf63, (4, 256, 128, 128), (4194304, 16384, 128, 1), 0); del buf63  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31.run(buf65, arg19_1, buf66, 1024, 16384, grid=grid(1024, 16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg19_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf65
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf144 = buf134; del buf134  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_5], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf66, (4, 256, 16384), (4194304, 16384, 1), 0), reinterpret_tensor(buf66, (4, 16384, 256), (4194304, 1, 16384), 0), out=buf144)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf146 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf148 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_5, mul_49, mul_50], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_27.run(buf144, buf146, buf148, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf147 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_5, repeat_5, mul_49, bmm_36], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf145, buf146, out=buf147)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf149 = buf146; del buf146  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_5, mul_50, bmm_37], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf148, buf145, out=buf149)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf150 = buf147; del buf147  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_5, add_19, mul_51, dcov_20, dcov_21, dcov_22, add_20, dcov_23], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28.run(buf150, buf149, buf144, 262144, grid=grid(262144), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf151 = buf149; del buf149  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_38], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf150, buf145, out=buf151)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf152 = buf144; del buf144  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_39], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf145, buf150, out=buf152)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf153 = buf148; del buf148  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_40], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf145, buf150, out=buf153)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf154 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_41], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf153, buf145, out=buf154)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf145
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf153
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf155 = empty_strided_cuda((4, 8), (8, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf157 = empty_strided_cuda((4, 8), (8, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf159 = empty_strided_cuda((4, 8), (8, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_32.run(buf139, buf140, buf141, buf143, buf150, buf151, buf152, buf154, buf155, buf157, buf159, 32, 8192, grid=grid(32), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf139
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf140
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf141
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf143
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf150
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf151
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf152
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf154
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf245 = reinterpret_tensor(buf248, (4, 1), (5, 1), 2)  # alias
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_33.run(buf155, buf157, buf159, buf245, 4, 8, grid=grid(4), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf155
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf157
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf159
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf162 = reinterpret_tensor(buf5, (4, 512, 512), (262144, 512, 1), 0); del buf5  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_6], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf162, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = reinterpret_tensor(buf126, (4, 256, 8, 8), (16384, 1, 2048, 256), 0); del buf126  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35.run(buf26, buf27, 1024, 64, grid=grid(1024, 64), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf26
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = empty_strided_cuda((512, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf68 = empty_strided_cuda((512, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36.run(arg20_1, buf28, buf68, 131072, 9, grid=grid(131072, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg20_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = extern_kernels.convolution(buf27, buf28, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf29, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf27
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf28
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = buf29; del buf29  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37.run(buf30, arg21_1, 131072, grid=grid(131072), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf71 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg22_1, buf31, buf71, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg22_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = extern_kernels.convolution(buf30, buf31, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf32, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf30
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = buf32; del buf32  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37.run(buf33, arg23_1, 131072, grid=grid(131072), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = buf31; del buf31  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf74 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg24_1, buf34, buf74, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg24_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = extern_kernels.convolution(buf33, buf34, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf35, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf33
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = buf35; del buf35  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37.run(buf36, arg25_1, 131072, grid=grid(131072), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf34; del buf34  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf77 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg26_1, buf37, buf77, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg26_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = extern_kernels.convolution(buf36, buf37, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf38, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = reinterpret_tensor(buf36, (4, 512, 8, 8), (32768, 64, 8, 1), 0); del buf36  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39.run(buf38, arg27_1, buf39, 2048, 64, grid=grid(2048, 64), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf38
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf161 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_6], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf39, (4, 512, 64), (32768, 64, 1), 0), reinterpret_tensor(buf39, (4, 64, 512), (32768, 1, 64), 0), out=buf161)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf163 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf165 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_6, mul_61, mul_62], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf161, buf163, buf165, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf164 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_6, repeat_6, mul_61, bmm_43], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf162, buf163, out=buf164)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf166 = buf163; del buf163  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_6, mul_62, bmm_44], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf165, buf162, out=buf166)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf167 = buf164; del buf164  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_6, add_24, mul_63, dcov_24, dcov_25, dcov_26, add_25, dcov_27], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf167, buf166, buf161, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf168 = buf166; del buf166  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_45], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf167, buf162, out=buf168)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf169 = buf161; del buf161  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_46], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf162, buf167, out=buf169)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf170 = buf165; del buf165  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_47], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf162, buf167, out=buf170)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf171 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_48], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf170, buf162, out=buf171)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf173 = buf170; del buf170  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_7], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf173, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf67 = empty_strided_cuda((4, 256, 64, 64), (1048576, 1, 16384, 256), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42.run(buf66, buf67, 1024, 4096, grid=grid(1024, 4096), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf66
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf69 = extern_kernels.convolution(buf67, buf68, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf69, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf67
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf68
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf70 = buf69; del buf69  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43.run(buf70, arg21_1, 8388608, grid=grid(8388608), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg21_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf72 = extern_kernels.convolution(buf70, buf71, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf72, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf70
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf73 = buf72; del buf72  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43.run(buf73, arg23_1, 8388608, grid=grid(8388608), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg23_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf75 = extern_kernels.convolution(buf73, buf74, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf75, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf73
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf76 = buf75; del buf75  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43.run(buf76, arg25_1, 8388608, grid=grid(8388608), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg25_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf78 = extern_kernels.convolution(buf76, buf77, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf78, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf79 = reinterpret_tensor(buf76, (4, 512, 64, 64), (2097152, 4096, 64, 1), 0); del buf76  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44.run(buf78, arg27_1, buf79, 2048, 4096, grid=grid(2048, 4096), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg27_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf78
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf172 = buf162; del buf162  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_7], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf79, (4, 512, 4096), (2097152, 4096, 1), 0), reinterpret_tensor(buf79, (4, 4096, 512), (2097152, 1, 4096), 0), out=buf172)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf174 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf176 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_7, mul_69, mul_70], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf172, buf174, buf176, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf175 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_7, repeat_7, mul_69, bmm_50], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf173, buf174, out=buf175)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf177 = buf174; del buf174  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_7, mul_70, bmm_51], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf176, buf173, out=buf177)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf178 = buf175; del buf175  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_7, add_27, mul_71, dcov_28, dcov_29, dcov_30, add_28, dcov_31], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf178, buf177, buf172, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf179 = buf177; del buf177  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_52], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf178, buf173, out=buf179)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf180 = buf172; del buf172  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_53], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf173, buf178, out=buf180)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf181 = buf176; del buf176  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_54], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf173, buf178, out=buf181)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf182 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_55], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf181, buf173, out=buf182)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf183 = empty_strided_cuda((4, 32), (32, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf185 = empty_strided_cuda((4, 32), (32, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf187 = empty_strided_cuda((4, 32), (32, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_45.run(buf167, buf168, buf169, buf171, buf178, buf179, buf180, buf182, buf183, buf185, buf187, 128, 8192, grid=grid(128), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf246 = reinterpret_tensor(buf248, (4, 1), (5, 1), 3)  # alias
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_46.run(buf183, buf185, buf187, buf246, 4, 32, grid=grid(4), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf203 = buf182; del buf182  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_8], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf203, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf189 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47.run(buf39, buf189, 2048, 16, grid=grid(2048, 16), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf39
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf190 = buf77; del buf77  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf214 = buf74; del buf74  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_65], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg28_1, buf190, buf214, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg28_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf191 = extern_kernels.convolution(buf189, buf190, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf191, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf189
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf192 = buf191; del buf191  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48.run(buf192, arg29_1, 32768, grid=grid(32768), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf193 = buf190; del buf190  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf217 = buf71; del buf71  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_30, x_31, x_65, x_66, x_67], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg30_1, buf193, buf217, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg30_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf194 = extern_kernels.convolution(buf192, buf193, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf194, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf192
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf195 = buf194; del buf194  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48.run(buf195, arg31_1, 32768, grid=grid(32768), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf196 = buf193; del buf193  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf220 = buf37; del buf37  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_30, x_31, x_32, x_33, x_65, x_66, x_67, x_68, x_69], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg32_1, buf196, buf220, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg32_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf197 = extern_kernels.convolution(buf195, buf196, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf197, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf195
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf198 = buf197; del buf197  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48.run(buf198, arg33_1, 32768, grid=grid(32768), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf199 = buf196; del buf196  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf223 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_30, x_31, x_32, x_33, x_34, x_35, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg34_1, buf199, buf223, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg34_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf200 = extern_kernels.convolution(buf198, buf199, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf200, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf199
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf201 = reinterpret_tensor(buf198, (4, 512, 4, 4), (8192, 16, 4, 1), 0); del buf198  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49.run(buf200, arg35_1, buf201, 2048, 16, grid=grid(2048, 16), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf200
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf202 = buf180; del buf180  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_8], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf201, (4, 512, 16), (8192, 16, 1), 0), reinterpret_tensor(buf201, (4, 16, 512), (8192, 1, 16), 0), out=buf202)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf201
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf204 = buf179; del buf179  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf206 = buf178; del buf178  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_8, mul_81, mul_82], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf202, buf204, buf206, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf205 = buf171; del buf171  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_8, repeat_8, mul_81, bmm_57], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf203, buf204, out=buf205)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf207 = buf204; del buf204  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_8, mul_82, bmm_58], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf206, buf203, out=buf207)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf208 = buf205; del buf205  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_8, add_32, mul_83, dcov_32, dcov_33, dcov_34, add_33, dcov_35], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf208, buf207, buf202, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf209 = buf207; del buf207  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_59], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf208, buf203, out=buf209)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf210 = buf202; del buf202  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_60], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf203, buf208, out=buf210)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf211 = buf206; del buf206  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_61], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf203, buf208, out=buf211)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf212 = buf169; del buf169  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_62], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf211, buf203, out=buf212)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf227 = buf211; del buf211  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_9], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf227, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf213 = empty_strided_cuda((4, 512, 32, 32), (524288, 1, 16384, 512), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50.run(buf79, buf213, 2048, 1024, grid=grid(2048, 1024), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf79
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf215 = extern_kernels.convolution(buf213, buf214, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf215, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf213
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf214
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf216 = buf215; del buf215  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51.run(buf216, arg29_1, 2097152, grid=grid(2097152), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg29_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf218 = extern_kernels.convolution(buf216, buf217, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf218, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf216
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf217
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf219 = buf218; del buf218  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51.run(buf219, arg31_1, 2097152, grid=grid(2097152), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg31_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf221 = extern_kernels.convolution(buf219, buf220, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf221, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf219
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf220
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf222 = buf221; del buf221  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51.run(buf222, arg33_1, 2097152, grid=grid(2097152), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg33_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf224 = extern_kernels.convolution(buf222, buf223, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf224, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf223
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf225 = reinterpret_tensor(buf222, (4, 512, 32, 32), (524288, 1024, 32, 1), 0); del buf222  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52.run(buf224, arg35_1, buf225, 2048, 1024, grid=grid(2048, 1024), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg35_1
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf224
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf226 = buf203; del buf203  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_9], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf225, (4, 512, 1024), (524288, 1024, 1), 0), reinterpret_tensor(buf225, (4, 1024, 512), (524288, 1, 1024), 0), out=buf226)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf225
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf228 = buf168; del buf168  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf230 = buf167; del buf167  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_9, mul_89, mul_90], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf226, buf228, buf230, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf229 = buf181; del buf181  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_9, repeat_9, mul_89, bmm_64], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf227, buf228, out=buf229)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf231 = buf228; del buf228  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_9, mul_90, bmm_65], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf230, buf227, out=buf231)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf232 = buf229; del buf229  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_9, add_35, mul_91, dcov_36, dcov_37, dcov_38, add_36, dcov_39], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf232, buf231, buf226, 1048576, grid=grid(1048576), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf233 = buf231; del buf231  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_66], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf232, buf227, out=buf233)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf234 = buf226; del buf226  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_67], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf227, buf232, out=buf234)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf235 = buf230; del buf230  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_68], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf227, buf232, out=buf235)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf236 = buf173; del buf173  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_69], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf235, buf227, out=buf236)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf227
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf235
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf237 = buf187; del buf187  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf239 = buf185; del buf185  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf241 = buf183; del buf183  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_85, sub_27, mul_86, sub_28, mul_87, dcdm_8, mul_93, sub_30, mul_94, sub_31, mul_95, dcdm_9, mul_96, Gamma_XY_4, mul_97, Gamma_XX_4, mul_98, Gamma_YY_4], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_45.run(buf208, buf209, buf210, buf212, buf232, buf233, buf234, buf236, buf237, buf239, buf241, 128, 8192, grid=grid(128), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf208
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf209
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf210
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf212
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf232
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf233
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf234
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf236
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf247 = reinterpret_tensor(buf248, (4, 1), (5, 1), 4)  # alias
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_85, sub_27, mul_86, sub_28, mul_87, dcdm_8, mul_93, sub_30, mul_94, sub_31, mul_95, dcdm_9, mul_96, Gamma_XY_4, mul_97, Gamma_XX_4, mul_98, Gamma_YY_4, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_46.run(buf237, buf239, buf241, buf247, 4, 32, grid=grid(4), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf237
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf239
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf241
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf81 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_53.run(buf81, 16384, grid=grid(16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf80 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf6, (4, 64, 4096), (262144, 4096, 1), 0), reinterpret_tensor(buf6, (4, 4096, 64), (262144, 1, 4096), 0), out=buf80)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf6
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf82 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf84 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat, mul_1, mul_2], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_54.run(buf80, buf82, buf84, 16384, grid=grid(16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf83 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones, repeat, mul_1, bmm_1], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf81, buf82, out=buf83)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf85 = buf82; del buf82  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat, mul_2, bmm_2], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf84, buf81, out=buf85)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf86 = buf83; del buf83  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp, add, mul_3, dcov, dcov_1, dcov_2, add_1, dcov_3], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55.run(buf86, buf85, buf80, 16384, grid=grid(16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf87 = buf85; del buf85  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_3], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf86, buf81, out=buf87)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf88 = buf80; del buf80  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_4], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf81, buf86, out=buf88)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf89 = buf84; del buf84  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_5], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf81, buf86, out=buf89)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf90 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_6], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf89, buf81, out=buf90)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf92 = buf89; del buf89  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_1], Original ATen: [aten.ones]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_53.run(buf92, 16384, grid=grid(16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf91 = buf81; del buf81  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_1], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf46, (4, 64, 262144), (16777216, 262144, 1), 0), reinterpret_tensor(buf46, (4, 262144, 64), (16777216, 1, 262144), 0), out=buf91)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf46
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf93 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf95 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_1, mul_9, mul_10], Original ATen: [aten.repeat, aten.mul]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_54.run(buf91, buf93, buf95, 16384, grid=grid(16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf94 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_1, repeat_1, mul_9, bmm_8], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf92, buf93, out=buf94)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf96 = buf93; del buf93  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_1, mul_10, bmm_9], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf95, buf92, out=buf96)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf97 = buf94; del buf94  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_1, add_3, mul_11, dcov_4, dcov_5, dcov_6, add_4, dcov_7], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55.run(buf97, buf96, buf91, 16384, grid=grid(16384), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf98 = buf96; del buf96  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_10], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf97, buf92, out=buf98)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf99 = buf91; del buf91  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_11], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf92, buf97, out=buf99)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf100 = buf95; del buf95  # reuse
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_12], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf92, buf97, out=buf100)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf101 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_13], Original ATen: [aten.bmm]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf100, buf92, out=buf101)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf100
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf92
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf243 = reinterpret_tensor(buf248, (4, 1), (5, 1), 0)  # alias
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_5, sub_3, mul_6, sub_4, mul_7, dcdm, mul_13, sub_6, mul_14, sub_7, mul_15, dcdm_1, mul_16, Gamma_XY, mul_17, Gamma_XX, mul_18, Gamma_YY, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_stack_sub_sum_56.run(buf86, buf87, buf88, buf90, buf97, buf98, buf99, buf101, buf243, 4, 4096, grid=grid(4), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf101
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf86
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf87
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf88
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf90
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf97
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf98
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf99
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf249 = empty_strided_cuda((4, 1), (1, 1), torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mean, score], Original ATen: [aten.mean, aten.rsub]
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mean_rsub_57.run(buf248, buf249, 4, grid=grid(4), stream=stream0)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf243
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf244
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf245
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf246
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf247
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf248
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf249, )
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg0_1 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg1_1 = rand_strided((4, 3, 512, 512), (786432, 262144, 512, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg2_1 = rand_strided((1, 3, 1, 1), (3, 1, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg3_1 = rand_strided((1, 3, 1, 1), (3, 1, 1, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg4_1 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg5_1 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg6_1 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg7_1 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg8_1 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg9_1 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg10_1 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg11_1 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg12_1 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg13_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg14_1 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg15_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg16_1 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg17_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg18_1 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg19_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg20_1 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg21_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg22_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg23_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg24_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg25_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg26_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg27_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg28_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg29_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg30_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg31_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg32_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg33_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg34_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg35_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1])
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0204 15:21:42.349000 1466791 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0204 15:21:42.464000 1466791 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: /tmp/torchinductor_sahanp/iy/ciy5suoqubm75cciduz2mczgdlfchexmf3wffaqkfo2dum7joyy4.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] Output code: 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # AOT ID: ['6_inference']
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import torch
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import random
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import os
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import tempfile
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from math import inf, nan
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch import device, empty_strided
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import (
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     split_scan_grid,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     grid_combo_kernels,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     start_graph,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     end_graph,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     cooperative_reduction_grid,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] aten = torch.ops.aten
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] _quantized = torch.ops._quantized
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile = AsyncCompile()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/4u/c4uphk3fqlj6q7n67bpi7eytulvyt7qomgbbaq7oo22qmpn4mxtm.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones_2], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones_2 => full_default_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_10 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 128, 128], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_0 = async_compile.triton('triton_poi_fused_ones_0', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_0(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ae/caezwt3dazloz6k5qlrlf2btuoq3t2jffhdyjxdg2kdfn4gpc6oh.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16384, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 16384
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/lx/clxoagskmjx5qordpcuqhf5cmcss3cct52b3w7porwml3uigcntv.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 8192, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 8192
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/rr/crrkolhzwcxnb7fcwtjvvn2euallcs5uu2tul4tymmeil3psm7ci.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, sub_1, x_36, x_37, x_38, x_39], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_3 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_3', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 4096, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_3', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_3(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 4096
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 64*x2 + 576*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/it/citnzpf6ukmbpkqrzwbjhz467f2dfgroknt742n6byzqdy2totcn.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, sub_1, x_36, x_37], Original ATen: [aten.sub, aten.div, aten.convolution]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_sub_4 = async_compile.triton('triton_poi_fused_convolution_div_sub_4', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_sub_4', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_sub_4(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 192
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 3*x2 + 27*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/hv/chvlqtgbvtew2pkavtfmpmi2no4jyfczetydksthpgitvsj363ma.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x], Original ATen: [aten.sub, aten.div]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_div_sub_5 = async_compile.triton('triton_poi_fused_div_sub_5', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 4096}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_div_sub_5', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_div_sub_5(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 4096*y3), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 / tmp3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 12288*y1), tmp4, ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/kg/ckg3urqn2dd4lzcaeoagf5gwyuvefbhaoswn2vlc24b7t6e7iqun.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_6 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_6', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_6', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_6(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/vw/cvw3al4oi5lzxpvwkqmaimlwmwbsg6ra2yoxuflcvapxe6gx5zwq.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_7 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_7', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 4096}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_7', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_7(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 64*x2 + 262144*y1), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 4096*y3), tmp4, ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/oe/coexrasmurz46jvg3thc4m26acaei6nrroxm5bcg5mrtl432vbj3.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 1024}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (64 + 2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (65 + 2*x2 + 128*x3 + 4096*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x5 + 65536*y1), tmp6, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/4o/c4o7i3qjuppjqidahaxm5bzhq5xsldnnx7gdtefwxw2pfhdofq5r.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 524288}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 524288
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/yk/cykebbth7kjxomqdyv637d4zebpzjwyo35iom6nuk35ytcsomf5h.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 1024}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 128*x2 + 131072*y1), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 1024*y3), tmp4, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7y/c7yplctydqvomwece7vi6vev2reakycwxse7sfybcqvpusutldeu.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat_2, mul_21, mul_22], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_21 => mul_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_22 => mul_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat_2 => repeat_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat_2 : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_9, [4, 1, 1]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_24 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_14, %repeat_2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_25 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_14, %repeat_2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_11 = async_compile.triton('triton_poi_fused_mul_repeat_11', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_11', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_11(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 128) % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ya/cyavguuiwrhd25nm3uvga4imk3csx5sr4eadqg6xvitmio4xy6ew.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp_2, add_8, mul_23, dcov_8, dcov_9, dcov_10, add_9, dcov_11], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_8 => add_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_9 => add_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_10 => mul_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_11 => sqrt_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_8 => sub_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_9 => clamp_min_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp_2 => full_default_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_23 => mul_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_11 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 6.103515625e-05), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_8 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_15, %bmm_16), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_26 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_14, 2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_8 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_8, %mul_26), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_2 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_8, 0.0), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_27 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_11, %clamp_min_2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_9 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_27, 1e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt_3 : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_9,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 65536}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 6.103515625e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qt/cqttxpins755lmba6tmii3pj7otftg3ydsrszivx2c7m5vofjaru.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36], Original ATen: [aten.sub, aten.div]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_div_sub_13 = async_compile.triton('triton_poi_fused_div_sub_13', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 16, 'x': 262144}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_div_sub_13', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_div_sub_13(in_ptr0, in_ptr1, in_ptr2, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 3)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 262144*y3), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 - tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 / tmp3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 3*x2 + 786432*y1), tmp4, ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/l4/cl4fabuq6fs3hvjklqmspp23uc4cidamix2dan7tmfvziu3o6f6r.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_14 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_14', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 67108864}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_14', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_14(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 67108864
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/nc/cnc2kqqwvia5gdxbjjyl44vjfwzilknjvxg26ecvyrrj6ndx4cxu.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_relu_sub_15 = async_compile.triton('triton_poi_fused_convolution_div_relu_sub_15', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 262144}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_relu_sub_15', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_relu_sub_15(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 64*x2 + 16777216*y1), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 262144*y3), tmp4, ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/pq/cpqgx3pqeahxytpbugniotlx23eddvrfgqdj7j6uh47lplu3t6xy.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 256, 'x': 65536}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (512 + 2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (513 + 2*x2 + 1024*x3 + 262144*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 64*x5 + 4194304*y1), tmp6, ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/kd/ckd2ryfdtkv44wiawkdredaf6zz4dlmxkchlcugqhh7vsxkeoa2t.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 33554432}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 33554432
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/f7/cf7y4k57xzogbyfip75pq7x3nb6vyyho6z3oellxx3zu3ulxetws.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 65536}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 65536
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 128*x2 + 8388608*y1), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 65536*y3), tmp4, ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/c4/cc4cxnivmqnkcuni2wbcuxq5h6gsvxt3dhyelkngo5rb6fen6wm4.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_1 => sum_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_1 => sum_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_1 => sum_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_2 => add_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_3 => add_13
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_25 => mul_28
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_26 => mul_29
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_27 => mul_30
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_33 => mul_37
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_34 => mul_38
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_35 => mul_39
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_36 => mul_40
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_37 => mul_41
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_38 => mul_42
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_10 => sub_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_12 => sub_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_13 => sub_13
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_9 => sub_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_28 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_17, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_9 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_3, %mul_28), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_18, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_10 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_9, %mul_29), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_30 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_20, 6.103515625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_10 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_10, %mul_30), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_37 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_24, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_12 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_4, %mul_37), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_38 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_25, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_13 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_12, %mul_38), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_39 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_27, 6.103515625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_13 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_13, %mul_39), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_40 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_13), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_40, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_41 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_10), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_41, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_42 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_13, %add_13), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_42, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_sub_sum_19 = async_compile.triton('triton_red_fused_add_mul_sub_sum_19', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8, 'r': 8192},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_sub_sum_19', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_sub_sum_19(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8192
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.0078125
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 6.103515625e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp24, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp28, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp32, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/7i/c7i667oq44lt437lh7ijd2fawdbunfuyskqyecrkmgjsq6sf3bka.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_1 => sum_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_1 => sum_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_1 => sum_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_2 => add_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_3 => add_13
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_25 => mul_28
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_26 => mul_29
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_27 => mul_30
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_33 => mul_37
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_34 => mul_38
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_35 => mul_39
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_36 => mul_40
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_37 => mul_41
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_38 => mul_42
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_10 => sub_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_12 => sub_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_13 => sub_13
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_9 => sub_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_28 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_17, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_9 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_3, %mul_28), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_18, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_10 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_9, %mul_29), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_30 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_20, 6.103515625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_10 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_10, %mul_30), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_37 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_24, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_12 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_4, %mul_37), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_38 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_25, 0.0078125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_13 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_12, %mul_38), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_39 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_27, 6.103515625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_13 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_13, %mul_39), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_40 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_13), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_4 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_40, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_41 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_10, %add_10), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_5 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_41, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_42 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_13, %add_13), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_6 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_42, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_add_mul_stack_sub_sum_20 = async_compile.triton('triton_per_fused_add_mul_stack_sub_sum_20', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 2},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_mul_stack_sub_sum_20', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_add_mul_stack_sub_sum_20(in_ptr0, in_ptr1, in_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 2*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r1 + 2*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r1 + 2*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = 1e-06
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp4 + tmp15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 * tmp14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = libdevice.sqrt(tmp17)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 + tmp15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp16 / tmp19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp20, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3d/c3dszbnfxhi6mel6ylwm373o7ssxzdwapx23km72gkryrizfnos4.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones_4], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones_4 => full_default_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_18 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 256, 256], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_21 = async_compile.triton('triton_poi_fused_ones_21', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_21', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_21(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/fb/cfbfjntq4hakpxqf6minwds45mpckhrqfpwwt4a5gz3ac6kbhipf.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 32768, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 32768
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 128*x2 + 1152*y1), tmp0, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/qz/cqzqjh3cssqlrg3q6nteutfqekzvtg6ienxjosjp2iqpnhkg5u66.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 256}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 16)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (32 + 2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (33 + 2*x2 + 64*x3 + 1024*y4), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x5 + 32768*y1), tmp6, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/m5/cm5eye3svuxtcojajpyhrwjumbwskmumotob4poekvcw4loxbxhw.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/yu/cyuwsgmljehmqabc46hh6ayd7hjjpfuxeghzw2fevssdtnp5frs7.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 65536, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 65536
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/iq/ciqrgfh3kg3cweeo4nonbgz2ovljh67er5v5mtavgsx3fbu7732h.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 256}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 256*x2 + 65536*y1), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 256*y3), tmp4, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/de/cderbz5kj3xmpm4orwj22mb6gtcjwcyoq52wsa3jbwxk4cmmjp3d.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat_4, mul_41, mul_42], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_41 => mul_46
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_42 => mul_47
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat_4 => repeat_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat_4 : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_17, [4, 1, 1]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_46 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_28, %repeat_4), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_47 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_28, %repeat_4), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_27 = async_compile.triton('triton_poi_fused_mul_repeat_27', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_27', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_27(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 256) % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/oe/coeu43v4eqkl2bcv5x5j22rh2m66ut2qyz5blbe62bbbozwoonc5.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp_4, add_16, mul_43, dcov_16, dcov_17, dcov_18, add_17, dcov_19], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_16 => add_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_17 => add_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_16 => sub_14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_17 => clamp_min_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_18 => mul_49
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_19 => sqrt_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp_4 => full_default_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_43 => mul_48
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_19 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 1.5258788153005298e-05), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_16 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_29, %bmm_30), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_28, 2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_14 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_16, %mul_48), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_4 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_14, 0.0), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_19, %clamp_min_4), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_17 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_49, 1e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt_6 : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 262144}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 262144
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 1.5258788153005298e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/gf/cgfz7srtyuyeeomnsa4yhd6zqdc34f2pgh6onmkvq6qkwenoz6kc.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 512, 'x': 16384}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 128)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (256 + 2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (257 + 2*x2 + 512*x3 + 65536*y4), ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 128*x5 + 2097152*y1), tmp6, ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/wf/cwfcn7tcxurfr72bvpgseejdtfxdfo5kts5zmljjdif5labx6hal.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16777216}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16777216
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/j3/cj3tlvpfpun2rpl557cio53halkqpeo3ggqidzc7xtmy37zlkldj.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 16384}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 256*x2 + 4194304*y1), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 16384*y3), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ez/cezmhvk5s7xoyhie6dxetwtwoe7cjgjsxcwb2w6er46rg6nvod7x.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_2 => sum_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_2 => sum_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_2 => sum_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_4 => add_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_5 => add_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_45 => mul_50
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_46 => mul_51
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_47 => mul_52
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_53 => mul_59
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_54 => mul_60
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_55 => mul_61
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_56 => mul_62
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_57 => mul_63
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_58 => mul_64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_15 => sub_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_16 => sub_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_18 => sub_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_19 => sub_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_31, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_15 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_6, %mul_50), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_51 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_32, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_16 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_15, %mul_51), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_52 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_34, 1.52587890625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_18 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_16, %mul_52), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_59 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_38, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_18 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_7, %mul_59), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_60 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_39, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_18, %mul_60), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_41, 1.52587890625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_21 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_19, %mul_61), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_62 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_21), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_62, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_63 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_18), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_63, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_64 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_21, %add_21), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_64, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_sub_sum_32 = async_compile.triton('triton_red_fused_add_mul_sub_sum_32', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32, 'r': 8192},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_sub_sum_32', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_sub_sum_32(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8192
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.00390625
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 1.52587890625e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp24, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp28, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp32, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/sb/csbuxprofcvghtgzfrp4xmdzagkjd3mcy2dvptvxj6vyh3y2ajxb.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_2 => sum_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_2 => sum_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_2 => sum_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_4 => add_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_5 => add_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_45 => mul_50
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_46 => mul_51
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_47 => mul_52
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_53 => mul_59
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_54 => mul_60
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_55 => mul_61
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_56 => mul_62
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_57 => mul_63
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_58 => mul_64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_15 => sub_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_16 => sub_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_18 => sub_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_19 => sub_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_31, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_15 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_6, %mul_50), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_51 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_32, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_16 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_15, %mul_51), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_52 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_34, 1.52587890625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_18 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_16, %mul_52), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_59 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_38, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_18 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_7, %mul_59), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_60 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_39, 0.00390625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_19 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_18, %mul_60), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_41, 1.52587890625e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_21 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_19, %mul_61), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_62 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_21), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_7 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_62, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_63 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_18, %add_18), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_8 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_63, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_64 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_21, %add_21), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_9 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_64, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_add_mul_stack_sub_sum_33 = async_compile.triton('triton_per_fused_add_mul_stack_sub_sum_33', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 8},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_mul_stack_sub_sum_33', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_add_mul_stack_sub_sum_33(in_ptr0, in_ptr1, in_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 8*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r1 + 8*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r1 + 8*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = 1e-06
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp4 + tmp15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 * tmp14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = libdevice.sqrt(tmp17)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 + tmp15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp16 / tmp19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp20, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/gv/cgvq2m3a77v6ovwh3kuhctq7izkxf2j2z7obpp7jefmi6lhip4bx.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones_6], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones_6 => full_default_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_26 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 512, 512], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_34 = async_compile.triton('triton_poi_fused_ones_34', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_34', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_34(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dd/cdd2pjizwfvgzygimhruablz7j3fyjg2hmwcvu2pvoh74hr6ugvk.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 64}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 8)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (16 + 2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (17 + 2*x2 + 32*x3 + 256*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x5 + 16384*y1), tmp6, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/gv/cgvliqgeblmyvvq4txz4cidrumc52utjlek5xhrszvuruudcsndk.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 131072, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 131072
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 256*x2 + 2304*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/we/cwetxl3zgnau4mu3vmiiffnls6utrqt6rrtwkca7sozek4ms7sem.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 131072}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 131072
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dr/cdryd4bhxduj7a5d4caqlfiuoezkuunlirso453zffifkusvmtwm.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 262144, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38(in_ptr0, out_ptr0, out_ptr1, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 262144
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = (tl.program_id(1) + tl.program_id(2) * tl.num_programs(1)) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = yindex < ynumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x2 + 9*y3), xmask & ymask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (y0 + 512*x2 + 4608*y1), tmp0, xmask & ymask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xw/cxwqnu5wptxcgkurc4idyth6wqeasp45qtklkdo4usbs7pcm3i75.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 64}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 32768*y1), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 64*y3), tmp4, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/jq/cjq3tdkgwqp6lmb7rpnpk25pjyyte23l4n5y5swniymbkqwa4ek7.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat_6, mul_61, mul_62], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_61 => mul_68
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_62 => mul_69
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat_6 => repeat_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat_6 : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_25, [4, 1, 1]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_68 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_42, %repeat_6), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_69 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_42, %repeat_6), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_40 = async_compile.triton('triton_poi_fused_mul_repeat_40', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_40', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_40(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 512) % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/i5/ci5b6abj7wh464v2wb27hjpwbuia43p7k2ik7rmehfeonlsivou2.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp_6, add_24, mul_63, dcov_24, dcov_25, dcov_26, add_25, dcov_27], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_24 => add_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_25 => add_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_24 => sub_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_25 => clamp_min_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_26 => mul_71
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_27 => sqrt_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp_6 => full_default_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_63 => mul_70
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_27 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 3.8146970382513246e-06), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_24 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_43, %bmm_44), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_70 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_42, 2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_20 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add_24, %mul_70), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min_6 : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_20, 0.0), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_71 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_27, %clamp_min_6), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_25 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_71, 1e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt_9 : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_25,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 1048576}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1048576
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 3.8146970382513246e-06
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/bu/cbud6knn2y57dh6roes5adenyj2xgidzxpiespagnlfnac7v5ozn.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 1024, 'x': 4096}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 256)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 256
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (128 + 2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (129 + 2*x2 + 256*x3 + 16384*y4), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 256*x5 + 1048576*y1), tmp6, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3y/c3y7rwqc3zy2j325hdmu3cbeugafb4sdgmoop5zz3gj73ndc6ksk.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 8388608}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 8388608
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3v/c3vmfrr47ib3in7qtnqueopr5e3r33dfnlpystxdgnh2q4pz24st.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 4096}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4096
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 2097152*y1), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1, 1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 4096*y3), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/2y/c2ybj64mlp5tjh6ti234lxsypxiza2du3cwgmx5trawkkmxzeole.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_3 => sum_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_3 => sum_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_3 => sum_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_6 => add_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_7 => add_29
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_65 => mul_72
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_66 => mul_73
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_67 => mul_74
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_73 => mul_81
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_74 => mul_82
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_75 => mul_83
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_76 => mul_84
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_77 => mul_85
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_78 => mul_86
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_21 => sub_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_22 => sub_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_24 => sub_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_25 => sub_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_72 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_45, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_21 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_9, %mul_72), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_73 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_46, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_22 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_21, %mul_73), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_74 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_48, 3.814697265625e-06), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_26 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_22, %mul_74), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_81 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_52, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_24 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_10, %mul_81), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_82 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_53, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_25 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_24, %mul_82), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_83 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_55, 3.814697265625e-06), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_29 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_25, %mul_83), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_84 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_29), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_84, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_85 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_26), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_85, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_86 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_29, %add_29), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_86, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_sub_sum_45 = async_compile.triton('triton_red_fused_add_mul_sub_sum_45', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 128, 'r': 8192},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'out_ptr2': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_sub_sum_45', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_sub_sum_45(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 128
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 8192
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 8192*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.001953125
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 3.814697265625e-06
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp24, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp28, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp32, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/ey/cey6iyfm3blcmlde3ozyjijfch4nbn75g24rzqtxem6houm2gyra.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX_3 => sum_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY_3 => sum_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY_3 => sum_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_6 => add_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_7 => add_29
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_65 => mul_72
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_66 => mul_73
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_67 => mul_74
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_73 => mul_81
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_74 => mul_82
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_75 => mul_83
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_76 => mul_84
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_77 => mul_85
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_78 => mul_86
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_21 => sub_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_22 => sub_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_24 => sub_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_25 => sub_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_72 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_45, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_21 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_9, %mul_72), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_73 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_46, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_22 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_21, %mul_73), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_74 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_48, 3.814697265625e-06), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_26 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_22, %mul_74), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_81 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_52, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_24 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_10, %mul_81), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_82 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_53, 0.001953125), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_25 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_24, %mul_82), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_83 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_55, 3.814697265625e-06), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_29 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_25, %mul_83), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_84 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_29), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_10 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_84, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_85 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_26, %add_26), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_11 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_85, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_86 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_29, %add_29), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_12 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_86, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_per_fused_add_mul_stack_sub_sum_46 = async_compile.triton('triton_per_fused_add_mul_stack_sub_sum_46', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 32},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 5), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_mul_stack_sub_sum_46', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_per_fused_add_mul_stack_sub_sum_46(in_ptr0, in_ptr1, in_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 32
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     RBLOCK: tl.constexpr = 32
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     roffset = 0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     r1 = rindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + 32*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr1 + (r1 + 32*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tl.load(in_ptr2 + (r1 + 32*x0), xmask, other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.where(xmask, tmp1, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tl.sum(tmp3, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.broadcast_to(tmp5, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tl.where(xmask, tmp6, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = tl.sum(tmp8, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp10, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = tl.where(xmask, tmp11, 0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp14 = tl.sum(tmp13, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp15 = 1e-06
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp16 = tmp4 + tmp15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp17 = tmp9 * tmp14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp18 = libdevice.sqrt(tmp17)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp19 = tmp18 + tmp15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp20 = tmp16 / tmp19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp20, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/m7/cm7fdwguvl4tbclhou7kdty2ysawnkfdgvjywfuzspan2spodll6.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => _low_memory_max_pool2d_with_offsets_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 16}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (8 + 2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (9 + 2*x2 + 16*x3 + 64*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x5 + 8192*y1), tmp6, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dc/cdcwjwxtlkqhgilrullqxguy5yoiubhrqtj3etz3qwd7xszqowks.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => _low_memory_max_pool2d_with_offsets_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => convolution_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_30 => relu_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 32768}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 32768
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/3w/c3wgjrcacagsfwc5u2ooonww3c3mdfuebwucn6cg5k3yvax6lpln.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub => sub
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x => div
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_1 => convolution
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_10 => _low_memory_max_pool2d_with_offsets_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_11 => convolution_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_12 => relu_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_13 => convolution_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_14 => relu_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_15 => convolution_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_16 => relu_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_17 => convolution_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_18 => relu_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_19 => _low_memory_max_pool2d_with_offsets_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_2 => relu
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_20 => convolution_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_21 => relu_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_22 => convolution_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_23 => relu_9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_24 => convolution_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_25 => relu_10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_26 => convolution_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_27 => relu_11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_28 => _low_memory_max_pool2d_with_offsets_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_29 => convolution_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_3 => convolution_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_30 => relu_12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_31 => convolution_13
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_32 => relu_13
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_33 => convolution_14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_34 => relu_14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_35 => convolution_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_4 => relu_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_5 => _low_memory_max_pool2d_with_offsets
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_6 => convolution_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_7 => relu_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_8 => convolution_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_9 => relu_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg0_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_1 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_1 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_1, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_2 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_2,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_3 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_2, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_3 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_3,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_1 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_3, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_4 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_2, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_4,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_5 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_4, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_5,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_6 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_5, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_6,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_7 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_6, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_7 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_7,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_2 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_7, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_8 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_4, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_8,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_9 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_8, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_9,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_10 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_9, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_10 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_10,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_11 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_10, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_11 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_11,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_3 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_11, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_12 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_6, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_12 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_12,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_13 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_12, %arg30_1, %arg31_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_13 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_13,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_14 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_13, %arg32_1, %arg33_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_14 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_14,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_15 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_14, %arg34_1, %arg35_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 16}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 8192*y1), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 16*y3), tmp2, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xz/cxzan4jsydudlfxx2x2pktpcbwczrpzjzb65ih6ycn6c454dlzsv.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => _low_memory_max_pool2d_with_offsets_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_7 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_26, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 1024}, tile_hint=TileHint.SQUARE,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = (xindex % 32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex // 32
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y4 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x5 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (64 + 2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (65 + 2*x2 + 128*x3 + 4096*y4), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = triton_helpers.maximum(tmp1, tmp0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp5, tmp4)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (y0 + 512*x5 + 524288*y1), tmp6, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/xd/cxdnrwaxqamyw7ilopuzxobmhk3qjevkalgv3arfx3qmx5czzc3p.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => _low_memory_max_pool2d_with_offsets_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_65 => convolution_28
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_7 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_26, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_14, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_27 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 2097152}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 2097152
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x2), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.full([1], 0, tl.int32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = triton_helpers.maximum(tmp3, tmp2)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x2), tmp4, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/pu/cpurrsc5vq4nye5jwox3u7t6jxacoj2yeqkdwkkzgv3uqttiy6ll.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_1 => sub_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_36 => div_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_37 => convolution_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_38 => relu_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_39 => convolution_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_40 => relu_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_41 => _low_memory_max_pool2d_with_offsets_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_42 => convolution_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_43 => relu_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_44 => convolution_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_45 => relu_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_46 => _low_memory_max_pool2d_with_offsets_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_47 => convolution_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_48 => relu_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_49 => convolution_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_50 => relu_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_51 => convolution_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_52 => relu_21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_53 => convolution_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_54 => relu_22
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_55 => _low_memory_max_pool2d_with_offsets_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_56 => convolution_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_57 => relu_23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_58 => convolution_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_59 => relu_24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_60 => convolution_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_61 => relu_25
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_62 => convolution_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_63 => relu_26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_64 => _low_memory_max_pool2d_with_offsets_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_65 => convolution_28
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_66 => relu_27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_67 => convolution_29
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_68 => relu_28
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_69 => convolution_30
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_70 => relu_29
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   x_71 => convolution_31
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_1 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%arg1_1, %arg2_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %div_1 : [num_users=1] = call_function[target=torch.ops.aten.div.Tensor](args = (%sub_1, %arg3_1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_16 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%div_1, %arg4_1, %arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_15 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_16,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_17 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_15, %arg6_1, %arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_16 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_17,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_4 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_16, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_18 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_8, %arg8_1, %arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_17 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_18,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_19 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_17, %arg10_1, %arg11_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_18 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_19,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_5 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_18, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_20 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_10, %arg12_1, %arg13_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_19 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_20,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_21 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_19, %arg14_1, %arg15_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_20 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_21,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_22 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_20, %arg16_1, %arg17_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_21 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_22,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_23 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_21, %arg18_1, %arg19_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_22 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_23,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_6 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_22, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_24 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_12, %arg20_1, %arg21_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_23 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_24,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_25 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_23, %arg22_1, %arg23_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_24 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_25,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_26 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_24, %arg24_1, %arg25_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_25 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_26,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_27 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_25, %arg26_1, %arg27_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_26 : [num_users=3] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_27,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %_low_memory_max_pool2d_with_offsets_7 : [num_users=1] = call_function[target=torch.ops.prims._low_memory_max_pool2d_with_offsets.default](args = (%relu_26, [2, 2], [2, 2], [0, 0], [1, 1], False), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_28 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%getitem_14, %arg28_1, %arg29_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_27 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_28,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_29 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_27, %arg30_1, %arg31_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_28 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_29,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_30 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_28, %arg32_1, %arg33_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %relu_29 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%convolution_30,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %convolution_31 : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%relu_29, %arg34_1, %arg35_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52 = async_compile.triton('triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'y': 2048, 'x': 1024}, tile_hint=TileHint.DEFAULT,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'ynumel': 'i32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ynumel = 2048
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 1024
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yoffset = tl.program_id(1) * YBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x2 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y0 = (yindex % 512)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y1 = yindex // 512
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     y3 = yindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (y0 + 512*x2 + 524288*y1), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (y0), None, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x2 + 1024*y3), tmp2, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/dr/cdrrshtd55lt32vwfihidtwi4x4nt4vc3necjrvl7gyzqbovemvo.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [ones], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   ones => full_default_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_2 : [num_users=6] = call_function[target=torch.ops.aten.full.default](args = ([4, 64, 64], 1), kwargs = {dtype: torch.float32, layout: torch.strided, device: cuda:0, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_ones_53 = async_compile.triton('triton_poi_fused_ones_53', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_ones_53', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 0, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_ones_53(out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp0, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/i7/ci723w6y6bcn5vp5k6uwp5diwjrvkwb3ervxtcpuspptiyyqbl5e.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [repeat, mul_1, mul_2], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_1 => mul_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_2 => mul_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   repeat => repeat
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %repeat : [num_users=2] = call_function[target=torch.ops.aten.repeat.default](args = (%view_1, [4, 1, 1]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm, %repeat), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm, %repeat), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mul_repeat_54 = async_compile.triton('triton_poi_fused_mul_repeat_54', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'out_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mul_repeat_54', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mul_repeat_54(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x3 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x1 = ((xindex // 64) % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = (xindex % 64)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x3), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = x1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = x0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tmp1 == tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tl.where(tmp3, tmp4, tmp5)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tmp0 * tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr1 + (x3), tmp7, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/as/casrn6v36ztvaeh2jdy3pfla4d2rqup6to7wtndj25uspy2nrvoh.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [exp, add, mul_3, dcov, dcov_1, dcov_2, add_1, dcov_3], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add => add
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   add_1 => add_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov => sub_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_1 => clamp_min
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_2 => mul_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcov_3 => sqrt
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   exp => full_default_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_3 => mul_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %full_default_3 : [num_users=1] = call_function[target=torch.ops.aten.full.default](args = ([], 0.000244140625), kwargs = {dtype: torch.float32, layout: torch.strided, device: cpu, pin_memory: False})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%bmm_1, %bmm_2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm, 2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_2 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%add, %mul_4), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %clamp_min : [num_users=1] = call_function[target=torch.ops.aten.clamp_min.default](args = (%sub_2, 0.0), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_5 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%full_default_3, %clamp_min), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_1 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_5, 1e-05), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sqrt : [num_users=4] = call_function[target=torch.ops.aten.sqrt.default](args = (%add_1,), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55 = async_compile.triton('triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 16384}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_out_ptr0': '*fp32', 'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 3, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55(in_out_ptr0, in_ptr0, in_ptr1, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 16384
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = tl.full([XBLOCK], True, tl.int1)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (x0), None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = 2.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tmp3 * tmp4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp2 - tmp5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = 0.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 0.000244140625
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp9 * tmp8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1e-05
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp10 + tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp13 = libdevice.sqrt(tmp12)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp13, None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/6n/c6n2vcodxy72aebth35l3zhk73tn4gqcqbglj6lknyqgua4d3xsv.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mul_5, sub_3, mul_6, sub_4, mul_7, dcdm, mul_13, sub_6, mul_14, sub_7, mul_15, dcdm_1, mul_16, Gamma_XY, mul_17, Gamma_XX, mul_18, Gamma_YY, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XX => sum_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_XY => sum_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   Gamma_YY => sum_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dc_scores => cat
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm => add_2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   dcdm_1 => add_5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_13 => mul_15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_14 => mul_16
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_15 => mul_17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_16 => mul_18
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_17 => mul_19
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_18 => mul_20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_5 => mul_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_6 => mul_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mul_7 => mul_8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_3 => sub_3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_4 => sub_4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_6 => sub_6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   sub_7 => sub_7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_6 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_3, 0.015625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_3 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt, %mul_6), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_4, 0.015625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_4 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_3, %mul_7), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_6, 0.000244140625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_2 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_4, %mul_8), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_10, 0.015625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_6 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sqrt_1, %mul_15), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_16 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_11, 0.015625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_7 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%sub_6, %mul_16), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_17 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%bmm_13, 0.000244140625), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %add_5 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%sub_7, %mul_17), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_18 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2, %add_5), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_1 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_18, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_19 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_2, %add_2), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_2 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_19, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mul_20 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%add_5, %add_5), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sum_3 : [num_users=1] = call_function[target=torch.ops.aten.sum.dim_IntList](args = (%mul_20, [1, 2]), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%unsqueeze_10, %unsqueeze_11, %unsqueeze_12, %unsqueeze_13, %unsqueeze_14], 1), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_red_fused_add_mul_stack_sub_sum_56 = async_compile.triton('triton_red_fused_add_mul_stack_sub_sum_56', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.reduction(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4, 'r': 4096},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'in_ptr2': '*fp32', 'in_ptr3': '*fp32', 'in_ptr4': '*fp32', 'in_ptr5': '*fp32', 'in_ptr6': '*fp32', 'in_ptr7': '*fp32', 'out_ptr3': '*fp32', 'xnumel': 'i32', 'rnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1, 2, 3, 4, 5, 6, 7, 8, 10), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused_add_mul_stack_sub_sum_56', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 8, 'num_reduction': 3, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_red_fused_add_mul_stack_sub_sum_56(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rnumel = 4096
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp24 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp28 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     _tmp32 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rindex = roffset + rbase
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         rmask = rindex < rnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         r1 = rindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp5 = tl.load(in_ptr2 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp8 = tl.load(in_ptr3 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp12 = tl.load(in_ptr4 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp13 = tl.load(in_ptr5 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp16 = tl.load(in_ptr6 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp19 = tl.load(in_ptr7 + (r1 + 4096*x0), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp2 = 0.015625
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp3 = tmp1 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp4 = tmp0 - tmp3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp6 = tmp5 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp7 = tmp4 - tmp6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp9 = 0.000244140625
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp11 = tmp7 + tmp10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp14 = tmp13 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp15 = tmp12 - tmp14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp17 = tmp16 * tmp2
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp18 = tmp15 - tmp17
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp20 = tmp19 * tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp21 = tmp18 + tmp20
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp22 = tmp11 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp23 = tl.broadcast_to(tmp22, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp25 = _tmp24 + tmp23
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp24 = tl.where(rmask & xmask, tmp25, _tmp24)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp26 = tmp11 * tmp11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp27 = tl.broadcast_to(tmp26, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp29 = _tmp28 + tmp27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp28 = tl.where(rmask & xmask, tmp29, _tmp28)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp30 = tmp21 * tmp21
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp31 = tl.broadcast_to(tmp30, [XBLOCK, RBLOCK])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         tmp33 = _tmp32 + tmp31
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         _tmp32 = tl.where(rmask & xmask, tmp33, _tmp32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp24 = tl.sum(_tmp24, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp28 = tl.sum(_tmp28, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp32 = tl.sum(_tmp32, 1)[:, None]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp34 = 1e-06
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp35 = tmp24 + tmp34
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp36 = tmp28 * tmp32
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp37 = libdevice.sqrt(tmp36)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp38 = tmp37 + tmp34
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp39 = tmp35 / tmp38
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr3 + (5*x0), tmp39, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # kernel path: inductor_cache/zq/czqm4qmckoybde6vhytq3zp4e62222goty27y3cbs2gkx25w63po.py
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Topologically Sorted Source Nodes: [mean, score], Original ATen: [aten.mean, aten.rsub]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Source node to ATen node mapping:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   mean => mean
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   score => sub_32
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] # Graph fragment:
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%cat, [1], True), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] #   %sub_32 : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (1, %mean), kwargs = {})
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_poi_fused_mean_rsub_57 = async_compile.triton('triton_poi_fused_mean_rsub_57', '''
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] import triton.language as tl
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton_heuristics.pointwise(
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     size_hints={'x': 4}, 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     filename=__file__,
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=132, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': (0, 1), 'tt.equal_to': ()}, 'cls': 'AttrsDescriptor'})]},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_mean_rsub_57', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'A0D3A2B50857E9501D843044B01F725922648D76E6D26323B14F8A4EA4473D1B', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     min_elem_per_thread=0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] @triton.jit
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def triton_poi_fused_mean_rsub_57(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xnumel = 4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     xmask = xindex < xnumel
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     x0 = xindex
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (5*x0), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (1 + 5*x0), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp3 = tl.load(in_ptr0 + (2 + 5*x0), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (3 + 5*x0), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp7 = tl.load(in_ptr0 + (4 + 5*x0), xmask, eviction_policy='evict_last')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp4 = tmp2 + tmp3
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp6 = tmp4 + tmp5
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp8 = tmp6 + tmp7
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp9 = 5.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp10 = tmp8 / tmp9
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp11 = 1.0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tmp12 = tmp11 - tmp10
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp12, xmask)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] ''', device_str='cuda')
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] async_compile.wait(globals())
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] del async_compile
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def call(args):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1 = args
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     args.clear()
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg0_1, (4, 3, 64, 64), (12288, 4096, 64, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg1_1, (4, 3, 512, 512), (786432, 262144, 512, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg2_1, (1, 3, 1, 1), (3, 1, 1, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg3_1, (1, 3, 1, 1), (3, 1, 1, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg4_1, (64, 3, 3, 3), (27, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg5_1, (64, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg6_1, (64, 64, 3, 3), (576, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg7_1, (64, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg8_1, (128, 64, 3, 3), (576, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg9_1, (128, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg10_1, (128, 128, 3, 3), (1152, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg11_1, (128, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg12_1, (256, 128, 3, 3), (1152, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg13_1, (256, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg14_1, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg15_1, (256, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg16_1, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg17_1, (256, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg18_1, (256, 256, 3, 3), (2304, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg19_1, (256, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg20_1, (512, 256, 3, 3), (2304, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg21_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg22_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg23_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg24_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg25_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg26_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg27_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg28_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg29_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg30_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg31_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg32_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg33_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg34_1, (512, 512, 3, 3), (4608, 9, 3, 1))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     assert_size_stride(arg35_1, (512, ), (1, ))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         torch.cuda.set_device(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf106 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_2], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_0.run(buf106, 65536, grid=grid(65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf11 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf51 = empty_strided_cuda((128, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_1.run(arg10_1, buf11, buf51, 16384, 9, grid=grid(16384, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg10_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf8 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf48 = empty_strided_cuda((128, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_2.run(arg8_1, buf8, buf48, 8192, 9, grid=grid(8192, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg8_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf4 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf44 = empty_strided_cuda((64, 64, 3, 3), (576, 1, 192, 64), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, sub_1, x_36, x_37, x_38, x_39], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_3.run(arg6_1, buf4, buf44, 4096, 9, grid=grid(4096, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg6_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf1 = empty_strided_cuda((64, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf41 = empty_strided_cuda((64, 3, 3, 3), (27, 1, 9, 3), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, sub_1, x_36, x_37], Original ATen: [aten.sub, aten.div, aten.convolution]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_sub_4.run(arg4_1, buf1, buf41, 192, 9, grid=grid(192, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg4_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf0 = empty_strided_cuda((4, 3, 64, 64), (12288, 1, 192, 3), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x], Original ATen: [aten.sub, aten.div]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_div_sub_5.run(arg0_1, arg2_1, arg3_1, buf0, 12, 4096, grid=grid(12, 4096), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg0_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1], Original ATen: [aten.sub, aten.div, aten.convolution]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf2 = extern_kernels.convolution(buf0, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf2, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf0
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf3 = buf2; del buf2  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_6.run(buf3, arg5_1, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf5 = extern_kernels.convolution(buf3, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf5, (4, 64, 64, 64), (262144, 1, 4096, 64))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf4
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf6 = reinterpret_tensor(buf3, (4, 64, 64, 64), (262144, 4096, 64, 1), 0); del buf3  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_7.run(buf5, arg7_1, buf6, 256, 4096, grid=grid(256, 4096), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf7 = empty_strided_cuda((4, 64, 32, 32), (65536, 1, 2048, 64), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_8.run(buf6, buf7, 256, 1024, grid=grid(256, 1024), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf9 = extern_kernels.convolution(buf7, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf9, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf8
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf10 = buf9; del buf9  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_9.run(buf10, arg9_1, 524288, grid=grid(524288), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf12 = extern_kernels.convolution(buf10, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf12, (4, 128, 32, 32), (131072, 1, 4096, 128))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf11
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf13 = reinterpret_tensor(buf10, (4, 128, 32, 32), (131072, 1024, 32, 1), 0); del buf10  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_10.run(buf12, arg11_1, buf13, 512, 1024, grid=grid(512, 1024), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf12
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf105 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_2], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf13, (4, 128, 1024), (131072, 1024, 1), 0), reinterpret_tensor(buf13, (4, 1024, 128), (131072, 1, 1024), 0), out=buf105)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf107 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf109 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_2, mul_21, mul_22], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_11.run(buf105, buf107, buf109, 65536, grid=grid(65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf108 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_2, repeat_2, mul_21, bmm_15], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf106, buf107, out=buf108)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf110 = buf107; del buf107  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_2, mul_22, bmm_16], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf109, buf106, out=buf110)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf111 = buf108; del buf108  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_2, add_8, mul_23, dcov_8, dcov_9, dcov_10, add_9, dcov_11], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12.run(buf111, buf110, buf105, 65536, grid=grid(65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf112 = buf110; del buf110  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_17], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf111, buf106, out=buf112)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf113 = buf105; del buf105  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_18], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf106, buf111, out=buf113)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf114 = buf109; del buf109  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_19], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf106, buf111, out=buf114)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf115 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_20], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf114, buf106, out=buf115)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf117 = buf114; del buf114  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_3], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_0.run(buf117, 65536, grid=grid(65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf40 = empty_strided_cuda((4, 3, 512, 512), (786432, 1, 1536, 3), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36], Original ATen: [aten.sub, aten.div]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_div_sub_13.run(arg1_1, arg2_1, arg3_1, buf40, 12, 262144, grid=grid(12, 262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg1_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg2_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg3_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37], Original ATen: [aten.sub, aten.div, aten.convolution]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf42 = extern_kernels.convolution(buf40, buf41, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf42, (4, 64, 512, 512), (16777216, 1, 32768, 64))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf40
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf41
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf43 = buf42; del buf42  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_14.run(buf43, arg5_1, 67108864, grid=grid(67108864), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg5_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf45 = extern_kernels.convolution(buf43, buf44, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf45, (4, 64, 512, 512), (16777216, 1, 32768, 64))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf44
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf46 = reinterpret_tensor(buf43, (4, 64, 512, 512), (16777216, 262144, 512, 1), 0); del buf43  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_relu_sub_15.run(buf45, arg7_1, buf46, 256, 262144, grid=grid(256, 262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg7_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf45
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf47 = empty_strided_cuda((4, 64, 256, 256), (4194304, 1, 16384, 64), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_16.run(buf46, buf47, 256, 65536, grid=grid(256, 65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf49 = extern_kernels.convolution(buf47, buf48, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf49, (4, 128, 256, 256), (8388608, 1, 32768, 128))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf47
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf48
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf50 = buf49; del buf49  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_17.run(buf50, arg9_1, 33554432, grid=grid(33554432), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg9_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf52 = extern_kernels.convolution(buf50, buf51, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf52, (4, 128, 256, 256), (8388608, 1, 32768, 128))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf51
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf53 = reinterpret_tensor(buf50, (4, 128, 256, 256), (8388608, 65536, 256, 1), 0); del buf50  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_18.run(buf52, arg11_1, buf53, 512, 65536, grid=grid(512, 65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg11_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf52
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf116 = buf106; del buf106  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_3], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf53, (4, 128, 65536), (8388608, 65536, 1), 0), reinterpret_tensor(buf53, (4, 65536, 128), (8388608, 1, 65536), 0), out=buf116)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf118 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf120 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_3, mul_29, mul_30], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_11.run(buf116, buf118, buf120, 65536, grid=grid(65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf119 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_3, repeat_3, mul_29, bmm_22], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf117, buf118, out=buf119)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf121 = buf118; del buf118  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_3, mul_30, bmm_23], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf120, buf117, out=buf121)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf122 = buf119; del buf119  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_3, add_11, mul_31, dcov_12, dcov_13, dcov_14, add_12, dcov_15], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_12.run(buf122, buf121, buf116, 65536, grid=grid(65536), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf123 = buf121; del buf121  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_24], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf122, buf117, out=buf123)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf124 = buf116; del buf116  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_25], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf117, buf122, out=buf124)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf125 = buf120; del buf120  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_26], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf117, buf122, out=buf125)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf126 = empty_strided_cuda((4, 128, 128), (16384, 128, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_27], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf125, buf117, out=buf126)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf117
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf125
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf127 = empty_strided_cuda((4, 2), (2, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf129 = empty_strided_cuda((4, 2), (2, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf131 = empty_strided_cuda((4, 2), (2, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_19.run(buf111, buf112, buf113, buf115, buf122, buf123, buf124, buf126, buf127, buf129, buf131, 8, 8192, grid=grid(8), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf111
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf112
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf113
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf115
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf122
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf123
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf124
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf248 = empty_strided_cuda((4, 5), (5, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf244 = reinterpret_tensor(buf248, (4, 1), (5, 1), 1)  # alias
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_25, sub_9, mul_26, sub_10, mul_27, dcdm_2, mul_33, sub_12, mul_34, sub_13, mul_35, dcdm_3, mul_36, Gamma_XY_1, mul_37, Gamma_XX_1, mul_38, Gamma_YY_1, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_20.run(buf127, buf129, buf131, buf244, 4, 2, grid=grid(4), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf127
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf129
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf131
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf134 = reinterpret_tensor(buf7, (4, 256, 256), (65536, 256, 1), 0); del buf7  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_4], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_21.run(buf134, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf15 = empty_strided_cuda((256, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf55 = empty_strided_cuda((256, 128, 3, 3), (1152, 1, 384, 128), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_22.run(arg12_1, buf15, buf55, 32768, 9, grid=grid(32768, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg12_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf14 = empty_strided_cuda((4, 128, 16, 16), (32768, 1, 2048, 128), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_23.run(buf13, buf14, 512, 256, grid=grid(512, 256), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf13
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf16 = extern_kernels.convolution(buf14, buf15, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf16, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf14
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf15
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf17 = buf16; del buf16  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24.run(buf17, arg13_1, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf18 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf58 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25.run(arg14_1, buf18, buf58, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg14_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf19 = extern_kernels.convolution(buf17, buf18, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf19, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf20 = buf19; del buf19  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24.run(buf20, arg15_1, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf21 = buf18; del buf18  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf61 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25.run(arg16_1, buf21, buf61, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg16_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf22 = extern_kernels.convolution(buf20, buf21, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf22, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf23 = buf22; del buf22  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_24.run(buf23, arg17_1, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf24 = buf21; del buf21  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf64 = empty_strided_cuda((256, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_25.run(arg18_1, buf24, buf64, 65536, 9, grid=grid(65536, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg18_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf25 = extern_kernels.convolution(buf23, buf24, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf25, (4, 256, 16, 16), (65536, 1, 4096, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf24
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf26 = reinterpret_tensor(buf23, (4, 256, 16, 16), (65536, 256, 16, 1), 0); del buf23  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_26.run(buf25, arg19_1, buf26, 1024, 256, grid=grid(1024, 256), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf133 = reinterpret_tensor(buf25, (4, 256, 256), (65536, 256, 1), 0); del buf25  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_4], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf26, (4, 256, 256), (65536, 256, 1), 0), reinterpret_tensor(buf26, (4, 256, 256), (65536, 1, 256), 0), out=buf133)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf135 = reinterpret_tensor(buf20, (4, 256, 256), (65536, 256, 1), 0); del buf20  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf137 = reinterpret_tensor(buf17, (4, 256, 256), (65536, 256, 1), 0); del buf17  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_4, mul_41, mul_42], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_27.run(buf133, buf135, buf137, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf136 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_4, repeat_4, mul_41, bmm_29], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf134, buf135, out=buf136)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf138 = buf135; del buf135  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_4, mul_42, bmm_30], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf137, buf134, out=buf138)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf139 = buf136; del buf136  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_4, add_16, mul_43, dcov_16, dcov_17, dcov_18, add_17, dcov_19], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28.run(buf139, buf138, buf133, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf140 = buf138; del buf138  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_31], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf139, buf134, out=buf140)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf141 = buf133; del buf133  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_32], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf134, buf139, out=buf141)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf142 = buf137; del buf137  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_33], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf134, buf139, out=buf142)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf143 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_34], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf142, buf134, out=buf143)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf145 = buf142; del buf142  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_5], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_21.run(buf145, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf54 = empty_strided_cuda((4, 128, 128, 128), (2097152, 1, 16384, 128), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_29.run(buf53, buf54, 512, 16384, grid=grid(512, 16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf53
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf56 = extern_kernels.convolution(buf54, buf55, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf56, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf54
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf55
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf57 = buf56; del buf56  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30.run(buf57, arg13_1, 16777216, grid=grid(16777216), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg13_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf59 = extern_kernels.convolution(buf57, buf58, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf59, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf57
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf58
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf60 = buf59; del buf59  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30.run(buf60, arg15_1, 16777216, grid=grid(16777216), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg15_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf62 = extern_kernels.convolution(buf60, buf61, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf62, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf60
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf61
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf63 = buf62; del buf62  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_30.run(buf63, arg17_1, 16777216, grid=grid(16777216), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg17_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf65 = extern_kernels.convolution(buf63, buf64, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf65, (4, 256, 128, 128), (4194304, 1, 32768, 256))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf64
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf66 = reinterpret_tensor(buf63, (4, 256, 128, 128), (4194304, 16384, 128, 1), 0); del buf63  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_31.run(buf65, arg19_1, buf66, 1024, 16384, grid=grid(1024, 16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg19_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf65
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf144 = buf134; del buf134  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_5], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf66, (4, 256, 16384), (4194304, 16384, 1), 0), reinterpret_tensor(buf66, (4, 16384, 256), (4194304, 1, 16384), 0), out=buf144)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf146 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf148 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_5, mul_49, mul_50], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_27.run(buf144, buf146, buf148, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf147 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_5, repeat_5, mul_49, bmm_36], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf145, buf146, out=buf147)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf149 = buf146; del buf146  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_5, mul_50, bmm_37], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf148, buf145, out=buf149)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf150 = buf147; del buf147  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_5, add_19, mul_51, dcov_20, dcov_21, dcov_22, add_20, dcov_23], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_28.run(buf150, buf149, buf144, 262144, grid=grid(262144), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf151 = buf149; del buf149  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_38], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf150, buf145, out=buf151)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf152 = buf144; del buf144  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_39], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf145, buf150, out=buf152)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf153 = buf148; del buf148  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_40], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf145, buf150, out=buf153)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf154 = empty_strided_cuda((4, 256, 256), (65536, 256, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_41], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf153, buf145, out=buf154)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf145
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf153
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf155 = empty_strided_cuda((4, 8), (8, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf157 = empty_strided_cuda((4, 8), (8, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf159 = empty_strided_cuda((4, 8), (8, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_32.run(buf139, buf140, buf141, buf143, buf150, buf151, buf152, buf154, buf155, buf157, buf159, 32, 8192, grid=grid(32), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf139
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf140
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf141
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf143
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf150
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf151
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf152
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf154
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf245 = reinterpret_tensor(buf248, (4, 1), (5, 1), 2)  # alias
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_45, sub_15, mul_46, sub_16, mul_47, dcdm_4, mul_53, sub_18, mul_54, sub_19, mul_55, dcdm_5, mul_56, Gamma_XY_2, mul_57, Gamma_XX_2, mul_58, Gamma_YY_2, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_33.run(buf155, buf157, buf159, buf245, 4, 8, grid=grid(4), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf155
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf157
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf159
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf162 = reinterpret_tensor(buf5, (4, 512, 512), (262144, 512, 1), 0); del buf5  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_6], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf162, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf27 = reinterpret_tensor(buf126, (4, 256, 8, 8), (16384, 1, 2048, 256), 0); del buf126  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_35.run(buf26, buf27, 1024, 64, grid=grid(1024, 64), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf26
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf28 = empty_strided_cuda((512, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf68 = empty_strided_cuda((512, 256, 3, 3), (2304, 1, 768, 256), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_36.run(arg20_1, buf28, buf68, 131072, 9, grid=grid(131072, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg20_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf29 = extern_kernels.convolution(buf27, buf28, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf29, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf27
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf28
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf30 = buf29; del buf29  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37.run(buf30, arg21_1, 131072, grid=grid(131072), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf31 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf71 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg22_1, buf31, buf71, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg22_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf32 = extern_kernels.convolution(buf30, buf31, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf32, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf30
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf33 = buf32; del buf32  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37.run(buf33, arg23_1, 131072, grid=grid(131072), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf34 = buf31; del buf31  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf74 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg24_1, buf34, buf74, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg24_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf35 = extern_kernels.convolution(buf33, buf34, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf35, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf33
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf36 = buf35; del buf35  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_37.run(buf36, arg25_1, 131072, grid=grid(131072), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf37 = buf34; del buf34  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf77 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg26_1, buf37, buf77, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg26_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf38 = extern_kernels.convolution(buf36, buf37, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf38, (4, 512, 8, 8), (32768, 1, 4096, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf39 = reinterpret_tensor(buf36, (4, 512, 8, 8), (32768, 64, 8, 1), 0); del buf36  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_39.run(buf38, arg27_1, buf39, 2048, 64, grid=grid(2048, 64), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf38
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf161 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_6], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf39, (4, 512, 64), (32768, 64, 1), 0), reinterpret_tensor(buf39, (4, 64, 512), (32768, 1, 64), 0), out=buf161)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf163 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf165 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_6, mul_61, mul_62], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf161, buf163, buf165, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf164 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_6, repeat_6, mul_61, bmm_43], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf162, buf163, out=buf164)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf166 = buf163; del buf163  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_6, mul_62, bmm_44], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf165, buf162, out=buf166)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf167 = buf164; del buf164  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_6, add_24, mul_63, dcov_24, dcov_25, dcov_26, add_25, dcov_27], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf167, buf166, buf161, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf168 = buf166; del buf166  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_45], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf167, buf162, out=buf168)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf169 = buf161; del buf161  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_46], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf162, buf167, out=buf169)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf170 = buf165; del buf165  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_47], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf162, buf167, out=buf170)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf171 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_48], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf170, buf162, out=buf171)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf173 = buf170; del buf170  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_7], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf173, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf67 = empty_strided_cuda((4, 256, 64, 64), (1048576, 1, 16384, 256), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_42.run(buf66, buf67, 1024, 4096, grid=grid(1024, 4096), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf66
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf69 = extern_kernels.convolution(buf67, buf68, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf69, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf67
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf68
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf70 = buf69; del buf69  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43.run(buf70, arg21_1, 8388608, grid=grid(8388608), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg21_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf72 = extern_kernels.convolution(buf70, buf71, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf72, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf70
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf73 = buf72; del buf72  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43.run(buf73, arg23_1, 8388608, grid=grid(8388608), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg23_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf75 = extern_kernels.convolution(buf73, buf74, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf75, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf73
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf76 = buf75; del buf75  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_43.run(buf76, arg25_1, 8388608, grid=grid(8388608), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg25_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf78 = extern_kernels.convolution(buf76, buf77, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf78, (4, 512, 64, 64), (2097152, 1, 32768, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf79 = reinterpret_tensor(buf76, (4, 512, 64, 64), (2097152, 4096, 64, 1), 0); del buf76  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_44.run(buf78, arg27_1, buf79, 2048, 4096, grid=grid(2048, 4096), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg27_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf78
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf172 = buf162; del buf162  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_7], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf79, (4, 512, 4096), (2097152, 4096, 1), 0), reinterpret_tensor(buf79, (4, 4096, 512), (2097152, 1, 4096), 0), out=buf172)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf174 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf176 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_7, mul_69, mul_70], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf172, buf174, buf176, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf175 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_7, repeat_7, mul_69, bmm_50], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf173, buf174, out=buf175)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf177 = buf174; del buf174  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_7, mul_70, bmm_51], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf176, buf173, out=buf177)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf178 = buf175; del buf175  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_7, add_27, mul_71, dcov_28, dcov_29, dcov_30, add_28, dcov_31], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf178, buf177, buf172, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf179 = buf177; del buf177  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_52], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf178, buf173, out=buf179)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf180 = buf172; del buf172  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_53], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf173, buf178, out=buf180)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf181 = buf176; del buf176  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_54], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf173, buf178, out=buf181)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf182 = empty_strided_cuda((4, 512, 512), (262144, 512, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_55], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf181, buf173, out=buf182)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf183 = empty_strided_cuda((4, 32), (32, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf185 = empty_strided_cuda((4, 32), (32, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf187 = empty_strided_cuda((4, 32), (32, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_45.run(buf167, buf168, buf169, buf171, buf178, buf179, buf180, buf182, buf183, buf185, buf187, 128, 8192, grid=grid(128), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf246 = reinterpret_tensor(buf248, (4, 1), (5, 1), 3)  # alias
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_65, sub_21, mul_66, sub_22, mul_67, dcdm_6, mul_73, sub_24, mul_74, sub_25, mul_75, dcdm_7, mul_76, Gamma_XY_3, mul_77, Gamma_XX_3, mul_78, Gamma_YY_3, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_46.run(buf183, buf185, buf187, buf246, 4, 32, grid=grid(4), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf203 = buf182; del buf182  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_8], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf203, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf189 = empty_strided_cuda((4, 512, 4, 4), (8192, 1, 2048, 512), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_47.run(buf39, buf189, 2048, 16, grid=grid(2048, 16), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf39
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf190 = buf77; del buf77  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf214 = buf74; del buf74  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_65], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg28_1, buf190, buf214, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg28_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf191 = extern_kernels.convolution(buf189, buf190, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf191, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf189
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf192 = buf191; del buf191  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48.run(buf192, arg29_1, 32768, grid=grid(32768), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf193 = buf190; del buf190  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf217 = buf71; del buf71  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_30, x_31, x_65, x_66, x_67], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg30_1, buf193, buf217, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg30_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf194 = extern_kernels.convolution(buf192, buf193, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf194, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf192
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf195 = buf194; del buf194  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48.run(buf195, arg31_1, 32768, grid=grid(32768), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf196 = buf193; del buf193  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf220 = buf37; del buf37  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_30, x_31, x_32, x_33, x_65, x_66, x_67, x_68, x_69], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg32_1, buf196, buf220, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg32_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf197 = extern_kernels.convolution(buf195, buf196, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf197, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf195
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf198 = buf197; del buf197  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_48.run(buf198, arg33_1, 32768, grid=grid(32768), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf199 = buf196; del buf196  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf223 = empty_strided_cuda((512, 512, 3, 3), (4608, 1, 1536, 512), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_29, x_30, x_31, x_32, x_33, x_34, x_35, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_38.run(arg34_1, buf199, buf223, 262144, 9, grid=grid(262144, 9), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg34_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf200 = extern_kernels.convolution(buf198, buf199, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf200, (4, 512, 4, 4), (8192, 1, 2048, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf199
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf201 = reinterpret_tensor(buf198, (4, 512, 4, 4), (8192, 16, 4, 1), 0); del buf198  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub, x, x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13, x_14, x_15, x_16, x_17, x_18, x_19, x_20, x_21, x_22, x_23, x_24, x_25, x_26, x_27, x_28, x_29, x_30, x_31, x_32, x_33, x_34, x_35], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_49.run(buf200, arg35_1, buf201, 2048, 16, grid=grid(2048, 16), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf200
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf202 = buf180; del buf180  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_8], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf201, (4, 512, 16), (8192, 16, 1), 0), reinterpret_tensor(buf201, (4, 16, 512), (8192, 1, 16), 0), out=buf202)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf201
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf204 = buf179; del buf179  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf206 = buf178; del buf178  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_8, mul_81, mul_82], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf202, buf204, buf206, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf205 = buf171; del buf171  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_8, repeat_8, mul_81, bmm_57], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf203, buf204, out=buf205)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf207 = buf204; del buf204  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_8, mul_82, bmm_58], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf206, buf203, out=buf207)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf208 = buf205; del buf205  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_8, add_32, mul_83, dcov_32, dcov_33, dcov_34, add_33, dcov_35], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf208, buf207, buf202, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf209 = buf207; del buf207  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_59], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf208, buf203, out=buf209)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf210 = buf202; del buf202  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_60], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf203, buf208, out=buf210)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf211 = buf206; del buf206  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_61], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf203, buf208, out=buf211)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf212 = buf169; del buf169  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_62], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf211, buf203, out=buf212)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf227 = buf211; del buf211  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_9], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_34.run(buf227, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf213 = empty_strided_cuda((4, 512, 32, 32), (524288, 1, 16384, 512), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_50.run(buf79, buf213, 2048, 1024, grid=grid(2048, 1024), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf79
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf215 = extern_kernels.convolution(buf213, buf214, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf215, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf213
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf214
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf216 = buf215; del buf215  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51.run(buf216, arg29_1, 2097152, grid=grid(2097152), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg29_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf218 = extern_kernels.convolution(buf216, buf217, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf218, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf216
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf217
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf219 = buf218; del buf218  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51.run(buf219, arg31_1, 2097152, grid=grid(2097152), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg31_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf221 = extern_kernels.convolution(buf219, buf220, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf221, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf219
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf220
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf222 = buf221; del buf221  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_51.run(buf222, arg33_1, 2097152, grid=grid(2097152), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg33_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf224 = extern_kernels.convolution(buf222, buf223, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         assert_size_stride(buf224, (4, 512, 32, 32), (524288, 1, 16384, 512))
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf223
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf225 = reinterpret_tensor(buf222, (4, 512, 32, 32), (524288, 1024, 32, 1), 0); del buf222  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [sub_1, x_36, x_37, x_38, x_39, x_40, x_41, x_42, x_43, x_44, x_45, x_46, x_47, x_48, x_49, x_50, x_51, x_52, x_53, x_54, x_55, x_56, x_57, x_58, x_59, x_60, x_61, x_62, x_63, x_64, x_65, x_66, x_67, x_68, x_69, x_70, x_71], Original ATen: [aten.sub, aten.div, aten.convolution, aten.relu, aten.max_pool2d_with_indices]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_convolution_div_max_pool2d_with_indices_relu_sub_52.run(buf224, arg35_1, buf225, 2048, 1024, grid=grid(2048, 1024), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del arg35_1
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf224
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf226 = buf203; del buf203  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_9], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf225, (4, 512, 1024), (524288, 1024, 1), 0), reinterpret_tensor(buf225, (4, 1024, 512), (524288, 1, 1024), 0), out=buf226)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf225
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf228 = buf168; del buf168  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf230 = buf167; del buf167  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_9, mul_89, mul_90], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_40.run(buf226, buf228, buf230, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf229 = buf181; del buf181  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_9, repeat_9, mul_89, bmm_64], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf227, buf228, out=buf229)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf231 = buf228; del buf228  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_9, mul_90, bmm_65], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf230, buf227, out=buf231)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf232 = buf229; del buf229  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_9, add_35, mul_91, dcov_36, dcov_37, dcov_38, add_36, dcov_39], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_41.run(buf232, buf231, buf226, 1048576, grid=grid(1048576), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf233 = buf231; del buf231  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_66], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf232, buf227, out=buf233)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf234 = buf226; del buf226  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_67], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf227, buf232, out=buf234)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf235 = buf230; del buf230  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_68], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf227, buf232, out=buf235)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf236 = buf173; del buf173  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_69], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf235, buf227, out=buf236)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf227
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf235
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf237 = buf187; del buf187  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf239 = buf185; del buf185  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf241 = buf183; del buf183  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_85, sub_27, mul_86, sub_28, mul_87, dcdm_8, mul_93, sub_30, mul_94, sub_31, mul_95, dcdm_9, mul_96, Gamma_XY_4, mul_97, Gamma_XX_4, mul_98, Gamma_YY_4], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_sub_sum_45.run(buf208, buf209, buf210, buf212, buf232, buf233, buf234, buf236, buf237, buf239, buf241, 128, 8192, grid=grid(128), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf208
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf209
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf210
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf212
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf232
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf233
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf234
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf236
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf247 = reinterpret_tensor(buf248, (4, 1), (5, 1), 4)  # alias
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_85, sub_27, mul_86, sub_28, mul_87, dcdm_8, mul_93, sub_30, mul_94, sub_31, mul_95, dcdm_9, mul_96, Gamma_XY_4, mul_97, Gamma_XX_4, mul_98, Gamma_YY_4, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_per_fused_add_mul_stack_sub_sum_46.run(buf237, buf239, buf241, buf247, 4, 32, grid=grid(4), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf237
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf239
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf241
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf81 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_53.run(buf81, 16384, grid=grid(16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf80 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf6, (4, 64, 4096), (262144, 4096, 1), 0), reinterpret_tensor(buf6, (4, 4096, 64), (262144, 1, 4096), 0), out=buf80)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf6
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf82 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf84 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat, mul_1, mul_2], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_54.run(buf80, buf82, buf84, 16384, grid=grid(16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf83 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones, repeat, mul_1, bmm_1], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf81, buf82, out=buf83)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf85 = buf82; del buf82  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat, mul_2, bmm_2], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf84, buf81, out=buf85)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf86 = buf83; del buf83  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp, add, mul_3, dcov, dcov_1, dcov_2, add_1, dcov_3], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55.run(buf86, buf85, buf80, 16384, grid=grid(16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf87 = buf85; del buf85  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_3], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf86, buf81, out=buf87)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf88 = buf80; del buf80  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_4], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf81, buf86, out=buf88)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf89 = buf84; del buf84  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_5], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf81, buf86, out=buf89)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf90 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_6], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf89, buf81, out=buf90)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf92 = buf89; del buf89  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_1], Original ATen: [aten.ones]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_ones_53.run(buf92, 16384, grid=grid(16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf91 = buf81; del buf81  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [x_pow2_1], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(reinterpret_tensor(buf46, (4, 64, 262144), (16777216, 262144, 1), 0), reinterpret_tensor(buf46, (4, 262144, 64), (16777216, 1, 262144), 0), out=buf91)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf46
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf93 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf95 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_1, mul_9, mul_10], Original ATen: [aten.repeat, aten.mul]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mul_repeat_54.run(buf91, buf93, buf95, 16384, grid=grid(16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf94 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [ones_1, repeat_1, mul_9, bmm_8], Original ATen: [aten.ones, aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf92, buf93, out=buf94)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf96 = buf93; del buf93  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [repeat_1, mul_10, bmm_9], Original ATen: [aten.repeat, aten.mul, aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf95, buf92, out=buf96)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf97 = buf94; del buf94  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [exp_1, add_3, mul_11, dcov_4, dcov_5, dcov_6, add_4, dcov_7], Original ATen: [aten.exp, aten.add, aten.mul, aten.sub, aten.clamp, aten.sqrt]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_add_clamp_exp_mul_sqrt_sub_55.run(buf97, buf96, buf91, 16384, grid=grid(16384), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf98 = buf96; del buf96  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_10], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf97, buf92, out=buf98)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf99 = buf91; del buf91  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_11], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf92, buf97, out=buf99)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf100 = buf95; del buf95  # reuse
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_12], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf92, buf97, out=buf100)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf101 = empty_strided_cuda((4, 64, 64), (4096, 64, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [bmm_13], Original ATen: [aten.bmm]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         extern_kernels.bmm(buf100, buf92, out=buf101)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf100
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf92
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf243 = reinterpret_tensor(buf248, (4, 1), (5, 1), 0)  # alias
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mul_5, sub_3, mul_6, sub_4, mul_7, dcdm, mul_13, sub_6, mul_14, sub_7, mul_15, dcdm_1, mul_16, Gamma_XY, mul_17, Gamma_XX, mul_18, Gamma_YY, dc_scores], Original ATen: [aten.mul, aten.sub, aten.add, aten.sum, aten.stack]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_red_fused_add_mul_stack_sub_sum_56.run(buf86, buf87, buf88, buf90, buf97, buf98, buf99, buf101, buf243, 4, 4096, grid=grid(4), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf101
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf86
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf87
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf88
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf90
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf97
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf98
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf99
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         buf249 = empty_strided_cuda((4, 1), (1, 1), torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         # Topologically Sorted Source Nodes: [mean, score], Original ATen: [aten.mean, aten.rsub]
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         triton_poi_fused_mean_rsub_57.run(buf248, buf249, 4, grid=grid(4), stream=stream0)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf243
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf244
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf245
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf246
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf247
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]         del buf248
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return (buf249, )
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg0_1 = rand_strided((4, 3, 64, 64), (12288, 4096, 64, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg1_1 = rand_strided((4, 3, 512, 512), (786432, 262144, 512, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg2_1 = rand_strided((1, 3, 1, 1), (3, 1, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg3_1 = rand_strided((1, 3, 1, 1), (3, 1, 1, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg4_1 = rand_strided((64, 3, 3, 3), (27, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg5_1 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg6_1 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg7_1 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg8_1 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg9_1 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg10_1 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg11_1 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg12_1 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg13_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg14_1 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg15_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg16_1 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg17_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg18_1 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg19_1 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg20_1 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg21_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg22_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg23_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg24_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg25_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg26_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg27_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg28_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg29_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg30_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg31_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg32_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg33_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg34_1 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     arg35_1 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1])
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] if __name__ == "__main__":
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0205 20:11:29.194000 2881049 site-packages/torch/_inductor/graph.py:2045] [0/0] [__output_code] 
V0205 20:11:29.315000 2881049 site-packages/torch/_inductor/graph.py:2053] [0/0] [__output_code] Output code written to: inductor_cache/iz/cizsjvb4iokgwrzzkecnhjnspuwbd4gpmet623zhh7x5emc536uu.py
