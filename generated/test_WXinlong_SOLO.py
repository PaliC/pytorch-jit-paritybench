import sys
_module = sys.modules[__name__]
del sys
mask_rcnn_r50_fpn_1x = _module
atss_r50_fpn_1x = _module
cascade_mask_rcnn_r101_fpn_1x = _module
cascade_mask_rcnn_r50_caffe_c4_1x = _module
cascade_mask_rcnn_r50_fpn_1x = _module
cascade_mask_rcnn_x101_32x4d_fpn_1x = _module
cascade_mask_rcnn_x101_64x4d_fpn_1x = _module
cascade_rcnn_r101_fpn_1x = _module
cascade_rcnn_r50_caffe_c4_1x = _module
cascade_rcnn_r50_fpn_1x = _module
cascade_rcnn_x101_32x4d_fpn_1x = _module
cascade_rcnn_x101_64x4d_fpn_1x = _module
faster_rcnn_r50_fpn_1x_cityscapes = _module
mask_rcnn_r50_fpn_1x_cityscapes = _module
faster_rcnn_dpool_r50_fpn_1x = _module
faster_rcnn_mdpool_r50_fpn_1x = _module
dh_faster_rcnn_r50_fpn_1x = _module
faster_rcnn_r50_fpn_attention_0010_1x = _module
faster_rcnn_r50_fpn_attention_0010_dcn_1x = _module
faster_rcnn_r50_fpn_attention_1111_1x = _module
faster_rcnn_r50_fpn_attention_1111_dcn_1x = _module
fast_mask_rcnn_r101_fpn_1x = _module
fast_mask_rcnn_r50_caffe_c4_1x = _module
fast_mask_rcnn_r50_fpn_1x = _module
fast_rcnn_r101_fpn_1x = _module
fast_rcnn_r50_caffe_c4_1x = _module
fast_rcnn_r50_fpn_1x = _module
faster_rcnn_ohem_r50_fpn_1x = _module
faster_rcnn_r101_fpn_1x = _module
faster_rcnn_r50_caffe_c4_1x = _module
faster_rcnn_r50_fpn_1x = _module
faster_rcnn_x101_32x4d_fpn_1x = _module
faster_rcnn_x101_64x4d_fpn_1x = _module
fcos_mstrain_640_800_r101_caffe_fpn_gn_2x_4gpu = _module
fcos_mstrain_640_800_x101_64x4d_fpn_gn_2x = _module
fcos_r50_caffe_fpn_gn_1x_4gpu = _module
fovea_align_gn_ms_r101_fpn_4gpu_2x = _module
fovea_align_gn_ms_r50_fpn_4gpu_2x = _module
fovea_align_gn_r101_fpn_4gpu_2x = _module
fovea_align_gn_r50_fpn_4gpu_2x = _module
fovea_r50_fpn_4gpu_1x = _module
faster_rcnn_r50_fpn_fp16_1x = _module
mask_rcnn_r50_fpn_fp16_1x = _module
retinanet_r50_fpn_fp16_1x = _module
retinanet_free_anchor_r101_fpn_1x = _module
retinanet_free_anchor_r50_fpn_1x = _module
mask_rcnn_r50_fpn_sbn_1x = _module
retinanet_ghm_r50_fpn_1x = _module
faster_rcnn_r50_fpn_gn_ws_1x = _module
mask_rcnn_r50_fpn_gn_ws_20_23_24e = _module
mask_rcnn_r50_fpn_gn_ws_2x = _module
mask_rcnn_x101_32x4d_fpn_gn_ws_2x = _module
mask_rcnn_r101_fpn_gn_2x = _module
mask_rcnn_r50_fpn_gn_2x = _module
mask_rcnn_r50_fpn_gn_contrib_2x = _module
grid_rcnn_gn_head_r50_fpn_2x = _module
grid_rcnn_gn_head_x101_32x4d_fpn_2x = _module
ga_fast_r50_caffe_fpn_1x = _module
ga_faster_r50_caffe_fpn_1x = _module
ga_faster_x101_32x4d_fpn_1x = _module
ga_retinanet_r50_caffe_fpn_1x = _module
ga_retinanet_x101_32x4d_fpn_1x = _module
ga_rpn_r101_caffe_rpn_1x = _module
ga_rpn_r50_caffe_fpn_1x = _module
ga_rpn_x101_32x4d_fpn_1x = _module
cascade_mask_rcnn_hrnetv2p_w32_20e = _module
cascade_rcnn_hrnetv2p_w32_20e = _module
faster_rcnn_hrnetv2p_w18_1x = _module
faster_rcnn_hrnetv2p_w32_1x = _module
faster_rcnn_hrnetv2p_w40_1x = _module
fcos_hrnetv2p_w32_gn_1x_4gpu = _module
htc_hrnetv2p_w32_20e = _module
mask_rcnn_hrnetv2p_w18_1x = _module
mask_rcnn_hrnetv2p_w32_1x = _module
htc_r101_fpn_20e = _module
htc_r50_fpn_1x = _module
htc_r50_fpn_20e = _module
htc_without_semantic_r50_fpn_1x = _module
htc_x101_32x4d_fpn_20e_16gpu = _module
htc_x101_64x4d_fpn_20e_16gpu = _module
cascade_mask_rcnn_r50_fpn_instaboost_4x = _module
mask_rcnn_r50_fpn_instaboost_4x = _module
ssd300_coco_instaboost_4x = _module
libra_fast_rcnn_r50_fpn_1x = _module
libra_faster_rcnn_r101_fpn_1x = _module
libra_faster_rcnn_r50_fpn_1x = _module
libra_faster_rcnn_x101_64x4d_fpn_1x = _module
libra_retinanet_r50_fpn_1x = _module
mask_rcnn_r101_fpn_1x = _module
mask_rcnn_r50_caffe_c4_1x = _module
mask_rcnn_x101_32x4d_fpn_1x = _module
mask_rcnn_x101_64x4d_fpn_1x = _module
ms_rcnn_r101_caffe_fpn_1x = _module
ms_rcnn_r50_caffe_fpn_1x = _module
ms_rcnn_x101_64x4d_fpn_1x = _module
retinanet_crop640_r50_fpn_50e = _module
retinanet_crop640_r50_nasfpn_50e = _module
faster_rcnn_r50_fpn_1x_voc0712 = _module
ssd300_voc = _module
ssd512_voc = _module
bbox_r50_grid_center_fpn_1x = _module
bbox_r50_grid_fpn_1x = _module
reppoints_minmax_r50_fpn_1x = _module
reppoints_moment_r101_dcn_fpn_2x = _module
reppoints_moment_r101_dcn_fpn_2x_mt = _module
reppoints_moment_r101_fpn_2x = _module
reppoints_moment_r101_fpn_2x_mt = _module
reppoints_moment_r50_fpn_1x = _module
reppoints_moment_r50_fpn_2x = _module
reppoints_moment_r50_fpn_2x_mt = _module
reppoints_moment_r50_no_gn_fpn_1x = _module
reppoints_moment_x101_dcn_fpn_2x = _module
reppoints_moment_x101_dcn_fpn_2x_mt = _module
reppoints_partial_minmax_r50_fpn_1x = _module
retinanet_r101_fpn_1x = _module
retinanet_r50_fpn_1x = _module
retinanet_x101_32x4d_fpn_1x = _module
retinanet_x101_64x4d_fpn_1x = _module
rpn_r101_fpn_1x = _module
rpn_r50_caffe_c4_1x = _module
rpn_r50_fpn_1x = _module
rpn_x101_32x4d_fpn_1x = _module
rpn_x101_64x4d_fpn_1x = _module
scratch_faster_rcnn_r50_fpn_gn_6x = _module
scratch_mask_rcnn_r50_fpn_gn_6x = _module
decoupled_solo_light_dcn_r50_fpn_8gpu_3x = _module
decoupled_solo_light_r50_fpn_8gpu_3x = _module
decoupled_solo_r101_fpn_8gpu_3x = _module
decoupled_solo_r50_fpn_8gpu_1x = _module
decoupled_solo_r50_fpn_8gpu_3x = _module
solo_r101_fpn_8gpu_3x = _module
solo_r50_fpn_8gpu_1x = _module
solo_r50_fpn_8gpu_3x = _module
solov2_light_448_r18_fpn_8gpu_3x = _module
solov2_light_448_r34_fpn_8gpu_3x = _module
solov2_light_448_r50_fpn_8gpu_3x = _module
solov2_light_512_dcn_r50_fpn_8gpu_3x = _module
solov2_r101_dcn_fpn_8gpu_3x = _module
solov2_r101_fpn_8gpu_3x = _module
solov2_r50_fpn_8gpu_1x = _module
solov2_r50_fpn_8gpu_3x = _module
solov2_x101_dcn_fpn_8gpu_3x = _module
ssd300_coco = _module
ssd512_coco = _module
ssd300_wider_face = _module
inference_demo = _module
webcam_demo = _module
conf = _module
mmdet = _module
apis = _module
inference = _module
train = _module
core = _module
anchor = _module
anchor_generator = _module
anchor_target = _module
guided_anchor_target = _module
point_generator = _module
point_target = _module
bbox = _module
assign_sampling = _module
assigners = _module
approx_max_iou_assigner = _module
assign_result = _module
atss_assigner = _module
base_assigner = _module
max_iou_assigner = _module
point_assigner = _module
bbox_target = _module
demodata = _module
geometry = _module
samplers = _module
base_sampler = _module
combined_sampler = _module
instance_balanced_pos_sampler = _module
iou_balanced_neg_sampler = _module
ohem_sampler = _module
pseudo_sampler = _module
random_sampler = _module
sampling_result = _module
transforms = _module
evaluation = _module
bbox_overlaps = _module
class_names = _module
coco_utils = _module
eval_hooks = _module
mean_ap = _module
recall = _module
fp16 = _module
decorators = _module
hooks = _module
utils = _module
mask = _module
mask_target = _module
post_processing = _module
bbox_nms = _module
matrix_nms = _module
merge_augs = _module
dist_utils = _module
misc = _module
datasets = _module
builder = _module
cityscapes = _module
coco = _module
custom = _module
dataset_wrappers = _module
loader = _module
build_loader = _module
sampler = _module
pipelines = _module
compose = _module
formating = _module
instaboost = _module
loading = _module
test_aug = _module
registry = _module
voc = _module
wider_face = _module
xml_style = _module
models = _module
anchor_heads = _module
anchor_head = _module
atss_head = _module
decoupled_solo_head = _module
decoupled_solo_light_head = _module
fcos_head = _module
fovea_head = _module
free_anchor_retina_head = _module
ga_retina_head = _module
ga_rpn_head = _module
guided_anchor_head = _module
reppoints_head = _module
retina_head = _module
retina_sepbn_head = _module
rpn_head = _module
solo_head = _module
solov2_head = _module
solov2_light_head = _module
ssd_head = _module
backbones = _module
hrnet = _module
resnet = _module
resnext = _module
ssd_vgg = _module
bbox_heads = _module
bbox_head = _module
convfc_bbox_head = _module
double_bbox_head = _module
builder = _module
detectors = _module
atss = _module
base = _module
cascade_rcnn = _module
double_head_rcnn = _module
fast_rcnn = _module
faster_rcnn = _module
fcos = _module
fovea = _module
grid_rcnn = _module
htc = _module
mask_rcnn = _module
mask_scoring_rcnn = _module
reppoints_detector = _module
retinanet = _module
rpn = _module
single_stage = _module
single_stage_ins = _module
solo = _module
solov2 = _module
test_mixins = _module
two_stage = _module
losses = _module
accuracy = _module
balanced_l1_loss = _module
cross_entropy_loss = _module
focal_loss = _module
ghm_loss = _module
iou_loss = _module
mse_loss = _module
smooth_l1_loss = _module
utils = _module
mask_heads = _module
fcn_mask_head = _module
fused_semantic_head = _module
grid_head = _module
htc_mask_head = _module
mask_feat_head = _module
maskiou_head = _module
necks = _module
bfp = _module
fpn = _module
hrfpn = _module
nas_fpn = _module
plugins = _module
generalized_attention = _module
non_local = _module
roi_extractors = _module
single_level = _module
shared_heads = _module
res_layer = _module
conv_module = _module
conv_ws = _module
norm = _module
scale = _module
weight_init = _module
ops = _module
context_block = _module
dcn = _module
deform_conv = _module
deform_pool = _module
masked_conv = _module
masked_conv = _module
nms = _module
nms_wrapper = _module
roi_align = _module
gradcheck = _module
roi_align = _module
roi_pool = _module
gradcheck = _module
roi_pool = _module
sigmoid_focal_loss = _module
sigmoid_focal_loss = _module
contextmanagers = _module
flops_counter = _module
logger = _module
profiling = _module
registry = _module
util_mixins = _module
paddlepaddle = _module
setup = _module
async_benchmark = _module
test_assigner = _module
test_async = _module
test_config = _module
test_forward = _module
test_heads = _module
test_nms = _module
test_sampler = _module
test_utils = _module
analyze_logs = _module
coco_error_analysis = _module
coco_eval = _module
collect_env = _module
pascal_voc = _module
detectron2pytorch = _module
get_flops = _module
publish_model = _module
robustness_eval = _module
test = _module
test_ins = _module
test_ins_vis = _module
test_robustness = _module
train = _module
upgrade_model_version = _module
voc_eval = _module

from _paritybench_helpers import _mock_config, patch_functional
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
import abc, collections, copy, enum, functools, inspect, itertools, logging, math, matplotlib, numbers, numpy, pandas, queue, random, re, scipy, sklearn, string, tensorflow, time, torch, torchaudio, torchvision, types, typing, uuid, warnings
import operator as op
from dataclasses import dataclass
import numpy as np
from torch import Tensor
patch_functional()
open = mock_open()
yaml = logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
yaml.load.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'
xrange = range
wraps = functools.wraps


import torch


import warnings


import matplotlib.pyplot as plt


import numpy as np


from scipy import ndimage


import random


import re


from collections import OrderedDict


import torch.distributed as dist


from abc import ABCMeta


from abc import abstractmethod


from torch.utils.data import Dataset


import functools


from inspect import getfullargspec


import copy


import torch.nn as nn


from collections import abc


from torch.nn.modules.utils import _pair


from torch._utils import _flatten_dense_tensors


from torch._utils import _take_tensors


from torch._utils import _unflatten_dense_tensors


from torch.utils.data.dataset import ConcatDataset as _ConcatDataset


from functools import partial


from torch.utils.data import DataLoader


import math


from torch.utils.data import DistributedSampler as _DistributedSampler


from torch.utils.data import Sampler


from collections.abc import Sequence


import torch.nn.functional as F


from torch.nn.modules.batchnorm import _BatchNorm


import torch.utils.checkpoint as cp


from torch import nn


import logging


from torch.utils.checkpoint import checkpoint


from torch.autograd import Function


from torch.autograd.function import once_differentiable


from torch.nn.modules.utils import _single


from torch.autograd import gradcheck


import time


from typing import List


from torch.nn.modules.conv import _ConvNd


from torch.nn.modules.conv import _ConvTransposeMixin


from torch.nn.modules.pooling import _AdaptiveAvgPoolNd


from torch.nn.modules.pooling import _AdaptiveMaxPoolNd


from torch.nn.modules.pooling import _AvgPoolNd


from torch.nn.modules.pooling import _MaxPoolNd


import inspect


from torch.utils.cpp_extension import BuildExtension


from torch.utils.cpp_extension import CUDAExtension


from collections import defaultdict


import torchvision


import matplotlib.cm as cm


class AnchorGenerator(object):
    """
    Examples:
        >>> from mmdet.core import AnchorGenerator
        >>> self = AnchorGenerator(9, [1.], [1.])
        >>> all_anchors = self.grid_anchors((2, 2), device='cpu')
        >>> print(all_anchors)
        tensor([[ 0.,  0.,  8.,  8.],
                [16.,  0., 24.,  8.],
                [ 0., 16.,  8., 24.],
                [16., 16., 24., 24.]])
    """

    def __init__(self, base_size, scales, ratios, scale_major=True, ctr=None):
        self.base_size = base_size
        self.scales = torch.Tensor(scales)
        self.ratios = torch.Tensor(ratios)
        self.scale_major = scale_major
        self.ctr = ctr
        self.base_anchors = self.gen_base_anchors()

    @property
    def num_base_anchors(self):
        return self.base_anchors.size(0)

    def gen_base_anchors(self):
        w = self.base_size
        h = self.base_size
        if self.ctr is None:
            x_ctr = 0.5 * (w - 1)
            y_ctr = 0.5 * (h - 1)
        else:
            x_ctr, y_ctr = self.ctr
        h_ratios = torch.sqrt(self.ratios)
        w_ratios = 1 / h_ratios
        if self.scale_major:
            ws = (w * w_ratios[:, None] * self.scales[None, :]).view(-1)
            hs = (h * h_ratios[:, None] * self.scales[None, :]).view(-1)
        else:
            ws = (w * self.scales[:, None] * w_ratios[None, :]).view(-1)
            hs = (h * self.scales[:, None] * h_ratios[None, :]).view(-1)
        base_anchors = torch.stack([x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1), x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1)], dim=-1).round()
        return base_anchors

    def _meshgrid(self, x, y, row_major=True):
        xx = x.repeat(len(y))
        yy = y.view(-1, 1).repeat(1, len(x)).view(-1)
        if row_major:
            return xx, yy
        else:
            return yy, xx

    def grid_anchors(self, featmap_size, stride=16, device='cuda'):
        base_anchors = self.base_anchors
        feat_h, feat_w = featmap_size
        shift_x = torch.arange(0, feat_w, device=device) * stride
        shift_y = torch.arange(0, feat_h, device=device) * stride
        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)
        shifts = torch.stack([shift_xx, shift_yy, shift_xx, shift_yy], dim=-1)
        shifts = shifts.type_as(base_anchors)
        all_anchors = base_anchors[None, :, :] + shifts[:, None, :]
        all_anchors = all_anchors.view(-1, 4)
        return all_anchors

    def valid_flags(self, featmap_size, valid_size, device='cuda'):
        feat_h, feat_w = featmap_size
        valid_h, valid_w = valid_size
        assert valid_h <= feat_h and valid_w <= feat_w
        valid_x = torch.zeros(feat_w, dtype=torch.uint8, device=device)
        valid_y = torch.zeros(feat_h, dtype=torch.uint8, device=device)
        valid_x[:valid_w] = 1
        valid_y[:valid_h] = 1
        valid_xx, valid_yy = self._meshgrid(valid_x, valid_y)
        valid = valid_xx & valid_yy
        valid = valid[:, None].expand(valid.size(0), self.num_base_anchors).contiguous().view(-1)
        return valid

