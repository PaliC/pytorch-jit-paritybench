import sys
_module = sys.modules[__name__]
del sys
conf = _module
md2ipynb = _module
mdinclude = _module
anomaly_detection = _module
benchmark_m4 = _module
evaluate_model = _module
example_binned_pareto = _module
gp_synthetic_example = _module
persist_model = _module
warm_start = _module
setup = _module
gluonts = _module
core = _module
_base = _module
component = _module
serde = _module
_dataclass = _module
_json = _module
_parse = _module
flat = _module
np = _module
pd = _module
settings = _module
dataset = _module
arrow = _module
dec = _module
enc = _module
file = _module
artificial = _module
ar_p = _module
recipe = _module
common = _module
field_names = _module
hierarchical = _module
jsonl = _module
loader = _module
multivariate_grouper = _module
pandas = _module
repository = _module
_airpassengers = _module
_artificial = _module
_ercot = _module
_ett_small = _module
_gp_copula_2019 = _module
_lstnet = _module
_m3 = _module
_m4 = _module
_m5 = _module
_tsf_datasets = _module
_tsf_reader = _module
_uber_tlc = _module
_util = _module
datasets = _module
schema = _module
translate = _module
split = _module
stat = _module
util = _module
env = _module
ev = _module
aggregations = _module
metrics = _module
stats = _module
ts_stats = _module
evaluation = _module
backtest = _module
exceptions = _module
ext = _module
hierarchicalforecast = _module
naive_2 = _module
_predictor = _module
prophet = _module
r_forecast = _module
_hierarchical_predictor = _module
_univariate_predictor = _module
rotbaum = _module
_estimator = _module
_model = _module
_preprocess = _module
_types = _module
statsforecast = _module
gluonts_tqdm = _module
itertools = _module
json = _module
maybe = _module
meta = _module
_version = _module
cli = _module
colors = _module
style = _module
model = _module
estimator = _module
forecast = _module
forecast_generator = _module
inputs = _module
npts = _module
_weighted_sampler = _module
predictor = _module
seasonal_agg = _module
seasonal_naive = _module
trivial = _module
constant = _module
identity = _module
mean = _module
mx = _module
activation = _module
batchify = _module
block = _module
cnn = _module
decoder = _module
dropout = _module
enc2dec = _module
encoder = _module
feature = _module
mlp = _module
quantile_output = _module
regularization = _module
rnn = _module
scaler = _module
sndense = _module
snmlp = _module
context = _module
distribution = _module
beta = _module
bijection = _module
bijection_output = _module
binned = _module
box_cox_transform = _module
categorical = _module
deterministic = _module
dirichlet = _module
dirichlet_multinomial = _module
distribution_output = _module
empirical_distribution = _module
gamma = _module
gaussian = _module
genpareto = _module
inflated_beta = _module
iresnet = _module
isqf = _module
laplace = _module
lds = _module
logit_normal = _module
lowrank_gp = _module
lowrank_multivariate_gaussian = _module
mixture = _module
multivariate_gaussian = _module
nan_mixture = _module
neg_binomial = _module
piecewise_linear = _module
poisson = _module
student_t = _module
transformed_distribution = _module
transformed_distribution_output = _module
uniform = _module
kernels = _module
_kernel = _module
_kernel_output = _module
_periodic_kernel = _module
_rbf_kernel = _module
linalg_util = _module
canonical = _module
_network = _module
RNNModel = _module
deep_factor = _module
deepar = _module
deepstate = _module
issm = _module
deepvar = _module
deepvar_hierarchical = _module
gp_forecaster = _module
gaussian_process = _module
gpvar = _module
lstnet = _module
n_beats = _module
_ensemble = _module
renewal = _module
_transform = _module
seq2seq = _module
_forking_estimator = _module
_forking_network = _module
_mq_dnn_estimator = _module
_seq2seq_estimator = _module
_seq2seq_network = _module
simple_feedforward = _module
tft = _module
_layers = _module
tpp = _module
deeptpp = _module
base = _module
loglogistic = _module
weibull = _module
transformer = _module
layers = _module
trans_decoder = _module
trans_encoder = _module
wavenet = _module
prelude = _module
representation = _module
binning_helpers = _module
custom_binning = _module
dim_expansion = _module
discrete_pit = _module
embedding = _module
global_relative_binning = _module
hybrid_representation = _module
local_absolute_binning = _module
mean_scaling = _module
representation_chain = _module
trainer = _module
callback = _module
learning_rate_scheduler = _module
model_averaging = _module
model_iteration_averaging = _module
algo_clustering = _module
electricity = _module
exchange_rate = _module
group_raw_data = _module
preprocess_data = _module
synthetic = _module
traffic = _module
ar = _module
ar_estimator = _module
ar_network = _module
lstm = _module
lstm_estimator = _module
lstm_network = _module
preprocess_data = _module
run = _module
Adagrad = _module
Adam = _module
SAdagrad = _module
SAdam = _module
SCSG = _module
SCott = _module
SGD = _module
trainers = _module
timer = _module
nursery = _module
filters = _module
supervised_metrics = _module
_buffered_precision_recall = _module
_precision_recall_utils = _module
_segment_precision_recall = _module
bounded_pr_auc = _module
utils = _module
auto_ode = _module
autogluon_tabular = _module
example = _module
quantile_example = _module
daf = _module
dataset = _module
engine = _module
parallel = _module
single = _module
domains = _module
hooks = _module
modules = _module
network = _module
block = _module
disc = _module
kernel = _module
tslib = _module
forecasting = _module
loader = _module
timeseries = _module
transform = _module
windows = _module
callback = _module
distributed = _module
evaluator = _module
hyperopt = _module
trainer = _module
dict = _module
meters = _module
metrics = _module
nn = _module
activations = _module
attention = _module
base = _module
interattn = _module
posemb = _module
selfattn = _module
distributions = _module
transformer = _module
utils = _module
callbacks = _module
count = _module
metric = _module
plot = _module
save = _module
common = _module
data = _module
batch = _module
dataset = _module
sampling = _module
artificial = _module
cheat = _module
dominick = _module
gluonts = _module
m1 = _module
m3 = _module
m4 = _module
preprocessing = _module
registry = _module
splits = _module
crps = _module
nd = _module
numpy = _module
quantile = _module
quantile_width = _module
EcDc = _module
components = _module
attention = _module
decoder = _module
feature = _module
query = _module
supps = _module
tcn = _module
meta = _module
series = _module
models = _module
common = _module
model = _module
module = _module
registry = _module
vis = _module
data = _module
train = _module
glide = _module
_partition = _module
pipeline = _module
sequential = _module
gmm_base = _module
simulation = _module
action = _module
attack_and_save = _module
attack_var = _module
attack_sparse_layer = _module
eval = _module
eval_sparse = _module
grouper = _module
pts = _module
loader = _module
implicit_quantile = _module
piecewise_linear = _module
zero_inflated = _module
fourier_date_feature = _module
holiday = _module
lags = _module
causal_deepar = _module
causal_deepar_estimator = _module
causal_deepar_network = _module
deepar_estimator = _module
deepar_network = _module
deepvar_estimator = _module
deepvar_network = _module
estimator = _module
lstnet_estimator = _module
lstnet_network = _module
n_beats_ensemble = _module
n_beats_estimator = _module
n_beats_network = _module
simple_feedforward_estimator = _module
simple_feedforward_network = _module
tempflow = _module
tempflow_estimator = _module
tempflow_network = _module
tft_estimator = _module
tft_modules = _module
tft_network = _module
tft_output = _module
tft_transform = _module
time_grad = _module
epsilon_theta = _module
time_grad_estimator = _module
time_grad_network = _module
transformer_estimator = _module
transformer_network = _module
transformer_tempflow = _module
transformer_tempflow_estimator = _module
transformer_tempflow_network = _module
utils = _module
distribution_output = _module
feature = _module
flows = _module
gaussian_diffusion = _module
iqn_modules = _module
scaler = _module
trainer = _module
read_pickle = _module
sparse_layer = _module
train = _module
train_adv = _module
utils = _module
sagemaker_sdk = _module
defaults = _module
run_entry_point = _module
train_entry_point = _module
san = _module
spliced_binned_pareto = _module
data_functions = _module
distr_tcn = _module
gaussian_model = _module
genpareto = _module
spliced_binned_pareto = _module
tcn = _module
training_functions = _module
temporal_hierarchical_forecasting = _module
cop_deepar = _module
gluonts_fixes = _module
gnn = _module
train_and_eval_cop_deepar = _module
gluonts_helper = _module
_main = _module
analysis = _module
ensemble = _module
ensemble_recommender = _module
recommender = _module
ensemble = _module
ensemble_recommender = _module
recommender = _module
surrogate = _module
compute_catch22 = _module
compute_stats = _module
download = _module
upload = _module
ensembles = _module
simulate = _module
evaluations = _module
archive = _module
schedule = _module
config = _module
subprocess = _module
evaluate = _module
tsbench = _module
analyzer = _module
tracking = _module
client = _module
experiment = _module
loocv = _module
misc = _module
mo_metrics = _module
multiprocessing = _module
ranks = _module
_factory = _module
sources = _module
constants = _module
aws = _module
analytics = _module
ecr = _module
framework = _module
s3 = _module
session = _module
performance = _module
sagemaker = _module
_evaluations = _module
_info = _module
job = _module
training = _module
fit = _module
logging = _module
forecasts = _module
ensembling = _module
owa = _module
prediction = _module
learning_rate = _module
_recommendation = _module
generator = _module
replay = _module
greedy = _module
optimal = _module
pareto = _module
surrogate = _module
autogluon = _module
deepset = _module
mlp = _module
nonparametric = _module
random = _module
random_forest = _module
deepset = _module
deepset_lightning_module = _module
losses = _module
mlp_lightning_module = _module
transformers = _module
xgboost = _module
filesystem = _module
latex = _module
scatterplot = _module
pydantic = _module
shell = _module
dyn = _module
nested_params = _module
params = _module
serve = _module
app = _module
testutil = _module
dummy_datasets = _module
equality = _module
time_feature = _module
lag = _module
seasonality = _module
batchify = _module
component = _module
affine_transformed = _module
binned_uniforms = _module
discrete_distribution = _module
distribution_output = _module
generalized_pareto = _module
implicit_quantile_network = _module
isqf = _module
negative_binomial = _module
output = _module
piecewise_linear = _module
quantile_output = _module
spliced_binned_pareto = _module
studentT = _module
truncated_normal = _module
d_linear = _module
estimator = _module
lightning_module = _module
module = _module
deep_npts = _module
_estimator = _module
_network = _module
scaling = _module
estimator = _module
lightning_module = _module
module = _module
estimator = _module
forecast = _module
forecast_generator = _module
i_transformer = _module
estimator = _module
lightning_module = _module
module = _module
lag_tst = _module
estimator = _module
lightning_module = _module
module = _module
lightning_util = _module
mqf2 = _module
distribution = _module
estimator = _module
icnn_utils = _module
lightning_module = _module
module = _module
patch_tst = _module
estimator = _module
lightning_module = _module
module = _module
predictor = _module
estimator = _module
lightning_module = _module
module = _module
estimator = _module
layers = _module
lightning_module = _module
module = _module
tide = _module
estimator = _module
lightning_module = _module
module = _module
estimator = _module
lightning_module = _module
module = _module
feature = _module
lambda_layer = _module
lookup_table = _module
scaler = _module
util = _module
convert = _module
field = _module
sampler = _module
zebras = _module
_freq = _module
_period = _module
_repr = _module
_split_frame = _module
_time_frame = _module
_time_series = _module
test = _module
conftest = _module
test_component = _module
test_serde = _module
test_serde_dataclass = _module
test_serde_flat = _module
test_settings = _module
test_complex_seasonal = _module
test_recipe = _module
test_util = _module
test_translate = _module
test_arrow = _module
test_common = _module
test_data_loader = _module
test_dataset_mutability = _module
test_dataset_types = _module
test_fieldnames = _module
test_hierarchical = _module
test_jsonl = _module
test_multivariate_grouper = _module
test_pandas = _module
test_split = _module
test_stat = _module
test_train_test_data_leakage = _module
test_tsf_reader = _module
test_writer = _module
test_aggregations = _module
test_metrics = _module
test_metrics_compared_to_previous_approach = _module
test_stats = _module
test_backtest_tools = _module
test_evaluator = _module
test_predictor = _module
test_predictors = _module
test_r_code_compliance_of_naive_2 = _module
test_prophet = _module
test_r_hierarchical_predictor = _module
test_r_multi_seasonality = _module
test_r_univariate_predictor = _module
test_r_util = _module
test_model = _module
test_rotbaum_smoke = _module
test_statsforecast = _module
test_npts = _module
test_seasonal_agg = _module
test_seasonal_naive = _module
test_evaluation = _module
test_forecast = _module
test_moving_average = _module
test_activations = _module
test_feature = _module
test_quantile_loss = _module
test_regularization = _module
test_scaler = _module
test_default_quantile_method = _module
test_distribution_methods = _module
test_distribution_output_serde = _module
test_distribution_output_shapes = _module
test_distribution_sampling = _module
test_distribution_shapes = _module
test_distribution_slice = _module
test_flows = _module
test_inflated_beta = _module
test_isqf = _module
test_issue_287 = _module
test_label_smoothing = _module
test_lds = _module
test_mixture = _module
test_mx_distribution_inference = _module
test_nan_mixture = _module
test_piecewise_linear = _module
test_transformed_distribution = _module
test_periodic_kernel = _module
test_rbf_kernel = _module
test_deepar_auxiliary_outputs = _module
test_deepar_lags = _module
test_deepar_smoke = _module
test_nonnegative_pred_samples = _module
test_deepstate_smoke = _module
test_issm = _module
test_using_tsf_dataset = _module
test_deepvar = _module
generate_hierarchical_dataset = _module
test_coherency_error = _module
test_deepvar_hierarchical = _module
test_projection = _module
test_reconcile_samples = _module
test_train_prediction_with_hts = _module
test_inference = _module
test_gpvar = _module
test_lstnet = _module
test_cnn = _module
test_encoders = _module
test_forking_sequence_splitter = _module
test_mx_incremental_training = _module
test_deeptpp = _module
test_tpp_predictor = _module
test_bin = _module
test_grb = _module
test_hyb = _module
test_lab = _module
test_mean = _module
test_rep = _module
test_distribution_forecast = _module
test_jitter = _module
test_mx_item_id_info = _module
test_mx_serde = _module
test_mx_util = _module
test_no_batches = _module
test_transform_equals = _module
test_variable_length = _module
test_callbacks = _module
test_learning_rate_scheduler = _module
test_model_averaging = _module
test_model_iteration_averaging = _module
test_trainer = _module
test_filters = _module
test_precision_recall = _module
test_autogluon_tabular = _module
test_entry_point_scripts = _module
test_axiv_paper_examples = _module
test_nested_params = _module
test_shell = _module
test_itertools = _module
test_json = _module
test_sanity = _module
test_agg_lags = _module
test_base = _module
test_features = _module
test_holiday = _module
test_lag = _module
test_seasonality = _module
test_affine_transformed = _module
test_discrete_distribution = _module
test_negative_binomial = _module
test_studentt = _module
test_torch_isqf = _module
test_torch_piecewise_linear = _module
test_truncated_normal = _module
test_deepar_modules = _module
test_deepar_nonnegative_pred_samples = _module
test_estimators = _module
test_jit = _module
test_modules = _module
test_mqf2_modules = _module
test_multivariate_estimators = _module
test_on_gpu = _module
test_tft = _module
test_torch_forecast = _module
test_torch_incremental_training = _module
test_torch_predictor = _module
test_torch_distribution_inference = _module
test_scaler = _module
test_torch_item_id_info = _module
test_torch_util = _module
test_add_time_features = _module
test_transform = _module
test_batch = _module
test_from_pandas = _module
test_period = _module
test_schema = _module
test_timeframe = _module

from _paritybench_helpers import _mock_config, patch_functional
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
import abc, collections, copy, enum, functools, inspect, itertools, logging, math, matplotlib, numbers, numpy, pandas, queue, random, re, scipy, sklearn, string, tensorflow, time, torch, torchaudio, torchvision, types, typing, uuid, warnings
import operator as op
from dataclasses import dataclass
import numpy as np
from torch import Tensor
patch_functional()
open = mock_open()
yaml = logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
yaml.load.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'
xrange = range
wraps = functools.wraps


import torch


import numpy as np


from matplotlib import pyplot as plt


from typing import Dict


from typing import List


from typing import Optional


from typing import Tuple


import math


import pandas as pd


import random


import time


import torch.nn as nn


from torch.utils.tensorboard import SummaryWriter


import copy


from copy import deepcopy


import torch as pt


from typing import Union


from itertools import product


from torch.utils.data import Dataset as TorchDataset


from torch import Tensor


from typing import Callable


from functools import partial


from itertools import chain


from torch import BoolTensor


from torch.utils.data import Dataset


from torch.optim import AdamW


from typing import Iterator


from collections import defaultdict


import warnings


from torch import LongTensor


from torch import nn


from torch.nn import Parameter


from torch.nn import functional as F


from typing import TYPE_CHECKING


from torch.nn import init


from typing import NamedTuple


import re


from torch.utils.data import DataLoader


from torch.utils.data import DistributedSampler


from typing import Sequence


from typing import overload


from sklearn.preprocessing import LabelEncoder


from sklearn.preprocessing import StandardScaler


from numpy import ndarray


from typing import Any


from itertools import repeat


from torch.nn.utils import clip_grad_norm_


from torch import distributed as dist


from typing import Iterable


from collections import OrderedDict


from functools import reduce


from torch.nn.parallel import DistributedDataParallel


from abc import ABC


from abc import abstractmethod


from torch.nn.functional import l1_loss


from torch.nn.functional import mse_loss


from torch.distributions import Distribution


from torch.distributions import Normal as Gaussian


from torch.nn.functional import linear


from torch.nn.functional import conv1d


from collections import deque


from torch.nn.utils.rnn import pad_sequence


from torch.utils.data import IterableDataset


from typing import Literal


from sklearn.gaussian_process import GaussianProcessRegressor


from sklearn.gaussian_process.kernels import RBF


from torch.utils.data import ConcatDataset


from functools import cached_property


from sklearn.neighbors import NearestNeighbors


import numpy.ma as ma


from itertools import cycle


import torch.nn.functional as F


from torch.nn.utils.rnn import pack_padded_sequence


from torch.nn.utils.rnn import pad_packed_sequence


import torch.optim as optim


from torch.optim.lr_scheduler import ReduceLROnPlateau


from typing import Type


from typing import TypeVar


import itertools


import matplotlib.pyplot as plt


from typing import cast


from torch.distributions import TransformedDistribution


from torch.distributions import AffineTransform


from torch.distributions import constraints


from torch.distributions import NegativeBinomial


from torch.distributions import Poisson


from torch.distributions.utils import broadcast_all


from torch.distributions.utils import lazy_property


from matplotlib.pyplot import sca


from torch.distributions import Beta


from torch.distributions import Gamma


from torch.distributions import Normal


from torch.distributions import StudentT


from torch.utils import data


from torch.nn.modules import loss


import inspect


from abc import abstractclassmethod


from torch.distributions import Categorical


from torch.distributions import MixtureSameFamily


from torch.distributions import Independent


from torch.distributions import LowRankMultivariateNormal


from torch.distributions import MultivariateNormal


from inspect import isfunction


from torch import einsum


from math import pi


from torch import nn as nn


from torch.optim import Adam


from torch.optim.lr_scheduler import OneCycleLR


import torch.distributions


from scipy import stats


import torch.nn


from torch.distributions.normal import Normal


from numbers import Number


from torch.distributions.distribution import Distribution


import torch.optim


import matplotlib


import logging


import numpy.typing as npt


from torch.utils.data import TensorDataset


from torch import optim


from torch.distributions import Laplace


from torch.distributions import NegativeBinomial as TorchNegativeBinomial


from scipy.stats import nbinom


from scipy.stats import t as ScipyStudentT


from torch.distributions import StudentT as TorchStudentT


from torch.distributions import Uniform


from itertools import islice


from scipy.special import softmax


from torch.optim import SGD


class ARNetworkBase(nn.Module):

    def __init__(self, prediction_length: 'int', context_length: 'int') ->None:
        super().__init__()
        self.prediction_length = prediction_length
        self.context_length = context_length
        self.criterion = nn.SmoothL1Loss(reduction='none')
        modules = []
        modules.append(nn.Linear(context_length, prediction_length))
        self.linear = nn.Sequential(*modules)


class ARTrainingNetwork(ARNetworkBase):

    def forward(self, past_target: 'torch.Tensor', future_target: 'torch.Tensor') ->torch.Tensor:
        nu = min(torch.mean(past_target).item(), torch.mean(future_target).item())
        past_target /= 1 + nu
        future_target /= 1 + nu
        prediction = self.linear(past_target)
        loss = self.criterion(prediction, future_target)
        return loss


class ARPredictionNetwork(ARNetworkBase):

    def __init__(self, num_parallel_samples: 'int'=100, *args, **kwargs) ->None:
        super().__init__(*args, **kwargs)
        self.num_parallel_samples = num_parallel_samples

    def forward(self, past_target: 'torch.Tensor') ->torch.Tensor:
        pass


class LSTMNetworkBase(nn.Module):

    def __init__(self, prediction_length: 'int', context_length: 'int', input_size: 'int'=1, hidden_layer_size: 'int'=100, num_layers: 'int'=2) ->None:
        super().__init__()
        self.prediction_length = prediction_length
        self.context_length = context_length
        self.criterion = nn.SmoothL1Loss(reduction='none')
        self.hidden_layer_size = hidden_layer_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers)
        self.linear = nn.Linear(hidden_layer_size, prediction_length)


class LSTMTrainingNetwork(LSTMNetworkBase):

    def forward(self, past_target: 'torch.Tensor', future_target: 'torch.Tensor') ->torch.Tensor:
        nu = min(torch.mean(past_target).item(), torch.mean(future_target).item())
        past_target /= 1 + nu
        future_target /= 1 + nu
        inputs = past_target.view(past_target.shape[1], past_target.shape[0], 1)
        lstm_out, _ = self.lstm(inputs)
        prediction = self.linear(lstm_out)
        loss = self.criterion(prediction[-1], future_target)
        return loss


class LSTMPredictionNetwork(LSTMNetworkBase):

    def __init__(self, num_parallel_samples: 'int'=100, *args, **kwargs) ->None:
        super().__init__(*args, **kwargs)
        self.num_parallel_samples = num_parallel_samples

    def forward(self, past_target: 'torch.Tensor') ->torch.Tensor:
        pass


class DomAdaptEstimator(nn.Module):

    def __init__(self, src_module: 'AttentionEstimator', tgt_module: 'AttentionEstimator', balance_loss: 'bool'=True, forecast_target: 'bool'=True) ->None:
        super(DomAdaptEstimator, self).__init__()
        self.src = src_module
        self.tgt = tgt_module
        self.balance_loss = balance_loss
        self.forecast_target = forecast_target

    def forward(self, src_data: 'Tensor', tgt_data: 'Tensor', src_feats: 'Optional[Tensor]'=None, tgt_feats: 'Optional[Tensor]'=None, src_nan_mask: 'Optional[BoolTensor]'=None, tgt_nan_mask: 'Optional[BoolTensor]'=None, src_length: 'Optional[LongTensor]'=None, tgt_length: 'Optional[LongTensor]'=None) ->Tensor:
        src_loss = self.src(src_data, src_feats, src_nan_mask, src_length)
        tgt_loss = self.tgt(tgt_data, tgt_feats, tgt_nan_mask, tgt_length)
        if not self.forecast_target:
            tgt_loss = tgt_loss - self.tgt.tradeoff * self.tgt.fc_loss
        if self.balance_loss:
            src_scale = self.src._normalizer._buffers['scale']
            tgt_scale = self.tgt._normalizer._buffers['scale']
            src_scale = src_scale.view(src_scale.size(0), -1)
            tgt_scale = tgt_scale.view(tgt_scale.size(0), -1)
            weight = pt.mean(tgt_scale / src_scale, dim=1)
            src_loss = src_loss * weight
        loss = src_loss + tgt_loss
        return loss


class AdversarialDomAdaptEstimator(DomAdaptEstimator):

    def __init__(self, src_module: 'AdversarialEstimator', tgt_module: 'AdversarialEstimator', balance_loss: 'bool'=True, forecast_target: 'bool'=True, disc_lambda: 'float'=1.0) ->None:
        super(AdversarialDomAdaptEstimator, self).__init__(src_module, tgt_module, balance_loss, forecast_target)
        self.disc_lambda = disc_lambda
        self._generative = True

    def generative(self):
        self._generative = True
        self.src.generative()
        self.tgt.generative()

    def discriminative(self):
        self._generative = False
        self.src.discriminative()
        self.tgt.discriminative()

    def forward(self, src_data: 'Tensor', tgt_data: 'Tensor', src_feats: 'Optional[Tensor]'=None, tgt_feats: 'Optional[Tensor]'=None, src_nan_mask: 'Optional[BoolTensor]'=None, tgt_nan_mask: 'Optional[BoolTensor]'=None, src_length: 'Optional[LongTensor]'=None, tgt_length: 'Optional[LongTensor]'=None) ->Tensor:
        gen_loss = super(AdversarialDomAdaptEstimator, self).forward(src_data, tgt_data, src_feats, tgt_feats, src_nan_mask, tgt_nan_mask, src_length, tgt_length)
        batch_size = gen_loss.size(0)
        src_prob_domain = self.src.prob_domain.view(batch_size, -1)
        tgt_prob_domain = self.tgt.prob_domain.view(batch_size, -1)
        adv_type = 'grad_rev'
        disc_loss = -src_prob_domain.mean(dim=1) - pt.log(1.0 - tgt_prob_domain.exp() + 1e-10).mean(dim=1)
        if self._generative:
            if adv_type == 'grad_rev':
                loss = gen_loss - self.disc_lambda * disc_loss
            elif adv_type == 'label_inv':
                invert_tgt_loss = -tgt_prob_domain.mean(dim=1)
                loss = gen_loss - self.disc_lambda * invert_tgt_loss
        else:
            loss = disc_loss
        return loss


class AttentionBlock(nn.Module):

    def __init__(self, encoder: 'EncoderModule', kernel: 'AttentionKernel', decoder: 'DecoderModule') ->None:
        super(AttentionBlock, self).__init__()
        self.encoder = encoder
        self.kernel = kernel
        self.decoder = decoder
        self.window_size = max(self.encoder.window_size)
        self.register_buffer('shape', None, persistent=False)
        self.register_buffer('query', None, persistent=False)
        self.register_buffer('key', None, persistent=False)
        self.register_buffer('inter_score', None, persistent=False)
        self.register_buffer('extra_score', None, persistent=False)
        self.register_buffer('inter_value', None, persistent=False)
        self.register_buffer('extra_value', None, persistent=False)

    def forward(self, data: 'Tensor', feats: 'Optional[Tensor]', mask: 'Optional[BoolTensor]') ->Tuple[Tensor, Tensor]:
        shape, inter_value, extra_value = self.encoder(data, feats)
        self.shape = shape.detach()
        self.inter_value = inter_value.detach()
        self.extra_value = extra_value.detach()
        interp, extrap = self.kernel(shape, inter_value, extra_value, mask)
        self.query = self.kernel._query
        self.key = self.kernel._key
        self.inter_score = self.kernel._inter_score
        self.extra_score = self.kernel._extra_score
        interp = self.decoder(interp)
        extrap = self.decoder(extrap)
        return interp, extrap


class DecoderModule(nn.Module):

    def __init__(self, d_data: 'int', d_hidden: 'int') ->None:
        super(DecoderModule, self).__init__()
        self.d_data = d_data
        self.d_hidden = d_hidden
        self.weight = nn.Parameter(Tensor(self.d_data, self.d_hidden))
        self.bias = nn.Parameter(Tensor(d_data))
        self._reset_parameters()

    def _reset_parameters(self):
        init.xavier_uniform_(self.weight)
        init.zeros_(self.bias)

    def forward(self, data: 'Tensor'):
        return F.linear(data, self.weight, self.bias)


T = TypeVar('T')


U = TypeVar('U')


R = TypeVar('R')

