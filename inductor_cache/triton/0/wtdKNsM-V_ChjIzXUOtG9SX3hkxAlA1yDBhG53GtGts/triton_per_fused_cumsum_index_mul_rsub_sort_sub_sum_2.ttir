#loc = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0)
#loc1 = loc(unknown)
#loc19 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":610:12)
#loc20 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":47:71)
#loc25 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":582:73)
#loc30 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:51)
#loc35 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:53)
#loc45 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:50)
#loc50 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:51)
#loc82 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":56:26)
#loc106 = loc(callsite(#loc1 at #loc30))
#loc112 = loc(callsite(#loc1 at #loc35))
#loc123 = loc(callsite(#loc1 at #loc45))
#loc129 = loc(callsite(#loc1 at #loc50))
#loc146 = loc(callsite(#loc1 at #loc82))
#loc158 = loc(callsite(#loc106 at #loc25))
#loc164 = loc(callsite(#loc112 at #loc25))
#loc176 = loc(callsite(#loc123 at #loc25))
#loc183 = loc(callsite(#loc129 at #loc25))
#loc206 = loc(callsite(#loc158 at #loc19))
#loc212 = loc(callsite(#loc164 at #loc19))
#loc224 = loc(callsite(#loc176 at #loc19))
#loc231 = loc(callsite(#loc183 at #loc19))
#loc249 = loc(callsite(#loc206 at #loc20))
#loc252 = loc(callsite(#loc212 at #loc20))
#loc255 = loc(callsite(#loc224 at #loc20))
#loc258 = loc(callsite(#loc231 at #loc20))
module {
  tt.func public @triton_per_fused_cumsum_index_mul_rsub_sort_sub_sum_2(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0), %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0), %arg3: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0), %arg4: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0), %arg5: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0), %arg6: i32 {tt.divisibility = 16 : i32} loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":24:0)) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %cst = arith.constant dense<0> : tensor<1x64xi16> loc(#loc1)
    %cst_0 = arith.constant dense<0> : tensor<1x64xi32> loc(#loc1)
    %cst_1 = arith.constant dense<1> : tensor<1x2x1xi32> loc(#loc1)
    %cst_2 = arith.constant dense<0> : tensor<1x64xi64> loc(#loc1)
    %cst_3 = arith.constant dense<64> : tensor<1x64xi64> loc(#loc1)
    %cst_4 = arith.constant dense<4> : tensor<1x64xi64> loc(#loc1)
    %cst_5 = arith.constant dense<16> : tensor<1x64xi64> loc(#loc1)
    %cst_6 = arith.constant dense<1.000000e+00> : tensor<1x64xf32> loc(#loc1)
    %cst_7 = arith.constant dense<2.000000e+00> : tensor<1x64xf32> loc(#loc1)
    %cst_8 = arith.constant dense<64> : tensor<1x64xi32> loc(#loc1)
    %cst_9 = arith.constant dense<16> : tensor<1x64xi32> loc(#loc1)
    %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32> loc(#loc2)
    %1 = tt.expand_dims %0 {axis = 0 : i32} : tensor<64xi32> -> tensor<1x64xi32> loc(#loc3)
    %2 = arith.divsi %1, %cst_9 : tensor<1x64xi32> loc(#loc4)
    %3 = arith.muli %2, %cst_8 : tensor<1x64xi32> loc(#loc5)
    %4 = arith.addi %3, %cst_9 : tensor<1x64xi32> loc(#loc6)
    %5 = arith.remsi %1, %cst_9 : tensor<1x64xi32> loc(#loc7)
    %6 = arith.addi %4, %5 : tensor<1x64xi32> loc(#loc8)
    %7 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>> loc(#loc9)
    %8 = tt.addptr %7, %6 : tensor<1x64x!tt.ptr<f32>>, tensor<1x64xi32> loc(#loc9)
    %9 = tt.load %8 : tensor<1x64x!tt.ptr<f32>> loc(#loc10)
    %10 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>> loc(#loc11)
    %11 = tt.addptr %10, %6 : tensor<1x64x!tt.ptr<f32>>, tensor<1x64xi32> loc(#loc11)
    %12 = tt.load %11 : tensor<1x64x!tt.ptr<f32>> loc(#loc12)
    %13 = arith.mulf %12, %cst_7 : tensor<1x64xf32> loc(#loc13)
    %14 = arith.subf %13, %cst_6 : tensor<1x64xf32> loc(#loc14)
    %15 = arith.mulf %9, %14 : tensor<1x64xf32> loc(#loc15)
    %16 = arith.subf %cst_6, %15 : tensor<1x64xf32> loc(#loc16)
    %17 = arith.trunci %1 : tensor<1x64xi32> to tensor<1x64xi16> loc(#loc17)
    %18 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32> loc(#loc149)
    %19 = tt.expand_dims %18 {axis = 0 : i32} : tensor<2xi32> -> tensor<1x2xi32> loc(#loc150)
    %20 = tt.expand_dims %19 {axis = 2 : i32} : tensor<1x2xi32> -> tensor<1x2x1xi32> loc(#loc150)
    %21 = tt.broadcast %20 : tensor<1x2x1xi32> -> tensor<16x2x2xi32> loc(#loc151)
    %22 = tt.reshape %21 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc152)
    %23 = tt.reshape %16 : tensor<1x64xf32> -> tensor<32x2x1xf32> loc(#loc201)
    %24 = tt.bitcast %23 : tensor<32x2x1xf32> -> tensor<32x2x1xi32> loc(#loc202)
    %25 = arith.subi %cst_1, %20 : tensor<1x2x1xi32> loc(#loc203)
    %26 = tt.broadcast %25 : tensor<1x2x1xi32> -> tensor<32x2x1xi32> loc(#loc204)
    %27 = arith.muli %24, %26 : tensor<32x2x1xi32> loc(#loc204)
    %28 = "tt.reduce"(%27) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc248)
    %29 = tt.expand_dims %28 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc208)
    %30 = tt.broadcast %29 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc209)
    %31 = tt.broadcast %20 : tensor<1x2x1xi32> -> tensor<32x2x1xi32> loc(#loc210)
    %32 = arith.muli %24, %31 : tensor<32x2x1xi32> loc(#loc210)
    %33 = "tt.reduce"(%32) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc251)
    %34 = tt.expand_dims %33 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc214)
    %35 = tt.broadcast %34 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc215)
    %36 = tt.reshape %30 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc216)
    %37 = tt.reshape %35 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc217)
    %38 = tt.bitcast %36 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %39 = tt.bitcast %37 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %40 = tt.reshape %17 : tensor<1x64xi16> -> tensor<32x2x1xi16> loc(#loc220)
    %41 = arith.trunci %25 : tensor<1x2x1xi32> to tensor<1x2x1xi16> loc(#loc221)
    %42 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<32x2x1xi16> loc(#loc222)
    %43 = arith.muli %40, %42 : tensor<32x2x1xi16> loc(#loc222)
    %44 = "tt.reduce"(%43) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc254)
    %45 = tt.expand_dims %44 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc226)
    %46 = tt.broadcast %45 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc227)
    %47 = arith.trunci %20 : tensor<1x2x1xi32> to tensor<1x2x1xi16> loc(#loc228)
    %48 = tt.broadcast %47 : tensor<1x2x1xi16> -> tensor<32x2x1xi16> loc(#loc229)
    %49 = arith.muli %40, %48 : tensor<32x2x1xi16> loc(#loc229)
    %50 = "tt.reduce"(%49) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc257)
    %51 = tt.expand_dims %50 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc233)
    %52 = tt.broadcast %51 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc234)
    %53 = tt.reshape %46 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc235)
    %54 = tt.reshape %52 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc236)
    %55 = tt.bitcast %16 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %56 = arith.cmpf olt, %38, %39 : tensor<1x64xf32> loc(#loc238)
    %57 = arith.extui %56 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %58 = arith.xori %57, %22 : tensor<1x64xi32> loc(#loc239)
    %59 = arith.cmpi ne, %58, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %60 = arith.xori %36, %37 : tensor<1x64xi32> loc(#loc241)
    %61 = arith.select %59, %60, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %62 = arith.xori %55, %61 : tensor<1x64xi32> loc(#loc243)
    %63 = arith.xori %53, %54 : tensor<1x64xi16> loc(#loc244)
    %64 = arith.select %59, %63, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %65 = arith.xori %17, %64 : tensor<1x64xi16> loc(#loc246)
    %66 = tt.bitcast %62 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %67 = tt.broadcast %20 : tensor<1x2x1xi32> -> tensor<8x2x4xi32> loc(#loc151)
    %68 = tt.reshape %67 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc152)
    %69 = tt.reshape %66 : tensor<1x64xf32> -> tensor<16x2x2xf32> loc(#loc201)
    %70 = tt.bitcast %69 : tensor<16x2x2xf32> -> tensor<16x2x2xi32> loc(#loc202)
    %71 = tt.broadcast %25 : tensor<1x2x1xi32> -> tensor<16x2x2xi32> loc(#loc204)
    %72 = arith.muli %70, %71 : tensor<16x2x2xi32> loc(#loc204)
    %73 = "tt.reduce"(%72) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc248)
    %74 = tt.expand_dims %73 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc208)
    %75 = tt.broadcast %74 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc209)
    %76 = arith.muli %70, %21 : tensor<16x2x2xi32> loc(#loc210)
    %77 = "tt.reduce"(%76) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc251)
    %78 = tt.expand_dims %77 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc214)
    %79 = tt.broadcast %78 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc215)
    %80 = tt.reshape %75 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc216)
    %81 = tt.reshape %79 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc217)
    %82 = tt.bitcast %80 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %83 = tt.bitcast %81 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %84 = tt.reshape %65 : tensor<1x64xi16> -> tensor<16x2x2xi16> loc(#loc220)
    %85 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<16x2x2xi16> loc(#loc222)
    %86 = arith.muli %84, %85 : tensor<16x2x2xi16> loc(#loc222)
    %87 = "tt.reduce"(%86) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc254)
    %88 = tt.expand_dims %87 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc226)
    %89 = tt.broadcast %88 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc227)
    %90 = tt.broadcast %47 : tensor<1x2x1xi16> -> tensor<16x2x2xi16> loc(#loc229)
    %91 = arith.muli %84, %90 : tensor<16x2x2xi16> loc(#loc229)
    %92 = "tt.reduce"(%91) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc257)
    %93 = tt.expand_dims %92 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc233)
    %94 = tt.broadcast %93 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc234)
    %95 = tt.reshape %89 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc235)
    %96 = tt.reshape %94 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc236)
    %97 = tt.bitcast %66 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %98 = arith.cmpf olt, %82, %83 : tensor<1x64xf32> loc(#loc238)
    %99 = arith.extui %98 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %100 = arith.xori %99, %68 : tensor<1x64xi32> loc(#loc239)
    %101 = arith.cmpi ne, %100, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %102 = arith.xori %80, %81 : tensor<1x64xi32> loc(#loc241)
    %103 = arith.select %101, %102, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %104 = arith.xori %97, %103 : tensor<1x64xi32> loc(#loc243)
    %105 = arith.xori %95, %96 : tensor<1x64xi16> loc(#loc244)
    %106 = arith.select %101, %105, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %107 = arith.xori %65, %106 : tensor<1x64xi16> loc(#loc246)
    %108 = tt.bitcast %104 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %109 = tt.reshape %108 : tensor<1x64xf32> -> tensor<32x2x1xf32> loc(#loc201)
    %110 = tt.bitcast %109 : tensor<32x2x1xf32> -> tensor<32x2x1xi32> loc(#loc202)
    %111 = arith.muli %110, %26 : tensor<32x2x1xi32> loc(#loc204)
    %112 = "tt.reduce"(%111) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc248)
    %113 = tt.expand_dims %112 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc208)
    %114 = tt.broadcast %113 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc209)
    %115 = arith.muli %110, %31 : tensor<32x2x1xi32> loc(#loc210)
    %116 = "tt.reduce"(%115) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc251)
    %117 = tt.expand_dims %116 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc214)
    %118 = tt.broadcast %117 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc215)
    %119 = tt.reshape %114 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc216)
    %120 = tt.reshape %118 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc217)
    %121 = tt.bitcast %119 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %122 = tt.bitcast %120 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %123 = tt.reshape %107 : tensor<1x64xi16> -> tensor<32x2x1xi16> loc(#loc220)
    %124 = arith.muli %123, %42 : tensor<32x2x1xi16> loc(#loc222)
    %125 = "tt.reduce"(%124) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc254)
    %126 = tt.expand_dims %125 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc226)
    %127 = tt.broadcast %126 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc227)
    %128 = arith.muli %123, %48 : tensor<32x2x1xi16> loc(#loc229)
    %129 = "tt.reduce"(%128) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc257)
    %130 = tt.expand_dims %129 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc233)
    %131 = tt.broadcast %130 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc234)
    %132 = tt.reshape %127 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc235)
    %133 = tt.reshape %131 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc236)
    %134 = tt.bitcast %108 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %135 = arith.cmpf olt, %121, %122 : tensor<1x64xf32> loc(#loc238)
    %136 = arith.extui %135 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %137 = arith.xori %136, %68 : tensor<1x64xi32> loc(#loc239)
    %138 = arith.cmpi ne, %137, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %139 = arith.xori %119, %120 : tensor<1x64xi32> loc(#loc241)
    %140 = arith.select %138, %139, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %141 = arith.xori %134, %140 : tensor<1x64xi32> loc(#loc243)
    %142 = arith.xori %132, %133 : tensor<1x64xi16> loc(#loc244)
    %143 = arith.select %138, %142, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %144 = arith.xori %107, %143 : tensor<1x64xi16> loc(#loc246)
    %145 = tt.bitcast %141 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %146 = tt.broadcast %20 : tensor<1x2x1xi32> -> tensor<4x2x8xi32> loc(#loc151)
    %147 = tt.reshape %146 : tensor<4x2x8xi32> -> tensor<1x64xi32> loc(#loc152)
    %148 = tt.reshape %145 : tensor<1x64xf32> -> tensor<8x2x4xf32> loc(#loc201)
    %149 = tt.bitcast %148 : tensor<8x2x4xf32> -> tensor<8x2x4xi32> loc(#loc202)
    %150 = tt.broadcast %25 : tensor<1x2x1xi32> -> tensor<8x2x4xi32> loc(#loc204)
    %151 = arith.muli %149, %150 : tensor<8x2x4xi32> loc(#loc204)
    %152 = "tt.reduce"(%151) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc248)
    %153 = tt.expand_dims %152 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc208)
    %154 = tt.broadcast %153 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc209)
    %155 = arith.muli %149, %67 : tensor<8x2x4xi32> loc(#loc210)
    %156 = "tt.reduce"(%155) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc251)
    %157 = tt.expand_dims %156 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc214)
    %158 = tt.broadcast %157 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc215)
    %159 = tt.reshape %154 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc216)
    %160 = tt.reshape %158 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc217)
    %161 = tt.bitcast %159 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %162 = tt.bitcast %160 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %163 = tt.reshape %144 : tensor<1x64xi16> -> tensor<8x2x4xi16> loc(#loc220)
    %164 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<8x2x4xi16> loc(#loc222)
    %165 = arith.muli %163, %164 : tensor<8x2x4xi16> loc(#loc222)
    %166 = "tt.reduce"(%165) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc254)
    %167 = tt.expand_dims %166 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc226)
    %168 = tt.broadcast %167 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc227)
    %169 = tt.broadcast %47 : tensor<1x2x1xi16> -> tensor<8x2x4xi16> loc(#loc229)
    %170 = arith.muli %163, %169 : tensor<8x2x4xi16> loc(#loc229)
    %171 = "tt.reduce"(%170) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc257)
    %172 = tt.expand_dims %171 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc233)
    %173 = tt.broadcast %172 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc234)
    %174 = tt.reshape %168 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc235)
    %175 = tt.reshape %173 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc236)
    %176 = tt.bitcast %145 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %177 = arith.cmpf olt, %161, %162 : tensor<1x64xf32> loc(#loc238)
    %178 = arith.extui %177 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %179 = arith.xori %178, %147 : tensor<1x64xi32> loc(#loc239)
    %180 = arith.cmpi ne, %179, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %181 = arith.xori %159, %160 : tensor<1x64xi32> loc(#loc241)
    %182 = arith.select %180, %181, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %183 = arith.xori %176, %182 : tensor<1x64xi32> loc(#loc243)
    %184 = arith.xori %174, %175 : tensor<1x64xi16> loc(#loc244)
    %185 = arith.select %180, %184, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %186 = arith.xori %144, %185 : tensor<1x64xi16> loc(#loc246)
    %187 = tt.bitcast %183 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %188 = tt.reshape %187 : tensor<1x64xf32> -> tensor<16x2x2xf32> loc(#loc201)
    %189 = tt.bitcast %188 : tensor<16x2x2xf32> -> tensor<16x2x2xi32> loc(#loc202)
    %190 = arith.muli %189, %71 : tensor<16x2x2xi32> loc(#loc204)
    %191 = "tt.reduce"(%190) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc248)
    %192 = tt.expand_dims %191 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc208)
    %193 = tt.broadcast %192 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc209)
    %194 = arith.muli %189, %21 : tensor<16x2x2xi32> loc(#loc210)
    %195 = "tt.reduce"(%194) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc251)
    %196 = tt.expand_dims %195 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc214)
    %197 = tt.broadcast %196 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc215)
    %198 = tt.reshape %193 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc216)
    %199 = tt.reshape %197 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc217)
    %200 = tt.bitcast %198 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %201 = tt.bitcast %199 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %202 = tt.reshape %186 : tensor<1x64xi16> -> tensor<16x2x2xi16> loc(#loc220)
    %203 = arith.muli %202, %85 : tensor<16x2x2xi16> loc(#loc222)
    %204 = "tt.reduce"(%203) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc254)
    %205 = tt.expand_dims %204 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc226)
    %206 = tt.broadcast %205 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc227)
    %207 = arith.muli %202, %90 : tensor<16x2x2xi16> loc(#loc229)
    %208 = "tt.reduce"(%207) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc257)
    %209 = tt.expand_dims %208 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc233)
    %210 = tt.broadcast %209 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc234)
    %211 = tt.reshape %206 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc235)
    %212 = tt.reshape %210 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc236)
    %213 = tt.bitcast %187 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %214 = arith.cmpf olt, %200, %201 : tensor<1x64xf32> loc(#loc238)
    %215 = arith.extui %214 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %216 = arith.xori %215, %147 : tensor<1x64xi32> loc(#loc239)
    %217 = arith.cmpi ne, %216, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %218 = arith.xori %198, %199 : tensor<1x64xi32> loc(#loc241)
    %219 = arith.select %217, %218, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %220 = arith.xori %213, %219 : tensor<1x64xi32> loc(#loc243)
    %221 = arith.xori %211, %212 : tensor<1x64xi16> loc(#loc244)
    %222 = arith.select %217, %221, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %223 = arith.xori %186, %222 : tensor<1x64xi16> loc(#loc246)
    %224 = tt.bitcast %220 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %225 = tt.reshape %224 : tensor<1x64xf32> -> tensor<32x2x1xf32> loc(#loc201)
    %226 = tt.bitcast %225 : tensor<32x2x1xf32> -> tensor<32x2x1xi32> loc(#loc202)
    %227 = arith.muli %226, %26 : tensor<32x2x1xi32> loc(#loc204)
    %228 = "tt.reduce"(%227) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc248)
    %229 = tt.expand_dims %228 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc208)
    %230 = tt.broadcast %229 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc209)
    %231 = arith.muli %226, %31 : tensor<32x2x1xi32> loc(#loc210)
    %232 = "tt.reduce"(%231) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc251)
    %233 = tt.expand_dims %232 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc214)
    %234 = tt.broadcast %233 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc215)
    %235 = tt.reshape %230 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc216)
    %236 = tt.reshape %234 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc217)
    %237 = tt.bitcast %235 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %238 = tt.bitcast %236 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %239 = tt.reshape %223 : tensor<1x64xi16> -> tensor<32x2x1xi16> loc(#loc220)
    %240 = arith.muli %239, %42 : tensor<32x2x1xi16> loc(#loc222)
    %241 = "tt.reduce"(%240) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc254)
    %242 = tt.expand_dims %241 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc226)
    %243 = tt.broadcast %242 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc227)
    %244 = arith.muli %239, %48 : tensor<32x2x1xi16> loc(#loc229)
    %245 = "tt.reduce"(%244) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc257)
    %246 = tt.expand_dims %245 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc233)
    %247 = tt.broadcast %246 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc234)
    %248 = tt.reshape %243 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc235)
    %249 = tt.reshape %247 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc236)
    %250 = tt.bitcast %224 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %251 = arith.cmpf olt, %237, %238 : tensor<1x64xf32> loc(#loc238)
    %252 = arith.extui %251 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %253 = arith.xori %252, %147 : tensor<1x64xi32> loc(#loc239)
    %254 = arith.cmpi ne, %253, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %255 = arith.xori %235, %236 : tensor<1x64xi32> loc(#loc241)
    %256 = arith.select %254, %255, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %257 = arith.xori %250, %256 : tensor<1x64xi32> loc(#loc243)
    %258 = arith.xori %248, %249 : tensor<1x64xi16> loc(#loc244)
    %259 = arith.select %254, %258, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %260 = arith.xori %223, %259 : tensor<1x64xi16> loc(#loc246)
    %261 = tt.bitcast %257 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %262 = tt.broadcast %20 : tensor<1x2x1xi32> -> tensor<2x2x16xi32> loc(#loc151)
    %263 = tt.reshape %262 : tensor<2x2x16xi32> -> tensor<1x64xi32> loc(#loc152)
    %264 = tt.reshape %261 : tensor<1x64xf32> -> tensor<4x2x8xf32> loc(#loc201)
    %265 = tt.bitcast %264 : tensor<4x2x8xf32> -> tensor<4x2x8xi32> loc(#loc202)
    %266 = tt.broadcast %25 : tensor<1x2x1xi32> -> tensor<4x2x8xi32> loc(#loc204)
    %267 = arith.muli %265, %266 : tensor<4x2x8xi32> loc(#loc204)
    %268 = "tt.reduce"(%267) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<4x2x8xi32>) -> tensor<4x8xi32> loc(#loc248)
    %269 = tt.expand_dims %268 {axis = 1 : i32} : tensor<4x8xi32> -> tensor<4x1x8xi32> loc(#loc208)
    %270 = tt.broadcast %269 : tensor<4x1x8xi32> -> tensor<4x2x8xi32> loc(#loc209)
    %271 = arith.muli %265, %146 : tensor<4x2x8xi32> loc(#loc210)
    %272 = "tt.reduce"(%271) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<4x2x8xi32>) -> tensor<4x8xi32> loc(#loc251)
    %273 = tt.expand_dims %272 {axis = 1 : i32} : tensor<4x8xi32> -> tensor<4x1x8xi32> loc(#loc214)
    %274 = tt.broadcast %273 : tensor<4x1x8xi32> -> tensor<4x2x8xi32> loc(#loc215)
    %275 = tt.reshape %270 : tensor<4x2x8xi32> -> tensor<1x64xi32> loc(#loc216)
    %276 = tt.reshape %274 : tensor<4x2x8xi32> -> tensor<1x64xi32> loc(#loc217)
    %277 = tt.bitcast %275 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %278 = tt.bitcast %276 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %279 = tt.reshape %260 : tensor<1x64xi16> -> tensor<4x2x8xi16> loc(#loc220)
    %280 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<4x2x8xi16> loc(#loc222)
    %281 = arith.muli %279, %280 : tensor<4x2x8xi16> loc(#loc222)
    %282 = "tt.reduce"(%281) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<4x2x8xi16>) -> tensor<4x8xi16> loc(#loc254)
    %283 = tt.expand_dims %282 {axis = 1 : i32} : tensor<4x8xi16> -> tensor<4x1x8xi16> loc(#loc226)
    %284 = tt.broadcast %283 : tensor<4x1x8xi16> -> tensor<4x2x8xi16> loc(#loc227)
    %285 = tt.broadcast %47 : tensor<1x2x1xi16> -> tensor<4x2x8xi16> loc(#loc229)
    %286 = arith.muli %279, %285 : tensor<4x2x8xi16> loc(#loc229)
    %287 = "tt.reduce"(%286) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<4x2x8xi16>) -> tensor<4x8xi16> loc(#loc257)
    %288 = tt.expand_dims %287 {axis = 1 : i32} : tensor<4x8xi16> -> tensor<4x1x8xi16> loc(#loc233)
    %289 = tt.broadcast %288 : tensor<4x1x8xi16> -> tensor<4x2x8xi16> loc(#loc234)
    %290 = tt.reshape %284 : tensor<4x2x8xi16> -> tensor<1x64xi16> loc(#loc235)
    %291 = tt.reshape %289 : tensor<4x2x8xi16> -> tensor<1x64xi16> loc(#loc236)
    %292 = tt.bitcast %261 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %293 = arith.cmpf olt, %277, %278 : tensor<1x64xf32> loc(#loc238)
    %294 = arith.extui %293 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %295 = arith.xori %294, %263 : tensor<1x64xi32> loc(#loc239)
    %296 = arith.cmpi ne, %295, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %297 = arith.xori %275, %276 : tensor<1x64xi32> loc(#loc241)
    %298 = arith.select %296, %297, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %299 = arith.xori %292, %298 : tensor<1x64xi32> loc(#loc243)
    %300 = arith.xori %290, %291 : tensor<1x64xi16> loc(#loc244)
    %301 = arith.select %296, %300, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %302 = arith.xori %260, %301 : tensor<1x64xi16> loc(#loc246)
    %303 = tt.bitcast %299 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %304 = tt.reshape %303 : tensor<1x64xf32> -> tensor<8x2x4xf32> loc(#loc201)
    %305 = tt.bitcast %304 : tensor<8x2x4xf32> -> tensor<8x2x4xi32> loc(#loc202)
    %306 = arith.muli %305, %150 : tensor<8x2x4xi32> loc(#loc204)
    %307 = "tt.reduce"(%306) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc248)
    %308 = tt.expand_dims %307 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc208)
    %309 = tt.broadcast %308 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc209)
    %310 = arith.muli %305, %67 : tensor<8x2x4xi32> loc(#loc210)
    %311 = "tt.reduce"(%310) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc251)
    %312 = tt.expand_dims %311 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc214)
    %313 = tt.broadcast %312 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc215)
    %314 = tt.reshape %309 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc216)
    %315 = tt.reshape %313 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc217)
    %316 = tt.bitcast %314 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %317 = tt.bitcast %315 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %318 = tt.reshape %302 : tensor<1x64xi16> -> tensor<8x2x4xi16> loc(#loc220)
    %319 = arith.muli %318, %164 : tensor<8x2x4xi16> loc(#loc222)
    %320 = "tt.reduce"(%319) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc254)
    %321 = tt.expand_dims %320 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc226)
    %322 = tt.broadcast %321 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc227)
    %323 = arith.muli %318, %169 : tensor<8x2x4xi16> loc(#loc229)
    %324 = "tt.reduce"(%323) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc257)
    %325 = tt.expand_dims %324 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc233)
    %326 = tt.broadcast %325 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc234)
    %327 = tt.reshape %322 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc235)
    %328 = tt.reshape %326 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc236)
    %329 = tt.bitcast %303 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %330 = arith.cmpf olt, %316, %317 : tensor<1x64xf32> loc(#loc238)
    %331 = arith.extui %330 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %332 = arith.xori %331, %263 : tensor<1x64xi32> loc(#loc239)
    %333 = arith.cmpi ne, %332, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %334 = arith.xori %314, %315 : tensor<1x64xi32> loc(#loc241)
    %335 = arith.select %333, %334, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %336 = arith.xori %329, %335 : tensor<1x64xi32> loc(#loc243)
    %337 = arith.xori %327, %328 : tensor<1x64xi16> loc(#loc244)
    %338 = arith.select %333, %337, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %339 = arith.xori %302, %338 : tensor<1x64xi16> loc(#loc246)
    %340 = tt.bitcast %336 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %341 = tt.reshape %340 : tensor<1x64xf32> -> tensor<16x2x2xf32> loc(#loc201)
    %342 = tt.bitcast %341 : tensor<16x2x2xf32> -> tensor<16x2x2xi32> loc(#loc202)
    %343 = arith.muli %342, %71 : tensor<16x2x2xi32> loc(#loc204)
    %344 = "tt.reduce"(%343) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc248)
    %345 = tt.expand_dims %344 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc208)
    %346 = tt.broadcast %345 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc209)
    %347 = arith.muli %342, %21 : tensor<16x2x2xi32> loc(#loc210)
    %348 = "tt.reduce"(%347) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc251)
    %349 = tt.expand_dims %348 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc214)
    %350 = tt.broadcast %349 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc215)
    %351 = tt.reshape %346 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc216)
    %352 = tt.reshape %350 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc217)
    %353 = tt.bitcast %351 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %354 = tt.bitcast %352 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %355 = tt.reshape %339 : tensor<1x64xi16> -> tensor<16x2x2xi16> loc(#loc220)
    %356 = arith.muli %355, %85 : tensor<16x2x2xi16> loc(#loc222)
    %357 = "tt.reduce"(%356) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc254)
    %358 = tt.expand_dims %357 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc226)
    %359 = tt.broadcast %358 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc227)
    %360 = arith.muli %355, %90 : tensor<16x2x2xi16> loc(#loc229)
    %361 = "tt.reduce"(%360) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc257)
    %362 = tt.expand_dims %361 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc233)
    %363 = tt.broadcast %362 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc234)
    %364 = tt.reshape %359 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc235)
    %365 = tt.reshape %363 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc236)
    %366 = tt.bitcast %340 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %367 = arith.cmpf olt, %353, %354 : tensor<1x64xf32> loc(#loc238)
    %368 = arith.extui %367 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %369 = arith.xori %368, %263 : tensor<1x64xi32> loc(#loc239)
    %370 = arith.cmpi ne, %369, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %371 = arith.xori %351, %352 : tensor<1x64xi32> loc(#loc241)
    %372 = arith.select %370, %371, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %373 = arith.xori %366, %372 : tensor<1x64xi32> loc(#loc243)
    %374 = arith.xori %364, %365 : tensor<1x64xi16> loc(#loc244)
    %375 = arith.select %370, %374, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %376 = arith.xori %339, %375 : tensor<1x64xi16> loc(#loc246)
    %377 = tt.bitcast %373 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %378 = tt.reshape %377 : tensor<1x64xf32> -> tensor<32x2x1xf32> loc(#loc201)
    %379 = tt.bitcast %378 : tensor<32x2x1xf32> -> tensor<32x2x1xi32> loc(#loc202)
    %380 = arith.muli %379, %26 : tensor<32x2x1xi32> loc(#loc204)
    %381 = "tt.reduce"(%380) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc248)
    %382 = tt.expand_dims %381 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc208)
    %383 = tt.broadcast %382 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc209)
    %384 = arith.muli %379, %31 : tensor<32x2x1xi32> loc(#loc210)
    %385 = "tt.reduce"(%384) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc251)
    %386 = tt.expand_dims %385 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc214)
    %387 = tt.broadcast %386 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc215)
    %388 = tt.reshape %383 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc216)
    %389 = tt.reshape %387 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc217)
    %390 = tt.bitcast %388 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %391 = tt.bitcast %389 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %392 = tt.reshape %376 : tensor<1x64xi16> -> tensor<32x2x1xi16> loc(#loc220)
    %393 = arith.muli %392, %42 : tensor<32x2x1xi16> loc(#loc222)
    %394 = "tt.reduce"(%393) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc254)
    %395 = tt.expand_dims %394 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc226)
    %396 = tt.broadcast %395 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc227)
    %397 = arith.muli %392, %48 : tensor<32x2x1xi16> loc(#loc229)
    %398 = "tt.reduce"(%397) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc257)
    %399 = tt.expand_dims %398 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc233)
    %400 = tt.broadcast %399 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc234)
    %401 = tt.reshape %396 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc235)
    %402 = tt.reshape %400 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc236)
    %403 = tt.bitcast %377 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %404 = arith.cmpf olt, %390, %391 : tensor<1x64xf32> loc(#loc238)
    %405 = arith.extui %404 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %406 = arith.xori %405, %263 : tensor<1x64xi32> loc(#loc239)
    %407 = arith.cmpi ne, %406, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %408 = arith.xori %388, %389 : tensor<1x64xi32> loc(#loc241)
    %409 = arith.select %407, %408, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %410 = arith.xori %403, %409 : tensor<1x64xi32> loc(#loc243)
    %411 = arith.xori %401, %402 : tensor<1x64xi16> loc(#loc244)
    %412 = arith.select %407, %411, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %413 = arith.xori %376, %412 : tensor<1x64xi16> loc(#loc246)
    %414 = tt.bitcast %410 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %415 = tt.broadcast %20 : tensor<1x2x1xi32> -> tensor<1x2x32xi32> loc(#loc151)
    %416 = tt.reshape %415 : tensor<1x2x32xi32> -> tensor<1x64xi32> loc(#loc152)
    %417 = tt.reshape %414 : tensor<1x64xf32> -> tensor<2x2x16xf32> loc(#loc201)
    %418 = tt.bitcast %417 : tensor<2x2x16xf32> -> tensor<2x2x16xi32> loc(#loc202)
    %419 = tt.broadcast %25 : tensor<1x2x1xi32> -> tensor<2x2x16xi32> loc(#loc204)
    %420 = arith.muli %418, %419 : tensor<2x2x16xi32> loc(#loc204)
    %421 = "tt.reduce"(%420) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<2x2x16xi32>) -> tensor<2x16xi32> loc(#loc248)
    %422 = tt.expand_dims %421 {axis = 1 : i32} : tensor<2x16xi32> -> tensor<2x1x16xi32> loc(#loc208)
    %423 = tt.broadcast %422 : tensor<2x1x16xi32> -> tensor<2x2x16xi32> loc(#loc209)
    %424 = arith.muli %418, %262 : tensor<2x2x16xi32> loc(#loc210)
    %425 = "tt.reduce"(%424) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<2x2x16xi32>) -> tensor<2x16xi32> loc(#loc251)
    %426 = tt.expand_dims %425 {axis = 1 : i32} : tensor<2x16xi32> -> tensor<2x1x16xi32> loc(#loc214)
    %427 = tt.broadcast %426 : tensor<2x1x16xi32> -> tensor<2x2x16xi32> loc(#loc215)
    %428 = tt.reshape %423 : tensor<2x2x16xi32> -> tensor<1x64xi32> loc(#loc216)
    %429 = tt.reshape %427 : tensor<2x2x16xi32> -> tensor<1x64xi32> loc(#loc217)
    %430 = tt.bitcast %428 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %431 = tt.bitcast %429 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %432 = tt.reshape %413 : tensor<1x64xi16> -> tensor<2x2x16xi16> loc(#loc220)
    %433 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<2x2x16xi16> loc(#loc222)
    %434 = arith.muli %432, %433 : tensor<2x2x16xi16> loc(#loc222)
    %435 = "tt.reduce"(%434) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<2x2x16xi16>) -> tensor<2x16xi16> loc(#loc254)
    %436 = tt.expand_dims %435 {axis = 1 : i32} : tensor<2x16xi16> -> tensor<2x1x16xi16> loc(#loc226)
    %437 = tt.broadcast %436 : tensor<2x1x16xi16> -> tensor<2x2x16xi16> loc(#loc227)
    %438 = tt.broadcast %47 : tensor<1x2x1xi16> -> tensor<2x2x16xi16> loc(#loc229)
    %439 = arith.muli %432, %438 : tensor<2x2x16xi16> loc(#loc229)
    %440 = "tt.reduce"(%439) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<2x2x16xi16>) -> tensor<2x16xi16> loc(#loc257)
    %441 = tt.expand_dims %440 {axis = 1 : i32} : tensor<2x16xi16> -> tensor<2x1x16xi16> loc(#loc233)
    %442 = tt.broadcast %441 : tensor<2x1x16xi16> -> tensor<2x2x16xi16> loc(#loc234)
    %443 = tt.reshape %437 : tensor<2x2x16xi16> -> tensor<1x64xi16> loc(#loc235)
    %444 = tt.reshape %442 : tensor<2x2x16xi16> -> tensor<1x64xi16> loc(#loc236)
    %445 = tt.bitcast %414 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %446 = arith.cmpf olt, %430, %431 : tensor<1x64xf32> loc(#loc238)
    %447 = arith.extui %446 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %448 = arith.xori %447, %416 : tensor<1x64xi32> loc(#loc239)
    %449 = arith.cmpi ne, %448, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %450 = arith.xori %428, %429 : tensor<1x64xi32> loc(#loc241)
    %451 = arith.select %449, %450, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %452 = arith.xori %445, %451 : tensor<1x64xi32> loc(#loc243)
    %453 = arith.xori %443, %444 : tensor<1x64xi16> loc(#loc244)
    %454 = arith.select %449, %453, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %455 = arith.xori %413, %454 : tensor<1x64xi16> loc(#loc246)
    %456 = tt.bitcast %452 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %457 = tt.reshape %456 : tensor<1x64xf32> -> tensor<4x2x8xf32> loc(#loc201)
    %458 = tt.bitcast %457 : tensor<4x2x8xf32> -> tensor<4x2x8xi32> loc(#loc202)
    %459 = arith.muli %458, %266 : tensor<4x2x8xi32> loc(#loc204)
    %460 = "tt.reduce"(%459) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<4x2x8xi32>) -> tensor<4x8xi32> loc(#loc248)
    %461 = tt.expand_dims %460 {axis = 1 : i32} : tensor<4x8xi32> -> tensor<4x1x8xi32> loc(#loc208)
    %462 = tt.broadcast %461 : tensor<4x1x8xi32> -> tensor<4x2x8xi32> loc(#loc209)
    %463 = arith.muli %458, %146 : tensor<4x2x8xi32> loc(#loc210)
    %464 = "tt.reduce"(%463) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<4x2x8xi32>) -> tensor<4x8xi32> loc(#loc251)
    %465 = tt.expand_dims %464 {axis = 1 : i32} : tensor<4x8xi32> -> tensor<4x1x8xi32> loc(#loc214)
    %466 = tt.broadcast %465 : tensor<4x1x8xi32> -> tensor<4x2x8xi32> loc(#loc215)
    %467 = tt.reshape %462 : tensor<4x2x8xi32> -> tensor<1x64xi32> loc(#loc216)
    %468 = tt.reshape %466 : tensor<4x2x8xi32> -> tensor<1x64xi32> loc(#loc217)
    %469 = tt.bitcast %467 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %470 = tt.bitcast %468 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %471 = tt.reshape %455 : tensor<1x64xi16> -> tensor<4x2x8xi16> loc(#loc220)
    %472 = arith.muli %471, %280 : tensor<4x2x8xi16> loc(#loc222)
    %473 = "tt.reduce"(%472) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<4x2x8xi16>) -> tensor<4x8xi16> loc(#loc254)
    %474 = tt.expand_dims %473 {axis = 1 : i32} : tensor<4x8xi16> -> tensor<4x1x8xi16> loc(#loc226)
    %475 = tt.broadcast %474 : tensor<4x1x8xi16> -> tensor<4x2x8xi16> loc(#loc227)
    %476 = arith.muli %471, %285 : tensor<4x2x8xi16> loc(#loc229)
    %477 = "tt.reduce"(%476) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<4x2x8xi16>) -> tensor<4x8xi16> loc(#loc257)
    %478 = tt.expand_dims %477 {axis = 1 : i32} : tensor<4x8xi16> -> tensor<4x1x8xi16> loc(#loc233)
    %479 = tt.broadcast %478 : tensor<4x1x8xi16> -> tensor<4x2x8xi16> loc(#loc234)
    %480 = tt.reshape %475 : tensor<4x2x8xi16> -> tensor<1x64xi16> loc(#loc235)
    %481 = tt.reshape %479 : tensor<4x2x8xi16> -> tensor<1x64xi16> loc(#loc236)
    %482 = tt.bitcast %456 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %483 = arith.cmpf olt, %469, %470 : tensor<1x64xf32> loc(#loc238)
    %484 = arith.extui %483 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %485 = arith.xori %484, %416 : tensor<1x64xi32> loc(#loc239)
    %486 = arith.cmpi ne, %485, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %487 = arith.xori %467, %468 : tensor<1x64xi32> loc(#loc241)
    %488 = arith.select %486, %487, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %489 = arith.xori %482, %488 : tensor<1x64xi32> loc(#loc243)
    %490 = arith.xori %480, %481 : tensor<1x64xi16> loc(#loc244)
    %491 = arith.select %486, %490, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %492 = arith.xori %455, %491 : tensor<1x64xi16> loc(#loc246)
    %493 = tt.bitcast %489 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %494 = tt.reshape %493 : tensor<1x64xf32> -> tensor<8x2x4xf32> loc(#loc201)
    %495 = tt.bitcast %494 : tensor<8x2x4xf32> -> tensor<8x2x4xi32> loc(#loc202)
    %496 = arith.muli %495, %150 : tensor<8x2x4xi32> loc(#loc204)
    %497 = "tt.reduce"(%496) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc248)
    %498 = tt.expand_dims %497 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc208)
    %499 = tt.broadcast %498 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc209)
    %500 = arith.muli %495, %67 : tensor<8x2x4xi32> loc(#loc210)
    %501 = "tt.reduce"(%500) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc251)
    %502 = tt.expand_dims %501 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc214)
    %503 = tt.broadcast %502 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc215)
    %504 = tt.reshape %499 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc216)
    %505 = tt.reshape %503 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc217)
    %506 = tt.bitcast %504 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %507 = tt.bitcast %505 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %508 = tt.reshape %492 : tensor<1x64xi16> -> tensor<8x2x4xi16> loc(#loc220)
    %509 = arith.muli %508, %164 : tensor<8x2x4xi16> loc(#loc222)
    %510 = "tt.reduce"(%509) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc254)
    %511 = tt.expand_dims %510 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc226)
    %512 = tt.broadcast %511 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc227)
    %513 = arith.muli %508, %169 : tensor<8x2x4xi16> loc(#loc229)
    %514 = "tt.reduce"(%513) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc257)
    %515 = tt.expand_dims %514 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc233)
    %516 = tt.broadcast %515 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc234)
    %517 = tt.reshape %512 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc235)
    %518 = tt.reshape %516 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc236)
    %519 = tt.bitcast %493 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %520 = arith.cmpf olt, %506, %507 : tensor<1x64xf32> loc(#loc238)
    %521 = arith.extui %520 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %522 = arith.xori %521, %416 : tensor<1x64xi32> loc(#loc239)
    %523 = arith.cmpi ne, %522, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %524 = arith.xori %504, %505 : tensor<1x64xi32> loc(#loc241)
    %525 = arith.select %523, %524, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %526 = arith.xori %519, %525 : tensor<1x64xi32> loc(#loc243)
    %527 = arith.xori %517, %518 : tensor<1x64xi16> loc(#loc244)
    %528 = arith.select %523, %527, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %529 = arith.xori %492, %528 : tensor<1x64xi16> loc(#loc246)
    %530 = tt.bitcast %526 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %531 = tt.reshape %530 : tensor<1x64xf32> -> tensor<16x2x2xf32> loc(#loc201)
    %532 = tt.bitcast %531 : tensor<16x2x2xf32> -> tensor<16x2x2xi32> loc(#loc202)
    %533 = arith.muli %532, %71 : tensor<16x2x2xi32> loc(#loc204)
    %534 = "tt.reduce"(%533) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc248)
    %535 = tt.expand_dims %534 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc208)
    %536 = tt.broadcast %535 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc209)
    %537 = arith.muli %532, %21 : tensor<16x2x2xi32> loc(#loc210)
    %538 = "tt.reduce"(%537) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc251)
    %539 = tt.expand_dims %538 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc214)
    %540 = tt.broadcast %539 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc215)
    %541 = tt.reshape %536 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc216)
    %542 = tt.reshape %540 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc217)
    %543 = tt.bitcast %541 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %544 = tt.bitcast %542 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %545 = tt.reshape %529 : tensor<1x64xi16> -> tensor<16x2x2xi16> loc(#loc220)
    %546 = arith.muli %545, %85 : tensor<16x2x2xi16> loc(#loc222)
    %547 = "tt.reduce"(%546) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc254)
    %548 = tt.expand_dims %547 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc226)
    %549 = tt.broadcast %548 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc227)
    %550 = arith.muli %545, %90 : tensor<16x2x2xi16> loc(#loc229)
    %551 = "tt.reduce"(%550) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc257)
    %552 = tt.expand_dims %551 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc233)
    %553 = tt.broadcast %552 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc234)
    %554 = tt.reshape %549 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc235)
    %555 = tt.reshape %553 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc236)
    %556 = tt.bitcast %530 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %557 = arith.cmpf olt, %543, %544 : tensor<1x64xf32> loc(#loc238)
    %558 = arith.extui %557 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %559 = arith.xori %558, %416 : tensor<1x64xi32> loc(#loc239)
    %560 = arith.cmpi ne, %559, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %561 = arith.xori %541, %542 : tensor<1x64xi32> loc(#loc241)
    %562 = arith.select %560, %561, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %563 = arith.xori %556, %562 : tensor<1x64xi32> loc(#loc243)
    %564 = arith.xori %554, %555 : tensor<1x64xi16> loc(#loc244)
    %565 = arith.select %560, %564, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %566 = arith.xori %529, %565 : tensor<1x64xi16> loc(#loc246)
    %567 = tt.bitcast %563 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %568 = tt.reshape %567 : tensor<1x64xf32> -> tensor<32x2x1xf32> loc(#loc201)
    %569 = tt.bitcast %568 : tensor<32x2x1xf32> -> tensor<32x2x1xi32> loc(#loc202)
    %570 = arith.muli %569, %26 : tensor<32x2x1xi32> loc(#loc204)
    %571 = "tt.reduce"(%570) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc248)
    %572 = tt.expand_dims %571 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc208)
    %573 = tt.broadcast %572 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc209)
    %574 = arith.muli %569, %31 : tensor<32x2x1xi32> loc(#loc210)
    %575 = "tt.reduce"(%574) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc251)
    %576 = tt.expand_dims %575 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc214)
    %577 = tt.broadcast %576 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc215)
    %578 = tt.reshape %573 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc216)
    %579 = tt.reshape %577 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc217)
    %580 = tt.bitcast %578 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %581 = tt.bitcast %579 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %582 = tt.reshape %566 : tensor<1x64xi16> -> tensor<32x2x1xi16> loc(#loc220)
    %583 = arith.muli %582, %42 : tensor<32x2x1xi16> loc(#loc222)
    %584 = "tt.reduce"(%583) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc254)
    %585 = tt.expand_dims %584 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc226)
    %586 = tt.broadcast %585 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc227)
    %587 = arith.muli %582, %48 : tensor<32x2x1xi16> loc(#loc229)
    %588 = "tt.reduce"(%587) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc257)
    %589 = tt.expand_dims %588 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc233)
    %590 = tt.broadcast %589 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc234)
    %591 = tt.reshape %586 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc235)
    %592 = tt.reshape %590 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc236)
    %593 = tt.bitcast %567 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %594 = arith.cmpf olt, %580, %581 : tensor<1x64xf32> loc(#loc238)
    %595 = arith.extui %594 : tensor<1x64xi1> to tensor<1x64xi32> loc(#loc239)
    %596 = arith.xori %595, %416 : tensor<1x64xi32> loc(#loc239)
    %597 = arith.cmpi ne, %596, %cst_0 : tensor<1x64xi32> loc(#loc240)
    %598 = arith.xori %578, %579 : tensor<1x64xi32> loc(#loc241)
    %599 = arith.select %597, %598, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %600 = arith.xori %593, %599 : tensor<1x64xi32> loc(#loc243)
    %601 = arith.xori %591, %592 : tensor<1x64xi16> loc(#loc244)
    %602 = arith.select %597, %601, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %603 = arith.xori %566, %602 : tensor<1x64xi16> loc(#loc246)
    %604 = tt.bitcast %600 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %605 = tt.reshape %604 : tensor<1x64xf32> -> tensor<1x2x32xf32> loc(#loc201)
    %606 = tt.bitcast %605 : tensor<1x2x32xf32> -> tensor<1x2x32xi32> loc(#loc202)
    %607 = tt.broadcast %25 : tensor<1x2x1xi32> -> tensor<1x2x32xi32> loc(#loc204)
    %608 = arith.muli %606, %607 : tensor<1x2x32xi32> loc(#loc204)
    %609 = "tt.reduce"(%608) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<1x2x32xi32>) -> tensor<1x32xi32> loc(#loc248)
    %610 = tt.expand_dims %609 {axis = 1 : i32} : tensor<1x32xi32> -> tensor<1x1x32xi32> loc(#loc208)
    %611 = tt.broadcast %610 : tensor<1x1x32xi32> -> tensor<1x2x32xi32> loc(#loc209)
    %612 = arith.muli %606, %415 : tensor<1x2x32xi32> loc(#loc210)
    %613 = "tt.reduce"(%612) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<1x2x32xi32>) -> tensor<1x32xi32> loc(#loc251)
    %614 = tt.expand_dims %613 {axis = 1 : i32} : tensor<1x32xi32> -> tensor<1x1x32xi32> loc(#loc214)
    %615 = tt.broadcast %614 : tensor<1x1x32xi32> -> tensor<1x2x32xi32> loc(#loc215)
    %616 = tt.reshape %611 : tensor<1x2x32xi32> -> tensor<1x64xi32> loc(#loc216)
    %617 = tt.reshape %615 : tensor<1x2x32xi32> -> tensor<1x64xi32> loc(#loc217)
    %618 = tt.bitcast %616 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %619 = tt.bitcast %617 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %620 = tt.reshape %603 : tensor<1x64xi16> -> tensor<1x2x32xi16> loc(#loc220)
    %621 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<1x2x32xi16> loc(#loc222)
    %622 = arith.muli %620, %621 : tensor<1x2x32xi16> loc(#loc222)
    %623 = "tt.reduce"(%622) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<1x2x32xi16>) -> tensor<1x32xi16> loc(#loc254)
    %624 = tt.expand_dims %623 {axis = 1 : i32} : tensor<1x32xi16> -> tensor<1x1x32xi16> loc(#loc226)
    %625 = tt.broadcast %624 : tensor<1x1x32xi16> -> tensor<1x2x32xi16> loc(#loc227)
    %626 = tt.broadcast %47 : tensor<1x2x1xi16> -> tensor<1x2x32xi16> loc(#loc229)
    %627 = arith.muli %620, %626 : tensor<1x2x32xi16> loc(#loc229)
    %628 = "tt.reduce"(%627) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<1x2x32xi16>) -> tensor<1x32xi16> loc(#loc257)
    %629 = tt.expand_dims %628 {axis = 1 : i32} : tensor<1x32xi16> -> tensor<1x1x32xi16> loc(#loc233)
    %630 = tt.broadcast %629 : tensor<1x1x32xi16> -> tensor<1x2x32xi16> loc(#loc234)
    %631 = tt.reshape %625 : tensor<1x2x32xi16> -> tensor<1x64xi16> loc(#loc235)
    %632 = tt.reshape %630 : tensor<1x2x32xi16> -> tensor<1x64xi16> loc(#loc236)
    %633 = tt.bitcast %604 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %634 = arith.cmpf olt, %618, %619 : tensor<1x64xf32> loc(#loc238)
    %635 = arith.xori %616, %617 : tensor<1x64xi32> loc(#loc241)
    %636 = arith.select %634, %635, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %637 = arith.xori %633, %636 : tensor<1x64xi32> loc(#loc243)
    %638 = arith.xori %631, %632 : tensor<1x64xi16> loc(#loc244)
    %639 = arith.select %634, %638, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %640 = arith.xori %603, %639 : tensor<1x64xi16> loc(#loc246)
    %641 = tt.bitcast %637 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %642 = tt.reshape %641 : tensor<1x64xf32> -> tensor<2x2x16xf32> loc(#loc201)
    %643 = tt.bitcast %642 : tensor<2x2x16xf32> -> tensor<2x2x16xi32> loc(#loc202)
    %644 = arith.muli %643, %419 : tensor<2x2x16xi32> loc(#loc204)
    %645 = "tt.reduce"(%644) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<2x2x16xi32>) -> tensor<2x16xi32> loc(#loc248)
    %646 = tt.expand_dims %645 {axis = 1 : i32} : tensor<2x16xi32> -> tensor<2x1x16xi32> loc(#loc208)
    %647 = tt.broadcast %646 : tensor<2x1x16xi32> -> tensor<2x2x16xi32> loc(#loc209)
    %648 = arith.muli %643, %262 : tensor<2x2x16xi32> loc(#loc210)
    %649 = "tt.reduce"(%648) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<2x2x16xi32>) -> tensor<2x16xi32> loc(#loc251)
    %650 = tt.expand_dims %649 {axis = 1 : i32} : tensor<2x16xi32> -> tensor<2x1x16xi32> loc(#loc214)
    %651 = tt.broadcast %650 : tensor<2x1x16xi32> -> tensor<2x2x16xi32> loc(#loc215)
    %652 = tt.reshape %647 : tensor<2x2x16xi32> -> tensor<1x64xi32> loc(#loc216)
    %653 = tt.reshape %651 : tensor<2x2x16xi32> -> tensor<1x64xi32> loc(#loc217)
    %654 = tt.bitcast %652 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %655 = tt.bitcast %653 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %656 = tt.reshape %640 : tensor<1x64xi16> -> tensor<2x2x16xi16> loc(#loc220)
    %657 = arith.muli %656, %433 : tensor<2x2x16xi16> loc(#loc222)
    %658 = "tt.reduce"(%657) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<2x2x16xi16>) -> tensor<2x16xi16> loc(#loc254)
    %659 = tt.expand_dims %658 {axis = 1 : i32} : tensor<2x16xi16> -> tensor<2x1x16xi16> loc(#loc226)
    %660 = tt.broadcast %659 : tensor<2x1x16xi16> -> tensor<2x2x16xi16> loc(#loc227)
    %661 = arith.muli %656, %438 : tensor<2x2x16xi16> loc(#loc229)
    %662 = "tt.reduce"(%661) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<2x2x16xi16>) -> tensor<2x16xi16> loc(#loc257)
    %663 = tt.expand_dims %662 {axis = 1 : i32} : tensor<2x16xi16> -> tensor<2x1x16xi16> loc(#loc233)
    %664 = tt.broadcast %663 : tensor<2x1x16xi16> -> tensor<2x2x16xi16> loc(#loc234)
    %665 = tt.reshape %660 : tensor<2x2x16xi16> -> tensor<1x64xi16> loc(#loc235)
    %666 = tt.reshape %664 : tensor<2x2x16xi16> -> tensor<1x64xi16> loc(#loc236)
    %667 = tt.bitcast %641 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %668 = arith.cmpf olt, %654, %655 : tensor<1x64xf32> loc(#loc238)
    %669 = arith.xori %652, %653 : tensor<1x64xi32> loc(#loc241)
    %670 = arith.select %668, %669, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %671 = arith.xori %667, %670 : tensor<1x64xi32> loc(#loc243)
    %672 = arith.xori %665, %666 : tensor<1x64xi16> loc(#loc244)
    %673 = arith.select %668, %672, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %674 = arith.xori %640, %673 : tensor<1x64xi16> loc(#loc246)
    %675 = tt.bitcast %671 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %676 = tt.reshape %675 : tensor<1x64xf32> -> tensor<4x2x8xf32> loc(#loc201)
    %677 = tt.bitcast %676 : tensor<4x2x8xf32> -> tensor<4x2x8xi32> loc(#loc202)
    %678 = arith.muli %677, %266 : tensor<4x2x8xi32> loc(#loc204)
    %679 = "tt.reduce"(%678) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<4x2x8xi32>) -> tensor<4x8xi32> loc(#loc248)
    %680 = tt.expand_dims %679 {axis = 1 : i32} : tensor<4x8xi32> -> tensor<4x1x8xi32> loc(#loc208)
    %681 = tt.broadcast %680 : tensor<4x1x8xi32> -> tensor<4x2x8xi32> loc(#loc209)
    %682 = arith.muli %677, %146 : tensor<4x2x8xi32> loc(#loc210)
    %683 = "tt.reduce"(%682) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<4x2x8xi32>) -> tensor<4x8xi32> loc(#loc251)
    %684 = tt.expand_dims %683 {axis = 1 : i32} : tensor<4x8xi32> -> tensor<4x1x8xi32> loc(#loc214)
    %685 = tt.broadcast %684 : tensor<4x1x8xi32> -> tensor<4x2x8xi32> loc(#loc215)
    %686 = tt.reshape %681 : tensor<4x2x8xi32> -> tensor<1x64xi32> loc(#loc216)
    %687 = tt.reshape %685 : tensor<4x2x8xi32> -> tensor<1x64xi32> loc(#loc217)
    %688 = tt.bitcast %686 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %689 = tt.bitcast %687 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %690 = tt.reshape %674 : tensor<1x64xi16> -> tensor<4x2x8xi16> loc(#loc220)
    %691 = arith.muli %690, %280 : tensor<4x2x8xi16> loc(#loc222)
    %692 = "tt.reduce"(%691) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<4x2x8xi16>) -> tensor<4x8xi16> loc(#loc254)
    %693 = tt.expand_dims %692 {axis = 1 : i32} : tensor<4x8xi16> -> tensor<4x1x8xi16> loc(#loc226)
    %694 = tt.broadcast %693 : tensor<4x1x8xi16> -> tensor<4x2x8xi16> loc(#loc227)
    %695 = arith.muli %690, %285 : tensor<4x2x8xi16> loc(#loc229)
    %696 = "tt.reduce"(%695) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<4x2x8xi16>) -> tensor<4x8xi16> loc(#loc257)
    %697 = tt.expand_dims %696 {axis = 1 : i32} : tensor<4x8xi16> -> tensor<4x1x8xi16> loc(#loc233)
    %698 = tt.broadcast %697 : tensor<4x1x8xi16> -> tensor<4x2x8xi16> loc(#loc234)
    %699 = tt.reshape %694 : tensor<4x2x8xi16> -> tensor<1x64xi16> loc(#loc235)
    %700 = tt.reshape %698 : tensor<4x2x8xi16> -> tensor<1x64xi16> loc(#loc236)
    %701 = tt.bitcast %675 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %702 = arith.cmpf olt, %688, %689 : tensor<1x64xf32> loc(#loc238)
    %703 = arith.xori %686, %687 : tensor<1x64xi32> loc(#loc241)
    %704 = arith.select %702, %703, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %705 = arith.xori %701, %704 : tensor<1x64xi32> loc(#loc243)
    %706 = arith.xori %699, %700 : tensor<1x64xi16> loc(#loc244)
    %707 = arith.select %702, %706, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %708 = arith.xori %674, %707 : tensor<1x64xi16> loc(#loc246)
    %709 = tt.bitcast %705 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %710 = tt.reshape %709 : tensor<1x64xf32> -> tensor<8x2x4xf32> loc(#loc201)
    %711 = tt.bitcast %710 : tensor<8x2x4xf32> -> tensor<8x2x4xi32> loc(#loc202)
    %712 = arith.muli %711, %150 : tensor<8x2x4xi32> loc(#loc204)
    %713 = "tt.reduce"(%712) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc248)
    %714 = tt.expand_dims %713 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc208)
    %715 = tt.broadcast %714 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc209)
    %716 = arith.muli %711, %67 : tensor<8x2x4xi32> loc(#loc210)
    %717 = "tt.reduce"(%716) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<8x2x4xi32>) -> tensor<8x4xi32> loc(#loc251)
    %718 = tt.expand_dims %717 {axis = 1 : i32} : tensor<8x4xi32> -> tensor<8x1x4xi32> loc(#loc214)
    %719 = tt.broadcast %718 : tensor<8x1x4xi32> -> tensor<8x2x4xi32> loc(#loc215)
    %720 = tt.reshape %715 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc216)
    %721 = tt.reshape %719 : tensor<8x2x4xi32> -> tensor<1x64xi32> loc(#loc217)
    %722 = tt.bitcast %720 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %723 = tt.bitcast %721 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %724 = tt.reshape %708 : tensor<1x64xi16> -> tensor<8x2x4xi16> loc(#loc220)
    %725 = arith.muli %724, %164 : tensor<8x2x4xi16> loc(#loc222)
    %726 = "tt.reduce"(%725) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc254)
    %727 = tt.expand_dims %726 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc226)
    %728 = tt.broadcast %727 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc227)
    %729 = arith.muli %724, %169 : tensor<8x2x4xi16> loc(#loc229)
    %730 = "tt.reduce"(%729) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<8x2x4xi16>) -> tensor<8x4xi16> loc(#loc257)
    %731 = tt.expand_dims %730 {axis = 1 : i32} : tensor<8x4xi16> -> tensor<8x1x4xi16> loc(#loc233)
    %732 = tt.broadcast %731 : tensor<8x1x4xi16> -> tensor<8x2x4xi16> loc(#loc234)
    %733 = tt.reshape %728 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc235)
    %734 = tt.reshape %732 : tensor<8x2x4xi16> -> tensor<1x64xi16> loc(#loc236)
    %735 = tt.bitcast %709 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %736 = arith.cmpf olt, %722, %723 : tensor<1x64xf32> loc(#loc238)
    %737 = arith.xori %720, %721 : tensor<1x64xi32> loc(#loc241)
    %738 = arith.select %736, %737, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %739 = arith.xori %735, %738 : tensor<1x64xi32> loc(#loc243)
    %740 = arith.xori %733, %734 : tensor<1x64xi16> loc(#loc244)
    %741 = arith.select %736, %740, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %742 = arith.xori %708, %741 : tensor<1x64xi16> loc(#loc246)
    %743 = tt.bitcast %739 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %744 = tt.reshape %743 : tensor<1x64xf32> -> tensor<16x2x2xf32> loc(#loc201)
    %745 = tt.bitcast %744 : tensor<16x2x2xf32> -> tensor<16x2x2xi32> loc(#loc202)
    %746 = arith.muli %745, %71 : tensor<16x2x2xi32> loc(#loc204)
    %747 = "tt.reduce"(%746) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc248)
    %748 = tt.expand_dims %747 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc208)
    %749 = tt.broadcast %748 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc209)
    %750 = arith.muli %745, %21 : tensor<16x2x2xi32> loc(#loc210)
    %751 = "tt.reduce"(%750) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<16x2x2xi32>) -> tensor<16x2xi32> loc(#loc251)
    %752 = tt.expand_dims %751 {axis = 1 : i32} : tensor<16x2xi32> -> tensor<16x1x2xi32> loc(#loc214)
    %753 = tt.broadcast %752 : tensor<16x1x2xi32> -> tensor<16x2x2xi32> loc(#loc215)
    %754 = tt.reshape %749 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc216)
    %755 = tt.reshape %753 : tensor<16x2x2xi32> -> tensor<1x64xi32> loc(#loc217)
    %756 = tt.bitcast %754 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %757 = tt.bitcast %755 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %758 = tt.reshape %742 : tensor<1x64xi16> -> tensor<16x2x2xi16> loc(#loc220)
    %759 = arith.muli %758, %85 : tensor<16x2x2xi16> loc(#loc222)
    %760 = "tt.reduce"(%759) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc254)
    %761 = tt.expand_dims %760 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc226)
    %762 = tt.broadcast %761 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc227)
    %763 = arith.muli %758, %90 : tensor<16x2x2xi16> loc(#loc229)
    %764 = "tt.reduce"(%763) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<16x2x2xi16>) -> tensor<16x2xi16> loc(#loc257)
    %765 = tt.expand_dims %764 {axis = 1 : i32} : tensor<16x2xi16> -> tensor<16x1x2xi16> loc(#loc233)
    %766 = tt.broadcast %765 : tensor<16x1x2xi16> -> tensor<16x2x2xi16> loc(#loc234)
    %767 = tt.reshape %762 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc235)
    %768 = tt.reshape %766 : tensor<16x2x2xi16> -> tensor<1x64xi16> loc(#loc236)
    %769 = tt.bitcast %743 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %770 = arith.cmpf olt, %756, %757 : tensor<1x64xf32> loc(#loc238)
    %771 = arith.xori %754, %755 : tensor<1x64xi32> loc(#loc241)
    %772 = arith.select %770, %771, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %773 = arith.xori %769, %772 : tensor<1x64xi32> loc(#loc243)
    %774 = arith.xori %767, %768 : tensor<1x64xi16> loc(#loc244)
    %775 = arith.select %770, %774, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %776 = arith.xori %742, %775 : tensor<1x64xi16> loc(#loc246)
    %777 = tt.bitcast %773 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %778 = tt.reshape %777 : tensor<1x64xf32> -> tensor<32x2x1xf32> loc(#loc201)
    %779 = tt.bitcast %778 : tensor<32x2x1xf32> -> tensor<32x2x1xi32> loc(#loc202)
    %780 = arith.muli %779, %26 : tensor<32x2x1xi32> loc(#loc204)
    %781 = "tt.reduce"(%780) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc206 at #loc20)), %arg8: i32 loc(callsite(#loc206 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc260)
      tt.reduce.return %840 : i32 loc(#loc248)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc248)
    %782 = tt.expand_dims %781 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc208)
    %783 = tt.broadcast %782 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc209)
    %784 = arith.muli %779, %31 : tensor<32x2x1xi32> loc(#loc210)
    %785 = "tt.reduce"(%784) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc212 at #loc20)), %arg8: i32 loc(callsite(#loc212 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i32 loc(#loc261)
      tt.reduce.return %840 : i32 loc(#loc251)
    }) : (tensor<32x2x1xi32>) -> tensor<32x1xi32> loc(#loc251)
    %786 = tt.expand_dims %785 {axis = 1 : i32} : tensor<32x1xi32> -> tensor<32x1x1xi32> loc(#loc214)
    %787 = tt.broadcast %786 : tensor<32x1x1xi32> -> tensor<32x2x1xi32> loc(#loc215)
    %788 = tt.reshape %783 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc216)
    %789 = tt.reshape %787 : tensor<32x2x1xi32> -> tensor<1x64xi32> loc(#loc217)
    %790 = tt.bitcast %788 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc218)
    %791 = tt.bitcast %789 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc219)
    %792 = tt.reshape %776 : tensor<1x64xi16> -> tensor<32x2x1xi16> loc(#loc220)
    %793 = arith.muli %792, %42 : tensor<32x2x1xi16> loc(#loc222)
    %794 = "tt.reduce"(%793) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc224 at #loc20)), %arg8: i16 loc(callsite(#loc224 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc262)
      tt.reduce.return %840 : i16 loc(#loc254)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc254)
    %795 = tt.expand_dims %794 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc226)
    %796 = tt.broadcast %795 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc227)
    %797 = arith.muli %792, %48 : tensor<32x2x1xi16> loc(#loc229)
    %798 = "tt.reduce"(%797) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc231 at #loc20)), %arg8: i16 loc(callsite(#loc231 at #loc20))):
      %840 = arith.addi %arg7, %arg8 : i16 loc(#loc263)
      tt.reduce.return %840 : i16 loc(#loc257)
    }) : (tensor<32x2x1xi16>) -> tensor<32x1xi16> loc(#loc257)
    %799 = tt.expand_dims %798 {axis = 1 : i32} : tensor<32x1xi16> -> tensor<32x1x1xi16> loc(#loc233)
    %800 = tt.broadcast %799 : tensor<32x1x1xi16> -> tensor<32x2x1xi16> loc(#loc234)
    %801 = tt.reshape %796 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc235)
    %802 = tt.reshape %800 : tensor<32x2x1xi16> -> tensor<1x64xi16> loc(#loc236)
    %803 = tt.bitcast %777 : tensor<1x64xf32> -> tensor<1x64xi32> loc(#loc237)
    %804 = arith.cmpf olt, %790, %791 : tensor<1x64xf32> loc(#loc238)
    %805 = arith.xori %788, %789 : tensor<1x64xi32> loc(#loc241)
    %806 = arith.select %804, %805, %cst_0 : tensor<1x64xi1>, tensor<1x64xi32> loc(#loc242)
    %807 = arith.xori %803, %806 : tensor<1x64xi32> loc(#loc243)
    %808 = arith.xori %801, %802 : tensor<1x64xi16> loc(#loc244)
    %809 = arith.select %804, %808, %cst : tensor<1x64xi1>, tensor<1x64xi16> loc(#loc245)
    %810 = arith.xori %776, %809 : tensor<1x64xi16> loc(#loc246)
    %811 = tt.bitcast %807 : tensor<1x64xi32> -> tensor<1x64xf32> loc(#loc247)
    %812 = arith.extsi %810 : tensor<1x64xi16> to tensor<1x64xi64> loc(#loc66)
    %813 = arith.addi %812, %cst_3 : tensor<1x64xi64> loc(#loc67)
    %814 = arith.cmpi slt, %812, %cst_2 : tensor<1x64xi64> loc(#loc68)
    %815 = arith.select %814, %813, %812 : tensor<1x64xi1>, tensor<1x64xi64> loc(#loc69)
    %816 = arith.cmpi sge, %815, %cst_2 : tensor<1x64xi64> loc(#loc70)
    %817 = arith.cmpi slt, %815, %cst_3 : tensor<1x64xi64> loc(#loc71)
    %818 = arith.andi %816, %817 : tensor<1x64xi1> loc(#loc72)
    tt.assert %818, "index out of bounds: 0 <= tmp18 < 64" : tensor<1x64xi1> loc(#loc73)
    %819 = arith.divsi %815, %cst_5 : tensor<1x64xi64> loc(#loc74)
    %820 = arith.remsi %819, %cst_4 : tensor<1x64xi64> loc(#loc75)
    %821 = arith.muli %820, %cst_3 : tensor<1x64xi64> loc(#loc76)
    %822 = arith.addi %821, %cst_5 : tensor<1x64xi64> loc(#loc77)
    %823 = arith.remsi %815, %cst_5 : tensor<1x64xi64> loc(#loc78)
    %824 = arith.addi %822, %823 : tensor<1x64xi64> loc(#loc79)
    %825 = tt.addptr %10, %824 : tensor<1x64x!tt.ptr<f32>>, tensor<1x64xi64> loc(#loc80)
    %826 = tt.load %825 evictionPolicy = evict_last : tensor<1x64x!tt.ptr<f32>> loc(#loc81)
    %827 = "tt.reduce"(%826) <{axis = 1 : i32}> ({
    ^bb0(%arg7: f32 loc(callsite(#loc1 at #loc82)), %arg8: f32 loc(callsite(#loc1 at #loc82))):
      %840 = arith.addf %arg7, %arg8 : f32 loc(#loc200)
      tt.reduce.return %840 : f32 loc(#loc145)
    }) : (tensor<1x64xf32>) -> tensor<1xf32> loc(#loc145)
    %828 = tt.expand_dims %827 {axis = 1 : i32} : tensor<1xf32> -> tensor<1x1xf32> loc(#loc83)
    %829 = "tt.scan"(%826) <{axis = 1 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %840 = arith.addf %arg7, %arg8 : f32 loc(#loc147)
      tt.scan.return %840 : f32 loc(#loc84)
    }) : (tensor<1x64xf32>) -> tensor<1x64xf32> loc(#loc84)
    %830 = arith.subf %cst_6, %826 : tensor<1x64xf32> loc(#loc86)
    %831 = "tt.scan"(%830) <{axis = 1 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %840 = arith.addf %arg7, %arg8 : f32 loc(#loc148)
      tt.scan.return %840 : f32 loc(#loc87)
    }) : (tensor<1x64xf32>) -> tensor<1x64xf32> loc(#loc87)
    %832 = tt.splat %arg2 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>> loc(#loc88)
    %833 = tt.addptr %832, %1 : tensor<1x64x!tt.ptr<f32>>, tensor<1x64xi32> loc(#loc88)
    tt.store %833, %811 : tensor<1x64x!tt.ptr<f32>> loc(#loc89)
    %834 = tt.splat %arg4 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>> loc(#loc90)
    %835 = tt.addptr %834, %1 : tensor<1x64x!tt.ptr<f32>>, tensor<1x64xi32> loc(#loc90)
    tt.store %835, %829 : tensor<1x64x!tt.ptr<f32>> loc(#loc91)
    %836 = tt.splat %arg5 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>> loc(#loc92)
    %837 = tt.addptr %836, %1 : tensor<1x64x!tt.ptr<f32>>, tensor<1x64xi32> loc(#loc92)
    tt.store %837, %831 : tensor<1x64x!tt.ptr<f32>> loc(#loc93)
    %838 = tt.addptr %arg3, %c0_i32 : !tt.ptr<f32>, i32 loc(#loc94)
    %839 = tt.splat %838 : !tt.ptr<f32> -> tensor<1x1x!tt.ptr<f32>> loc(#loc94)
    tt.store %839, %828 : tensor<1x1x!tt.ptr<f32>> loc(#loc95)
    tt.return loc(#loc96)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":31:26)
#loc3 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":31:34)
#loc4 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":35:45)
#loc5 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":35:39)
#loc6 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":35:35)
#loc7 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":35:58)
#loc8 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":35:53)
#loc9 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":35:30)
#loc10 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":35:65)
#loc11 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":36:30)
#loc12 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":36:65)
#loc13 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":38:18)
#loc14 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":40:18)
#loc15 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":41:18)
#loc16 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":42:18)
#loc17 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":44:19)
#loc18 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:41)
#loc21 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:44)
#loc22 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:60)
#loc23 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:68)
#loc24 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":501:22)
#loc26 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":502:14)
#loc27 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":505:21)
#loc28 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:40)
#loc29 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":267:36)
#loc31 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":256:15)
#loc32 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:54)
#loc33 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:67)
#loc34 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:41)
#loc36 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:56)
#loc37 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:69)
#loc38 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":508:30)
#loc39 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":509:32)
#loc40 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":510:20)
#loc41 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":511:22)
#loc42 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":514:29)
#loc43 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:36)
#loc44 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:23)
#loc46 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:53)
#loc47 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:66)
#loc48 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:37)
#loc49 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:23)
#loc51 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:54)
#loc52 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:67)
#loc53 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":521:36)
#loc54 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":522:38)
#loc55 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":533:14)
#loc56 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":536:22)
#loc57 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:19)
#loc58 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:28)
#loc59 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:38)
#loc60 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:46)
#loc61 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:15)
#loc62 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:48)
#loc63 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:59)
#loc64 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:22)
#loc65 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":551:18)
#loc66 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":48:21)
#loc67 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":50:20)
#loc68 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":51:20)
#loc69 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":52:35)
#loc70 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":53:27)
#loc71 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":53:45)
#loc72 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":53:37)
#loc73 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":53:50)
#loc74 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:51)
#loc75 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:57)
#loc76 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:41)
#loc77 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:36)
#loc78 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:73)
#loc79 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:65)
#loc80 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:31)
#loc81 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":54:80)
#loc83 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":56:29)
#loc84 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":59:46)
#loc85 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":13:20)
#loc86 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":60:19)
#loc87 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":63:46)
#loc88 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":64:25)
#loc89 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":64:72)
#loc90 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":65:25)
#loc91 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":65:72)
#loc92 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":66:25)
#loc93 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":66:72)
#loc94 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":67:25)
#loc95 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":67:68)
#loc96 = loc("inductor_cache/xt/cxtiegln6xkum57ozsiuv6fnnj4itfsc2puifyknloelgx2ba6ms.py":67:4)
#loc97 = loc(callsite(#loc18 at #loc19))
#loc98 = loc(callsite(#loc21 at #loc19))
#loc99 = loc(callsite(#loc22 at #loc19))
#loc100 = loc(callsite(#loc23 at #loc19))
#loc101 = loc(callsite(#loc24 at #loc25))
#loc102 = loc(callsite(#loc26 at #loc25))
#loc103 = loc(callsite(#loc27 at #loc25))
#loc104 = loc(callsite(#loc28 at #loc25))
#loc105 = loc(callsite(#loc29 at #loc30))
#loc107 = loc(callsite(#loc31 at #loc29))
#loc108 = loc(callsite(#loc32 at #loc25))
#loc109 = loc(callsite(#loc33 at #loc25))
#loc110 = loc(callsite(#loc34 at #loc25))
#loc111 = loc(callsite(#loc29 at #loc35))
#loc113 = loc(callsite(#loc36 at #loc25))
#loc114 = loc(callsite(#loc37 at #loc25))
#loc115 = loc(callsite(#loc38 at #loc25))
#loc116 = loc(callsite(#loc39 at #loc25))
#loc117 = loc(callsite(#loc40 at #loc25))
#loc118 = loc(callsite(#loc41 at #loc25))
#loc119 = loc(callsite(#loc42 at #loc25))
#loc120 = loc(callsite(#loc43 at #loc25))
#loc121 = loc(callsite(#loc44 at #loc25))
#loc122 = loc(callsite(#loc29 at #loc45))
#loc124 = loc(callsite(#loc46 at #loc25))
#loc125 = loc(callsite(#loc47 at #loc25))
#loc126 = loc(callsite(#loc48 at #loc25))
#loc127 = loc(callsite(#loc49 at #loc25))
#loc128 = loc(callsite(#loc29 at #loc50))
#loc130 = loc(callsite(#loc51 at #loc25))
#loc131 = loc(callsite(#loc52 at #loc25))
#loc132 = loc(callsite(#loc53 at #loc25))
#loc133 = loc(callsite(#loc54 at #loc25))
#loc134 = loc(callsite(#loc55 at #loc25))
#loc135 = loc(callsite(#loc56 at #loc25))
#loc136 = loc(callsite(#loc57 at #loc25))
#loc137 = loc(callsite(#loc58 at #loc25))
#loc138 = loc(callsite(#loc59 at #loc25))
#loc139 = loc(callsite(#loc60 at #loc25))
#loc140 = loc(callsite(#loc61 at #loc25))
#loc141 = loc(callsite(#loc62 at #loc25))
#loc142 = loc(callsite(#loc63 at #loc25))
#loc143 = loc(callsite(#loc64 at #loc25))
#loc144 = loc(callsite(#loc65 at #loc25))
#loc145 = loc(callsite(#loc29 at #loc82))
#loc147 = loc(callsite(#loc85 at #loc84))
#loc148 = loc(callsite(#loc85 at #loc87))
#loc149 = loc(callsite(#loc97 at #loc20))
#loc150 = loc(callsite(#loc98 at #loc20))
#loc151 = loc(callsite(#loc99 at #loc20))
#loc152 = loc(callsite(#loc100 at #loc20))
#loc153 = loc(callsite(#loc101 at #loc19))
#loc154 = loc(callsite(#loc102 at #loc19))
#loc155 = loc(callsite(#loc103 at #loc19))
#loc156 = loc(callsite(#loc104 at #loc19))
#loc157 = loc(callsite(#loc105 at #loc25))
#loc159 = loc(callsite(#loc107 at #loc30))
#loc160 = loc(callsite(#loc108 at #loc19))
#loc161 = loc(callsite(#loc109 at #loc19))
#loc162 = loc(callsite(#loc110 at #loc19))
#loc163 = loc(callsite(#loc111 at #loc25))
#loc165 = loc(callsite(#loc107 at #loc35))
#loc166 = loc(callsite(#loc113 at #loc19))
#loc167 = loc(callsite(#loc114 at #loc19))
#loc168 = loc(callsite(#loc115 at #loc19))
#loc169 = loc(callsite(#loc116 at #loc19))
#loc170 = loc(callsite(#loc117 at #loc19))
#loc171 = loc(callsite(#loc118 at #loc19))
#loc172 = loc(callsite(#loc119 at #loc19))
#loc173 = loc(callsite(#loc120 at #loc19))
#loc174 = loc(callsite(#loc121 at #loc19))
#loc175 = loc(callsite(#loc122 at #loc25))
#loc177 = loc(callsite(#loc107 at #loc45))
#loc178 = loc(callsite(#loc124 at #loc19))
#loc179 = loc(callsite(#loc125 at #loc19))
#loc180 = loc(callsite(#loc126 at #loc19))
#loc181 = loc(callsite(#loc127 at #loc19))
#loc182 = loc(callsite(#loc128 at #loc25))
#loc184 = loc(callsite(#loc107 at #loc50))
#loc185 = loc(callsite(#loc130 at #loc19))
#loc186 = loc(callsite(#loc131 at #loc19))
#loc187 = loc(callsite(#loc132 at #loc19))
#loc188 = loc(callsite(#loc133 at #loc19))
#loc189 = loc(callsite(#loc134 at #loc19))
#loc190 = loc(callsite(#loc135 at #loc19))
#loc191 = loc(callsite(#loc136 at #loc19))
#loc192 = loc(callsite(#loc137 at #loc19))
#loc193 = loc(callsite(#loc138 at #loc19))
#loc194 = loc(callsite(#loc139 at #loc19))
#loc195 = loc(callsite(#loc140 at #loc19))
#loc196 = loc(callsite(#loc141 at #loc19))
#loc197 = loc(callsite(#loc142 at #loc19))
#loc198 = loc(callsite(#loc143 at #loc19))
#loc199 = loc(callsite(#loc144 at #loc19))
#loc200 = loc(callsite(#loc107 at #loc82))
#loc201 = loc(callsite(#loc153 at #loc20))
#loc202 = loc(callsite(#loc154 at #loc20))
#loc203 = loc(callsite(#loc155 at #loc20))
#loc204 = loc(callsite(#loc156 at #loc20))
#loc205 = loc(callsite(#loc157 at #loc19))
#loc207 = loc(callsite(#loc159 at #loc25))
#loc208 = loc(callsite(#loc160 at #loc20))
#loc209 = loc(callsite(#loc161 at #loc20))
#loc210 = loc(callsite(#loc162 at #loc20))
#loc211 = loc(callsite(#loc163 at #loc19))
#loc213 = loc(callsite(#loc165 at #loc25))
#loc214 = loc(callsite(#loc166 at #loc20))
#loc215 = loc(callsite(#loc167 at #loc20))
#loc216 = loc(callsite(#loc168 at #loc20))
#loc217 = loc(callsite(#loc169 at #loc20))
#loc218 = loc(callsite(#loc170 at #loc20))
#loc219 = loc(callsite(#loc171 at #loc20))
#loc220 = loc(callsite(#loc172 at #loc20))
#loc221 = loc(callsite(#loc173 at #loc20))
#loc222 = loc(callsite(#loc174 at #loc20))
#loc223 = loc(callsite(#loc175 at #loc19))
#loc225 = loc(callsite(#loc177 at #loc25))
#loc226 = loc(callsite(#loc178 at #loc20))
#loc227 = loc(callsite(#loc179 at #loc20))
#loc228 = loc(callsite(#loc180 at #loc20))
#loc229 = loc(callsite(#loc181 at #loc20))
#loc230 = loc(callsite(#loc182 at #loc19))
#loc232 = loc(callsite(#loc184 at #loc25))
#loc233 = loc(callsite(#loc185 at #loc20))
#loc234 = loc(callsite(#loc186 at #loc20))
#loc235 = loc(callsite(#loc187 at #loc20))
#loc236 = loc(callsite(#loc188 at #loc20))
#loc237 = loc(callsite(#loc189 at #loc20))
#loc238 = loc(callsite(#loc190 at #loc20))
#loc239 = loc(callsite(#loc191 at #loc20))
#loc240 = loc(callsite(#loc192 at #loc20))
#loc241 = loc(callsite(#loc193 at #loc20))
#loc242 = loc(callsite(#loc194 at #loc20))
#loc243 = loc(callsite(#loc195 at #loc20))
#loc244 = loc(callsite(#loc196 at #loc20))
#loc245 = loc(callsite(#loc197 at #loc20))
#loc246 = loc(callsite(#loc198 at #loc20))
#loc247 = loc(callsite(#loc199 at #loc20))
#loc248 = loc(callsite(#loc205 at #loc20))
#loc250 = loc(callsite(#loc207 at #loc19))
#loc251 = loc(callsite(#loc211 at #loc20))
#loc253 = loc(callsite(#loc213 at #loc19))
#loc254 = loc(callsite(#loc223 at #loc20))
#loc256 = loc(callsite(#loc225 at #loc19))
#loc257 = loc(callsite(#loc230 at #loc20))
#loc259 = loc(callsite(#loc232 at #loc19))
#loc260 = loc(callsite(#loc250 at #loc20))
#loc261 = loc(callsite(#loc253 at #loc20))
#loc262 = loc(callsite(#loc256 at #loc20))
#loc263 = loc(callsite(#loc259 at #loc20))
