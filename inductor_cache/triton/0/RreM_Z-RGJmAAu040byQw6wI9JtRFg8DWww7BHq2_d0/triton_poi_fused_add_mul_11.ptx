//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	triton_poi_fused_add_mul_11 // -- Begin function triton_poi_fused_add_mul_11
.extern .shared .align 16 .b8 global_smem[];
                                        // @triton_poi_fused_add_mul_11
.visible .entry triton_poi_fused_add_mul_11(
	.param .u64 .ptr .global .align 1 triton_poi_fused_add_mul_11_param_0,
	.param .u64 .ptr .global .align 1 triton_poi_fused_add_mul_11_param_1,
	.param .u64 .ptr .global .align 1 triton_poi_fused_add_mul_11_param_2,
	.param .u64 .ptr .global .align 1 triton_poi_fused_add_mul_11_param_3,
	.param .u64 .ptr .global .align 1 triton_poi_fused_add_mul_11_param_4,
	.param .u64 .ptr .global .align 1 triton_poi_fused_add_mul_11_param_5,
	.param .u32 triton_poi_fused_add_mul_11_param_6,
	.param .u32 triton_poi_fused_add_mul_11_param_7
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<57>;
	.reg .b32 	%r<270>;
	.reg .f32 	%f<133>;
	.reg .b64 	%rd<40>;
	.loc	1 19 0                          // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:19:0
$L__func_begin0:
	.loc	1 19 0                          // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:19:0

// %bb.0:
	ld.param.u64 	%rd25, [triton_poi_fused_add_mul_11_param_0];
	ld.param.u64 	%rd26, [triton_poi_fused_add_mul_11_param_1];
$L__tmp0:
	.loc	1 22 28                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:22:28
	// begin inline asm
	mov.u32 %r1, %ctaid.y;
	// end inline asm
	.loc	1 22 33                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:22:33
	shl.b32 	%r151, %r1, 6;
	ld.param.u64 	%rd27, [triton_poi_fused_add_mul_11_param_2];
	ld.param.u64 	%rd28, [triton_poi_fused_add_mul_11_param_3];
	.loc	1 23 44                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:23:44
	mov.u32 	%r152, %tid.x;
	ld.param.u64 	%rd29, [triton_poi_fused_add_mul_11_param_4];
	bfe.u32 	%r153, %r152, 4, 4;
	ld.param.u64 	%rd30, [triton_poi_fused_add_mul_11_param_5];
	or.b32  	%r154, %r153, 16;
	or.b32  	%r155, %r153, 32;
	or.b32  	%r156, %r153, 48;
	shl.b32 	%r157, %r152, 2;
	and.b32  	%r158, %r157, 60;
	.loc	1 23 23                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:23:23
	or.b32  	%r159, %r151, %r153;
	or.b32  	%r160, %r151, %r154;
	or.b32  	%r161, %r151, %r155;
	or.b32  	%r162, %r151, %r156;
	or.b32  	%r163, %r151, %r158;
	.loc	1 25 28                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:25:28
	// begin inline asm
	mov.u32 %r2, %ctaid.x;
	// end inline asm
	.loc	1 25 33                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:25:33
	shl.b32 	%r164, %r2, 6;
	.loc	1 26 23                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:26:23
	or.b32  	%r165, %r164, %r158;
	or.b32  	%r166, %r164, %r153;
	or.b32  	%r167, %r164, %r154;
	or.b32  	%r168, %r164, %r155;
	or.b32  	%r169, %r164, %r156;
	.loc	1 27 21                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:27:21
	setp.lt.s32 	%p1, %r165, 128;
	setp.lt.s32 	%p9, %r166, 128;
	setp.lt.s32 	%p10, %r167, 128;
	setp.lt.s32 	%p11, %r168, 128;
	setp.lt.s32 	%p12, %r169, 128;
	.loc	1 30 19                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:30:19
	shr.s32 	%r171, %r163, 31;
	shr.u32 	%r172, %r171, 24;
	add.s32 	%r173, %r163, %r172;
	.loc	1 31 19                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:31:19
	and.b32  	%r174, %r173, -256;
	sub.s32 	%r175, %r163, %r174;
	.loc	1 32 21                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:32:21
	bfe.s32 	%r176, %r1, 25, 1;
	shr.u32 	%r177, %r176, 28;
	add.s32 	%r178, %r163, %r177;
	shr.s32 	%r179, %r178, 4;
	.loc	1 32 27                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:32:27
	shr.u32 	%r180, %r179, 28;
	add.s32 	%r181, %r179, %r180;
	and.b32  	%r182, %r181, -16;
	sub.s32 	%r183, %r179, %r182;
	.loc	1 33 39                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:33:39
	shl.b32 	%r184, %r159, 7;
	shl.b32 	%r185, %r160, 7;
	shl.b32 	%r186, %r161, 7;
	shl.b32 	%r187, %r162, 7;
	.loc	1 33 35                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:33:35
	add.s32 	%r188, %r165, %r184;
	add.s32 	%r189, %r165, %r185;
	add.s32 	%r190, %r165, %r186;
	add.s32 	%r191, %r165, %r187;
	.loc	1 33 30                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:33:30
	mul.wide.s32 	%rd31, %r188, 4;
	add.s64 	%rd1, %rd25, %rd31;
	mul.wide.s32 	%rd32, %r189, 4;
	add.s64 	%rd2, %rd25, %rd32;
	mul.wide.s32 	%rd33, %r190, 4;
	add.s64 	%rd3, %rd25, %rd33;
	mul.wide.s32 	%rd34, %r191, 4;
	add.s64 	%rd4, %rd25, %rd34;
	.loc	1 33 44                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:33:44
	// begin inline asm
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	mov.u32 %r5, 0x0;
	mov.u32 %r6, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r3, %r4, %r5, %r6 }, [ %rd1 + 0 ];
	// end inline asm
	mov.b32 	%f1, %r3;
	mov.b32 	%f2, %r4;
	mov.b32 	%f3, %r5;
	mov.b32 	%f4, %r6;
	// begin inline asm
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	mov.u32 %r9, 0x0;
	mov.u32 %r10, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r7, %r8, %r9, %r10 }, [ %rd2 + 0 ];
	// end inline asm
	mov.b32 	%f5, %r7;
	mov.b32 	%f6, %r8;
	mov.b32 	%f7, %r9;
	mov.b32 	%f8, %r10;
	// begin inline asm
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	mov.u32 %r13, 0x0;
	mov.u32 %r14, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r11, %r12, %r13, %r14 }, [ %rd3 + 0 ];
	// end inline asm
	mov.b32 	%f9, %r11;
	mov.b32 	%f10, %r12;
	mov.b32 	%f11, %r13;
	mov.b32 	%f12, %r14;
	// begin inline asm
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	mov.u32 %r17, 0x0;
	mov.u32 %r18, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r15, %r16, %r17, %r18 }, [ %rd4 + 0 ];
	// end inline asm
	mov.b32 	%f13, %r15;
	mov.b32 	%f14, %r16;
	mov.b32 	%f15, %r17;
	mov.b32 	%f16, %r18;
	.loc	1 34 30                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:34:30
	add.s64 	%rd5, %rd26, %rd31;
	add.s64 	%rd6, %rd26, %rd32;
	add.s64 	%rd7, %rd26, %rd33;
	add.s64 	%rd8, %rd26, %rd34;
	.loc	1 34 44                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:34:44
	// begin inline asm
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	mov.u32 %r21, 0x0;
	mov.u32 %r22, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r19, %r20, %r21, %r22 }, [ %rd5 + 0 ];
	// end inline asm
	mov.b32 	%f17, %r19;
	mov.b32 	%f18, %r20;
	mov.b32 	%f19, %r21;
	mov.b32 	%f20, %r22;
	// begin inline asm
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	mov.u32 %r25, 0x0;
	mov.u32 %r26, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r23, %r24, %r25, %r26 }, [ %rd6 + 0 ];
	// end inline asm
	mov.b32 	%f21, %r23;
	mov.b32 	%f22, %r24;
	mov.b32 	%f23, %r25;
	mov.b32 	%f24, %r26;
	// begin inline asm
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	mov.u32 %r29, 0x0;
	mov.u32 %r30, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r27, %r28, %r29, %r30 }, [ %rd7 + 0 ];
	// end inline asm
	mov.b32 	%f25, %r27;
	mov.b32 	%f26, %r28;
	mov.b32 	%f27, %r29;
	mov.b32 	%f28, %r30;
	// begin inline asm
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	mov.u32 %r33, 0x0;
	mov.u32 %r34, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r31, %r32, %r33, %r34 }, [ %rd8 + 0 ];
	// end inline asm
	mov.b32 	%f29, %r31;
	mov.b32 	%f30, %r32;
	mov.b32 	%f31, %r33;
	mov.b32 	%f32, %r34;
	.loc	1 35 39                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:35:39
	shl.b32 	%r192, %r166, 8;
	shl.b32 	%r193, %r167, 8;
	shl.b32 	%r194, %r168, 8;
	shl.b32 	%r195, %r169, 8;
	.loc	1 35 50                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:35:50
	shl.b32 	%r196, %r173, 7;
	and.b32  	%r197, %r196, -32768;
	.loc	1 35 35                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:35:35
	add.s32 	%r198, %r197, %r175;
	.loc	1 35 44                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:35:44
	add.s32 	%r199, %r198, %r192;
	add.s32 	%r200, %r198, %r193;
	add.s32 	%r201, %r198, %r194;
	add.s32 	%r202, %r198, %r195;
	.loc	1 35 30                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:35:30
	mul.wide.s32 	%rd35, %r199, 4;
	add.s64 	%rd9, %rd27, %rd35;
	mul.wide.s32 	%rd36, %r200, 4;
	add.s64 	%rd10, %rd27, %rd36;
	mul.wide.s32 	%rd37, %r201, 4;
	add.s64 	%rd11, %rd27, %rd37;
	mul.wide.s32 	%rd38, %r202, 4;
	add.s64 	%rd12, %rd27, %rd38;
	.loc	1 35 55                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:35:55
	// begin inline asm
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	mov.u32 %r37, 0x0;
	mov.u32 %r38, 0x0;
	@%p9 ld.global.L1::evict_last.v4.b32 { %r35, %r36, %r37, %r38 }, [ %rd9 + 0 ];
	// end inline asm
	mov.b32 	%f33, %r35;
	mov.b32 	%f34, %r36;
	mov.b32 	%f35, %r37;
	mov.b32 	%f36, %r38;
	// begin inline asm
	mov.u32 %r39, 0x0;
	mov.u32 %r40, 0x0;
	mov.u32 %r41, 0x0;
	mov.u32 %r42, 0x0;
	@%p10 ld.global.L1::evict_last.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd10 + 0 ];
	// end inline asm
	mov.b32 	%f37, %r39;
	mov.b32 	%f38, %r40;
	mov.b32 	%f39, %r41;
	mov.b32 	%f40, %r42;
	// begin inline asm
	mov.u32 %r43, 0x0;
	mov.u32 %r44, 0x0;
	mov.u32 %r45, 0x0;
	mov.u32 %r46, 0x0;
	@%p11 ld.global.L1::evict_last.v4.b32 { %r43, %r44, %r45, %r46 }, [ %rd11 + 0 ];
	// end inline asm
	mov.b32 	%f41, %r43;
	mov.b32 	%f42, %r44;
	mov.b32 	%f43, %r45;
	mov.b32 	%f44, %r46;
	// begin inline asm
	mov.u32 %r47, 0x0;
	mov.u32 %r48, 0x0;
	mov.u32 %r49, 0x0;
	mov.u32 %r50, 0x0;
	@%p12 ld.global.L1::evict_last.v4.b32 { %r47, %r48, %r49, %r50 }, [ %rd12 + 0 ];
	// end inline asm
	mov.b32 	%f45, %r47;
	mov.b32 	%f46, %r48;
	mov.b32 	%f47, %r49;
	mov.b32 	%f48, %r50;
	.loc	1 36 30                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:36:30
	add.s64 	%rd13, %rd28, %rd35;
	add.s64 	%rd14, %rd28, %rd36;
	add.s64 	%rd15, %rd28, %rd37;
	add.s64 	%rd16, %rd28, %rd38;
	.loc	1 36 55                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:36:55
	// begin inline asm
	mov.u32 %r51, 0x0;
	mov.u32 %r52, 0x0;
	mov.u32 %r53, 0x0;
	mov.u32 %r54, 0x0;
	@%p9 ld.global.L1::evict_last.v4.b32 { %r51, %r52, %r53, %r54 }, [ %rd13 + 0 ];
	// end inline asm
	mov.b32 	%f49, %r51;
	mov.b32 	%f50, %r52;
	mov.b32 	%f51, %r53;
	mov.b32 	%f52, %r54;
	// begin inline asm
	mov.u32 %r55, 0x0;
	mov.u32 %r56, 0x0;
	mov.u32 %r57, 0x0;
	mov.u32 %r58, 0x0;
	@%p10 ld.global.L1::evict_last.v4.b32 { %r55, %r56, %r57, %r58 }, [ %rd14 + 0 ];
	// end inline asm
	mov.b32 	%f53, %r55;
	mov.b32 	%f54, %r56;
	mov.b32 	%f55, %r57;
	mov.b32 	%f56, %r58;
	// begin inline asm
	mov.u32 %r59, 0x0;
	mov.u32 %r60, 0x0;
	mov.u32 %r61, 0x0;
	mov.u32 %r62, 0x0;
	@%p11 ld.global.L1::evict_last.v4.b32 { %r59, %r60, %r61, %r62 }, [ %rd15 + 0 ];
	// end inline asm
	mov.b32 	%f57, %r59;
	mov.b32 	%f58, %r60;
	mov.b32 	%f59, %r61;
	mov.b32 	%f60, %r62;
	// begin inline asm
	mov.u32 %r63, 0x0;
	mov.u32 %r64, 0x0;
	mov.u32 %r65, 0x0;
	mov.u32 %r66, 0x0;
	@%p12 ld.global.L1::evict_last.v4.b32 { %r63, %r64, %r65, %r66 }, [ %rd16 + 0 ];
	// end inline asm
	mov.b32 	%f61, %r63;
	mov.b32 	%f62, %r64;
	mov.b32 	%f63, %r65;
	mov.b32 	%f64, %r66;
	.loc	1 37 30                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:37:30
	mul.wide.s32 	%rd39, %r183, 4;
	add.s64 	%rd17, %rd29, %rd39;
	mov.pred 	%p17, -1;
	.loc	1 37 35                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:37:35
	// begin inline asm
	mov.u32 %r67, 0x0;
	@%p17 ld.global.L1::evict_last.b32 { %r67 }, [ %rd17 + 0 ];
	// end inline asm
	mov.b32 	%f65, %r67;
	// begin inline asm
	mov.u32 %r68, 0x0;
	@%p17 ld.global.L1::evict_last.b32 { %r68 }, [ %rd17 + 0 ];
	// end inline asm
	mov.b32 	%f66, %r68;
	// begin inline asm
	mov.u32 %r69, 0x0;
	@%p17 ld.global.L1::evict_last.b32 { %r69 }, [ %rd17 + 0 ];
	// end inline asm
	mov.b32 	%f67, %r69;
	// begin inline asm
	mov.u32 %r70, 0x0;
	@%p17 ld.global.L1::evict_last.b32 { %r70 }, [ %rd17 + 0 ];
	// end inline asm
	mov.b32 	%f68, %r70;
	.loc	1 38 18                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:38:18
	mul.f32 	%f69, %f1, %f17;
	mul.f32 	%f70, %f2, %f18;
	mul.f32 	%f71, %f3, %f19;
	mul.f32 	%f72, %f4, %f20;
	mul.f32 	%f73, %f5, %f21;
	mul.f32 	%f74, %f6, %f22;
	mul.f32 	%f75, %f7, %f23;
	mul.f32 	%f76, %f8, %f24;
	mul.f32 	%f77, %f9, %f25;
	mul.f32 	%f78, %f10, %f26;
	mul.f32 	%f79, %f11, %f27;
	mul.f32 	%f80, %f12, %f28;
	mul.f32 	%f81, %f13, %f29;
	mul.f32 	%f82, %f14, %f30;
	mul.f32 	%f83, %f15, %f31;
	mul.f32 	%f84, %f16, %f32;
	shl.b32 	%r203, %r152, 8;
	and.b32  	%r204, %r203, 3840;
	or.b32  	%r205, %r204, %r153;
	and.b32  	%r206, %r157, 1020;
	shr.u32 	%r207, %r204, 2;
	mov.u32 	%r208, global_smem;
	add.s32 	%r209, %r208, %r207;
	shl.b32 	%r210, %r205, 2;
	add.s32 	%r71, %r209, %r210;
	mov.b32 	%r72, %f69;
	// begin inline asm
	@%p17 st.shared.b32 [ %r71 + 0 ], %r72;
	// end inline asm
	or.b32  	%r211, %r204, 64;
	shr.u32 	%r212, %r211, 6;
	shl.b32 	%r213, %r212, 4;
	add.s32 	%r214, %r208, %r213;
	add.s32 	%r215, %r214, %r210;
	add.s32 	%r73, %r215, 256;
	mov.b32 	%r74, %f70;
	// begin inline asm
	@%p17 st.shared.b32 [ %r73 + 0 ], %r74;
	// end inline asm
	or.b32  	%r216, %r204, 128;
	shr.u32 	%r217, %r216, 6;
	shl.b32 	%r218, %r217, 4;
	add.s32 	%r219, %r208, %r218;
	add.s32 	%r220, %r219, %r210;
	add.s32 	%r75, %r220, 512;
	mov.b32 	%r76, %f71;
	// begin inline asm
	@%p17 st.shared.b32 [ %r75 + 0 ], %r76;
	// end inline asm
	or.b32  	%r221, %r204, 192;
	shr.u32 	%r222, %r221, 6;
	shl.b32 	%r223, %r222, 4;
	add.s32 	%r224, %r208, %r223;
	add.s32 	%r225, %r224, %r210;
	add.s32 	%r77, %r225, 768;
	mov.b32 	%r78, %f72;
	// begin inline asm
	@%p17 st.shared.b32 [ %r77 + 0 ], %r78;
	// end inline asm
	add.s32 	%r79, %r71, 64;
	mov.b32 	%r80, %f73;
	// begin inline asm
	@%p17 st.shared.b32 [ %r79 + 0 ], %r80;
	// end inline asm
	add.s32 	%r81, %r215, 320;
	mov.b32 	%r82, %f74;
	// begin inline asm
	@%p17 st.shared.b32 [ %r81 + 0 ], %r82;
	// end inline asm
	add.s32 	%r83, %r220, 576;
	mov.b32 	%r84, %f75;
	// begin inline asm
	@%p17 st.shared.b32 [ %r83 + 0 ], %r84;
	// end inline asm
	add.s32 	%r85, %r225, 832;
	mov.b32 	%r86, %f76;
	// begin inline asm
	@%p17 st.shared.b32 [ %r85 + 0 ], %r86;
	// end inline asm
	add.s32 	%r87, %r71, 128;
	mov.b32 	%r88, %f77;
	// begin inline asm
	@%p17 st.shared.b32 [ %r87 + 0 ], %r88;
	// end inline asm
	add.s32 	%r89, %r215, 384;
	mov.b32 	%r90, %f78;
	// begin inline asm
	@%p17 st.shared.b32 [ %r89 + 0 ], %r90;
	// end inline asm
	add.s32 	%r91, %r220, 640;
	mov.b32 	%r92, %f79;
	// begin inline asm
	@%p17 st.shared.b32 [ %r91 + 0 ], %r92;
	// end inline asm
	add.s32 	%r93, %r225, 896;
	mov.b32 	%r94, %f80;
	// begin inline asm
	@%p17 st.shared.b32 [ %r93 + 0 ], %r94;
	// end inline asm
	add.s32 	%r95, %r71, 192;
	mov.b32 	%r96, %f81;
	// begin inline asm
	@%p17 st.shared.b32 [ %r95 + 0 ], %r96;
	// end inline asm
	add.s32 	%r97, %r215, 448;
	mov.b32 	%r98, %f82;
	// begin inline asm
	@%p17 st.shared.b32 [ %r97 + 0 ], %r98;
	// end inline asm
	add.s32 	%r99, %r220, 704;
	mov.b32 	%r100, %f83;
	// begin inline asm
	@%p17 st.shared.b32 [ %r99 + 0 ], %r100;
	// end inline asm
	add.s32 	%r101, %r225, 960;
	mov.b32 	%r102, %f84;
	// begin inline asm
	@%p17 st.shared.b32 [ %r101 + 0 ], %r102;
	// end inline asm
	bar.sync 	0;
	bfe.u32 	%r226, %r157, 6, 4;
	and.b32  	%r227, %r152, 255;
	add.s32 	%r228, %r226, %r227;
	shl.b32 	%r229, %r228, 4;
	add.s32 	%r230, %r208, %r229;
	ld.shared.v4.f32 	{%f85, %f86, %f87, %f88}, [%r230];
	or.b32  	%r231, %r206, 1024;
	shr.u32 	%r232, %r231, 6;
	shl.b32 	%r233, %r232, 4;
	add.s32 	%r234, %r208, %r233;
	shl.b32 	%r235, %r206, 2;
	add.s32 	%r236, %r234, %r235;
	ld.shared.v4.f32 	{%f89, %f90, %f91, %f92}, [%r236+4096];
	or.b32  	%r237, %r206, 2048;
	shr.u32 	%r238, %r237, 6;
	shl.b32 	%r239, %r238, 4;
	add.s32 	%r240, %r208, %r239;
	add.s32 	%r241, %r240, %r235;
	ld.shared.v4.f32 	{%f93, %f94, %f95, %f96}, [%r241+8192];
	or.b32  	%r242, %r206, 3072;
	shr.u32 	%r243, %r242, 6;
	shl.b32 	%r244, %r243, 4;
	add.s32 	%r245, %r208, %r244;
	add.s32 	%r246, %r245, %r235;
	ld.shared.v4.f32 	{%f97, %f98, %f99, %f100}, [%r246+12288];
	.loc	1 40 18                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:40:18
	fma.rn.f32 	%f101, %f49, %f65, %f33;
	fma.rn.f32 	%f102, %f50, %f66, %f34;
	fma.rn.f32 	%f103, %f51, %f67, %f35;
	fma.rn.f32 	%f104, %f52, %f68, %f36;
	fma.rn.f32 	%f105, %f53, %f65, %f37;
	fma.rn.f32 	%f106, %f54, %f66, %f38;
	fma.rn.f32 	%f107, %f55, %f67, %f39;
	fma.rn.f32 	%f108, %f56, %f68, %f40;
	fma.rn.f32 	%f109, %f57, %f65, %f41;
	fma.rn.f32 	%f110, %f58, %f66, %f42;
	fma.rn.f32 	%f111, %f59, %f67, %f43;
	fma.rn.f32 	%f112, %f60, %f68, %f44;
	fma.rn.f32 	%f113, %f61, %f65, %f45;
	fma.rn.f32 	%f114, %f62, %f66, %f46;
	fma.rn.f32 	%f115, %f63, %f67, %f47;
	fma.rn.f32 	%f116, %f64, %f68, %f48;
	.loc	1 41 18                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:41:18
	add.f32 	%f117, %f101, %f85;
	add.f32 	%f118, %f102, %f86;
	add.f32 	%f119, %f103, %f87;
	add.f32 	%f120, %f104, %f88;
	add.f32 	%f121, %f105, %f89;
	add.f32 	%f122, %f106, %f90;
	add.f32 	%f123, %f107, %f91;
	add.f32 	%f124, %f108, %f92;
	add.f32 	%f125, %f109, %f93;
	add.f32 	%f126, %f110, %f94;
	add.f32 	%f127, %f111, %f95;
	add.f32 	%f128, %f112, %f96;
	add.f32 	%f129, %f113, %f97;
	add.f32 	%f130, %f114, %f98;
	add.f32 	%f131, %f115, %f99;
	add.f32 	%f132, %f116, %f100;
	.loc	1 42 25                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:42:25
	add.s64 	%rd21, %rd30, %rd31;
	add.s64 	%rd22, %rd30, %rd32;
	add.s64 	%rd23, %rd30, %rd33;
	add.s64 	%rd24, %rd30, %rd34;
	.loc	1 42 45                         // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:42:45
	bar.sync 	0;
	shr.u32 	%r247, %r204, 4;
	add.s32 	%r248, %r208, %r247;
	add.s32 	%r103, %r248, %r210;
	mov.b32 	%r104, %f117;
	// begin inline asm
	@%p17 st.shared.b32 [ %r103 + 0 ], %r104;
	// end inline asm
	shl.b32 	%r249, %r212, 2;
	add.s32 	%r250, %r208, %r249;
	add.s32 	%r251, %r250, %r210;
	add.s32 	%r105, %r251, 256;
	mov.b32 	%r106, %f118;
	// begin inline asm
	@%p17 st.shared.b32 [ %r105 + 0 ], %r106;
	// end inline asm
	shl.b32 	%r252, %r217, 2;
	add.s32 	%r253, %r208, %r252;
	add.s32 	%r254, %r253, %r210;
	add.s32 	%r107, %r254, 512;
	mov.b32 	%r108, %f119;
	// begin inline asm
	@%p17 st.shared.b32 [ %r107 + 0 ], %r108;
	// end inline asm
	shl.b32 	%r255, %r222, 2;
	add.s32 	%r256, %r208, %r255;
	add.s32 	%r257, %r256, %r210;
	add.s32 	%r109, %r257, 768;
	mov.b32 	%r110, %f120;
	// begin inline asm
	@%p17 st.shared.b32 [ %r109 + 0 ], %r110;
	// end inline asm
	add.s32 	%r111, %r103, 64;
	mov.b32 	%r112, %f121;
	// begin inline asm
	@%p17 st.shared.b32 [ %r111 + 0 ], %r112;
	// end inline asm
	add.s32 	%r113, %r251, 320;
	mov.b32 	%r114, %f122;
	// begin inline asm
	@%p17 st.shared.b32 [ %r113 + 0 ], %r114;
	// end inline asm
	add.s32 	%r115, %r254, 576;
	mov.b32 	%r116, %f123;
	// begin inline asm
	@%p17 st.shared.b32 [ %r115 + 0 ], %r116;
	// end inline asm
	add.s32 	%r117, %r257, 832;
	mov.b32 	%r118, %f124;
	// begin inline asm
	@%p17 st.shared.b32 [ %r117 + 0 ], %r118;
	// end inline asm
	add.s32 	%r119, %r103, 128;
	mov.b32 	%r120, %f125;
	// begin inline asm
	@%p17 st.shared.b32 [ %r119 + 0 ], %r120;
	// end inline asm
	add.s32 	%r121, %r251, 384;
	mov.b32 	%r122, %f126;
	// begin inline asm
	@%p17 st.shared.b32 [ %r121 + 0 ], %r122;
	// end inline asm
	add.s32 	%r123, %r254, 640;
	mov.b32 	%r124, %f127;
	// begin inline asm
	@%p17 st.shared.b32 [ %r123 + 0 ], %r124;
	// end inline asm
	add.s32 	%r125, %r257, 896;
	mov.b32 	%r126, %f128;
	// begin inline asm
	@%p17 st.shared.b32 [ %r125 + 0 ], %r126;
	// end inline asm
	add.s32 	%r127, %r103, 192;
	mov.b32 	%r128, %f129;
	// begin inline asm
	@%p17 st.shared.b32 [ %r127 + 0 ], %r128;
	// end inline asm
	add.s32 	%r129, %r251, 448;
	mov.b32 	%r130, %f130;
	// begin inline asm
	@%p17 st.shared.b32 [ %r129 + 0 ], %r130;
	// end inline asm
	add.s32 	%r131, %r254, 704;
	mov.b32 	%r132, %f131;
	// begin inline asm
	@%p17 st.shared.b32 [ %r131 + 0 ], %r132;
	// end inline asm
	add.s32 	%r133, %r257, 960;
	mov.b32 	%r134, %f132;
	// begin inline asm
	@%p17 st.shared.b32 [ %r133 + 0 ], %r134;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r258, %r226, 2;
	add.s32 	%r259, %r208, %r258;
	add.s32 	%r260, %r259, %r235;
	ld.shared.u32 	%r135, [%r260];
	ld.shared.u32 	%r136, [%r260+4];
	ld.shared.u32 	%r137, [%r260+8];
	ld.shared.u32 	%r138, [%r260+12];
	shl.b32 	%r261, %r232, 2;
	add.s32 	%r262, %r208, %r261;
	add.s32 	%r263, %r262, %r235;
	ld.shared.u32 	%r139, [%r263+4096];
	ld.shared.u32 	%r140, [%r263+4100];
	ld.shared.u32 	%r141, [%r263+4104];
	ld.shared.u32 	%r142, [%r263+4108];
	shl.b32 	%r264, %r238, 2;
	add.s32 	%r265, %r208, %r264;
	add.s32 	%r266, %r265, %r235;
	ld.shared.u32 	%r143, [%r266+8192];
	ld.shared.u32 	%r144, [%r266+8196];
	ld.shared.u32 	%r145, [%r266+8200];
	ld.shared.u32 	%r146, [%r266+8204];
	shl.b32 	%r267, %r243, 2;
	add.s32 	%r268, %r208, %r267;
	add.s32 	%r269, %r268, %r235;
	ld.shared.u32 	%r147, [%r269+12288];
	ld.shared.u32 	%r148, [%r269+12292];
	ld.shared.u32 	%r149, [%r269+12296];
	ld.shared.u32 	%r150, [%r269+12300];
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd21 + 0 ], { %r135, %r136, %r137, %r138 };
	// end inline asm
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd22 + 0 ], { %r139, %r140, %r141, %r142 };
	// end inline asm
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd23 + 0 ], { %r143, %r144, %r145, %r146 };
	// end inline asm
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd24 + 0 ], { %r147, %r148, %r149, %r150 };
	// end inline asm
	.loc	1 42 4                          // cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py:42:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "inductor_cache/jp/cjp3nejrw3berdc4jtalvvuvyiounrucgcf5gdphvissk4u26rjo.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 95                                 // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x58 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 99                                  // DW_AT_name
.b8 106
.b8 112
.b8 51
.b8 110
.b8 101
.b8 106
.b8 114
.b8 119
.b8 51
.b8 98
.b8 101
.b8 114
.b8 100
.b8 99
.b8 52
.b8 106
.b8 116
.b8 97
.b8 108
.b8 118
.b8 118
.b8 117
.b8 118
.b8 121
.b8 105
.b8 111
.b8 117
.b8 110
.b8 114
.b8 117
.b8 99
.b8 103
.b8 99
.b8 102
.b8 53
.b8 103
.b8 100
.b8 112
.b8 104
.b8 118
.b8 105
.b8 115
.b8 115
.b8 107
.b8 52
.b8 117
.b8 50
.b8 54
.b8 114
.b8 106
.b8 111
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 105                                 // DW_AT_comp_dir
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 99
.b8 97
.b8 99
.b8 104
.b8 101
.b8 47
.b8 106
.b8 112
.b8 0
	}
	.section	.debug_macinfo	{	}
