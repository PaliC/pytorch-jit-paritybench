//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1 // -- Begin function triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};
.global .align 1 .b8 _$_str_$_2[17] = {95, 95, 67, 85, 68, 65, 95, 80, 82, 69, 67, 95, 83, 81, 82, 84};
                                        // @triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1
.visible .entry triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1(
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_0,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_1,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_2,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_3,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_4,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_5,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_6,
	.param .u32 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_7,
	.param .u32 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_8
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<59>;
	.reg .b32 	%r<198>;
	.reg .f32 	%f<145>;
	.reg .b64 	%rd<34>;
	.loc	1 19 0                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:19:0
$L__func_begin0:
	.loc	1 19 0                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:19:0

// %bb.0:                               // %__nv_sqrtf.exit
	ld.param.u64 	%rd18, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_0];
	ld.param.u64 	%rd19, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_1];
$L__tmp0:
	.loc	1 22 28                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:22:28
	// begin inline asm
	mov.u32 %r1, %ctaid.y;
	// end inline asm
	.loc	1 22 33                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:22:33
	shl.b32 	%r115, %r1, 6;
	ld.param.u64 	%rd20, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_2];
	ld.param.u64 	%rd21, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_3];
	.loc	1 23 44                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:23:44
	mov.u32 	%r116, %tid.x;
	ld.param.u64 	%rd22, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_4];
	bfe.u32 	%r117, %r116, 4, 4;
	ld.param.u64 	%rd23, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_5];
	or.b32  	%r118, %r117, 16;
	ld.param.u64 	%rd24, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_6];
	or.b32  	%r119, %r117, 32;
	or.b32  	%r120, %r117, 48;
	shl.b32 	%r121, %r116, 2;
	and.b32  	%r122, %r121, 60;
	.loc	1 23 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:23:23
	or.b32  	%r123, %r115, %r117;
	or.b32  	%r124, %r115, %r118;
	or.b32  	%r125, %r115, %r119;
	or.b32  	%r126, %r115, %r120;
	.loc	1 24 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:24:21
	setp.lt.s32 	%p34, %r123, 64;
	setp.lt.s32 	%p35, %r124, 64;
	setp.lt.s32 	%p36, %r125, 64;
	setp.lt.s32 	%p37, %r126, 64;
	.loc	1 25 28                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:25:28
	// begin inline asm
	mov.u32 %r2, %ctaid.x;
	// end inline asm
	.loc	1 25 33                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:25:33
	shl.b32 	%r127, %r2, 6;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r128, %r127, %r122;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p5, %r128, 256;
	.loc	1 32 43                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:43
	shl.b32 	%r129, %r123, 8;
	shl.b32 	%r130, %r124, 8;
	shl.b32 	%r131, %r125, 8;
	shl.b32 	%r132, %r126, 8;
	.loc	1 32 39                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:39
	add.s32 	%r133, %r128, %r129;
	add.s32 	%r134, %r128, %r130;
	add.s32 	%r135, %r128, %r131;
	add.s32 	%r136, %r128, %r132;
	.loc	1 32 34                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:34
	mul.wide.s32 	%rd25, %r133, 4;
	add.s64 	%rd1, %rd18, %rd25;
	mul.wide.s32 	%rd26, %r134, 4;
	add.s64 	%rd2, %rd18, %rd26;
	mul.wide.s32 	%rd27, %r135, 4;
	add.s64 	%rd3, %rd18, %rd27;
	mul.wide.s32 	%rd28, %r136, 4;
	add.s64 	%rd4, %rd18, %rd28;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p1, %p34, %p5;
	and.pred  	%p2, %p35, %p5;
	and.pred  	%p3, %p36, %p5;
	and.pred  	%p4, %p37, %p5;
	.loc	1 32 48                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:48
	// begin inline asm
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	mov.u32 %r5, 0x0;
	mov.u32 %r6, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r3, %r4, %r5, %r6 }, [ %rd1 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	mov.u32 %r9, 0x0;
	mov.u32 %r10, 0x0;
	@%p2 ld.global.L1::evict_last.v4.b32 { %r7, %r8, %r9, %r10 }, [ %rd2 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	mov.u32 %r13, 0x0;
	mov.u32 %r14, 0x0;
	@%p3 ld.global.L1::evict_last.v4.b32 { %r11, %r12, %r13, %r14 }, [ %rd3 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	mov.u32 %r17, 0x0;
	mov.u32 %r18, 0x0;
	@%p4 ld.global.L1::evict_last.v4.b32 { %r15, %r16, %r17, %r18 }, [ %rd4 + 0 ];
	// end inline asm
	.loc	1 33 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:33:30
	mul.wide.s32 	%rd29, %r128, 4;
	add.s64 	%rd5, %rd19, %rd29;
	.loc	1 33 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:33:35
	// begin inline asm
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	mov.u32 %r21, 0x0;
	mov.u32 %r22, 0x0;
	@%p5 ld.global.L1::evict_last.v4.b32 { %r19, %r20, %r21, %r22 }, [ %rd5 + 0 ];
	// end inline asm
	.loc	1 34 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:34:30
	add.s64 	%rd6, %rd20, %rd29;
	.loc	1 34 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:34:35
	// begin inline asm
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	mov.u32 %r25, 0x0;
	mov.u32 %r26, 0x0;
	@%p5 ld.global.L1::evict_last.v4.b32 { %r23, %r24, %r25, %r26 }, [ %rd6 + 0 ];
	// end inline asm
	.loc	1 35 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:35:30
	add.s64 	%rd7, %rd21, %rd29;
	.loc	1 35 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:35:35
	// begin inline asm
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	mov.u32 %r29, 0x0;
	mov.u32 %r30, 0x0;
	@%p5 ld.global.L1::evict_last.v4.b32 { %r27, %r28, %r29, %r30 }, [ %rd7 + 0 ];
	// end inline asm
	mov.b32 	%f1, %r27;
	mov.b32 	%f2, %r28;
	mov.b32 	%f3, %r29;
	mov.b32 	%f4, %r30;
	.loc	1 36 31                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:36:31
	add.s64 	%rd8, %rd22, %rd29;
	.loc	1 36 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:36:36
	// begin inline asm
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	mov.u32 %r33, 0x0;
	mov.u32 %r34, 0x0;
	@%p5 ld.global.L1::evict_last.v4.b32 { %r31, %r32, %r33, %r34 }, [ %rd8 + 0 ];
	// end inline asm
	.loc	1 37 31                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:37:31
	add.s64 	%rd9, %rd23, %rd29;
	.loc	1 37 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:37:36
	// begin inline asm
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	mov.u32 %r37, 0x0;
	mov.u32 %r38, 0x0;
	@%p5 ld.global.L1::evict_last.v4.b32 { %r35, %r36, %r37, %r38 }, [ %rd9 + 0 ];
	// end inline asm
	.loc	1 41 18                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:41:18
	add.f32 	%f5, %f1, 0f3727C5AC;
	add.f32 	%f6, %f2, 0f3727C5AC;
	add.f32 	%f7, %f3, 0f3727C5AC;
	add.f32 	%f8, %f4, 0f3727C5AC;
	.loc	1 42 26                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:42:26
	sqrt.approx.ftz.f32 	%f9, %f5;
	sqrt.approx.ftz.f32 	%f10, %f6;
	sqrt.approx.ftz.f32 	%f11, %f7;
	sqrt.approx.ftz.f32 	%f12, %f8;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r137, %r127, %r120;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p38, %r137, 256;
	.loc	1 23 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:23:23
	or.b32  	%r138, %r115, %r122;
	.loc	1 24 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:24:21
	setp.lt.s32 	%p39, %r138, 64;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p33, %p39, %p38;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r139, %r127, %r119;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p40, %r139, 256;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p32, %p39, %p40;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r140, %r127, %r118;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p41, %r140, 256;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p31, %p39, %p41;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r141, %r127, %r117;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p42, %r141, 256;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p30, %p39, %p42;
	.loc	1 31 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:31:19
	shr.s32 	%r143, %r138, 31;
	shr.u32 	%r144, %r143, 28;
	add.s32 	%r145, %r138, %r144;
	.loc	1 30 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:30:19
	and.b32  	%r146, %r145, -16;
	sub.s32 	%r147, %r138, %r146;
	.loc	1 44 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:44:19
	mov.b32 	%r41, %f9;
	mov.b32 	%r40, 1065353216;
	// begin inline asm
	div.full.f32 %r39, %r40, %r41;
	// end inline asm
	mov.b32 	%f13, %r39;
	mov.b32 	%r44, %f10;
	// begin inline asm
	div.full.f32 %r42, %r40, %r44;
	// end inline asm
	mov.b32 	%f14, %r42;
	mov.b32 	%r47, %f11;
	// begin inline asm
	div.full.f32 %r45, %r40, %r47;
	// end inline asm
	mov.b32 	%f15, %r45;
	mov.b32 	%r50, %f12;
	// begin inline asm
	div.full.f32 %r48, %r40, %r50;
	// end inline asm
	mov.b32 	%f16, %r48;
	.loc	1 33 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:33:35
	mov.b32 	%f17, %r19;
	mov.b32 	%f18, %r20;
	mov.b32 	%f19, %r21;
	mov.b32 	%f20, %r22;
	.loc	1 34 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:34:35
	mov.b32 	%f21, %r26;
	mov.b32 	%f22, %r25;
	mov.b32 	%f23, %r24;
	mov.b32 	%f24, %r23;
	.loc	1 32 48                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:48
	mov.b32 	%f25, %r3;
	mov.b32 	%f26, %r4;
	mov.b32 	%f27, %r5;
	mov.b32 	%f28, %r6;
	mov.b32 	%f29, %r7;
	mov.b32 	%f30, %r8;
	mov.b32 	%f31, %r9;
	mov.b32 	%f32, %r10;
	mov.b32 	%f33, %r11;
	mov.b32 	%f34, %r12;
	mov.b32 	%f35, %r13;
	mov.b32 	%f36, %r14;
	mov.b32 	%f37, %r15;
	mov.b32 	%f38, %r16;
	mov.b32 	%f39, %r17;
	mov.b32 	%f40, %r18;
	.loc	1 38 18                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:38:18
	add.f32 	%f41, %f20, %f40;
	add.f32 	%f42, %f19, %f39;
	add.f32 	%f43, %f18, %f38;
	add.f32 	%f44, %f17, %f37;
	add.f32 	%f45, %f20, %f36;
	add.f32 	%f46, %f19, %f35;
	add.f32 	%f47, %f18, %f34;
	add.f32 	%f48, %f17, %f33;
	add.f32 	%f49, %f20, %f32;
	add.f32 	%f50, %f19, %f31;
	add.f32 	%f51, %f18, %f30;
	add.f32 	%f52, %f17, %f29;
	add.f32 	%f53, %f20, %f28;
	add.f32 	%f54, %f19, %f27;
	add.f32 	%f55, %f18, %f26;
	add.f32 	%f56, %f17, %f25;
	.loc	1 39 18                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:39:18
	sub.f32 	%f57, %f56, %f24;
	sub.f32 	%f58, %f55, %f23;
	sub.f32 	%f59, %f54, %f22;
	sub.f32 	%f60, %f53, %f21;
	sub.f32 	%f61, %f52, %f24;
	sub.f32 	%f62, %f51, %f23;
	sub.f32 	%f63, %f50, %f22;
	sub.f32 	%f64, %f49, %f21;
	sub.f32 	%f65, %f48, %f24;
	sub.f32 	%f66, %f47, %f23;
	sub.f32 	%f67, %f46, %f22;
	sub.f32 	%f68, %f45, %f21;
	sub.f32 	%f69, %f44, %f24;
	sub.f32 	%f70, %f43, %f23;
	sub.f32 	%f71, %f42, %f22;
	sub.f32 	%f72, %f41, %f21;
	.loc	1 37 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:37:36
	mov.b32 	%f73, %r38;
	mov.b32 	%f74, %r37;
	mov.b32 	%f75, %r36;
	mov.b32 	%f76, %r35;
	.loc	1 36 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:36:36
	mov.b32 	%f77, %r34;
	mov.b32 	%f78, %r33;
	mov.b32 	%f79, %r32;
	mov.b32 	%f80, %r31;
	.loc	1 47 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:47:19
	mul.f32 	%f81, %f72, %f16;
	mul.f32 	%f82, %f71, %f15;
	mul.f32 	%f83, %f70, %f14;
	mul.f32 	%f84, %f69, %f13;
	mul.f32 	%f85, %f68, %f16;
	mul.f32 	%f86, %f67, %f15;
	mul.f32 	%f87, %f66, %f14;
	mul.f32 	%f88, %f65, %f13;
	mul.f32 	%f89, %f64, %f16;
	mul.f32 	%f90, %f63, %f15;
	mul.f32 	%f91, %f62, %f14;
	mul.f32 	%f92, %f61, %f13;
	mul.f32 	%f93, %f60, %f16;
	mul.f32 	%f94, %f59, %f15;
	mul.f32 	%f95, %f58, %f14;
	mul.f32 	%f96, %f57, %f13;
	.loc	1 49 20                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:49:20
	fma.rn.f32 	%f97, %f96, %f80, %f76;
	fma.rn.f32 	%f98, %f95, %f79, %f75;
	fma.rn.f32 	%f99, %f94, %f78, %f74;
	fma.rn.f32 	%f100, %f93, %f77, %f73;
	fma.rn.f32 	%f101, %f92, %f80, %f76;
	fma.rn.f32 	%f102, %f91, %f79, %f75;
	fma.rn.f32 	%f103, %f90, %f78, %f74;
	fma.rn.f32 	%f104, %f89, %f77, %f73;
	fma.rn.f32 	%f105, %f88, %f80, %f76;
	fma.rn.f32 	%f106, %f87, %f79, %f75;
	fma.rn.f32 	%f107, %f86, %f78, %f74;
	fma.rn.f32 	%f108, %f85, %f77, %f73;
	fma.rn.f32 	%f109, %f84, %f80, %f76;
	fma.rn.f32 	%f110, %f83, %f79, %f75;
	fma.rn.f32 	%f111, %f82, %f78, %f74;
	fma.rn.f32 	%f112, %f81, %f77, %f73;
	.loc	1 51 20                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:51:20
	setp.gt.f32 	%p43, %f112, 0f00000000;
	setp.gt.f32 	%p44, %f111, 0f00000000;
	setp.gt.f32 	%p45, %f110, 0f00000000;
	setp.gt.f32 	%p46, %f109, 0f00000000;
	setp.gt.f32 	%p47, %f108, 0f00000000;
	setp.gt.f32 	%p48, %f107, 0f00000000;
	setp.gt.f32 	%p49, %f106, 0f00000000;
	setp.gt.f32 	%p50, %f105, 0f00000000;
	setp.gt.f32 	%p51, %f104, 0f00000000;
	setp.gt.f32 	%p52, %f103, 0f00000000;
	setp.gt.f32 	%p53, %f102, 0f00000000;
	setp.gt.f32 	%p54, %f101, 0f00000000;
	setp.gt.f32 	%p55, %f100, 0f00000000;
	setp.gt.f32 	%p56, %f99, 0f00000000;
	setp.gt.f32 	%p57, %f98, 0f00000000;
	setp.gt.f32 	%p58, %f97, 0f00000000;
	.loc	1 53 20                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:53:20
	mul.f32 	%f113, %f97, 0f3E4CCCCD;
	mul.f32 	%f114, %f98, 0f3E4CCCCD;
	mul.f32 	%f115, %f99, 0f3E4CCCCD;
	mul.f32 	%f116, %f100, 0f3E4CCCCD;
	mul.f32 	%f117, %f101, 0f3E4CCCCD;
	mul.f32 	%f118, %f102, 0f3E4CCCCD;
	mul.f32 	%f119, %f103, 0f3E4CCCCD;
	mul.f32 	%f120, %f104, 0f3E4CCCCD;
	mul.f32 	%f121, %f105, 0f3E4CCCCD;
	mul.f32 	%f122, %f106, 0f3E4CCCCD;
	mul.f32 	%f123, %f107, 0f3E4CCCCD;
	mul.f32 	%f124, %f108, 0f3E4CCCCD;
	mul.f32 	%f125, %f109, 0f3E4CCCCD;
	mul.f32 	%f126, %f110, 0f3E4CCCCD;
	mul.f32 	%f127, %f111, 0f3E4CCCCD;
	mul.f32 	%f128, %f112, 0f3E4CCCCD;
	.loc	1 54 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:54:35
	selp.f32 	%f129, %f97, %f113, %p58;
	selp.f32 	%f130, %f98, %f114, %p57;
	selp.f32 	%f131, %f99, %f115, %p56;
	selp.f32 	%f132, %f100, %f116, %p55;
	selp.f32 	%f133, %f101, %f117, %p54;
	selp.f32 	%f134, %f102, %f118, %p53;
	selp.f32 	%f135, %f103, %f119, %p52;
	selp.f32 	%f136, %f104, %f120, %p51;
	selp.f32 	%f137, %f105, %f121, %p50;
	selp.f32 	%f138, %f106, %f122, %p49;
	selp.f32 	%f139, %f107, %f123, %p48;
	selp.f32 	%f140, %f108, %f124, %p47;
	selp.f32 	%f141, %f109, %f125, %p46;
	selp.f32 	%f142, %f110, %f126, %p45;
	selp.f32 	%f143, %f111, %f127, %p44;
	selp.f32 	%f144, %f112, %f128, %p43;
	.loc	1 55 4                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:55:4
	bar.sync 	0;
	.loc	1 56 48                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:56:48
	mov.b32 	%r63, %f44;
	mov.b32 	%r64, %f43;
	mov.b32 	%r65, %f42;
	mov.b32 	%r66, %f41;
	mov.b32 	%r59, %f48;
	mov.b32 	%r60, %f47;
	mov.b32 	%r61, %f46;
	mov.b32 	%r62, %f45;
	mov.b32 	%r55, %f52;
	mov.b32 	%r56, %f51;
	mov.b32 	%r57, %f50;
	mov.b32 	%r58, %f49;
	mov.b32 	%r51, %f56;
	mov.b32 	%r52, %f55;
	mov.b32 	%r53, %f54;
	mov.b32 	%r54, %f53;
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd1 + 0 ], { %r51, %r52, %r53, %r54 };
	// end inline asm
	// begin inline asm
	@%p2 st.global.v4.b32 [ %rd2 + 0 ], { %r55, %r56, %r57, %r58 };
	// end inline asm
	// begin inline asm
	@%p3 st.global.v4.b32 [ %rd3 + 0 ], { %r59, %r60, %r61, %r62 };
	// end inline asm
	// begin inline asm
	@%p4 st.global.v4.b32 [ %rd4 + 0 ], { %r63, %r64, %r65, %r66 };
	// end inline asm
	.loc	1 57 33                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:33
	shl.b32 	%r148, %r141, 4;
	shl.b32 	%r149, %r140, 4;
	shl.b32 	%r150, %r139, 4;
	shl.b32 	%r151, %r137, 4;
	.loc	1 57 43                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:43
	shl.b32 	%r152, %r145, 8;
	and.b32  	%r153, %r152, -4096;
	.loc	1 57 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:30
	add.s32 	%r154, %r153, %r147;
	.loc	1 57 38                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:38
	add.s32 	%r155, %r154, %r148;
	add.s32 	%r156, %r154, %r149;
	add.s32 	%r157, %r154, %r150;
	add.s32 	%r158, %r154, %r151;
	.loc	1 57 25                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:25
	mul.wide.s32 	%rd30, %r155, 4;
	add.s64 	%rd14, %rd24, %rd30;
	mul.wide.s32 	%rd31, %r156, 4;
	add.s64 	%rd15, %rd24, %rd31;
	mul.wide.s32 	%rd32, %r157, 4;
	add.s64 	%rd16, %rd24, %rd32;
	mul.wide.s32 	%rd33, %r158, 4;
	add.s64 	%rd17, %rd24, %rd33;
	.loc	1 57 55                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:55
	shl.b32 	%r159, %r116, 8;
	and.b32  	%r160, %r159, 3840;
	or.b32  	%r161, %r160, %r117;
	and.b32  	%r162, %r121, 1020;
	shr.u32 	%r163, %r160, 2;
	mov.u32 	%r164, global_smem;
	add.s32 	%r165, %r164, %r163;
	shl.b32 	%r166, %r161, 2;
	add.s32 	%r67, %r165, %r166;
	mov.b32 	%r68, %f129;
	mov.pred 	%p14, -1;
	// begin inline asm
	@%p14 st.shared.b32 [ %r67 + 0 ], %r68;
	// end inline asm
	or.b32  	%r167, %r160, 64;
	shr.u32 	%r168, %r167, 2;
	add.s32 	%r169, %r164, %r168;
	add.s32 	%r170, %r169, %r166;
	add.s32 	%r69, %r170, 256;
	mov.b32 	%r70, %f130;
	// begin inline asm
	@%p14 st.shared.b32 [ %r69 + 0 ], %r70;
	// end inline asm
	or.b32  	%r171, %r160, 128;
	shr.u32 	%r172, %r171, 2;
	add.s32 	%r173, %r164, %r172;
	add.s32 	%r174, %r173, %r166;
	add.s32 	%r71, %r174, 512;
	mov.b32 	%r72, %f131;
	// begin inline asm
	@%p14 st.shared.b32 [ %r71 + 0 ], %r72;
	// end inline asm
	or.b32  	%r175, %r160, 192;
	shr.u32 	%r176, %r175, 2;
	add.s32 	%r177, %r164, %r176;
	add.s32 	%r178, %r177, %r166;
	add.s32 	%r73, %r178, 768;
	mov.b32 	%r74, %f132;
	// begin inline asm
	@%p14 st.shared.b32 [ %r73 + 0 ], %r74;
	// end inline asm
	add.s32 	%r75, %r67, 64;
	mov.b32 	%r76, %f133;
	// begin inline asm
	@%p14 st.shared.b32 [ %r75 + 0 ], %r76;
	// end inline asm
	add.s32 	%r77, %r170, 320;
	mov.b32 	%r78, %f134;
	// begin inline asm
	@%p14 st.shared.b32 [ %r77 + 0 ], %r78;
	// end inline asm
	add.s32 	%r79, %r174, 576;
	mov.b32 	%r80, %f135;
	// begin inline asm
	@%p14 st.shared.b32 [ %r79 + 0 ], %r80;
	// end inline asm
	add.s32 	%r81, %r178, 832;
	mov.b32 	%r82, %f136;
	// begin inline asm
	@%p14 st.shared.b32 [ %r81 + 0 ], %r82;
	// end inline asm
	add.s32 	%r83, %r67, 128;
	mov.b32 	%r84, %f137;
	// begin inline asm
	@%p14 st.shared.b32 [ %r83 + 0 ], %r84;
	// end inline asm
	add.s32 	%r85, %r170, 384;
	mov.b32 	%r86, %f138;
	// begin inline asm
	@%p14 st.shared.b32 [ %r85 + 0 ], %r86;
	// end inline asm
	add.s32 	%r87, %r174, 640;
	mov.b32 	%r88, %f139;
	// begin inline asm
	@%p14 st.shared.b32 [ %r87 + 0 ], %r88;
	// end inline asm
	add.s32 	%r89, %r178, 896;
	mov.b32 	%r90, %f140;
	// begin inline asm
	@%p14 st.shared.b32 [ %r89 + 0 ], %r90;
	// end inline asm
	add.s32 	%r91, %r67, 192;
	mov.b32 	%r92, %f141;
	// begin inline asm
	@%p14 st.shared.b32 [ %r91 + 0 ], %r92;
	// end inline asm
	add.s32 	%r93, %r170, 448;
	mov.b32 	%r94, %f142;
	// begin inline asm
	@%p14 st.shared.b32 [ %r93 + 0 ], %r94;
	// end inline asm
	add.s32 	%r95, %r174, 704;
	mov.b32 	%r96, %f143;
	// begin inline asm
	@%p14 st.shared.b32 [ %r95 + 0 ], %r96;
	// end inline asm
	add.s32 	%r97, %r178, 960;
	mov.b32 	%r98, %f144;
	// begin inline asm
	@%p14 st.shared.b32 [ %r97 + 0 ], %r98;
	// end inline asm
	bar.sync 	0;
	and.b32  	%r179, %r116, 240;
	add.s32 	%r180, %r164, %r179;
	shl.b32 	%r181, %r162, 2;
	add.s32 	%r182, %r180, %r181;
	or.b32  	%r183, %r162, 1024;
	shr.u32 	%r184, %r183, 2;
	and.b32  	%r185, %r184, 496;
	add.s32 	%r186, %r164, %r185;
	add.s32 	%r187, %r186, %r181;
	ld.shared.v4.u32 	{%r103, %r104, %r105, %r106}, [%r187+4096];
	or.b32  	%r188, %r162, 2048;
	shr.u32 	%r189, %r188, 2;
	and.b32  	%r190, %r189, 752;
	add.s32 	%r191, %r164, %r190;
	add.s32 	%r192, %r191, %r181;
	ld.shared.v4.u32 	{%r107, %r108, %r109, %r110}, [%r192+8192];
	or.b32  	%r193, %r162, 3072;
	shr.u32 	%r194, %r193, 2;
	and.b32  	%r195, %r194, 1008;
	add.s32 	%r196, %r164, %r195;
	add.s32 	%r197, %r196, %r181;
	ld.shared.v4.u32 	{%r111, %r112, %r113, %r114}, [%r197+12288];
	ld.shared.v4.u32 	{%r99, %r100, %r101, %r102}, [%r182];
	// begin inline asm
	@%p30 st.global.v4.b32 [ %rd14 + 0 ], { %r99, %r100, %r101, %r102 };
	// end inline asm
	// begin inline asm
	@%p31 st.global.v4.b32 [ %rd15 + 0 ], { %r103, %r104, %r105, %r106 };
	// end inline asm
	// begin inline asm
	@%p32 st.global.v4.b32 [ %rd16 + 0 ], { %r107, %r108, %r109, %r110 };
	// end inline asm
	// begin inline asm
	@%p33 st.global.v4.b32 [ %rd17 + 0 ], { %r111, %r112, %r113, %r114 };
	// end inline asm
	.loc	1 57 4                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "inductor_cache/2i/c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 95                                 // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x58 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 99                                  // DW_AT_name
.b8 50
.b8 105
.b8 110
.b8 110
.b8 102
.b8 101
.b8 108
.b8 104
.b8 107
.b8 100
.b8 120
.b8 53
.b8 98
.b8 114
.b8 112
.b8 122
.b8 105
.b8 122
.b8 117
.b8 102
.b8 115
.b8 51
.b8 108
.b8 52
.b8 98
.b8 100
.b8 110
.b8 106
.b8 100
.b8 111
.b8 50
.b8 53
.b8 118
.b8 118
.b8 120
.b8 103
.b8 113
.b8 108
.b8 109
.b8 117
.b8 97
.b8 54
.b8 55
.b8 97
.b8 114
.b8 117
.b8 51
.b8 51
.b8 118
.b8 100
.b8 117
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 105                                 // DW_AT_comp_dir
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 99
.b8 97
.b8 99
.b8 104
.b8 101
.b8 47
.b8 50
.b8 105
.b8 0
	}
	.section	.debug_macinfo	{	}
