//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1 // -- Begin function triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};
.global .align 1 .b8 _$_str_$_2[17] = {95, 95, 67, 85, 68, 65, 95, 80, 82, 69, 67, 95, 83, 81, 82, 84};
                                        // @triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1
.visible .entry triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1(
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_0,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_1,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_2,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_3,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_4,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_5,
	.param .u64 .ptr .global .align 1 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_6,
	.param .u32 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_7,
	.param .u32 triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_8
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<33>;
	.reg .b32 	%r<135>;
	.reg .f32 	%f<89>;
	.reg .b64 	%rd<24>;
	.loc	1 19 0                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:19:0
$L__func_begin0:
	.loc	1 19 0                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:19:0

// %bb.0:                               // %__nv_sqrtf.exit
	ld.param.u64 	%rd12, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_0];
	ld.param.u64 	%rd13, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_1];
$L__tmp0:
	.loc	1 22 28                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:22:28
	// begin inline asm
	mov.u32 %r1, %ctaid.y;
	// end inline asm
	.loc	1 22 33                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:22:33
	shl.b32 	%r75, %r1, 5;
	ld.param.u64 	%rd14, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_2];
	ld.param.u64 	%rd15, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_3];
	.loc	1 23 44                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:23:44
	mov.u32 	%r76, %tid.x;
	ld.param.u64 	%rd16, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_4];
	bfe.u32 	%r77, %r76, 3, 4;
	ld.param.u64 	%rd17, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_5];
	or.b32  	%r78, %r77, 16;
	ld.param.u64 	%rd18, [triton_poi_fused__native_batch_norm_legit_no_training_convolution_leaky_relu_1_param_6];
	shl.b32 	%r79, %r76, 2;
	and.b32  	%r80, %r79, 28;
	.loc	1 23 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:23:23
	or.b32  	%r81, %r75, %r77;
	or.b32  	%r82, %r75, %r78;
	.loc	1 24 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:24:21
	setp.lt.s32 	%p20, %r81, 64;
	setp.lt.s32 	%p21, %r82, 64;
	.loc	1 25 28                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:25:28
	// begin inline asm
	mov.u32 %r2, %ctaid.x;
	// end inline asm
	.loc	1 25 33                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:25:33
	shl.b32 	%r83, %r2, 5;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r84, %r83, %r80;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p3, %r84, 256;
	.loc	1 32 43                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:43
	shl.b32 	%r85, %r81, 8;
	shl.b32 	%r86, %r82, 8;
	.loc	1 32 39                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:39
	add.s32 	%r87, %r84, %r85;
	add.s32 	%r88, %r84, %r86;
	.loc	1 32 34                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:34
	mul.wide.s32 	%rd19, %r87, 4;
	add.s64 	%rd1, %rd12, %rd19;
	mul.wide.s32 	%rd20, %r88, 4;
	add.s64 	%rd2, %rd12, %rd20;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p1, %p20, %p3;
	and.pred  	%p2, %p21, %p3;
	.loc	1 32 48                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:48
	// begin inline asm
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	mov.u32 %r5, 0x0;
	mov.u32 %r6, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r3, %r4, %r5, %r6 }, [ %rd1 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	mov.u32 %r9, 0x0;
	mov.u32 %r10, 0x0;
	@%p2 ld.global.L1::evict_last.v4.b32 { %r7, %r8, %r9, %r10 }, [ %rd2 + 0 ];
	// end inline asm
	.loc	1 33 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:33:30
	mul.wide.s32 	%rd21, %r84, 4;
	add.s64 	%rd3, %rd13, %rd21;
	.loc	1 33 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:33:35
	// begin inline asm
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	mov.u32 %r13, 0x0;
	mov.u32 %r14, 0x0;
	@%p3 ld.global.L1::evict_last.v4.b32 { %r11, %r12, %r13, %r14 }, [ %rd3 + 0 ];
	// end inline asm
	.loc	1 34 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:34:30
	add.s64 	%rd4, %rd14, %rd21;
	.loc	1 34 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:34:35
	// begin inline asm
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	mov.u32 %r17, 0x0;
	mov.u32 %r18, 0x0;
	@%p3 ld.global.L1::evict_last.v4.b32 { %r15, %r16, %r17, %r18 }, [ %rd4 + 0 ];
	// end inline asm
	.loc	1 35 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:35:30
	add.s64 	%rd5, %rd15, %rd21;
	.loc	1 35 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:35:35
	// begin inline asm
	mov.u32 %r19, 0x0;
	mov.u32 %r20, 0x0;
	mov.u32 %r21, 0x0;
	mov.u32 %r22, 0x0;
	@%p3 ld.global.L1::evict_last.v4.b32 { %r19, %r20, %r21, %r22 }, [ %rd5 + 0 ];
	// end inline asm
	mov.b32 	%f1, %r19;
	mov.b32 	%f2, %r20;
	mov.b32 	%f3, %r21;
	mov.b32 	%f4, %r22;
	.loc	1 36 31                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:36:31
	add.s64 	%rd6, %rd16, %rd21;
	.loc	1 36 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:36:36
	// begin inline asm
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	mov.u32 %r25, 0x0;
	mov.u32 %r26, 0x0;
	@%p3 ld.global.L1::evict_last.v4.b32 { %r23, %r24, %r25, %r26 }, [ %rd6 + 0 ];
	// end inline asm
	.loc	1 37 31                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:37:31
	add.s64 	%rd7, %rd17, %rd21;
	.loc	1 37 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:37:36
	// begin inline asm
	mov.u32 %r27, 0x0;
	mov.u32 %r28, 0x0;
	mov.u32 %r29, 0x0;
	mov.u32 %r30, 0x0;
	@%p3 ld.global.L1::evict_last.v4.b32 { %r27, %r28, %r29, %r30 }, [ %rd7 + 0 ];
	// end inline asm
	.loc	1 41 18                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:41:18
	add.f32 	%f5, %f1, 0f3727C5AC;
	add.f32 	%f6, %f2, 0f3727C5AC;
	add.f32 	%f7, %f3, 0f3727C5AC;
	add.f32 	%f8, %f4, 0f3727C5AC;
	.loc	1 42 26                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:42:26
	sqrt.approx.ftz.f32 	%f9, %f5;
	sqrt.approx.ftz.f32 	%f10, %f6;
	sqrt.approx.ftz.f32 	%f11, %f7;
	sqrt.approx.ftz.f32 	%f12, %f8;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r89, %r83, %r78;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p22, %r89, 256;
	.loc	1 23 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:23:23
	or.b32  	%r90, %r75, %r80;
	.loc	1 24 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:24:21
	setp.lt.s32 	%p23, %r90, 64;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p19, %p23, %p22;
	.loc	1 26 23                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:26:23
	or.b32  	%r91, %r83, %r77;
	.loc	1 27 21                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:27:21
	setp.lt.s32 	%p24, %r91, 256;
	.loc	1 32 56                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:56
	and.pred  	%p18, %p23, %p24;
	.loc	1 31 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:31:19
	shr.s32 	%r93, %r90, 31;
	shr.u32 	%r94, %r93, 28;
	add.s32 	%r95, %r90, %r94;
	.loc	1 30 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:30:19
	and.b32  	%r96, %r95, -16;
	sub.s32 	%r97, %r90, %r96;
	.loc	1 44 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:44:19
	mov.b32 	%r33, %f9;
	mov.b32 	%r32, 1065353216;
	// begin inline asm
	div.full.f32 %r31, %r32, %r33;
	// end inline asm
	mov.b32 	%f13, %r31;
	mov.b32 	%r36, %f10;
	// begin inline asm
	div.full.f32 %r34, %r32, %r36;
	// end inline asm
	mov.b32 	%f14, %r34;
	mov.b32 	%r39, %f11;
	// begin inline asm
	div.full.f32 %r37, %r32, %r39;
	// end inline asm
	mov.b32 	%f15, %r37;
	mov.b32 	%r42, %f12;
	// begin inline asm
	div.full.f32 %r40, %r32, %r42;
	// end inline asm
	mov.b32 	%f16, %r40;
	.loc	1 33 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:33:35
	mov.b32 	%f17, %r11;
	mov.b32 	%f18, %r12;
	mov.b32 	%f19, %r13;
	mov.b32 	%f20, %r14;
	.loc	1 34 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:34:35
	mov.b32 	%f21, %r18;
	mov.b32 	%f22, %r17;
	mov.b32 	%f23, %r16;
	mov.b32 	%f24, %r15;
	.loc	1 32 48                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:32:48
	mov.b32 	%f25, %r3;
	mov.b32 	%f26, %r4;
	mov.b32 	%f27, %r5;
	mov.b32 	%f28, %r6;
	mov.b32 	%f29, %r7;
	mov.b32 	%f30, %r8;
	mov.b32 	%f31, %r9;
	mov.b32 	%f32, %r10;
	.loc	1 38 18                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:38:18
	add.f32 	%f33, %f20, %f32;
	add.f32 	%f34, %f19, %f31;
	add.f32 	%f35, %f18, %f30;
	add.f32 	%f36, %f17, %f29;
	add.f32 	%f37, %f20, %f28;
	add.f32 	%f38, %f19, %f27;
	add.f32 	%f39, %f18, %f26;
	add.f32 	%f40, %f17, %f25;
	.loc	1 39 18                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:39:18
	sub.f32 	%f41, %f40, %f24;
	sub.f32 	%f42, %f39, %f23;
	sub.f32 	%f43, %f38, %f22;
	sub.f32 	%f44, %f37, %f21;
	sub.f32 	%f45, %f36, %f24;
	sub.f32 	%f46, %f35, %f23;
	sub.f32 	%f47, %f34, %f22;
	sub.f32 	%f48, %f33, %f21;
	.loc	1 37 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:37:36
	mov.b32 	%f49, %r30;
	mov.b32 	%f50, %r29;
	mov.b32 	%f51, %r28;
	mov.b32 	%f52, %r27;
	.loc	1 36 36                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:36:36
	mov.b32 	%f53, %r26;
	mov.b32 	%f54, %r25;
	mov.b32 	%f55, %r24;
	mov.b32 	%f56, %r23;
	.loc	1 47 19                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:47:19
	mul.f32 	%f57, %f48, %f16;
	mul.f32 	%f58, %f47, %f15;
	mul.f32 	%f59, %f46, %f14;
	mul.f32 	%f60, %f45, %f13;
	mul.f32 	%f61, %f44, %f16;
	mul.f32 	%f62, %f43, %f15;
	mul.f32 	%f63, %f42, %f14;
	mul.f32 	%f64, %f41, %f13;
	.loc	1 49 20                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:49:20
	fma.rn.f32 	%f65, %f64, %f56, %f52;
	fma.rn.f32 	%f66, %f63, %f55, %f51;
	fma.rn.f32 	%f67, %f62, %f54, %f50;
	fma.rn.f32 	%f68, %f61, %f53, %f49;
	fma.rn.f32 	%f69, %f60, %f56, %f52;
	fma.rn.f32 	%f70, %f59, %f55, %f51;
	fma.rn.f32 	%f71, %f58, %f54, %f50;
	fma.rn.f32 	%f72, %f57, %f53, %f49;
	.loc	1 51 20                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:51:20
	setp.gt.f32 	%p25, %f72, 0f00000000;
	setp.gt.f32 	%p26, %f71, 0f00000000;
	setp.gt.f32 	%p27, %f70, 0f00000000;
	setp.gt.f32 	%p28, %f69, 0f00000000;
	setp.gt.f32 	%p29, %f68, 0f00000000;
	setp.gt.f32 	%p30, %f67, 0f00000000;
	setp.gt.f32 	%p31, %f66, 0f00000000;
	setp.gt.f32 	%p32, %f65, 0f00000000;
	.loc	1 53 20                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:53:20
	mul.f32 	%f73, %f65, 0f3E4CCCCD;
	mul.f32 	%f74, %f66, 0f3E4CCCCD;
	mul.f32 	%f75, %f67, 0f3E4CCCCD;
	mul.f32 	%f76, %f68, 0f3E4CCCCD;
	mul.f32 	%f77, %f69, 0f3E4CCCCD;
	mul.f32 	%f78, %f70, 0f3E4CCCCD;
	mul.f32 	%f79, %f71, 0f3E4CCCCD;
	mul.f32 	%f80, %f72, 0f3E4CCCCD;
	.loc	1 54 35                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:54:35
	selp.f32 	%f81, %f65, %f73, %p32;
	selp.f32 	%f82, %f66, %f74, %p31;
	selp.f32 	%f83, %f67, %f75, %p30;
	selp.f32 	%f84, %f68, %f76, %p29;
	selp.f32 	%f85, %f69, %f77, %p28;
	selp.f32 	%f86, %f70, %f78, %p27;
	selp.f32 	%f87, %f71, %f79, %p26;
	selp.f32 	%f88, %f72, %f80, %p25;
	.loc	1 55 4                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:55:4
	bar.sync 	0;
	.loc	1 56 48                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:56:48
	mov.b32 	%r47, %f36;
	mov.b32 	%r48, %f35;
	mov.b32 	%r49, %f34;
	mov.b32 	%r50, %f33;
	mov.b32 	%r43, %f40;
	mov.b32 	%r44, %f39;
	mov.b32 	%r45, %f38;
	mov.b32 	%r46, %f37;
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd1 + 0 ], { %r43, %r44, %r45, %r46 };
	// end inline asm
	// begin inline asm
	@%p2 st.global.v4.b32 [ %rd2 + 0 ], { %r47, %r48, %r49, %r50 };
	// end inline asm
	.loc	1 57 33                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:33
	shl.b32 	%r98, %r91, 4;
	shl.b32 	%r99, %r89, 4;
	.loc	1 57 43                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:43
	shl.b32 	%r100, %r95, 8;
	and.b32  	%r101, %r100, -4096;
	.loc	1 57 30                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:30
	add.s32 	%r102, %r101, %r97;
	.loc	1 57 38                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:38
	add.s32 	%r103, %r102, %r98;
	add.s32 	%r104, %r102, %r99;
	.loc	1 57 25                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:25
	mul.wide.s32 	%rd22, %r103, 4;
	add.s64 	%rd10, %rd18, %rd22;
	mul.wide.s32 	%rd23, %r104, 4;
	add.s64 	%rd11, %rd18, %rd23;
	.loc	1 57 55                         // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:55
	shl.b32 	%r105, %r76, 7;
	and.b32  	%r106, %r105, 896;
	or.b32  	%r107, %r106, %r77;
	and.b32  	%r108, %r79, 508;
	shr.u32 	%r109, %r106, 1;
	mov.u32 	%r110, global_smem;
	add.s32 	%r111, %r110, %r109;
	shl.b32 	%r112, %r107, 2;
	add.s32 	%r51, %r111, %r112;
	mov.b32 	%r52, %f81;
	mov.pred 	%p10, -1;
	// begin inline asm
	@%p10 st.shared.b32 [ %r51 + 0 ], %r52;
	// end inline asm
	or.b32  	%r113, %r106, 32;
	shr.u32 	%r114, %r113, 1;
	add.s32 	%r115, %r110, %r114;
	add.s32 	%r116, %r115, %r112;
	add.s32 	%r53, %r116, 128;
	mov.b32 	%r54, %f82;
	// begin inline asm
	@%p10 st.shared.b32 [ %r53 + 0 ], %r54;
	// end inline asm
	or.b32  	%r117, %r106, 64;
	shr.u32 	%r118, %r117, 1;
	add.s32 	%r119, %r110, %r118;
	add.s32 	%r120, %r119, %r112;
	add.s32 	%r55, %r120, 256;
	mov.b32 	%r56, %f83;
	// begin inline asm
	@%p10 st.shared.b32 [ %r55 + 0 ], %r56;
	// end inline asm
	or.b32  	%r121, %r106, 96;
	shr.u32 	%r122, %r121, 1;
	add.s32 	%r123, %r110, %r122;
	add.s32 	%r124, %r123, %r112;
	add.s32 	%r57, %r124, 384;
	mov.b32 	%r58, %f84;
	// begin inline asm
	@%p10 st.shared.b32 [ %r57 + 0 ], %r58;
	// end inline asm
	add.s32 	%r59, %r51, 64;
	mov.b32 	%r60, %f85;
	// begin inline asm
	@%p10 st.shared.b32 [ %r59 + 0 ], %r60;
	// end inline asm
	add.s32 	%r61, %r116, 192;
	mov.b32 	%r62, %f86;
	// begin inline asm
	@%p10 st.shared.b32 [ %r61 + 0 ], %r62;
	// end inline asm
	add.s32 	%r63, %r120, 320;
	mov.b32 	%r64, %f87;
	// begin inline asm
	@%p10 st.shared.b32 [ %r63 + 0 ], %r64;
	// end inline asm
	add.s32 	%r65, %r124, 448;
	mov.b32 	%r66, %f88;
	// begin inline asm
	@%p10 st.shared.b32 [ %r65 + 0 ], %r66;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r125, %r76, 1;
	and.b32  	%r126, %r125, 240;
	add.s32 	%r127, %r110, %r126;
	shl.b32 	%r128, %r108, 2;
	add.s32 	%r129, %r127, %r128;
	or.b32  	%r130, %r108, 512;
	shr.u32 	%r131, %r130, 1;
	and.b32  	%r132, %r131, 496;
	add.s32 	%r133, %r110, %r132;
	add.s32 	%r134, %r133, %r128;
	ld.shared.v4.u32 	{%r71, %r72, %r73, %r74}, [%r134+2048];
	ld.shared.v4.u32 	{%r67, %r68, %r69, %r70}, [%r129];
	// begin inline asm
	@%p18 st.global.v4.b32 [ %rd10 + 0 ], { %r67, %r68, %r69, %r70 };
	// end inline asm
	// begin inline asm
	@%p19 st.global.v4.b32 [ %rd11 + 0 ], { %r71, %r72, %r73, %r74 };
	// end inline asm
	.loc	1 57 4                          // c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py:57:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "inductor_cache/2i/c2innfelhkdx5brpzizufs3l4bdnjdo25vvxgqlmua67aru33vdu.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 95                                 // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x58 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 99                                  // DW_AT_name
.b8 50
.b8 105
.b8 110
.b8 110
.b8 102
.b8 101
.b8 108
.b8 104
.b8 107
.b8 100
.b8 120
.b8 53
.b8 98
.b8 114
.b8 112
.b8 122
.b8 105
.b8 122
.b8 117
.b8 102
.b8 115
.b8 51
.b8 108
.b8 52
.b8 98
.b8 100
.b8 110
.b8 106
.b8 100
.b8 111
.b8 50
.b8 53
.b8 118
.b8 118
.b8 120
.b8 103
.b8 113
.b8 108
.b8 109
.b8 117
.b8 97
.b8 54
.b8 55
.b8 97
.b8 114
.b8 117
.b8 51
.b8 51
.b8 118
.b8 100
.b8 117
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 105                                 // DW_AT_comp_dir
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 99
.b8 97
.b8 99
.b8 104
.b8 101
.b8 47
.b8 50
.b8 105
.b8 0
	}
	.section	.debug_macinfo	{	}
