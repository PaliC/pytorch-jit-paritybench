#loc = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0)
#loc1 = loc(unknown)
#loc13 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":610:12)
#loc14 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":48:71)
#loc19 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":582:73)
#loc24 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:51)
#loc29 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:53)
#loc39 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:50)
#loc44 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:51)
#loc70 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":57:59)
#loc95 = loc(callsite(#loc1 at #loc24))
#loc101 = loc(callsite(#loc1 at #loc29))
#loc112 = loc(callsite(#loc1 at #loc39))
#loc118 = loc(callsite(#loc1 at #loc44))
#loc135 = loc(callsite(#loc1 at #loc70))
#loc148 = loc(callsite(#loc95 at #loc19))
#loc154 = loc(callsite(#loc101 at #loc19))
#loc166 = loc(callsite(#loc112 at #loc19))
#loc173 = loc(callsite(#loc118 at #loc19))
#loc196 = loc(callsite(#loc148 at #loc13))
#loc202 = loc(callsite(#loc154 at #loc13))
#loc214 = loc(callsite(#loc166 at #loc13))
#loc221 = loc(callsite(#loc173 at #loc13))
#loc239 = loc(callsite(#loc196 at #loc14))
#loc242 = loc(callsite(#loc202 at #loc14))
#loc245 = loc(callsite(#loc214 at #loc14))
#loc248 = loc(callsite(#loc221 at #loc14))
module {
  tt.func public @triton_per_fused_cumsum_index_mul_rsub_sort_sub_sum_0(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg3: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg4: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg5: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg6: i32 {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0)) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc1)
    %cst_0 = arith.constant dense<0> : tensor<256xi16> loc(#loc1)
    %cst_1 = arith.constant dense<0> : tensor<256xi32> loc(#loc1)
    %cst_2 = arith.constant dense<1> : tensor<1x2x1xi32> loc(#loc1)
    %cst_3 = arith.constant dense<0> : tensor<256xi64> loc(#loc1)
    %cst_4 = arith.constant dense<256> : tensor<256xi64> loc(#loc1)
    %cst_5 = arith.constant dense<1.000000e+00> : tensor<256xf32> loc(#loc1)
    %cst_6 = arith.constant dense<2.000000e+00> : tensor<256xf32> loc(#loc1)
    %0 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32> loc(#loc2)
    %1 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>> loc(#loc3)
    %2 = tt.addptr %1, %0 : tensor<256x!tt.ptr<f32>>, tensor<256xi32> loc(#loc3)
    %3 = tt.load %2 : tensor<256x!tt.ptr<f32>> loc(#loc4)
    %4 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>> loc(#loc5)
    %5 = tt.addptr %4, %0 : tensor<256x!tt.ptr<f32>>, tensor<256xi32> loc(#loc5)
    %6 = tt.load %5 : tensor<256x!tt.ptr<f32>> loc(#loc6)
    %7 = arith.mulf %6, %cst_6 : tensor<256xf32> loc(#loc7)
    %8 = arith.subf %7, %cst_5 : tensor<256xf32> loc(#loc8)
    %9 = arith.mulf %3, %8 : tensor<256xf32> loc(#loc9)
    %10 = arith.subf %cst_5, %9 : tensor<256xf32> loc(#loc10)
    %11 = arith.trunci %0 : tensor<256xi32> to tensor<256xi16> loc(#loc11)
    %12 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32> loc(#loc139)
    %13 = tt.expand_dims %12 {axis = 0 : i32} : tensor<2xi32> -> tensor<1x2xi32> loc(#loc140)
    %14 = tt.expand_dims %13 {axis = 2 : i32} : tensor<1x2xi32> -> tensor<1x2x1xi32> loc(#loc140)
    %15 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<64x2x2xi32> loc(#loc141)
    %16 = tt.reshape %15 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc142)
    %17 = tt.reshape %10 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %18 = tt.bitcast %17 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %19 = arith.subi %cst_2, %14 : tensor<1x2x1xi32> loc(#loc193)
    %20 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<128x2x1xi32> loc(#loc194)
    %21 = arith.muli %18, %20 : tensor<128x2x1xi32> loc(#loc194)
    %22 = "tt.reduce"(%21) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %23 = tt.expand_dims %22 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %24 = tt.broadcast %23 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %25 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<128x2x1xi32> loc(#loc200)
    %26 = arith.muli %18, %25 : tensor<128x2x1xi32> loc(#loc200)
    %27 = "tt.reduce"(%26) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %28 = tt.expand_dims %27 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %29 = tt.broadcast %28 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %30 = tt.reshape %24 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %31 = tt.reshape %29 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %32 = tt.bitcast %30 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %33 = tt.bitcast %31 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %34 = tt.reshape %11 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %35 = arith.trunci %19 : tensor<1x2x1xi32> to tensor<1x2x1xi16> loc(#loc211)
    %36 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<128x2x1xi16> loc(#loc212)
    %37 = arith.muli %34, %36 : tensor<128x2x1xi16> loc(#loc212)
    %38 = "tt.reduce"(%37) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %39 = tt.expand_dims %38 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %40 = tt.broadcast %39 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %41 = arith.trunci %14 : tensor<1x2x1xi32> to tensor<1x2x1xi16> loc(#loc218)
    %42 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<128x2x1xi16> loc(#loc219)
    %43 = arith.muli %34, %42 : tensor<128x2x1xi16> loc(#loc219)
    %44 = "tt.reduce"(%43) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %45 = tt.expand_dims %44 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %46 = tt.broadcast %45 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %47 = tt.reshape %40 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %48 = tt.reshape %46 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %49 = tt.bitcast %10 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %50 = arith.cmpf olt, %32, %33 : tensor<256xf32> loc(#loc228)
    %51 = arith.extui %50 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %52 = arith.xori %51, %16 : tensor<256xi32> loc(#loc229)
    %53 = arith.cmpi ne, %52, %cst_1 : tensor<256xi32> loc(#loc230)
    %54 = arith.xori %30, %31 : tensor<256xi32> loc(#loc231)
    %55 = arith.select %53, %54, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %56 = arith.xori %49, %55 : tensor<256xi32> loc(#loc233)
    %57 = arith.xori %47, %48 : tensor<256xi16> loc(#loc234)
    %58 = arith.select %53, %57, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %59 = arith.xori %11, %58 : tensor<256xi16> loc(#loc236)
    %60 = tt.bitcast %56 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %61 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<32x2x4xi32> loc(#loc141)
    %62 = tt.reshape %61 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc142)
    %63 = tt.reshape %60 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc191)
    %64 = tt.bitcast %63 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc192)
    %65 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<64x2x2xi32> loc(#loc194)
    %66 = arith.muli %64, %65 : tensor<64x2x2xi32> loc(#loc194)
    %67 = "tt.reduce"(%66) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc238)
    %68 = tt.expand_dims %67 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc198)
    %69 = tt.broadcast %68 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc199)
    %70 = arith.muli %64, %15 : tensor<64x2x2xi32> loc(#loc200)
    %71 = "tt.reduce"(%70) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc241)
    %72 = tt.expand_dims %71 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc204)
    %73 = tt.broadcast %72 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc205)
    %74 = tt.reshape %69 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc206)
    %75 = tt.reshape %73 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc207)
    %76 = tt.bitcast %74 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %77 = tt.bitcast %75 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %78 = tt.reshape %59 : tensor<256xi16> -> tensor<64x2x2xi16> loc(#loc210)
    %79 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<64x2x2xi16> loc(#loc212)
    %80 = arith.muli %78, %79 : tensor<64x2x2xi16> loc(#loc212)
    %81 = "tt.reduce"(%80) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc244)
    %82 = tt.expand_dims %81 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc216)
    %83 = tt.broadcast %82 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc217)
    %84 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<64x2x2xi16> loc(#loc219)
    %85 = arith.muli %78, %84 : tensor<64x2x2xi16> loc(#loc219)
    %86 = "tt.reduce"(%85) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc247)
    %87 = tt.expand_dims %86 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc223)
    %88 = tt.broadcast %87 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc224)
    %89 = tt.reshape %83 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc225)
    %90 = tt.reshape %88 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc226)
    %91 = tt.bitcast %60 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %92 = arith.cmpf olt, %76, %77 : tensor<256xf32> loc(#loc228)
    %93 = arith.extui %92 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %94 = arith.xori %93, %62 : tensor<256xi32> loc(#loc229)
    %95 = arith.cmpi ne, %94, %cst_1 : tensor<256xi32> loc(#loc230)
    %96 = arith.xori %74, %75 : tensor<256xi32> loc(#loc231)
    %97 = arith.select %95, %96, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %98 = arith.xori %91, %97 : tensor<256xi32> loc(#loc233)
    %99 = arith.xori %89, %90 : tensor<256xi16> loc(#loc234)
    %100 = arith.select %95, %99, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %101 = arith.xori %59, %100 : tensor<256xi16> loc(#loc236)
    %102 = tt.bitcast %98 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %103 = tt.reshape %102 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %104 = tt.bitcast %103 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %105 = arith.muli %104, %20 : tensor<128x2x1xi32> loc(#loc194)
    %106 = "tt.reduce"(%105) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %107 = tt.expand_dims %106 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %108 = tt.broadcast %107 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %109 = arith.muli %104, %25 : tensor<128x2x1xi32> loc(#loc200)
    %110 = "tt.reduce"(%109) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %111 = tt.expand_dims %110 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %112 = tt.broadcast %111 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %113 = tt.reshape %108 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %114 = tt.reshape %112 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %115 = tt.bitcast %113 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %116 = tt.bitcast %114 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %117 = tt.reshape %101 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %118 = arith.muli %117, %36 : tensor<128x2x1xi16> loc(#loc212)
    %119 = "tt.reduce"(%118) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %120 = tt.expand_dims %119 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %121 = tt.broadcast %120 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %122 = arith.muli %117, %42 : tensor<128x2x1xi16> loc(#loc219)
    %123 = "tt.reduce"(%122) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %124 = tt.expand_dims %123 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %125 = tt.broadcast %124 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %126 = tt.reshape %121 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %127 = tt.reshape %125 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %128 = tt.bitcast %102 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %129 = arith.cmpf olt, %115, %116 : tensor<256xf32> loc(#loc228)
    %130 = arith.extui %129 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %131 = arith.xori %130, %62 : tensor<256xi32> loc(#loc229)
    %132 = arith.cmpi ne, %131, %cst_1 : tensor<256xi32> loc(#loc230)
    %133 = arith.xori %113, %114 : tensor<256xi32> loc(#loc231)
    %134 = arith.select %132, %133, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %135 = arith.xori %128, %134 : tensor<256xi32> loc(#loc233)
    %136 = arith.xori %126, %127 : tensor<256xi16> loc(#loc234)
    %137 = arith.select %132, %136, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %138 = arith.xori %101, %137 : tensor<256xi16> loc(#loc236)
    %139 = tt.bitcast %135 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %140 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<16x2x8xi32> loc(#loc141)
    %141 = tt.reshape %140 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc142)
    %142 = tt.reshape %139 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc191)
    %143 = tt.bitcast %142 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc192)
    %144 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<32x2x4xi32> loc(#loc194)
    %145 = arith.muli %143, %144 : tensor<32x2x4xi32> loc(#loc194)
    %146 = "tt.reduce"(%145) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc238)
    %147 = tt.expand_dims %146 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc198)
    %148 = tt.broadcast %147 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc199)
    %149 = arith.muli %143, %61 : tensor<32x2x4xi32> loc(#loc200)
    %150 = "tt.reduce"(%149) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc241)
    %151 = tt.expand_dims %150 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc204)
    %152 = tt.broadcast %151 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc205)
    %153 = tt.reshape %148 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc206)
    %154 = tt.reshape %152 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc207)
    %155 = tt.bitcast %153 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %156 = tt.bitcast %154 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %157 = tt.reshape %138 : tensor<256xi16> -> tensor<32x2x4xi16> loc(#loc210)
    %158 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<32x2x4xi16> loc(#loc212)
    %159 = arith.muli %157, %158 : tensor<32x2x4xi16> loc(#loc212)
    %160 = "tt.reduce"(%159) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc244)
    %161 = tt.expand_dims %160 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc216)
    %162 = tt.broadcast %161 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc217)
    %163 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<32x2x4xi16> loc(#loc219)
    %164 = arith.muli %157, %163 : tensor<32x2x4xi16> loc(#loc219)
    %165 = "tt.reduce"(%164) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc247)
    %166 = tt.expand_dims %165 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc223)
    %167 = tt.broadcast %166 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc224)
    %168 = tt.reshape %162 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc225)
    %169 = tt.reshape %167 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc226)
    %170 = tt.bitcast %139 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %171 = arith.cmpf olt, %155, %156 : tensor<256xf32> loc(#loc228)
    %172 = arith.extui %171 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %173 = arith.xori %172, %141 : tensor<256xi32> loc(#loc229)
    %174 = arith.cmpi ne, %173, %cst_1 : tensor<256xi32> loc(#loc230)
    %175 = arith.xori %153, %154 : tensor<256xi32> loc(#loc231)
    %176 = arith.select %174, %175, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %177 = arith.xori %170, %176 : tensor<256xi32> loc(#loc233)
    %178 = arith.xori %168, %169 : tensor<256xi16> loc(#loc234)
    %179 = arith.select %174, %178, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %180 = arith.xori %138, %179 : tensor<256xi16> loc(#loc236)
    %181 = tt.bitcast %177 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %182 = tt.reshape %181 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc191)
    %183 = tt.bitcast %182 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc192)
    %184 = arith.muli %183, %65 : tensor<64x2x2xi32> loc(#loc194)
    %185 = "tt.reduce"(%184) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc238)
    %186 = tt.expand_dims %185 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc198)
    %187 = tt.broadcast %186 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc199)
    %188 = arith.muli %183, %15 : tensor<64x2x2xi32> loc(#loc200)
    %189 = "tt.reduce"(%188) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc241)
    %190 = tt.expand_dims %189 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc204)
    %191 = tt.broadcast %190 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc205)
    %192 = tt.reshape %187 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc206)
    %193 = tt.reshape %191 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc207)
    %194 = tt.bitcast %192 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %195 = tt.bitcast %193 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %196 = tt.reshape %180 : tensor<256xi16> -> tensor<64x2x2xi16> loc(#loc210)
    %197 = arith.muli %196, %79 : tensor<64x2x2xi16> loc(#loc212)
    %198 = "tt.reduce"(%197) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc244)
    %199 = tt.expand_dims %198 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc216)
    %200 = tt.broadcast %199 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc217)
    %201 = arith.muli %196, %84 : tensor<64x2x2xi16> loc(#loc219)
    %202 = "tt.reduce"(%201) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc247)
    %203 = tt.expand_dims %202 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc223)
    %204 = tt.broadcast %203 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc224)
    %205 = tt.reshape %200 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc225)
    %206 = tt.reshape %204 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc226)
    %207 = tt.bitcast %181 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %208 = arith.cmpf olt, %194, %195 : tensor<256xf32> loc(#loc228)
    %209 = arith.extui %208 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %210 = arith.xori %209, %141 : tensor<256xi32> loc(#loc229)
    %211 = arith.cmpi ne, %210, %cst_1 : tensor<256xi32> loc(#loc230)
    %212 = arith.xori %192, %193 : tensor<256xi32> loc(#loc231)
    %213 = arith.select %211, %212, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %214 = arith.xori %207, %213 : tensor<256xi32> loc(#loc233)
    %215 = arith.xori %205, %206 : tensor<256xi16> loc(#loc234)
    %216 = arith.select %211, %215, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %217 = arith.xori %180, %216 : tensor<256xi16> loc(#loc236)
    %218 = tt.bitcast %214 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %219 = tt.reshape %218 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %220 = tt.bitcast %219 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %221 = arith.muli %220, %20 : tensor<128x2x1xi32> loc(#loc194)
    %222 = "tt.reduce"(%221) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %223 = tt.expand_dims %222 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %224 = tt.broadcast %223 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %225 = arith.muli %220, %25 : tensor<128x2x1xi32> loc(#loc200)
    %226 = "tt.reduce"(%225) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %227 = tt.expand_dims %226 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %228 = tt.broadcast %227 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %229 = tt.reshape %224 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %230 = tt.reshape %228 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %231 = tt.bitcast %229 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %232 = tt.bitcast %230 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %233 = tt.reshape %217 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %234 = arith.muli %233, %36 : tensor<128x2x1xi16> loc(#loc212)
    %235 = "tt.reduce"(%234) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %236 = tt.expand_dims %235 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %237 = tt.broadcast %236 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %238 = arith.muli %233, %42 : tensor<128x2x1xi16> loc(#loc219)
    %239 = "tt.reduce"(%238) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %240 = tt.expand_dims %239 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %241 = tt.broadcast %240 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %242 = tt.reshape %237 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %243 = tt.reshape %241 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %244 = tt.bitcast %218 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %245 = arith.cmpf olt, %231, %232 : tensor<256xf32> loc(#loc228)
    %246 = arith.extui %245 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %247 = arith.xori %246, %141 : tensor<256xi32> loc(#loc229)
    %248 = arith.cmpi ne, %247, %cst_1 : tensor<256xi32> loc(#loc230)
    %249 = arith.xori %229, %230 : tensor<256xi32> loc(#loc231)
    %250 = arith.select %248, %249, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %251 = arith.xori %244, %250 : tensor<256xi32> loc(#loc233)
    %252 = arith.xori %242, %243 : tensor<256xi16> loc(#loc234)
    %253 = arith.select %248, %252, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %254 = arith.xori %217, %253 : tensor<256xi16> loc(#loc236)
    %255 = tt.bitcast %251 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %256 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<8x2x16xi32> loc(#loc141)
    %257 = tt.reshape %256 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc142)
    %258 = tt.reshape %255 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc191)
    %259 = tt.bitcast %258 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc192)
    %260 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<16x2x8xi32> loc(#loc194)
    %261 = arith.muli %259, %260 : tensor<16x2x8xi32> loc(#loc194)
    %262 = "tt.reduce"(%261) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc238)
    %263 = tt.expand_dims %262 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc198)
    %264 = tt.broadcast %263 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc199)
    %265 = arith.muli %259, %140 : tensor<16x2x8xi32> loc(#loc200)
    %266 = "tt.reduce"(%265) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc241)
    %267 = tt.expand_dims %266 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc204)
    %268 = tt.broadcast %267 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc205)
    %269 = tt.reshape %264 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc206)
    %270 = tt.reshape %268 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc207)
    %271 = tt.bitcast %269 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %272 = tt.bitcast %270 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %273 = tt.reshape %254 : tensor<256xi16> -> tensor<16x2x8xi16> loc(#loc210)
    %274 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<16x2x8xi16> loc(#loc212)
    %275 = arith.muli %273, %274 : tensor<16x2x8xi16> loc(#loc212)
    %276 = "tt.reduce"(%275) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc244)
    %277 = tt.expand_dims %276 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc216)
    %278 = tt.broadcast %277 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc217)
    %279 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<16x2x8xi16> loc(#loc219)
    %280 = arith.muli %273, %279 : tensor<16x2x8xi16> loc(#loc219)
    %281 = "tt.reduce"(%280) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc247)
    %282 = tt.expand_dims %281 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc223)
    %283 = tt.broadcast %282 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc224)
    %284 = tt.reshape %278 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc225)
    %285 = tt.reshape %283 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc226)
    %286 = tt.bitcast %255 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %287 = arith.cmpf olt, %271, %272 : tensor<256xf32> loc(#loc228)
    %288 = arith.extui %287 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %289 = arith.xori %288, %257 : tensor<256xi32> loc(#loc229)
    %290 = arith.cmpi ne, %289, %cst_1 : tensor<256xi32> loc(#loc230)
    %291 = arith.xori %269, %270 : tensor<256xi32> loc(#loc231)
    %292 = arith.select %290, %291, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %293 = arith.xori %286, %292 : tensor<256xi32> loc(#loc233)
    %294 = arith.xori %284, %285 : tensor<256xi16> loc(#loc234)
    %295 = arith.select %290, %294, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %296 = arith.xori %254, %295 : tensor<256xi16> loc(#loc236)
    %297 = tt.bitcast %293 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %298 = tt.reshape %297 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc191)
    %299 = tt.bitcast %298 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc192)
    %300 = arith.muli %299, %144 : tensor<32x2x4xi32> loc(#loc194)
    %301 = "tt.reduce"(%300) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc238)
    %302 = tt.expand_dims %301 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc198)
    %303 = tt.broadcast %302 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc199)
    %304 = arith.muli %299, %61 : tensor<32x2x4xi32> loc(#loc200)
    %305 = "tt.reduce"(%304) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc241)
    %306 = tt.expand_dims %305 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc204)
    %307 = tt.broadcast %306 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc205)
    %308 = tt.reshape %303 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc206)
    %309 = tt.reshape %307 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc207)
    %310 = tt.bitcast %308 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %311 = tt.bitcast %309 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %312 = tt.reshape %296 : tensor<256xi16> -> tensor<32x2x4xi16> loc(#loc210)
    %313 = arith.muli %312, %158 : tensor<32x2x4xi16> loc(#loc212)
    %314 = "tt.reduce"(%313) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc244)
    %315 = tt.expand_dims %314 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc216)
    %316 = tt.broadcast %315 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc217)
    %317 = arith.muli %312, %163 : tensor<32x2x4xi16> loc(#loc219)
    %318 = "tt.reduce"(%317) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc247)
    %319 = tt.expand_dims %318 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc223)
    %320 = tt.broadcast %319 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc224)
    %321 = tt.reshape %316 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc225)
    %322 = tt.reshape %320 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc226)
    %323 = tt.bitcast %297 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %324 = arith.cmpf olt, %310, %311 : tensor<256xf32> loc(#loc228)
    %325 = arith.extui %324 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %326 = arith.xori %325, %257 : tensor<256xi32> loc(#loc229)
    %327 = arith.cmpi ne, %326, %cst_1 : tensor<256xi32> loc(#loc230)
    %328 = arith.xori %308, %309 : tensor<256xi32> loc(#loc231)
    %329 = arith.select %327, %328, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %330 = arith.xori %323, %329 : tensor<256xi32> loc(#loc233)
    %331 = arith.xori %321, %322 : tensor<256xi16> loc(#loc234)
    %332 = arith.select %327, %331, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %333 = arith.xori %296, %332 : tensor<256xi16> loc(#loc236)
    %334 = tt.bitcast %330 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %335 = tt.reshape %334 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc191)
    %336 = tt.bitcast %335 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc192)
    %337 = arith.muli %336, %65 : tensor<64x2x2xi32> loc(#loc194)
    %338 = "tt.reduce"(%337) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc238)
    %339 = tt.expand_dims %338 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc198)
    %340 = tt.broadcast %339 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc199)
    %341 = arith.muli %336, %15 : tensor<64x2x2xi32> loc(#loc200)
    %342 = "tt.reduce"(%341) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc241)
    %343 = tt.expand_dims %342 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc204)
    %344 = tt.broadcast %343 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc205)
    %345 = tt.reshape %340 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc206)
    %346 = tt.reshape %344 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc207)
    %347 = tt.bitcast %345 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %348 = tt.bitcast %346 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %349 = tt.reshape %333 : tensor<256xi16> -> tensor<64x2x2xi16> loc(#loc210)
    %350 = arith.muli %349, %79 : tensor<64x2x2xi16> loc(#loc212)
    %351 = "tt.reduce"(%350) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc244)
    %352 = tt.expand_dims %351 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc216)
    %353 = tt.broadcast %352 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc217)
    %354 = arith.muli %349, %84 : tensor<64x2x2xi16> loc(#loc219)
    %355 = "tt.reduce"(%354) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc247)
    %356 = tt.expand_dims %355 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc223)
    %357 = tt.broadcast %356 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc224)
    %358 = tt.reshape %353 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc225)
    %359 = tt.reshape %357 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc226)
    %360 = tt.bitcast %334 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %361 = arith.cmpf olt, %347, %348 : tensor<256xf32> loc(#loc228)
    %362 = arith.extui %361 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %363 = arith.xori %362, %257 : tensor<256xi32> loc(#loc229)
    %364 = arith.cmpi ne, %363, %cst_1 : tensor<256xi32> loc(#loc230)
    %365 = arith.xori %345, %346 : tensor<256xi32> loc(#loc231)
    %366 = arith.select %364, %365, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %367 = arith.xori %360, %366 : tensor<256xi32> loc(#loc233)
    %368 = arith.xori %358, %359 : tensor<256xi16> loc(#loc234)
    %369 = arith.select %364, %368, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %370 = arith.xori %333, %369 : tensor<256xi16> loc(#loc236)
    %371 = tt.bitcast %367 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %372 = tt.reshape %371 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %373 = tt.bitcast %372 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %374 = arith.muli %373, %20 : tensor<128x2x1xi32> loc(#loc194)
    %375 = "tt.reduce"(%374) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %376 = tt.expand_dims %375 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %377 = tt.broadcast %376 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %378 = arith.muli %373, %25 : tensor<128x2x1xi32> loc(#loc200)
    %379 = "tt.reduce"(%378) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %380 = tt.expand_dims %379 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %381 = tt.broadcast %380 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %382 = tt.reshape %377 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %383 = tt.reshape %381 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %384 = tt.bitcast %382 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %385 = tt.bitcast %383 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %386 = tt.reshape %370 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %387 = arith.muli %386, %36 : tensor<128x2x1xi16> loc(#loc212)
    %388 = "tt.reduce"(%387) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %389 = tt.expand_dims %388 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %390 = tt.broadcast %389 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %391 = arith.muli %386, %42 : tensor<128x2x1xi16> loc(#loc219)
    %392 = "tt.reduce"(%391) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %393 = tt.expand_dims %392 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %394 = tt.broadcast %393 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %395 = tt.reshape %390 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %396 = tt.reshape %394 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %397 = tt.bitcast %371 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %398 = arith.cmpf olt, %384, %385 : tensor<256xf32> loc(#loc228)
    %399 = arith.extui %398 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %400 = arith.xori %399, %257 : tensor<256xi32> loc(#loc229)
    %401 = arith.cmpi ne, %400, %cst_1 : tensor<256xi32> loc(#loc230)
    %402 = arith.xori %382, %383 : tensor<256xi32> loc(#loc231)
    %403 = arith.select %401, %402, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %404 = arith.xori %397, %403 : tensor<256xi32> loc(#loc233)
    %405 = arith.xori %395, %396 : tensor<256xi16> loc(#loc234)
    %406 = arith.select %401, %405, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %407 = arith.xori %370, %406 : tensor<256xi16> loc(#loc236)
    %408 = tt.bitcast %404 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %409 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<4x2x32xi32> loc(#loc141)
    %410 = tt.reshape %409 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc142)
    %411 = tt.reshape %408 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc191)
    %412 = tt.bitcast %411 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc192)
    %413 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<8x2x16xi32> loc(#loc194)
    %414 = arith.muli %412, %413 : tensor<8x2x16xi32> loc(#loc194)
    %415 = "tt.reduce"(%414) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc238)
    %416 = tt.expand_dims %415 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc198)
    %417 = tt.broadcast %416 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc199)
    %418 = arith.muli %412, %256 : tensor<8x2x16xi32> loc(#loc200)
    %419 = "tt.reduce"(%418) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc241)
    %420 = tt.expand_dims %419 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc204)
    %421 = tt.broadcast %420 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc205)
    %422 = tt.reshape %417 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc206)
    %423 = tt.reshape %421 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc207)
    %424 = tt.bitcast %422 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %425 = tt.bitcast %423 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %426 = tt.reshape %407 : tensor<256xi16> -> tensor<8x2x16xi16> loc(#loc210)
    %427 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<8x2x16xi16> loc(#loc212)
    %428 = arith.muli %426, %427 : tensor<8x2x16xi16> loc(#loc212)
    %429 = "tt.reduce"(%428) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc244)
    %430 = tt.expand_dims %429 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc216)
    %431 = tt.broadcast %430 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc217)
    %432 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<8x2x16xi16> loc(#loc219)
    %433 = arith.muli %426, %432 : tensor<8x2x16xi16> loc(#loc219)
    %434 = "tt.reduce"(%433) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc247)
    %435 = tt.expand_dims %434 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc223)
    %436 = tt.broadcast %435 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc224)
    %437 = tt.reshape %431 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc225)
    %438 = tt.reshape %436 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc226)
    %439 = tt.bitcast %408 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %440 = arith.cmpf olt, %424, %425 : tensor<256xf32> loc(#loc228)
    %441 = arith.extui %440 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %442 = arith.xori %441, %410 : tensor<256xi32> loc(#loc229)
    %443 = arith.cmpi ne, %442, %cst_1 : tensor<256xi32> loc(#loc230)
    %444 = arith.xori %422, %423 : tensor<256xi32> loc(#loc231)
    %445 = arith.select %443, %444, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %446 = arith.xori %439, %445 : tensor<256xi32> loc(#loc233)
    %447 = arith.xori %437, %438 : tensor<256xi16> loc(#loc234)
    %448 = arith.select %443, %447, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %449 = arith.xori %407, %448 : tensor<256xi16> loc(#loc236)
    %450 = tt.bitcast %446 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %451 = tt.reshape %450 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc191)
    %452 = tt.bitcast %451 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc192)
    %453 = arith.muli %452, %260 : tensor<16x2x8xi32> loc(#loc194)
    %454 = "tt.reduce"(%453) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc238)
    %455 = tt.expand_dims %454 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc198)
    %456 = tt.broadcast %455 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc199)
    %457 = arith.muli %452, %140 : tensor<16x2x8xi32> loc(#loc200)
    %458 = "tt.reduce"(%457) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc241)
    %459 = tt.expand_dims %458 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc204)
    %460 = tt.broadcast %459 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc205)
    %461 = tt.reshape %456 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc206)
    %462 = tt.reshape %460 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc207)
    %463 = tt.bitcast %461 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %464 = tt.bitcast %462 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %465 = tt.reshape %449 : tensor<256xi16> -> tensor<16x2x8xi16> loc(#loc210)
    %466 = arith.muli %465, %274 : tensor<16x2x8xi16> loc(#loc212)
    %467 = "tt.reduce"(%466) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc244)
    %468 = tt.expand_dims %467 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc216)
    %469 = tt.broadcast %468 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc217)
    %470 = arith.muli %465, %279 : tensor<16x2x8xi16> loc(#loc219)
    %471 = "tt.reduce"(%470) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc247)
    %472 = tt.expand_dims %471 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc223)
    %473 = tt.broadcast %472 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc224)
    %474 = tt.reshape %469 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc225)
    %475 = tt.reshape %473 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc226)
    %476 = tt.bitcast %450 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %477 = arith.cmpf olt, %463, %464 : tensor<256xf32> loc(#loc228)
    %478 = arith.extui %477 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %479 = arith.xori %478, %410 : tensor<256xi32> loc(#loc229)
    %480 = arith.cmpi ne, %479, %cst_1 : tensor<256xi32> loc(#loc230)
    %481 = arith.xori %461, %462 : tensor<256xi32> loc(#loc231)
    %482 = arith.select %480, %481, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %483 = arith.xori %476, %482 : tensor<256xi32> loc(#loc233)
    %484 = arith.xori %474, %475 : tensor<256xi16> loc(#loc234)
    %485 = arith.select %480, %484, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %486 = arith.xori %449, %485 : tensor<256xi16> loc(#loc236)
    %487 = tt.bitcast %483 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %488 = tt.reshape %487 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc191)
    %489 = tt.bitcast %488 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc192)
    %490 = arith.muli %489, %144 : tensor<32x2x4xi32> loc(#loc194)
    %491 = "tt.reduce"(%490) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc238)
    %492 = tt.expand_dims %491 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc198)
    %493 = tt.broadcast %492 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc199)
    %494 = arith.muli %489, %61 : tensor<32x2x4xi32> loc(#loc200)
    %495 = "tt.reduce"(%494) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc241)
    %496 = tt.expand_dims %495 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc204)
    %497 = tt.broadcast %496 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc205)
    %498 = tt.reshape %493 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc206)
    %499 = tt.reshape %497 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc207)
    %500 = tt.bitcast %498 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %501 = tt.bitcast %499 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %502 = tt.reshape %486 : tensor<256xi16> -> tensor<32x2x4xi16> loc(#loc210)
    %503 = arith.muli %502, %158 : tensor<32x2x4xi16> loc(#loc212)
    %504 = "tt.reduce"(%503) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc244)
    %505 = tt.expand_dims %504 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc216)
    %506 = tt.broadcast %505 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc217)
    %507 = arith.muli %502, %163 : tensor<32x2x4xi16> loc(#loc219)
    %508 = "tt.reduce"(%507) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc247)
    %509 = tt.expand_dims %508 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc223)
    %510 = tt.broadcast %509 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc224)
    %511 = tt.reshape %506 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc225)
    %512 = tt.reshape %510 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc226)
    %513 = tt.bitcast %487 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %514 = arith.cmpf olt, %500, %501 : tensor<256xf32> loc(#loc228)
    %515 = arith.extui %514 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %516 = arith.xori %515, %410 : tensor<256xi32> loc(#loc229)
    %517 = arith.cmpi ne, %516, %cst_1 : tensor<256xi32> loc(#loc230)
    %518 = arith.xori %498, %499 : tensor<256xi32> loc(#loc231)
    %519 = arith.select %517, %518, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %520 = arith.xori %513, %519 : tensor<256xi32> loc(#loc233)
    %521 = arith.xori %511, %512 : tensor<256xi16> loc(#loc234)
    %522 = arith.select %517, %521, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %523 = arith.xori %486, %522 : tensor<256xi16> loc(#loc236)
    %524 = tt.bitcast %520 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %525 = tt.reshape %524 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc191)
    %526 = tt.bitcast %525 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc192)
    %527 = arith.muli %526, %65 : tensor<64x2x2xi32> loc(#loc194)
    %528 = "tt.reduce"(%527) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc238)
    %529 = tt.expand_dims %528 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc198)
    %530 = tt.broadcast %529 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc199)
    %531 = arith.muli %526, %15 : tensor<64x2x2xi32> loc(#loc200)
    %532 = "tt.reduce"(%531) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc241)
    %533 = tt.expand_dims %532 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc204)
    %534 = tt.broadcast %533 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc205)
    %535 = tt.reshape %530 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc206)
    %536 = tt.reshape %534 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc207)
    %537 = tt.bitcast %535 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %538 = tt.bitcast %536 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %539 = tt.reshape %523 : tensor<256xi16> -> tensor<64x2x2xi16> loc(#loc210)
    %540 = arith.muli %539, %79 : tensor<64x2x2xi16> loc(#loc212)
    %541 = "tt.reduce"(%540) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc244)
    %542 = tt.expand_dims %541 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc216)
    %543 = tt.broadcast %542 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc217)
    %544 = arith.muli %539, %84 : tensor<64x2x2xi16> loc(#loc219)
    %545 = "tt.reduce"(%544) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc247)
    %546 = tt.expand_dims %545 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc223)
    %547 = tt.broadcast %546 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc224)
    %548 = tt.reshape %543 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc225)
    %549 = tt.reshape %547 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc226)
    %550 = tt.bitcast %524 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %551 = arith.cmpf olt, %537, %538 : tensor<256xf32> loc(#loc228)
    %552 = arith.extui %551 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %553 = arith.xori %552, %410 : tensor<256xi32> loc(#loc229)
    %554 = arith.cmpi ne, %553, %cst_1 : tensor<256xi32> loc(#loc230)
    %555 = arith.xori %535, %536 : tensor<256xi32> loc(#loc231)
    %556 = arith.select %554, %555, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %557 = arith.xori %550, %556 : tensor<256xi32> loc(#loc233)
    %558 = arith.xori %548, %549 : tensor<256xi16> loc(#loc234)
    %559 = arith.select %554, %558, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %560 = arith.xori %523, %559 : tensor<256xi16> loc(#loc236)
    %561 = tt.bitcast %557 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %562 = tt.reshape %561 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %563 = tt.bitcast %562 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %564 = arith.muli %563, %20 : tensor<128x2x1xi32> loc(#loc194)
    %565 = "tt.reduce"(%564) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %566 = tt.expand_dims %565 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %567 = tt.broadcast %566 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %568 = arith.muli %563, %25 : tensor<128x2x1xi32> loc(#loc200)
    %569 = "tt.reduce"(%568) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %570 = tt.expand_dims %569 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %571 = tt.broadcast %570 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %572 = tt.reshape %567 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %573 = tt.reshape %571 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %574 = tt.bitcast %572 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %575 = tt.bitcast %573 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %576 = tt.reshape %560 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %577 = arith.muli %576, %36 : tensor<128x2x1xi16> loc(#loc212)
    %578 = "tt.reduce"(%577) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %579 = tt.expand_dims %578 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %580 = tt.broadcast %579 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %581 = arith.muli %576, %42 : tensor<128x2x1xi16> loc(#loc219)
    %582 = "tt.reduce"(%581) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %583 = tt.expand_dims %582 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %584 = tt.broadcast %583 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %585 = tt.reshape %580 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %586 = tt.reshape %584 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %587 = tt.bitcast %561 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %588 = arith.cmpf olt, %574, %575 : tensor<256xf32> loc(#loc228)
    %589 = arith.extui %588 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %590 = arith.xori %589, %410 : tensor<256xi32> loc(#loc229)
    %591 = arith.cmpi ne, %590, %cst_1 : tensor<256xi32> loc(#loc230)
    %592 = arith.xori %572, %573 : tensor<256xi32> loc(#loc231)
    %593 = arith.select %591, %592, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %594 = arith.xori %587, %593 : tensor<256xi32> loc(#loc233)
    %595 = arith.xori %585, %586 : tensor<256xi16> loc(#loc234)
    %596 = arith.select %591, %595, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %597 = arith.xori %560, %596 : tensor<256xi16> loc(#loc236)
    %598 = tt.bitcast %594 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %599 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<2x2x64xi32> loc(#loc141)
    %600 = tt.reshape %599 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc142)
    %601 = tt.reshape %598 : tensor<256xf32> -> tensor<4x2x32xf32> loc(#loc191)
    %602 = tt.bitcast %601 : tensor<4x2x32xf32> -> tensor<4x2x32xi32> loc(#loc192)
    %603 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<4x2x32xi32> loc(#loc194)
    %604 = arith.muli %602, %603 : tensor<4x2x32xi32> loc(#loc194)
    %605 = "tt.reduce"(%604) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc238)
    %606 = tt.expand_dims %605 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc198)
    %607 = tt.broadcast %606 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc199)
    %608 = arith.muli %602, %409 : tensor<4x2x32xi32> loc(#loc200)
    %609 = "tt.reduce"(%608) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc241)
    %610 = tt.expand_dims %609 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc204)
    %611 = tt.broadcast %610 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc205)
    %612 = tt.reshape %607 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc206)
    %613 = tt.reshape %611 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc207)
    %614 = tt.bitcast %612 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %615 = tt.bitcast %613 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %616 = tt.reshape %597 : tensor<256xi16> -> tensor<4x2x32xi16> loc(#loc210)
    %617 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<4x2x32xi16> loc(#loc212)
    %618 = arith.muli %616, %617 : tensor<4x2x32xi16> loc(#loc212)
    %619 = "tt.reduce"(%618) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<4x2x32xi16>) -> tensor<4x32xi16> loc(#loc244)
    %620 = tt.expand_dims %619 {axis = 1 : i32} : tensor<4x32xi16> -> tensor<4x1x32xi16> loc(#loc216)
    %621 = tt.broadcast %620 : tensor<4x1x32xi16> -> tensor<4x2x32xi16> loc(#loc217)
    %622 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<4x2x32xi16> loc(#loc219)
    %623 = arith.muli %616, %622 : tensor<4x2x32xi16> loc(#loc219)
    %624 = "tt.reduce"(%623) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<4x2x32xi16>) -> tensor<4x32xi16> loc(#loc247)
    %625 = tt.expand_dims %624 {axis = 1 : i32} : tensor<4x32xi16> -> tensor<4x1x32xi16> loc(#loc223)
    %626 = tt.broadcast %625 : tensor<4x1x32xi16> -> tensor<4x2x32xi16> loc(#loc224)
    %627 = tt.reshape %621 : tensor<4x2x32xi16> -> tensor<256xi16> loc(#loc225)
    %628 = tt.reshape %626 : tensor<4x2x32xi16> -> tensor<256xi16> loc(#loc226)
    %629 = tt.bitcast %598 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %630 = arith.cmpf olt, %614, %615 : tensor<256xf32> loc(#loc228)
    %631 = arith.extui %630 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %632 = arith.xori %631, %600 : tensor<256xi32> loc(#loc229)
    %633 = arith.cmpi ne, %632, %cst_1 : tensor<256xi32> loc(#loc230)
    %634 = arith.xori %612, %613 : tensor<256xi32> loc(#loc231)
    %635 = arith.select %633, %634, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %636 = arith.xori %629, %635 : tensor<256xi32> loc(#loc233)
    %637 = arith.xori %627, %628 : tensor<256xi16> loc(#loc234)
    %638 = arith.select %633, %637, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %639 = arith.xori %597, %638 : tensor<256xi16> loc(#loc236)
    %640 = tt.bitcast %636 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %641 = tt.reshape %640 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc191)
    %642 = tt.bitcast %641 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc192)
    %643 = arith.muli %642, %413 : tensor<8x2x16xi32> loc(#loc194)
    %644 = "tt.reduce"(%643) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc238)
    %645 = tt.expand_dims %644 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc198)
    %646 = tt.broadcast %645 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc199)
    %647 = arith.muli %642, %256 : tensor<8x2x16xi32> loc(#loc200)
    %648 = "tt.reduce"(%647) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc241)
    %649 = tt.expand_dims %648 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc204)
    %650 = tt.broadcast %649 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc205)
    %651 = tt.reshape %646 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc206)
    %652 = tt.reshape %650 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc207)
    %653 = tt.bitcast %651 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %654 = tt.bitcast %652 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %655 = tt.reshape %639 : tensor<256xi16> -> tensor<8x2x16xi16> loc(#loc210)
    %656 = arith.muli %655, %427 : tensor<8x2x16xi16> loc(#loc212)
    %657 = "tt.reduce"(%656) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc244)
    %658 = tt.expand_dims %657 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc216)
    %659 = tt.broadcast %658 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc217)
    %660 = arith.muli %655, %432 : tensor<8x2x16xi16> loc(#loc219)
    %661 = "tt.reduce"(%660) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc247)
    %662 = tt.expand_dims %661 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc223)
    %663 = tt.broadcast %662 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc224)
    %664 = tt.reshape %659 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc225)
    %665 = tt.reshape %663 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc226)
    %666 = tt.bitcast %640 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %667 = arith.cmpf olt, %653, %654 : tensor<256xf32> loc(#loc228)
    %668 = arith.extui %667 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %669 = arith.xori %668, %600 : tensor<256xi32> loc(#loc229)
    %670 = arith.cmpi ne, %669, %cst_1 : tensor<256xi32> loc(#loc230)
    %671 = arith.xori %651, %652 : tensor<256xi32> loc(#loc231)
    %672 = arith.select %670, %671, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %673 = arith.xori %666, %672 : tensor<256xi32> loc(#loc233)
    %674 = arith.xori %664, %665 : tensor<256xi16> loc(#loc234)
    %675 = arith.select %670, %674, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %676 = arith.xori %639, %675 : tensor<256xi16> loc(#loc236)
    %677 = tt.bitcast %673 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %678 = tt.reshape %677 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc191)
    %679 = tt.bitcast %678 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc192)
    %680 = arith.muli %679, %260 : tensor<16x2x8xi32> loc(#loc194)
    %681 = "tt.reduce"(%680) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc238)
    %682 = tt.expand_dims %681 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc198)
    %683 = tt.broadcast %682 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc199)
    %684 = arith.muli %679, %140 : tensor<16x2x8xi32> loc(#loc200)
    %685 = "tt.reduce"(%684) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc241)
    %686 = tt.expand_dims %685 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc204)
    %687 = tt.broadcast %686 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc205)
    %688 = tt.reshape %683 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc206)
    %689 = tt.reshape %687 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc207)
    %690 = tt.bitcast %688 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %691 = tt.bitcast %689 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %692 = tt.reshape %676 : tensor<256xi16> -> tensor<16x2x8xi16> loc(#loc210)
    %693 = arith.muli %692, %274 : tensor<16x2x8xi16> loc(#loc212)
    %694 = "tt.reduce"(%693) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc244)
    %695 = tt.expand_dims %694 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc216)
    %696 = tt.broadcast %695 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc217)
    %697 = arith.muli %692, %279 : tensor<16x2x8xi16> loc(#loc219)
    %698 = "tt.reduce"(%697) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc247)
    %699 = tt.expand_dims %698 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc223)
    %700 = tt.broadcast %699 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc224)
    %701 = tt.reshape %696 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc225)
    %702 = tt.reshape %700 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc226)
    %703 = tt.bitcast %677 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %704 = arith.cmpf olt, %690, %691 : tensor<256xf32> loc(#loc228)
    %705 = arith.extui %704 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %706 = arith.xori %705, %600 : tensor<256xi32> loc(#loc229)
    %707 = arith.cmpi ne, %706, %cst_1 : tensor<256xi32> loc(#loc230)
    %708 = arith.xori %688, %689 : tensor<256xi32> loc(#loc231)
    %709 = arith.select %707, %708, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %710 = arith.xori %703, %709 : tensor<256xi32> loc(#loc233)
    %711 = arith.xori %701, %702 : tensor<256xi16> loc(#loc234)
    %712 = arith.select %707, %711, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %713 = arith.xori %676, %712 : tensor<256xi16> loc(#loc236)
    %714 = tt.bitcast %710 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %715 = tt.reshape %714 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc191)
    %716 = tt.bitcast %715 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc192)
    %717 = arith.muli %716, %144 : tensor<32x2x4xi32> loc(#loc194)
    %718 = "tt.reduce"(%717) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc238)
    %719 = tt.expand_dims %718 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc198)
    %720 = tt.broadcast %719 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc199)
    %721 = arith.muli %716, %61 : tensor<32x2x4xi32> loc(#loc200)
    %722 = "tt.reduce"(%721) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc241)
    %723 = tt.expand_dims %722 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc204)
    %724 = tt.broadcast %723 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc205)
    %725 = tt.reshape %720 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc206)
    %726 = tt.reshape %724 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc207)
    %727 = tt.bitcast %725 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %728 = tt.bitcast %726 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %729 = tt.reshape %713 : tensor<256xi16> -> tensor<32x2x4xi16> loc(#loc210)
    %730 = arith.muli %729, %158 : tensor<32x2x4xi16> loc(#loc212)
    %731 = "tt.reduce"(%730) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc244)
    %732 = tt.expand_dims %731 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc216)
    %733 = tt.broadcast %732 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc217)
    %734 = arith.muli %729, %163 : tensor<32x2x4xi16> loc(#loc219)
    %735 = "tt.reduce"(%734) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc247)
    %736 = tt.expand_dims %735 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc223)
    %737 = tt.broadcast %736 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc224)
    %738 = tt.reshape %733 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc225)
    %739 = tt.reshape %737 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc226)
    %740 = tt.bitcast %714 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %741 = arith.cmpf olt, %727, %728 : tensor<256xf32> loc(#loc228)
    %742 = arith.extui %741 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %743 = arith.xori %742, %600 : tensor<256xi32> loc(#loc229)
    %744 = arith.cmpi ne, %743, %cst_1 : tensor<256xi32> loc(#loc230)
    %745 = arith.xori %725, %726 : tensor<256xi32> loc(#loc231)
    %746 = arith.select %744, %745, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %747 = arith.xori %740, %746 : tensor<256xi32> loc(#loc233)
    %748 = arith.xori %738, %739 : tensor<256xi16> loc(#loc234)
    %749 = arith.select %744, %748, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %750 = arith.xori %713, %749 : tensor<256xi16> loc(#loc236)
    %751 = tt.bitcast %747 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %752 = tt.reshape %751 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc191)
    %753 = tt.bitcast %752 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc192)
    %754 = arith.muli %753, %65 : tensor<64x2x2xi32> loc(#loc194)
    %755 = "tt.reduce"(%754) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc238)
    %756 = tt.expand_dims %755 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc198)
    %757 = tt.broadcast %756 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc199)
    %758 = arith.muli %753, %15 : tensor<64x2x2xi32> loc(#loc200)
    %759 = "tt.reduce"(%758) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc241)
    %760 = tt.expand_dims %759 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc204)
    %761 = tt.broadcast %760 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc205)
    %762 = tt.reshape %757 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc206)
    %763 = tt.reshape %761 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc207)
    %764 = tt.bitcast %762 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %765 = tt.bitcast %763 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %766 = tt.reshape %750 : tensor<256xi16> -> tensor<64x2x2xi16> loc(#loc210)
    %767 = arith.muli %766, %79 : tensor<64x2x2xi16> loc(#loc212)
    %768 = "tt.reduce"(%767) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc244)
    %769 = tt.expand_dims %768 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc216)
    %770 = tt.broadcast %769 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc217)
    %771 = arith.muli %766, %84 : tensor<64x2x2xi16> loc(#loc219)
    %772 = "tt.reduce"(%771) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc247)
    %773 = tt.expand_dims %772 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc223)
    %774 = tt.broadcast %773 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc224)
    %775 = tt.reshape %770 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc225)
    %776 = tt.reshape %774 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc226)
    %777 = tt.bitcast %751 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %778 = arith.cmpf olt, %764, %765 : tensor<256xf32> loc(#loc228)
    %779 = arith.extui %778 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %780 = arith.xori %779, %600 : tensor<256xi32> loc(#loc229)
    %781 = arith.cmpi ne, %780, %cst_1 : tensor<256xi32> loc(#loc230)
    %782 = arith.xori %762, %763 : tensor<256xi32> loc(#loc231)
    %783 = arith.select %781, %782, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %784 = arith.xori %777, %783 : tensor<256xi32> loc(#loc233)
    %785 = arith.xori %775, %776 : tensor<256xi16> loc(#loc234)
    %786 = arith.select %781, %785, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %787 = arith.xori %750, %786 : tensor<256xi16> loc(#loc236)
    %788 = tt.bitcast %784 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %789 = tt.reshape %788 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %790 = tt.bitcast %789 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %791 = arith.muli %790, %20 : tensor<128x2x1xi32> loc(#loc194)
    %792 = "tt.reduce"(%791) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %793 = tt.expand_dims %792 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %794 = tt.broadcast %793 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %795 = arith.muli %790, %25 : tensor<128x2x1xi32> loc(#loc200)
    %796 = "tt.reduce"(%795) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %797 = tt.expand_dims %796 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %798 = tt.broadcast %797 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %799 = tt.reshape %794 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %800 = tt.reshape %798 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %801 = tt.bitcast %799 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %802 = tt.bitcast %800 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %803 = tt.reshape %787 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %804 = arith.muli %803, %36 : tensor<128x2x1xi16> loc(#loc212)
    %805 = "tt.reduce"(%804) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %806 = tt.expand_dims %805 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %807 = tt.broadcast %806 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %808 = arith.muli %803, %42 : tensor<128x2x1xi16> loc(#loc219)
    %809 = "tt.reduce"(%808) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %810 = tt.expand_dims %809 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %811 = tt.broadcast %810 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %812 = tt.reshape %807 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %813 = tt.reshape %811 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %814 = tt.bitcast %788 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %815 = arith.cmpf olt, %801, %802 : tensor<256xf32> loc(#loc228)
    %816 = arith.extui %815 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %817 = arith.xori %816, %600 : tensor<256xi32> loc(#loc229)
    %818 = arith.cmpi ne, %817, %cst_1 : tensor<256xi32> loc(#loc230)
    %819 = arith.xori %799, %800 : tensor<256xi32> loc(#loc231)
    %820 = arith.select %818, %819, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %821 = arith.xori %814, %820 : tensor<256xi32> loc(#loc233)
    %822 = arith.xori %812, %813 : tensor<256xi16> loc(#loc234)
    %823 = arith.select %818, %822, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %824 = arith.xori %787, %823 : tensor<256xi16> loc(#loc236)
    %825 = tt.bitcast %821 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %826 = tt.broadcast %14 : tensor<1x2x1xi32> -> tensor<1x2x128xi32> loc(#loc141)
    %827 = tt.reshape %826 : tensor<1x2x128xi32> -> tensor<256xi32> loc(#loc142)
    %828 = tt.reshape %825 : tensor<256xf32> -> tensor<2x2x64xf32> loc(#loc191)
    %829 = tt.bitcast %828 : tensor<2x2x64xf32> -> tensor<2x2x64xi32> loc(#loc192)
    %830 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<2x2x64xi32> loc(#loc194)
    %831 = arith.muli %829, %830 : tensor<2x2x64xi32> loc(#loc194)
    %832 = "tt.reduce"(%831) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc238)
    %833 = tt.expand_dims %832 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc198)
    %834 = tt.broadcast %833 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc199)
    %835 = arith.muli %829, %599 : tensor<2x2x64xi32> loc(#loc200)
    %836 = "tt.reduce"(%835) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc241)
    %837 = tt.expand_dims %836 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc204)
    %838 = tt.broadcast %837 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc205)
    %839 = tt.reshape %834 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc206)
    %840 = tt.reshape %838 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc207)
    %841 = tt.bitcast %839 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %842 = tt.bitcast %840 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %843 = tt.reshape %824 : tensor<256xi16> -> tensor<2x2x64xi16> loc(#loc210)
    %844 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<2x2x64xi16> loc(#loc212)
    %845 = arith.muli %843, %844 : tensor<2x2x64xi16> loc(#loc212)
    %846 = "tt.reduce"(%845) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<2x2x64xi16>) -> tensor<2x64xi16> loc(#loc244)
    %847 = tt.expand_dims %846 {axis = 1 : i32} : tensor<2x64xi16> -> tensor<2x1x64xi16> loc(#loc216)
    %848 = tt.broadcast %847 : tensor<2x1x64xi16> -> tensor<2x2x64xi16> loc(#loc217)
    %849 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<2x2x64xi16> loc(#loc219)
    %850 = arith.muli %843, %849 : tensor<2x2x64xi16> loc(#loc219)
    %851 = "tt.reduce"(%850) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<2x2x64xi16>) -> tensor<2x64xi16> loc(#loc247)
    %852 = tt.expand_dims %851 {axis = 1 : i32} : tensor<2x64xi16> -> tensor<2x1x64xi16> loc(#loc223)
    %853 = tt.broadcast %852 : tensor<2x1x64xi16> -> tensor<2x2x64xi16> loc(#loc224)
    %854 = tt.reshape %848 : tensor<2x2x64xi16> -> tensor<256xi16> loc(#loc225)
    %855 = tt.reshape %853 : tensor<2x2x64xi16> -> tensor<256xi16> loc(#loc226)
    %856 = tt.bitcast %825 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %857 = arith.cmpf olt, %841, %842 : tensor<256xf32> loc(#loc228)
    %858 = arith.extui %857 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %859 = arith.xori %858, %827 : tensor<256xi32> loc(#loc229)
    %860 = arith.cmpi ne, %859, %cst_1 : tensor<256xi32> loc(#loc230)
    %861 = arith.xori %839, %840 : tensor<256xi32> loc(#loc231)
    %862 = arith.select %860, %861, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %863 = arith.xori %856, %862 : tensor<256xi32> loc(#loc233)
    %864 = arith.xori %854, %855 : tensor<256xi16> loc(#loc234)
    %865 = arith.select %860, %864, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %866 = arith.xori %824, %865 : tensor<256xi16> loc(#loc236)
    %867 = tt.bitcast %863 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %868 = tt.reshape %867 : tensor<256xf32> -> tensor<4x2x32xf32> loc(#loc191)
    %869 = tt.bitcast %868 : tensor<4x2x32xf32> -> tensor<4x2x32xi32> loc(#loc192)
    %870 = arith.muli %869, %603 : tensor<4x2x32xi32> loc(#loc194)
    %871 = "tt.reduce"(%870) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc238)
    %872 = tt.expand_dims %871 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc198)
    %873 = tt.broadcast %872 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc199)
    %874 = arith.muli %869, %409 : tensor<4x2x32xi32> loc(#loc200)
    %875 = "tt.reduce"(%874) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc241)
    %876 = tt.expand_dims %875 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc204)
    %877 = tt.broadcast %876 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc205)
    %878 = tt.reshape %873 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc206)
    %879 = tt.reshape %877 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc207)
    %880 = tt.bitcast %878 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %881 = tt.bitcast %879 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %882 = tt.reshape %866 : tensor<256xi16> -> tensor<4x2x32xi16> loc(#loc210)
    %883 = arith.muli %882, %617 : tensor<4x2x32xi16> loc(#loc212)
    %884 = "tt.reduce"(%883) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<4x2x32xi16>) -> tensor<4x32xi16> loc(#loc244)
    %885 = tt.expand_dims %884 {axis = 1 : i32} : tensor<4x32xi16> -> tensor<4x1x32xi16> loc(#loc216)
    %886 = tt.broadcast %885 : tensor<4x1x32xi16> -> tensor<4x2x32xi16> loc(#loc217)
    %887 = arith.muli %882, %622 : tensor<4x2x32xi16> loc(#loc219)
    %888 = "tt.reduce"(%887) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<4x2x32xi16>) -> tensor<4x32xi16> loc(#loc247)
    %889 = tt.expand_dims %888 {axis = 1 : i32} : tensor<4x32xi16> -> tensor<4x1x32xi16> loc(#loc223)
    %890 = tt.broadcast %889 : tensor<4x1x32xi16> -> tensor<4x2x32xi16> loc(#loc224)
    %891 = tt.reshape %886 : tensor<4x2x32xi16> -> tensor<256xi16> loc(#loc225)
    %892 = tt.reshape %890 : tensor<4x2x32xi16> -> tensor<256xi16> loc(#loc226)
    %893 = tt.bitcast %867 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %894 = arith.cmpf olt, %880, %881 : tensor<256xf32> loc(#loc228)
    %895 = arith.extui %894 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %896 = arith.xori %895, %827 : tensor<256xi32> loc(#loc229)
    %897 = arith.cmpi ne, %896, %cst_1 : tensor<256xi32> loc(#loc230)
    %898 = arith.xori %878, %879 : tensor<256xi32> loc(#loc231)
    %899 = arith.select %897, %898, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %900 = arith.xori %893, %899 : tensor<256xi32> loc(#loc233)
    %901 = arith.xori %891, %892 : tensor<256xi16> loc(#loc234)
    %902 = arith.select %897, %901, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %903 = arith.xori %866, %902 : tensor<256xi16> loc(#loc236)
    %904 = tt.bitcast %900 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %905 = tt.reshape %904 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc191)
    %906 = tt.bitcast %905 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc192)
    %907 = arith.muli %906, %413 : tensor<8x2x16xi32> loc(#loc194)
    %908 = "tt.reduce"(%907) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc238)
    %909 = tt.expand_dims %908 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc198)
    %910 = tt.broadcast %909 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc199)
    %911 = arith.muli %906, %256 : tensor<8x2x16xi32> loc(#loc200)
    %912 = "tt.reduce"(%911) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc241)
    %913 = tt.expand_dims %912 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc204)
    %914 = tt.broadcast %913 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc205)
    %915 = tt.reshape %910 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc206)
    %916 = tt.reshape %914 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc207)
    %917 = tt.bitcast %915 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %918 = tt.bitcast %916 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %919 = tt.reshape %903 : tensor<256xi16> -> tensor<8x2x16xi16> loc(#loc210)
    %920 = arith.muli %919, %427 : tensor<8x2x16xi16> loc(#loc212)
    %921 = "tt.reduce"(%920) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc244)
    %922 = tt.expand_dims %921 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc216)
    %923 = tt.broadcast %922 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc217)
    %924 = arith.muli %919, %432 : tensor<8x2x16xi16> loc(#loc219)
    %925 = "tt.reduce"(%924) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc247)
    %926 = tt.expand_dims %925 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc223)
    %927 = tt.broadcast %926 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc224)
    %928 = tt.reshape %923 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc225)
    %929 = tt.reshape %927 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc226)
    %930 = tt.bitcast %904 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %931 = arith.cmpf olt, %917, %918 : tensor<256xf32> loc(#loc228)
    %932 = arith.extui %931 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %933 = arith.xori %932, %827 : tensor<256xi32> loc(#loc229)
    %934 = arith.cmpi ne, %933, %cst_1 : tensor<256xi32> loc(#loc230)
    %935 = arith.xori %915, %916 : tensor<256xi32> loc(#loc231)
    %936 = arith.select %934, %935, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %937 = arith.xori %930, %936 : tensor<256xi32> loc(#loc233)
    %938 = arith.xori %928, %929 : tensor<256xi16> loc(#loc234)
    %939 = arith.select %934, %938, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %940 = arith.xori %903, %939 : tensor<256xi16> loc(#loc236)
    %941 = tt.bitcast %937 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %942 = tt.reshape %941 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc191)
    %943 = tt.bitcast %942 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc192)
    %944 = arith.muli %943, %260 : tensor<16x2x8xi32> loc(#loc194)
    %945 = "tt.reduce"(%944) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc238)
    %946 = tt.expand_dims %945 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc198)
    %947 = tt.broadcast %946 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc199)
    %948 = arith.muli %943, %140 : tensor<16x2x8xi32> loc(#loc200)
    %949 = "tt.reduce"(%948) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc241)
    %950 = tt.expand_dims %949 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc204)
    %951 = tt.broadcast %950 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc205)
    %952 = tt.reshape %947 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc206)
    %953 = tt.reshape %951 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc207)
    %954 = tt.bitcast %952 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %955 = tt.bitcast %953 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %956 = tt.reshape %940 : tensor<256xi16> -> tensor<16x2x8xi16> loc(#loc210)
    %957 = arith.muli %956, %274 : tensor<16x2x8xi16> loc(#loc212)
    %958 = "tt.reduce"(%957) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc244)
    %959 = tt.expand_dims %958 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc216)
    %960 = tt.broadcast %959 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc217)
    %961 = arith.muli %956, %279 : tensor<16x2x8xi16> loc(#loc219)
    %962 = "tt.reduce"(%961) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc247)
    %963 = tt.expand_dims %962 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc223)
    %964 = tt.broadcast %963 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc224)
    %965 = tt.reshape %960 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc225)
    %966 = tt.reshape %964 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc226)
    %967 = tt.bitcast %941 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %968 = arith.cmpf olt, %954, %955 : tensor<256xf32> loc(#loc228)
    %969 = arith.extui %968 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %970 = arith.xori %969, %827 : tensor<256xi32> loc(#loc229)
    %971 = arith.cmpi ne, %970, %cst_1 : tensor<256xi32> loc(#loc230)
    %972 = arith.xori %952, %953 : tensor<256xi32> loc(#loc231)
    %973 = arith.select %971, %972, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %974 = arith.xori %967, %973 : tensor<256xi32> loc(#loc233)
    %975 = arith.xori %965, %966 : tensor<256xi16> loc(#loc234)
    %976 = arith.select %971, %975, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %977 = arith.xori %940, %976 : tensor<256xi16> loc(#loc236)
    %978 = tt.bitcast %974 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %979 = tt.reshape %978 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc191)
    %980 = tt.bitcast %979 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc192)
    %981 = arith.muli %980, %144 : tensor<32x2x4xi32> loc(#loc194)
    %982 = "tt.reduce"(%981) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc238)
    %983 = tt.expand_dims %982 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc198)
    %984 = tt.broadcast %983 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc199)
    %985 = arith.muli %980, %61 : tensor<32x2x4xi32> loc(#loc200)
    %986 = "tt.reduce"(%985) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc241)
    %987 = tt.expand_dims %986 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc204)
    %988 = tt.broadcast %987 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc205)
    %989 = tt.reshape %984 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc206)
    %990 = tt.reshape %988 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc207)
    %991 = tt.bitcast %989 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %992 = tt.bitcast %990 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %993 = tt.reshape %977 : tensor<256xi16> -> tensor<32x2x4xi16> loc(#loc210)
    %994 = arith.muli %993, %158 : tensor<32x2x4xi16> loc(#loc212)
    %995 = "tt.reduce"(%994) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc244)
    %996 = tt.expand_dims %995 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc216)
    %997 = tt.broadcast %996 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc217)
    %998 = arith.muli %993, %163 : tensor<32x2x4xi16> loc(#loc219)
    %999 = "tt.reduce"(%998) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc247)
    %1000 = tt.expand_dims %999 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc223)
    %1001 = tt.broadcast %1000 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc224)
    %1002 = tt.reshape %997 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc225)
    %1003 = tt.reshape %1001 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc226)
    %1004 = tt.bitcast %978 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1005 = arith.cmpf olt, %991, %992 : tensor<256xf32> loc(#loc228)
    %1006 = arith.extui %1005 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %1007 = arith.xori %1006, %827 : tensor<256xi32> loc(#loc229)
    %1008 = arith.cmpi ne, %1007, %cst_1 : tensor<256xi32> loc(#loc230)
    %1009 = arith.xori %989, %990 : tensor<256xi32> loc(#loc231)
    %1010 = arith.select %1008, %1009, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1011 = arith.xori %1004, %1010 : tensor<256xi32> loc(#loc233)
    %1012 = arith.xori %1002, %1003 : tensor<256xi16> loc(#loc234)
    %1013 = arith.select %1008, %1012, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1014 = arith.xori %977, %1013 : tensor<256xi16> loc(#loc236)
    %1015 = tt.bitcast %1011 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1016 = tt.reshape %1015 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc191)
    %1017 = tt.bitcast %1016 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc192)
    %1018 = arith.muli %1017, %65 : tensor<64x2x2xi32> loc(#loc194)
    %1019 = "tt.reduce"(%1018) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc238)
    %1020 = tt.expand_dims %1019 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc198)
    %1021 = tt.broadcast %1020 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc199)
    %1022 = arith.muli %1017, %15 : tensor<64x2x2xi32> loc(#loc200)
    %1023 = "tt.reduce"(%1022) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc241)
    %1024 = tt.expand_dims %1023 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc204)
    %1025 = tt.broadcast %1024 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc205)
    %1026 = tt.reshape %1021 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc206)
    %1027 = tt.reshape %1025 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc207)
    %1028 = tt.bitcast %1026 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1029 = tt.bitcast %1027 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1030 = tt.reshape %1014 : tensor<256xi16> -> tensor<64x2x2xi16> loc(#loc210)
    %1031 = arith.muli %1030, %79 : tensor<64x2x2xi16> loc(#loc212)
    %1032 = "tt.reduce"(%1031) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc244)
    %1033 = tt.expand_dims %1032 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc216)
    %1034 = tt.broadcast %1033 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc217)
    %1035 = arith.muli %1030, %84 : tensor<64x2x2xi16> loc(#loc219)
    %1036 = "tt.reduce"(%1035) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc247)
    %1037 = tt.expand_dims %1036 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc223)
    %1038 = tt.broadcast %1037 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc224)
    %1039 = tt.reshape %1034 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc225)
    %1040 = tt.reshape %1038 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc226)
    %1041 = tt.bitcast %1015 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1042 = arith.cmpf olt, %1028, %1029 : tensor<256xf32> loc(#loc228)
    %1043 = arith.extui %1042 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %1044 = arith.xori %1043, %827 : tensor<256xi32> loc(#loc229)
    %1045 = arith.cmpi ne, %1044, %cst_1 : tensor<256xi32> loc(#loc230)
    %1046 = arith.xori %1026, %1027 : tensor<256xi32> loc(#loc231)
    %1047 = arith.select %1045, %1046, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1048 = arith.xori %1041, %1047 : tensor<256xi32> loc(#loc233)
    %1049 = arith.xori %1039, %1040 : tensor<256xi16> loc(#loc234)
    %1050 = arith.select %1045, %1049, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1051 = arith.xori %1014, %1050 : tensor<256xi16> loc(#loc236)
    %1052 = tt.bitcast %1048 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1053 = tt.reshape %1052 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %1054 = tt.bitcast %1053 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %1055 = arith.muli %1054, %20 : tensor<128x2x1xi32> loc(#loc194)
    %1056 = "tt.reduce"(%1055) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %1057 = tt.expand_dims %1056 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %1058 = tt.broadcast %1057 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %1059 = arith.muli %1054, %25 : tensor<128x2x1xi32> loc(#loc200)
    %1060 = "tt.reduce"(%1059) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %1061 = tt.expand_dims %1060 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %1062 = tt.broadcast %1061 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %1063 = tt.reshape %1058 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %1064 = tt.reshape %1062 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %1065 = tt.bitcast %1063 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1066 = tt.bitcast %1064 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1067 = tt.reshape %1051 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %1068 = arith.muli %1067, %36 : tensor<128x2x1xi16> loc(#loc212)
    %1069 = "tt.reduce"(%1068) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %1070 = tt.expand_dims %1069 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %1071 = tt.broadcast %1070 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %1072 = arith.muli %1067, %42 : tensor<128x2x1xi16> loc(#loc219)
    %1073 = "tt.reduce"(%1072) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %1074 = tt.expand_dims %1073 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %1075 = tt.broadcast %1074 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %1076 = tt.reshape %1071 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %1077 = tt.reshape %1075 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %1078 = tt.bitcast %1052 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1079 = arith.cmpf olt, %1065, %1066 : tensor<256xf32> loc(#loc228)
    %1080 = arith.extui %1079 : tensor<256xi1> to tensor<256xi32> loc(#loc229)
    %1081 = arith.xori %1080, %827 : tensor<256xi32> loc(#loc229)
    %1082 = arith.cmpi ne, %1081, %cst_1 : tensor<256xi32> loc(#loc230)
    %1083 = arith.xori %1063, %1064 : tensor<256xi32> loc(#loc231)
    %1084 = arith.select %1082, %1083, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1085 = arith.xori %1078, %1084 : tensor<256xi32> loc(#loc233)
    %1086 = arith.xori %1076, %1077 : tensor<256xi16> loc(#loc234)
    %1087 = arith.select %1082, %1086, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1088 = arith.xori %1051, %1087 : tensor<256xi16> loc(#loc236)
    %1089 = tt.bitcast %1085 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1090 = tt.reshape %1089 : tensor<256xf32> -> tensor<1x2x128xf32> loc(#loc191)
    %1091 = tt.bitcast %1090 : tensor<1x2x128xf32> -> tensor<1x2x128xi32> loc(#loc192)
    %1092 = tt.broadcast %19 : tensor<1x2x1xi32> -> tensor<1x2x128xi32> loc(#loc194)
    %1093 = arith.muli %1091, %1092 : tensor<1x2x128xi32> loc(#loc194)
    %1094 = "tt.reduce"(%1093) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<1x2x128xi32>) -> tensor<1x128xi32> loc(#loc238)
    %1095 = tt.expand_dims %1094 {axis = 1 : i32} : tensor<1x128xi32> -> tensor<1x1x128xi32> loc(#loc198)
    %1096 = tt.broadcast %1095 : tensor<1x1x128xi32> -> tensor<1x2x128xi32> loc(#loc199)
    %1097 = arith.muli %1091, %826 : tensor<1x2x128xi32> loc(#loc200)
    %1098 = "tt.reduce"(%1097) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<1x2x128xi32>) -> tensor<1x128xi32> loc(#loc241)
    %1099 = tt.expand_dims %1098 {axis = 1 : i32} : tensor<1x128xi32> -> tensor<1x1x128xi32> loc(#loc204)
    %1100 = tt.broadcast %1099 : tensor<1x1x128xi32> -> tensor<1x2x128xi32> loc(#loc205)
    %1101 = tt.reshape %1096 : tensor<1x2x128xi32> -> tensor<256xi32> loc(#loc206)
    %1102 = tt.reshape %1100 : tensor<1x2x128xi32> -> tensor<256xi32> loc(#loc207)
    %1103 = tt.bitcast %1101 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1104 = tt.bitcast %1102 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1105 = tt.reshape %1088 : tensor<256xi16> -> tensor<1x2x128xi16> loc(#loc210)
    %1106 = tt.broadcast %35 : tensor<1x2x1xi16> -> tensor<1x2x128xi16> loc(#loc212)
    %1107 = arith.muli %1105, %1106 : tensor<1x2x128xi16> loc(#loc212)
    %1108 = "tt.reduce"(%1107) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<1x2x128xi16>) -> tensor<1x128xi16> loc(#loc244)
    %1109 = tt.expand_dims %1108 {axis = 1 : i32} : tensor<1x128xi16> -> tensor<1x1x128xi16> loc(#loc216)
    %1110 = tt.broadcast %1109 : tensor<1x1x128xi16> -> tensor<1x2x128xi16> loc(#loc217)
    %1111 = tt.broadcast %41 : tensor<1x2x1xi16> -> tensor<1x2x128xi16> loc(#loc219)
    %1112 = arith.muli %1105, %1111 : tensor<1x2x128xi16> loc(#loc219)
    %1113 = "tt.reduce"(%1112) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<1x2x128xi16>) -> tensor<1x128xi16> loc(#loc247)
    %1114 = tt.expand_dims %1113 {axis = 1 : i32} : tensor<1x128xi16> -> tensor<1x1x128xi16> loc(#loc223)
    %1115 = tt.broadcast %1114 : tensor<1x1x128xi16> -> tensor<1x2x128xi16> loc(#loc224)
    %1116 = tt.reshape %1110 : tensor<1x2x128xi16> -> tensor<256xi16> loc(#loc225)
    %1117 = tt.reshape %1115 : tensor<1x2x128xi16> -> tensor<256xi16> loc(#loc226)
    %1118 = tt.bitcast %1089 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1119 = arith.cmpf olt, %1103, %1104 : tensor<256xf32> loc(#loc228)
    %1120 = arith.xori %1101, %1102 : tensor<256xi32> loc(#loc231)
    %1121 = arith.select %1119, %1120, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1122 = arith.xori %1118, %1121 : tensor<256xi32> loc(#loc233)
    %1123 = arith.xori %1116, %1117 : tensor<256xi16> loc(#loc234)
    %1124 = arith.select %1119, %1123, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1125 = arith.xori %1088, %1124 : tensor<256xi16> loc(#loc236)
    %1126 = tt.bitcast %1122 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1127 = tt.reshape %1126 : tensor<256xf32> -> tensor<2x2x64xf32> loc(#loc191)
    %1128 = tt.bitcast %1127 : tensor<2x2x64xf32> -> tensor<2x2x64xi32> loc(#loc192)
    %1129 = arith.muli %1128, %830 : tensor<2x2x64xi32> loc(#loc194)
    %1130 = "tt.reduce"(%1129) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc238)
    %1131 = tt.expand_dims %1130 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc198)
    %1132 = tt.broadcast %1131 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc199)
    %1133 = arith.muli %1128, %599 : tensor<2x2x64xi32> loc(#loc200)
    %1134 = "tt.reduce"(%1133) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc241)
    %1135 = tt.expand_dims %1134 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc204)
    %1136 = tt.broadcast %1135 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc205)
    %1137 = tt.reshape %1132 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc206)
    %1138 = tt.reshape %1136 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc207)
    %1139 = tt.bitcast %1137 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1140 = tt.bitcast %1138 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1141 = tt.reshape %1125 : tensor<256xi16> -> tensor<2x2x64xi16> loc(#loc210)
    %1142 = arith.muli %1141, %844 : tensor<2x2x64xi16> loc(#loc212)
    %1143 = "tt.reduce"(%1142) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<2x2x64xi16>) -> tensor<2x64xi16> loc(#loc244)
    %1144 = tt.expand_dims %1143 {axis = 1 : i32} : tensor<2x64xi16> -> tensor<2x1x64xi16> loc(#loc216)
    %1145 = tt.broadcast %1144 : tensor<2x1x64xi16> -> tensor<2x2x64xi16> loc(#loc217)
    %1146 = arith.muli %1141, %849 : tensor<2x2x64xi16> loc(#loc219)
    %1147 = "tt.reduce"(%1146) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<2x2x64xi16>) -> tensor<2x64xi16> loc(#loc247)
    %1148 = tt.expand_dims %1147 {axis = 1 : i32} : tensor<2x64xi16> -> tensor<2x1x64xi16> loc(#loc223)
    %1149 = tt.broadcast %1148 : tensor<2x1x64xi16> -> tensor<2x2x64xi16> loc(#loc224)
    %1150 = tt.reshape %1145 : tensor<2x2x64xi16> -> tensor<256xi16> loc(#loc225)
    %1151 = tt.reshape %1149 : tensor<2x2x64xi16> -> tensor<256xi16> loc(#loc226)
    %1152 = tt.bitcast %1126 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1153 = arith.cmpf olt, %1139, %1140 : tensor<256xf32> loc(#loc228)
    %1154 = arith.xori %1137, %1138 : tensor<256xi32> loc(#loc231)
    %1155 = arith.select %1153, %1154, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1156 = arith.xori %1152, %1155 : tensor<256xi32> loc(#loc233)
    %1157 = arith.xori %1150, %1151 : tensor<256xi16> loc(#loc234)
    %1158 = arith.select %1153, %1157, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1159 = arith.xori %1125, %1158 : tensor<256xi16> loc(#loc236)
    %1160 = tt.bitcast %1156 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1161 = tt.reshape %1160 : tensor<256xf32> -> tensor<4x2x32xf32> loc(#loc191)
    %1162 = tt.bitcast %1161 : tensor<4x2x32xf32> -> tensor<4x2x32xi32> loc(#loc192)
    %1163 = arith.muli %1162, %603 : tensor<4x2x32xi32> loc(#loc194)
    %1164 = "tt.reduce"(%1163) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc238)
    %1165 = tt.expand_dims %1164 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc198)
    %1166 = tt.broadcast %1165 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc199)
    %1167 = arith.muli %1162, %409 : tensor<4x2x32xi32> loc(#loc200)
    %1168 = "tt.reduce"(%1167) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc241)
    %1169 = tt.expand_dims %1168 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc204)
    %1170 = tt.broadcast %1169 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc205)
    %1171 = tt.reshape %1166 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc206)
    %1172 = tt.reshape %1170 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc207)
    %1173 = tt.bitcast %1171 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1174 = tt.bitcast %1172 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1175 = tt.reshape %1159 : tensor<256xi16> -> tensor<4x2x32xi16> loc(#loc210)
    %1176 = arith.muli %1175, %617 : tensor<4x2x32xi16> loc(#loc212)
    %1177 = "tt.reduce"(%1176) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<4x2x32xi16>) -> tensor<4x32xi16> loc(#loc244)
    %1178 = tt.expand_dims %1177 {axis = 1 : i32} : tensor<4x32xi16> -> tensor<4x1x32xi16> loc(#loc216)
    %1179 = tt.broadcast %1178 : tensor<4x1x32xi16> -> tensor<4x2x32xi16> loc(#loc217)
    %1180 = arith.muli %1175, %622 : tensor<4x2x32xi16> loc(#loc219)
    %1181 = "tt.reduce"(%1180) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<4x2x32xi16>) -> tensor<4x32xi16> loc(#loc247)
    %1182 = tt.expand_dims %1181 {axis = 1 : i32} : tensor<4x32xi16> -> tensor<4x1x32xi16> loc(#loc223)
    %1183 = tt.broadcast %1182 : tensor<4x1x32xi16> -> tensor<4x2x32xi16> loc(#loc224)
    %1184 = tt.reshape %1179 : tensor<4x2x32xi16> -> tensor<256xi16> loc(#loc225)
    %1185 = tt.reshape %1183 : tensor<4x2x32xi16> -> tensor<256xi16> loc(#loc226)
    %1186 = tt.bitcast %1160 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1187 = arith.cmpf olt, %1173, %1174 : tensor<256xf32> loc(#loc228)
    %1188 = arith.xori %1171, %1172 : tensor<256xi32> loc(#loc231)
    %1189 = arith.select %1187, %1188, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1190 = arith.xori %1186, %1189 : tensor<256xi32> loc(#loc233)
    %1191 = arith.xori %1184, %1185 : tensor<256xi16> loc(#loc234)
    %1192 = arith.select %1187, %1191, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1193 = arith.xori %1159, %1192 : tensor<256xi16> loc(#loc236)
    %1194 = tt.bitcast %1190 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1195 = tt.reshape %1194 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc191)
    %1196 = tt.bitcast %1195 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc192)
    %1197 = arith.muli %1196, %413 : tensor<8x2x16xi32> loc(#loc194)
    %1198 = "tt.reduce"(%1197) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc238)
    %1199 = tt.expand_dims %1198 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc198)
    %1200 = tt.broadcast %1199 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc199)
    %1201 = arith.muli %1196, %256 : tensor<8x2x16xi32> loc(#loc200)
    %1202 = "tt.reduce"(%1201) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc241)
    %1203 = tt.expand_dims %1202 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc204)
    %1204 = tt.broadcast %1203 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc205)
    %1205 = tt.reshape %1200 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc206)
    %1206 = tt.reshape %1204 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc207)
    %1207 = tt.bitcast %1205 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1208 = tt.bitcast %1206 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1209 = tt.reshape %1193 : tensor<256xi16> -> tensor<8x2x16xi16> loc(#loc210)
    %1210 = arith.muli %1209, %427 : tensor<8x2x16xi16> loc(#loc212)
    %1211 = "tt.reduce"(%1210) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc244)
    %1212 = tt.expand_dims %1211 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc216)
    %1213 = tt.broadcast %1212 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc217)
    %1214 = arith.muli %1209, %432 : tensor<8x2x16xi16> loc(#loc219)
    %1215 = "tt.reduce"(%1214) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<8x2x16xi16>) -> tensor<8x16xi16> loc(#loc247)
    %1216 = tt.expand_dims %1215 {axis = 1 : i32} : tensor<8x16xi16> -> tensor<8x1x16xi16> loc(#loc223)
    %1217 = tt.broadcast %1216 : tensor<8x1x16xi16> -> tensor<8x2x16xi16> loc(#loc224)
    %1218 = tt.reshape %1213 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc225)
    %1219 = tt.reshape %1217 : tensor<8x2x16xi16> -> tensor<256xi16> loc(#loc226)
    %1220 = tt.bitcast %1194 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1221 = arith.cmpf olt, %1207, %1208 : tensor<256xf32> loc(#loc228)
    %1222 = arith.xori %1205, %1206 : tensor<256xi32> loc(#loc231)
    %1223 = arith.select %1221, %1222, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1224 = arith.xori %1220, %1223 : tensor<256xi32> loc(#loc233)
    %1225 = arith.xori %1218, %1219 : tensor<256xi16> loc(#loc234)
    %1226 = arith.select %1221, %1225, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1227 = arith.xori %1193, %1226 : tensor<256xi16> loc(#loc236)
    %1228 = tt.bitcast %1224 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1229 = tt.reshape %1228 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc191)
    %1230 = tt.bitcast %1229 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc192)
    %1231 = arith.muli %1230, %260 : tensor<16x2x8xi32> loc(#loc194)
    %1232 = "tt.reduce"(%1231) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc238)
    %1233 = tt.expand_dims %1232 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc198)
    %1234 = tt.broadcast %1233 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc199)
    %1235 = arith.muli %1230, %140 : tensor<16x2x8xi32> loc(#loc200)
    %1236 = "tt.reduce"(%1235) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc241)
    %1237 = tt.expand_dims %1236 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc204)
    %1238 = tt.broadcast %1237 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc205)
    %1239 = tt.reshape %1234 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc206)
    %1240 = tt.reshape %1238 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc207)
    %1241 = tt.bitcast %1239 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1242 = tt.bitcast %1240 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1243 = tt.reshape %1227 : tensor<256xi16> -> tensor<16x2x8xi16> loc(#loc210)
    %1244 = arith.muli %1243, %274 : tensor<16x2x8xi16> loc(#loc212)
    %1245 = "tt.reduce"(%1244) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc244)
    %1246 = tt.expand_dims %1245 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc216)
    %1247 = tt.broadcast %1246 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc217)
    %1248 = arith.muli %1243, %279 : tensor<16x2x8xi16> loc(#loc219)
    %1249 = "tt.reduce"(%1248) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<16x2x8xi16>) -> tensor<16x8xi16> loc(#loc247)
    %1250 = tt.expand_dims %1249 {axis = 1 : i32} : tensor<16x8xi16> -> tensor<16x1x8xi16> loc(#loc223)
    %1251 = tt.broadcast %1250 : tensor<16x1x8xi16> -> tensor<16x2x8xi16> loc(#loc224)
    %1252 = tt.reshape %1247 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc225)
    %1253 = tt.reshape %1251 : tensor<16x2x8xi16> -> tensor<256xi16> loc(#loc226)
    %1254 = tt.bitcast %1228 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1255 = arith.cmpf olt, %1241, %1242 : tensor<256xf32> loc(#loc228)
    %1256 = arith.xori %1239, %1240 : tensor<256xi32> loc(#loc231)
    %1257 = arith.select %1255, %1256, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1258 = arith.xori %1254, %1257 : tensor<256xi32> loc(#loc233)
    %1259 = arith.xori %1252, %1253 : tensor<256xi16> loc(#loc234)
    %1260 = arith.select %1255, %1259, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1261 = arith.xori %1227, %1260 : tensor<256xi16> loc(#loc236)
    %1262 = tt.bitcast %1258 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1263 = tt.reshape %1262 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc191)
    %1264 = tt.bitcast %1263 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc192)
    %1265 = arith.muli %1264, %144 : tensor<32x2x4xi32> loc(#loc194)
    %1266 = "tt.reduce"(%1265) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc238)
    %1267 = tt.expand_dims %1266 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc198)
    %1268 = tt.broadcast %1267 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc199)
    %1269 = arith.muli %1264, %61 : tensor<32x2x4xi32> loc(#loc200)
    %1270 = "tt.reduce"(%1269) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc241)
    %1271 = tt.expand_dims %1270 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc204)
    %1272 = tt.broadcast %1271 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc205)
    %1273 = tt.reshape %1268 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc206)
    %1274 = tt.reshape %1272 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc207)
    %1275 = tt.bitcast %1273 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1276 = tt.bitcast %1274 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1277 = tt.reshape %1261 : tensor<256xi16> -> tensor<32x2x4xi16> loc(#loc210)
    %1278 = arith.muli %1277, %158 : tensor<32x2x4xi16> loc(#loc212)
    %1279 = "tt.reduce"(%1278) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc244)
    %1280 = tt.expand_dims %1279 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc216)
    %1281 = tt.broadcast %1280 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc217)
    %1282 = arith.muli %1277, %163 : tensor<32x2x4xi16> loc(#loc219)
    %1283 = "tt.reduce"(%1282) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<32x2x4xi16>) -> tensor<32x4xi16> loc(#loc247)
    %1284 = tt.expand_dims %1283 {axis = 1 : i32} : tensor<32x4xi16> -> tensor<32x1x4xi16> loc(#loc223)
    %1285 = tt.broadcast %1284 : tensor<32x1x4xi16> -> tensor<32x2x4xi16> loc(#loc224)
    %1286 = tt.reshape %1281 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc225)
    %1287 = tt.reshape %1285 : tensor<32x2x4xi16> -> tensor<256xi16> loc(#loc226)
    %1288 = tt.bitcast %1262 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1289 = arith.cmpf olt, %1275, %1276 : tensor<256xf32> loc(#loc228)
    %1290 = arith.xori %1273, %1274 : tensor<256xi32> loc(#loc231)
    %1291 = arith.select %1289, %1290, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1292 = arith.xori %1288, %1291 : tensor<256xi32> loc(#loc233)
    %1293 = arith.xori %1286, %1287 : tensor<256xi16> loc(#loc234)
    %1294 = arith.select %1289, %1293, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1295 = arith.xori %1261, %1294 : tensor<256xi16> loc(#loc236)
    %1296 = tt.bitcast %1292 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1297 = tt.reshape %1296 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc191)
    %1298 = tt.bitcast %1297 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc192)
    %1299 = arith.muli %1298, %65 : tensor<64x2x2xi32> loc(#loc194)
    %1300 = "tt.reduce"(%1299) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc238)
    %1301 = tt.expand_dims %1300 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc198)
    %1302 = tt.broadcast %1301 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc199)
    %1303 = arith.muli %1298, %15 : tensor<64x2x2xi32> loc(#loc200)
    %1304 = "tt.reduce"(%1303) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc241)
    %1305 = tt.expand_dims %1304 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc204)
    %1306 = tt.broadcast %1305 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc205)
    %1307 = tt.reshape %1302 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc206)
    %1308 = tt.reshape %1306 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc207)
    %1309 = tt.bitcast %1307 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1310 = tt.bitcast %1308 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1311 = tt.reshape %1295 : tensor<256xi16> -> tensor<64x2x2xi16> loc(#loc210)
    %1312 = arith.muli %1311, %79 : tensor<64x2x2xi16> loc(#loc212)
    %1313 = "tt.reduce"(%1312) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc244)
    %1314 = tt.expand_dims %1313 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc216)
    %1315 = tt.broadcast %1314 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc217)
    %1316 = arith.muli %1311, %84 : tensor<64x2x2xi16> loc(#loc219)
    %1317 = "tt.reduce"(%1316) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<64x2x2xi16>) -> tensor<64x2xi16> loc(#loc247)
    %1318 = tt.expand_dims %1317 {axis = 1 : i32} : tensor<64x2xi16> -> tensor<64x1x2xi16> loc(#loc223)
    %1319 = tt.broadcast %1318 : tensor<64x1x2xi16> -> tensor<64x2x2xi16> loc(#loc224)
    %1320 = tt.reshape %1315 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc225)
    %1321 = tt.reshape %1319 : tensor<64x2x2xi16> -> tensor<256xi16> loc(#loc226)
    %1322 = tt.bitcast %1296 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1323 = arith.cmpf olt, %1309, %1310 : tensor<256xf32> loc(#loc228)
    %1324 = arith.xori %1307, %1308 : tensor<256xi32> loc(#loc231)
    %1325 = arith.select %1323, %1324, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1326 = arith.xori %1322, %1325 : tensor<256xi32> loc(#loc233)
    %1327 = arith.xori %1320, %1321 : tensor<256xi16> loc(#loc234)
    %1328 = arith.select %1323, %1327, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1329 = arith.xori %1295, %1328 : tensor<256xi16> loc(#loc236)
    %1330 = tt.bitcast %1326 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1331 = tt.reshape %1330 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc191)
    %1332 = tt.bitcast %1331 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc192)
    %1333 = arith.muli %1332, %20 : tensor<128x2x1xi32> loc(#loc194)
    %1334 = "tt.reduce"(%1333) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc196 at #loc14)), %arg8: i32 loc(callsite(#loc196 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc250)
      tt.reduce.return %1388 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc238)
    %1335 = tt.expand_dims %1334 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc198)
    %1336 = tt.broadcast %1335 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc199)
    %1337 = arith.muli %1332, %25 : tensor<128x2x1xi32> loc(#loc200)
    %1338 = "tt.reduce"(%1337) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc14)), %arg8: i32 loc(callsite(#loc202 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i32 loc(#loc251)
      tt.reduce.return %1388 : i32 loc(#loc241)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc241)
    %1339 = tt.expand_dims %1338 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc204)
    %1340 = tt.broadcast %1339 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc205)
    %1341 = tt.reshape %1336 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc206)
    %1342 = tt.reshape %1340 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc207)
    %1343 = tt.bitcast %1341 : tensor<256xi32> -> tensor<256xf32> loc(#loc208)
    %1344 = tt.bitcast %1342 : tensor<256xi32> -> tensor<256xf32> loc(#loc209)
    %1345 = tt.reshape %1329 : tensor<256xi16> -> tensor<128x2x1xi16> loc(#loc210)
    %1346 = arith.muli %1345, %36 : tensor<128x2x1xi16> loc(#loc212)
    %1347 = "tt.reduce"(%1346) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc214 at #loc14)), %arg8: i16 loc(callsite(#loc214 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc252)
      tt.reduce.return %1388 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc244)
    %1348 = tt.expand_dims %1347 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc216)
    %1349 = tt.broadcast %1348 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc217)
    %1350 = arith.muli %1345, %42 : tensor<128x2x1xi16> loc(#loc219)
    %1351 = "tt.reduce"(%1350) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc221 at #loc14)), %arg8: i16 loc(callsite(#loc221 at #loc14))):
      %1388 = arith.addi %arg7, %arg8 : i16 loc(#loc253)
      tt.reduce.return %1388 : i16 loc(#loc247)
    }) : (tensor<128x2x1xi16>) -> tensor<128x1xi16> loc(#loc247)
    %1352 = tt.expand_dims %1351 {axis = 1 : i32} : tensor<128x1xi16> -> tensor<128x1x1xi16> loc(#loc223)
    %1353 = tt.broadcast %1352 : tensor<128x1x1xi16> -> tensor<128x2x1xi16> loc(#loc224)
    %1354 = tt.reshape %1349 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc225)
    %1355 = tt.reshape %1353 : tensor<128x2x1xi16> -> tensor<256xi16> loc(#loc226)
    %1356 = tt.bitcast %1330 : tensor<256xf32> -> tensor<256xi32> loc(#loc227)
    %1357 = arith.cmpf olt, %1343, %1344 : tensor<256xf32> loc(#loc228)
    %1358 = arith.xori %1341, %1342 : tensor<256xi32> loc(#loc231)
    %1359 = arith.select %1357, %1358, %cst_1 : tensor<256xi1>, tensor<256xi32> loc(#loc232)
    %1360 = arith.xori %1356, %1359 : tensor<256xi32> loc(#loc233)
    %1361 = arith.xori %1354, %1355 : tensor<256xi16> loc(#loc234)
    %1362 = arith.select %1357, %1361, %cst_0 : tensor<256xi1>, tensor<256xi16> loc(#loc235)
    %1363 = arith.xori %1329, %1362 : tensor<256xi16> loc(#loc236)
    %1364 = tt.bitcast %1360 : tensor<256xi32> -> tensor<256xf32> loc(#loc237)
    %1365 = arith.extsi %1363 : tensor<256xi16> to tensor<256xi64> loc(#loc60)
    %1366 = arith.addi %1365, %cst_4 : tensor<256xi64> loc(#loc61)
    %1367 = arith.cmpi slt, %1365, %cst_3 : tensor<256xi64> loc(#loc62)
    %1368 = arith.select %1367, %1366, %1365 : tensor<256xi1>, tensor<256xi64> loc(#loc63)
    %1369 = arith.cmpi sge, %1368, %cst_3 : tensor<256xi64> loc(#loc64)
    %1370 = arith.cmpi slt, %1368, %cst_4 : tensor<256xi64> loc(#loc65)
    %1371 = arith.andi %1369, %1370 : tensor<256xi1> loc(#loc66)
    tt.assert %1371, "index out of bounds: 0 <= tmp18 < 256" : tensor<256xi1> loc(#loc67)
    %1372 = tt.addptr %4, %1368 : tensor<256x!tt.ptr<f32>>, tensor<256xi64> loc(#loc68)
    %1373 = tt.load %1372 evictionPolicy = evict_last : tensor<256x!tt.ptr<f32>> loc(#loc69)
    %1374 = "tt.reduce"(%1373) <{axis = 0 : i32}> ({
    ^bb0(%arg7: f32 loc(callsite(#loc1 at #loc70)), %arg8: f32 loc(callsite(#loc1 at #loc70))):
      %1388 = arith.addf %arg7, %arg8 : f32 loc(#loc190)
      tt.reduce.return %1388 : f32 loc(#loc134)
    }) : (tensor<256xf32>) -> f32 loc(#loc134)
    %1375 = arith.addf %1374, %cst : f32 loc(#loc136)
    %1376 = tt.splat %1375 : f32 -> tensor<1xf32> loc(#loc136)
    %1377 = "tt.scan"(%1373) <{axis = 0 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %1388 = arith.addf %arg7, %arg8 : f32 loc(#loc137)
      tt.scan.return %1388 : f32 loc(#loc73)
    }) : (tensor<256xf32>) -> tensor<256xf32> loc(#loc73)
    %1378 = arith.subf %cst_5, %1373 : tensor<256xf32> loc(#loc75)
    %1379 = "tt.scan"(%1378) <{axis = 0 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %1388 = arith.addf %arg7, %arg8 : f32 loc(#loc138)
      tt.scan.return %1388 : f32 loc(#loc76)
    }) : (tensor<256xf32>) -> tensor<256xf32> loc(#loc76)
    %1380 = tt.splat %arg2 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>> loc(#loc77)
    %1381 = tt.addptr %1380, %0 : tensor<256x!tt.ptr<f32>>, tensor<256xi32> loc(#loc77)
    tt.store %1381, %1364 : tensor<256x!tt.ptr<f32>> loc(#loc78)
    %1382 = tt.splat %arg4 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>> loc(#loc79)
    %1383 = tt.addptr %1382, %0 : tensor<256x!tt.ptr<f32>>, tensor<256xi32> loc(#loc79)
    tt.store %1383, %1377 : tensor<256x!tt.ptr<f32>> loc(#loc80)
    %1384 = tt.splat %arg5 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>> loc(#loc81)
    %1385 = tt.addptr %1384, %0 : tensor<256x!tt.ptr<f32>>, tensor<256xi32> loc(#loc81)
    tt.store %1385, %1379 : tensor<256x!tt.ptr<f32>> loc(#loc82)
    %1386 = tt.addptr %arg3, %c0_i32 : !tt.ptr<f32>, i32 loc(#loc83)
    %1387 = tt.splat %1386 : !tt.ptr<f32> -> tensor<1x!tt.ptr<f32>> loc(#loc83)
    tt.store %1387, %1376 : tensor<1x!tt.ptr<f32>> loc(#loc84)
    tt.return loc(#loc85)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":32:26)
#loc3 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":36:30)
#loc4 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":36:35)
#loc5 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":37:30)
#loc6 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":37:35)
#loc7 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":39:18)
#loc8 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":41:18)
#loc9 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":42:18)
#loc10 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":43:18)
#loc11 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":45:19)
#loc12 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:41)
#loc15 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:44)
#loc16 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:60)
#loc17 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:68)
#loc18 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":501:22)
#loc20 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":502:14)
#loc21 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":505:21)
#loc22 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:40)
#loc23 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":267:36)
#loc25 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":256:15)
#loc26 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:54)
#loc27 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:67)
#loc28 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:41)
#loc30 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:56)
#loc31 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:69)
#loc32 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":508:30)
#loc33 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":509:32)
#loc34 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":510:20)
#loc35 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":511:22)
#loc36 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":514:29)
#loc37 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:36)
#loc38 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:23)
#loc40 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:53)
#loc41 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:66)
#loc42 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:37)
#loc43 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:23)
#loc45 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:54)
#loc46 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:67)
#loc47 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":521:36)
#loc48 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":522:38)
#loc49 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":533:14)
#loc50 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":536:22)
#loc51 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:19)
#loc52 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:28)
#loc53 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:38)
#loc54 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:46)
#loc55 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:15)
#loc56 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:48)
#loc57 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:59)
#loc58 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:22)
#loc59 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":551:18)
#loc60 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":49:21)
#loc61 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":51:20)
#loc62 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":52:20)
#loc63 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":53:35)
#loc64 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:27)
#loc65 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:45)
#loc66 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:37)
#loc67 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:51)
#loc68 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":55:31)
#loc69 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":55:39)
#loc71 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":73:15)
#loc72 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":57:45)
#loc73 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":60:46)
#loc74 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":13:20)
#loc75 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":61:19)
#loc76 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":64:46)
#loc77 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":65:25)
#loc78 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":65:64)
#loc79 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":66:25)
#loc80 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":66:64)
#loc81 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":67:25)
#loc82 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":67:64)
#loc83 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":68:25)
#loc84 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":68:60)
#loc85 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":68:4)
#loc86 = loc(callsite(#loc12 at #loc13))
#loc87 = loc(callsite(#loc15 at #loc13))
#loc88 = loc(callsite(#loc16 at #loc13))
#loc89 = loc(callsite(#loc17 at #loc13))
#loc90 = loc(callsite(#loc18 at #loc19))
#loc91 = loc(callsite(#loc20 at #loc19))
#loc92 = loc(callsite(#loc21 at #loc19))
#loc93 = loc(callsite(#loc22 at #loc19))
#loc94 = loc(callsite(#loc23 at #loc24))
#loc96 = loc(callsite(#loc25 at #loc23))
#loc97 = loc(callsite(#loc26 at #loc19))
#loc98 = loc(callsite(#loc27 at #loc19))
#loc99 = loc(callsite(#loc28 at #loc19))
#loc100 = loc(callsite(#loc23 at #loc29))
#loc102 = loc(callsite(#loc30 at #loc19))
#loc103 = loc(callsite(#loc31 at #loc19))
#loc104 = loc(callsite(#loc32 at #loc19))
#loc105 = loc(callsite(#loc33 at #loc19))
#loc106 = loc(callsite(#loc34 at #loc19))
#loc107 = loc(callsite(#loc35 at #loc19))
#loc108 = loc(callsite(#loc36 at #loc19))
#loc109 = loc(callsite(#loc37 at #loc19))
#loc110 = loc(callsite(#loc38 at #loc19))
#loc111 = loc(callsite(#loc23 at #loc39))
#loc113 = loc(callsite(#loc40 at #loc19))
#loc114 = loc(callsite(#loc41 at #loc19))
#loc115 = loc(callsite(#loc42 at #loc19))
#loc116 = loc(callsite(#loc43 at #loc19))
#loc117 = loc(callsite(#loc23 at #loc44))
#loc119 = loc(callsite(#loc45 at #loc19))
#loc120 = loc(callsite(#loc46 at #loc19))
#loc121 = loc(callsite(#loc47 at #loc19))
#loc122 = loc(callsite(#loc48 at #loc19))
#loc123 = loc(callsite(#loc49 at #loc19))
#loc124 = loc(callsite(#loc50 at #loc19))
#loc125 = loc(callsite(#loc51 at #loc19))
#loc126 = loc(callsite(#loc52 at #loc19))
#loc127 = loc(callsite(#loc53 at #loc19))
#loc128 = loc(callsite(#loc54 at #loc19))
#loc129 = loc(callsite(#loc55 at #loc19))
#loc130 = loc(callsite(#loc56 at #loc19))
#loc131 = loc(callsite(#loc57 at #loc19))
#loc132 = loc(callsite(#loc58 at #loc19))
#loc133 = loc(callsite(#loc59 at #loc19))
#loc134 = loc(callsite(#loc23 at #loc70))
#loc136 = loc(callsite(#loc71 at #loc72))
#loc137 = loc(callsite(#loc74 at #loc73))
#loc138 = loc(callsite(#loc74 at #loc76))
#loc139 = loc(callsite(#loc86 at #loc14))
#loc140 = loc(callsite(#loc87 at #loc14))
#loc141 = loc(callsite(#loc88 at #loc14))
#loc142 = loc(callsite(#loc89 at #loc14))
#loc143 = loc(callsite(#loc90 at #loc13))
#loc144 = loc(callsite(#loc91 at #loc13))
#loc145 = loc(callsite(#loc92 at #loc13))
#loc146 = loc(callsite(#loc93 at #loc13))
#loc147 = loc(callsite(#loc94 at #loc19))
#loc149 = loc(callsite(#loc96 at #loc24))
#loc150 = loc(callsite(#loc97 at #loc13))
#loc151 = loc(callsite(#loc98 at #loc13))
#loc152 = loc(callsite(#loc99 at #loc13))
#loc153 = loc(callsite(#loc100 at #loc19))
#loc155 = loc(callsite(#loc96 at #loc29))
#loc156 = loc(callsite(#loc102 at #loc13))
#loc157 = loc(callsite(#loc103 at #loc13))
#loc158 = loc(callsite(#loc104 at #loc13))
#loc159 = loc(callsite(#loc105 at #loc13))
#loc160 = loc(callsite(#loc106 at #loc13))
#loc161 = loc(callsite(#loc107 at #loc13))
#loc162 = loc(callsite(#loc108 at #loc13))
#loc163 = loc(callsite(#loc109 at #loc13))
#loc164 = loc(callsite(#loc110 at #loc13))
#loc165 = loc(callsite(#loc111 at #loc19))
#loc167 = loc(callsite(#loc96 at #loc39))
#loc168 = loc(callsite(#loc113 at #loc13))
#loc169 = loc(callsite(#loc114 at #loc13))
#loc170 = loc(callsite(#loc115 at #loc13))
#loc171 = loc(callsite(#loc116 at #loc13))
#loc172 = loc(callsite(#loc117 at #loc19))
#loc174 = loc(callsite(#loc96 at #loc44))
#loc175 = loc(callsite(#loc119 at #loc13))
#loc176 = loc(callsite(#loc120 at #loc13))
#loc177 = loc(callsite(#loc121 at #loc13))
#loc178 = loc(callsite(#loc122 at #loc13))
#loc179 = loc(callsite(#loc123 at #loc13))
#loc180 = loc(callsite(#loc124 at #loc13))
#loc181 = loc(callsite(#loc125 at #loc13))
#loc182 = loc(callsite(#loc126 at #loc13))
#loc183 = loc(callsite(#loc127 at #loc13))
#loc184 = loc(callsite(#loc128 at #loc13))
#loc185 = loc(callsite(#loc129 at #loc13))
#loc186 = loc(callsite(#loc130 at #loc13))
#loc187 = loc(callsite(#loc131 at #loc13))
#loc188 = loc(callsite(#loc132 at #loc13))
#loc189 = loc(callsite(#loc133 at #loc13))
#loc190 = loc(callsite(#loc96 at #loc70))
#loc191 = loc(callsite(#loc143 at #loc14))
#loc192 = loc(callsite(#loc144 at #loc14))
#loc193 = loc(callsite(#loc145 at #loc14))
#loc194 = loc(callsite(#loc146 at #loc14))
#loc195 = loc(callsite(#loc147 at #loc13))
#loc197 = loc(callsite(#loc149 at #loc19))
#loc198 = loc(callsite(#loc150 at #loc14))
#loc199 = loc(callsite(#loc151 at #loc14))
#loc200 = loc(callsite(#loc152 at #loc14))
#loc201 = loc(callsite(#loc153 at #loc13))
#loc203 = loc(callsite(#loc155 at #loc19))
#loc204 = loc(callsite(#loc156 at #loc14))
#loc205 = loc(callsite(#loc157 at #loc14))
#loc206 = loc(callsite(#loc158 at #loc14))
#loc207 = loc(callsite(#loc159 at #loc14))
#loc208 = loc(callsite(#loc160 at #loc14))
#loc209 = loc(callsite(#loc161 at #loc14))
#loc210 = loc(callsite(#loc162 at #loc14))
#loc211 = loc(callsite(#loc163 at #loc14))
#loc212 = loc(callsite(#loc164 at #loc14))
#loc213 = loc(callsite(#loc165 at #loc13))
#loc215 = loc(callsite(#loc167 at #loc19))
#loc216 = loc(callsite(#loc168 at #loc14))
#loc217 = loc(callsite(#loc169 at #loc14))
#loc218 = loc(callsite(#loc170 at #loc14))
#loc219 = loc(callsite(#loc171 at #loc14))
#loc220 = loc(callsite(#loc172 at #loc13))
#loc222 = loc(callsite(#loc174 at #loc19))
#loc223 = loc(callsite(#loc175 at #loc14))
#loc224 = loc(callsite(#loc176 at #loc14))
#loc225 = loc(callsite(#loc177 at #loc14))
#loc226 = loc(callsite(#loc178 at #loc14))
#loc227 = loc(callsite(#loc179 at #loc14))
#loc228 = loc(callsite(#loc180 at #loc14))
#loc229 = loc(callsite(#loc181 at #loc14))
#loc230 = loc(callsite(#loc182 at #loc14))
#loc231 = loc(callsite(#loc183 at #loc14))
#loc232 = loc(callsite(#loc184 at #loc14))
#loc233 = loc(callsite(#loc185 at #loc14))
#loc234 = loc(callsite(#loc186 at #loc14))
#loc235 = loc(callsite(#loc187 at #loc14))
#loc236 = loc(callsite(#loc188 at #loc14))
#loc237 = loc(callsite(#loc189 at #loc14))
#loc238 = loc(callsite(#loc195 at #loc14))
#loc240 = loc(callsite(#loc197 at #loc13))
#loc241 = loc(callsite(#loc201 at #loc14))
#loc243 = loc(callsite(#loc203 at #loc13))
#loc244 = loc(callsite(#loc213 at #loc14))
#loc246 = loc(callsite(#loc215 at #loc13))
#loc247 = loc(callsite(#loc220 at #loc14))
#loc249 = loc(callsite(#loc222 at #loc13))
#loc250 = loc(callsite(#loc240 at #loc14))
#loc251 = loc(callsite(#loc243 at #loc14))
#loc252 = loc(callsite(#loc246 at #loc14))
#loc253 = loc(callsite(#loc249 at #loc14))
