#blocked = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [2], order = [0]}>
#blocked1 = #triton_gpu.blocked<{sizePerThread = [2, 2, 1], threadsPerWarp = [32, 1, 1], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 2, 2], threadsPerWarp = [32, 1, 1], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked3 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [16, 2, 1], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked4 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [8, 2, 2], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked5 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [4, 2, 4], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked6 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [2, 2, 8], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked7 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [1, 2, 16], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked8 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [1, 1, 32], warpsPerCTA = [1, 2, 1], order = [2, 1, 0]}>
#blocked9 = #triton_gpu.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [2], order = [0]}>
#loc = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0)
#loc1 = loc(unknown)
#loc13 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":610:12)
#loc14 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":48:71)
#loc18 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":582:73)
#loc23 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:51)
#loc28 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:53)
#loc38 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:50)
#loc43 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:51)
#loc69 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":57:59)
#loc93 = loc(callsite(#loc1 at #loc23))
#loc99 = loc(callsite(#loc1 at #loc28))
#loc110 = loc(callsite(#loc1 at #loc38))
#loc116 = loc(callsite(#loc1 at #loc43))
#loc133 = loc(callsite(#loc1 at #loc69))
#loc145 = loc(callsite(#loc93 at #loc18))
#loc151 = loc(callsite(#loc99 at #loc18))
#loc163 = loc(callsite(#loc110 at #loc18))
#loc170 = loc(callsite(#loc116 at #loc18))
#loc193 = loc(callsite(#loc145 at #loc13))
#loc199 = loc(callsite(#loc151 at #loc13))
#loc211 = loc(callsite(#loc163 at #loc13))
#loc218 = loc(callsite(#loc170 at #loc13))
#loc236 = loc(callsite(#loc193 at #loc14))
#loc239 = loc(callsite(#loc199 at #loc14))
#loc242 = loc(callsite(#loc211 at #loc14))
#loc245 = loc(callsite(#loc218 at #loc14))
module attributes {"triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 2 : i32, triton_gpu.target = "cuda:90", "triton_gpu.threads-per-warp" = 32 : i32} {
  tt.func public @triton_per_fused_cumsum_index_mul_rsub_sort_sub_sum_0(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg3: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg4: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg5: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0), %arg6: i32 {tt.divisibility = 16 : i32} loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":24:0)) attributes {noinline = false} {
    %cst = arith.constant dense<2.000000e+00> : tensor<256xf32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<1.000000e+00> : tensor<256xf32, #blocked> loc(#loc1)
    %cst_1 = arith.constant dense<256> : tensor<256xi64, #blocked> loc(#loc1)
    %cst_2 = arith.constant dense<0> : tensor<256xi64, #blocked> loc(#loc1)
    %cst_3 = arith.constant dense<0> : tensor<256xi32, #blocked> loc(#loc1)
    %cst_4 = arith.constant dense<0> : tensor<256xi16, #blocked> loc(#loc1)
    %cst_5 = arith.constant 0.000000e+00 : f32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %cst_6 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked1> loc(#loc1)
    %cst_7 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked2> loc(#loc1)
    %cst_8 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked3> loc(#loc1)
    %cst_9 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked4> loc(#loc1)
    %cst_10 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked5> loc(#loc1)
    %cst_11 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked6> loc(#loc1)
    %cst_12 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked7> loc(#loc1)
    %cst_13 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked8> loc(#loc1)
    %0 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked> loc(#loc2)
    %1 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc3)
    %2 = tt.addptr %1, %0 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc3)
    %3 = tt.load %2 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc4)
    %4 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc5)
    %5 = tt.addptr %4, %0 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc5)
    %6 = tt.load %5 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc6)
    %7 = arith.mulf %6, %cst : tensor<256xf32, #blocked> loc(#loc7)
    %8 = arith.subf %7, %cst_0 : tensor<256xf32, #blocked> loc(#loc8)
    %9 = arith.mulf %3, %8 : tensor<256xf32, #blocked> loc(#loc9)
    %10 = arith.subf %cst_0, %9 : tensor<256xf32, #blocked> loc(#loc10)
    %11 = arith.trunci %0 : tensor<256xi32, #blocked> to tensor<256xi16, #blocked> loc(#loc11)
    %12 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked2}>}>> loc(#loc137)
    %13 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked1}>}>> loc(#loc137)
    %14 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked3}>}>> loc(#loc137)
    %15 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked4}>}>> loc(#loc137)
    %16 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked5}>}>> loc(#loc137)
    %17 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked6}>}>> loc(#loc137)
    %18 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked7}>}>> loc(#loc137)
    %19 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked8}>}>> loc(#loc137)
    %20 = tt.expand_dims %12 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked2}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked2}>> loc(#loc137)
    %21 = tt.expand_dims %13 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked1}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked1}>> loc(#loc137)
    %22 = tt.expand_dims %14 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked3}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked3}>> loc(#loc137)
    %23 = tt.expand_dims %15 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked4}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked4}>> loc(#loc137)
    %24 = tt.expand_dims %16 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked5}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked5}>> loc(#loc137)
    %25 = tt.expand_dims %17 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked6}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked6}>> loc(#loc137)
    %26 = tt.expand_dims %18 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked7}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked7}>> loc(#loc137)
    %27 = tt.expand_dims %19 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked8}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked8}>> loc(#loc137)
    %28 = tt.expand_dims %20 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked2}>> -> tensor<1x2x1xi32, #blocked2> loc(#loc137)
    %29 = tt.expand_dims %21 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked1}>> -> tensor<1x2x1xi32, #blocked1> loc(#loc137)
    %30 = tt.expand_dims %22 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked3}>> -> tensor<1x2x1xi32, #blocked3> loc(#loc137)
    %31 = tt.expand_dims %23 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked4}>> -> tensor<1x2x1xi32, #blocked4> loc(#loc137)
    %32 = tt.expand_dims %24 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked5}>> -> tensor<1x2x1xi32, #blocked5> loc(#loc137)
    %33 = tt.expand_dims %25 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked6}>> -> tensor<1x2x1xi32, #blocked6> loc(#loc137)
    %34 = tt.expand_dims %26 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked7}>> -> tensor<1x2x1xi32, #blocked7> loc(#loc137)
    %35 = tt.expand_dims %27 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked8}>> -> tensor<1x2x1xi32, #blocked8> loc(#loc137)
    %36 = tt.broadcast %28 : tensor<1x2x1xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc138)
    %37 = tt.reshape %36 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc139)
    %38 = tt.reshape %10 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %39 = tt.bitcast %38 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %40 = arith.subi %cst_6, %29 : tensor<1x2x1xi32, #blocked1> loc(#loc190)
    %41 = arith.subi %cst_7, %28 : tensor<1x2x1xi32, #blocked2> loc(#loc190)
    %42 = arith.subi %cst_8, %30 : tensor<1x2x1xi32, #blocked3> loc(#loc190)
    %43 = arith.subi %cst_9, %31 : tensor<1x2x1xi32, #blocked4> loc(#loc190)
    %44 = arith.subi %cst_10, %32 : tensor<1x2x1xi32, #blocked5> loc(#loc190)
    %45 = arith.subi %cst_11, %33 : tensor<1x2x1xi32, #blocked6> loc(#loc190)
    %46 = arith.subi %cst_12, %34 : tensor<1x2x1xi32, #blocked7> loc(#loc190)
    %47 = arith.subi %cst_13, %35 : tensor<1x2x1xi32, #blocked8> loc(#loc190)
    %48 = tt.broadcast %40 : tensor<1x2x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %49 = arith.muli %39, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %50 = "tt.reduce"(%49) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %51 = tt.expand_dims %50 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %52 = tt.broadcast %51 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %53 = tt.broadcast %29 : tensor<1x2x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %54 = arith.muli %39, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %55 = "tt.reduce"(%54) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %56 = tt.expand_dims %55 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %57 = tt.broadcast %56 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %58 = tt.reshape %52 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %59 = tt.reshape %57 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %60 = tt.bitcast %58 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %61 = tt.bitcast %59 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %62 = tt.reshape %11 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %63 = arith.trunci %40 : tensor<1x2x1xi32, #blocked1> to tensor<1x2x1xi16, #blocked1> loc(#loc208)
    %64 = arith.trunci %41 : tensor<1x2x1xi32, #blocked2> to tensor<1x2x1xi16, #blocked2> loc(#loc208)
    %65 = arith.trunci %42 : tensor<1x2x1xi32, #blocked3> to tensor<1x2x1xi16, #blocked3> loc(#loc208)
    %66 = arith.trunci %43 : tensor<1x2x1xi32, #blocked4> to tensor<1x2x1xi16, #blocked4> loc(#loc208)
    %67 = arith.trunci %44 : tensor<1x2x1xi32, #blocked5> to tensor<1x2x1xi16, #blocked5> loc(#loc208)
    %68 = arith.trunci %45 : tensor<1x2x1xi32, #blocked6> to tensor<1x2x1xi16, #blocked6> loc(#loc208)
    %69 = arith.trunci %46 : tensor<1x2x1xi32, #blocked7> to tensor<1x2x1xi16, #blocked7> loc(#loc208)
    %70 = arith.trunci %47 : tensor<1x2x1xi32, #blocked8> to tensor<1x2x1xi16, #blocked8> loc(#loc208)
    %71 = tt.broadcast %63 : tensor<1x2x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %72 = arith.muli %62, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %73 = "tt.reduce"(%72) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %74 = tt.expand_dims %73 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %75 = tt.broadcast %74 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %76 = arith.trunci %29 : tensor<1x2x1xi32, #blocked1> to tensor<1x2x1xi16, #blocked1> loc(#loc215)
    %77 = arith.trunci %28 : tensor<1x2x1xi32, #blocked2> to tensor<1x2x1xi16, #blocked2> loc(#loc215)
    %78 = arith.trunci %30 : tensor<1x2x1xi32, #blocked3> to tensor<1x2x1xi16, #blocked3> loc(#loc215)
    %79 = arith.trunci %31 : tensor<1x2x1xi32, #blocked4> to tensor<1x2x1xi16, #blocked4> loc(#loc215)
    %80 = arith.trunci %32 : tensor<1x2x1xi32, #blocked5> to tensor<1x2x1xi16, #blocked5> loc(#loc215)
    %81 = arith.trunci %33 : tensor<1x2x1xi32, #blocked6> to tensor<1x2x1xi16, #blocked6> loc(#loc215)
    %82 = arith.trunci %34 : tensor<1x2x1xi32, #blocked7> to tensor<1x2x1xi16, #blocked7> loc(#loc215)
    %83 = arith.trunci %35 : tensor<1x2x1xi32, #blocked8> to tensor<1x2x1xi16, #blocked8> loc(#loc215)
    %84 = tt.broadcast %76 : tensor<1x2x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %85 = arith.muli %62, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %86 = "tt.reduce"(%85) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %87 = tt.expand_dims %86 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %88 = tt.broadcast %87 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %89 = tt.reshape %75 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %90 = tt.reshape %88 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %91 = tt.bitcast %10 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %92 = arith.cmpf olt, %60, %61 : tensor<256xf32, #blocked> loc(#loc225)
    %93 = arith.extui %92 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %94 = arith.xori %93, %37 : tensor<256xi32, #blocked> loc(#loc226)
    %95 = arith.cmpi ne, %94, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %96 = arith.xori %58, %59 : tensor<256xi32, #blocked> loc(#loc228)
    %97 = arith.select %95, %96, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %98 = arith.xori %91, %97 : tensor<256xi32, #blocked> loc(#loc230)
    %99 = arith.xori %89, %90 : tensor<256xi16, #blocked> loc(#loc231)
    %100 = arith.select %95, %99, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %101 = arith.xori %11, %100 : tensor<256xi16, #blocked> loc(#loc233)
    %102 = tt.bitcast %98 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %103 = tt.broadcast %30 : tensor<1x2x1xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc138)
    %104 = tt.reshape %103 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc139)
    %105 = tt.reshape %102 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc188)
    %106 = tt.bitcast %105 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc189)
    %107 = tt.broadcast %41 : tensor<1x2x1xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %108 = arith.muli %106, %107 : tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %109 = "tt.reduce"(%108) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc235)
    %110 = tt.expand_dims %109 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc195)
    %111 = tt.broadcast %110 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc196)
    %112 = arith.muli %106, %36 : tensor<64x2x2xi32, #blocked2> loc(#loc197)
    %113 = "tt.reduce"(%112) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc238)
    %114 = tt.expand_dims %113 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc201)
    %115 = tt.broadcast %114 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc202)
    %116 = tt.reshape %111 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc203)
    %117 = tt.reshape %115 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc204)
    %118 = tt.bitcast %116 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %119 = tt.bitcast %117 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %120 = tt.reshape %101 : tensor<256xi16, #blocked> -> tensor<64x2x2xi16, #blocked2> loc(#loc207)
    %121 = tt.broadcast %64 : tensor<1x2x1xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %122 = arith.muli %120, %121 : tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %123 = "tt.reduce"(%122) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc241)
    %124 = tt.expand_dims %123 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc213)
    %125 = tt.broadcast %124 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc214)
    %126 = tt.broadcast %77 : tensor<1x2x1xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %127 = arith.muli %120, %126 : tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %128 = "tt.reduce"(%127) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %129 = tt.expand_dims %128 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc220)
    %130 = tt.broadcast %129 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc221)
    %131 = tt.reshape %125 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc222)
    %132 = tt.reshape %130 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc223)
    %133 = tt.bitcast %102 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %134 = arith.cmpf olt, %118, %119 : tensor<256xf32, #blocked> loc(#loc225)
    %135 = arith.extui %134 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %136 = arith.xori %135, %104 : tensor<256xi32, #blocked> loc(#loc226)
    %137 = arith.cmpi ne, %136, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %138 = arith.xori %116, %117 : tensor<256xi32, #blocked> loc(#loc228)
    %139 = arith.select %137, %138, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %140 = arith.xori %133, %139 : tensor<256xi32, #blocked> loc(#loc230)
    %141 = arith.xori %131, %132 : tensor<256xi16, #blocked> loc(#loc231)
    %142 = arith.select %137, %141, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %143 = arith.xori %101, %142 : tensor<256xi16, #blocked> loc(#loc233)
    %144 = tt.bitcast %140 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %145 = tt.reshape %144 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %146 = tt.bitcast %145 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %147 = arith.muli %146, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %148 = "tt.reduce"(%147) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %149 = tt.expand_dims %148 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %150 = tt.broadcast %149 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %151 = arith.muli %146, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %152 = "tt.reduce"(%151) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %153 = tt.expand_dims %152 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %154 = tt.broadcast %153 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %155 = tt.reshape %150 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %156 = tt.reshape %154 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %157 = tt.bitcast %155 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %158 = tt.bitcast %156 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %159 = tt.reshape %143 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %160 = arith.muli %159, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %161 = "tt.reduce"(%160) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %162 = tt.expand_dims %161 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %163 = tt.broadcast %162 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %164 = arith.muli %159, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %165 = "tt.reduce"(%164) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %166 = tt.expand_dims %165 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %167 = tt.broadcast %166 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %168 = tt.reshape %163 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %169 = tt.reshape %167 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %170 = tt.bitcast %144 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %171 = arith.cmpf olt, %157, %158 : tensor<256xf32, #blocked> loc(#loc225)
    %172 = arith.extui %171 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %173 = arith.xori %172, %104 : tensor<256xi32, #blocked> loc(#loc226)
    %174 = arith.cmpi ne, %173, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %175 = arith.xori %155, %156 : tensor<256xi32, #blocked> loc(#loc228)
    %176 = arith.select %174, %175, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %177 = arith.xori %170, %176 : tensor<256xi32, #blocked> loc(#loc230)
    %178 = arith.xori %168, %169 : tensor<256xi16, #blocked> loc(#loc231)
    %179 = arith.select %174, %178, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %180 = arith.xori %143, %179 : tensor<256xi16, #blocked> loc(#loc233)
    %181 = tt.bitcast %177 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %182 = tt.broadcast %31 : tensor<1x2x1xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc138)
    %183 = tt.reshape %182 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc139)
    %184 = tt.reshape %181 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc188)
    %185 = tt.bitcast %184 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc189)
    %186 = tt.broadcast %42 : tensor<1x2x1xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc191)
    %187 = arith.muli %185, %186 : tensor<32x2x4xi32, #blocked3> loc(#loc191)
    %188 = "tt.reduce"(%187) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc235)
    %189 = tt.expand_dims %188 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc195)
    %190 = tt.broadcast %189 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc196)
    %191 = arith.muli %185, %103 : tensor<32x2x4xi32, #blocked3> loc(#loc197)
    %192 = "tt.reduce"(%191) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc238)
    %193 = tt.expand_dims %192 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc201)
    %194 = tt.broadcast %193 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc202)
    %195 = tt.reshape %190 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc203)
    %196 = tt.reshape %194 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc204)
    %197 = tt.bitcast %195 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %198 = tt.bitcast %196 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %199 = tt.reshape %180 : tensor<256xi16, #blocked> -> tensor<32x2x4xi16, #blocked3> loc(#loc207)
    %200 = tt.broadcast %65 : tensor<1x2x1xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc209)
    %201 = arith.muli %199, %200 : tensor<32x2x4xi16, #blocked3> loc(#loc209)
    %202 = "tt.reduce"(%201) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc241)
    %203 = tt.expand_dims %202 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc213)
    %204 = tt.broadcast %203 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc214)
    %205 = tt.broadcast %78 : tensor<1x2x1xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc216)
    %206 = arith.muli %199, %205 : tensor<32x2x4xi16, #blocked3> loc(#loc216)
    %207 = "tt.reduce"(%206) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %208 = tt.expand_dims %207 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc220)
    %209 = tt.broadcast %208 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc221)
    %210 = tt.reshape %204 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc222)
    %211 = tt.reshape %209 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc223)
    %212 = tt.bitcast %181 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %213 = arith.cmpf olt, %197, %198 : tensor<256xf32, #blocked> loc(#loc225)
    %214 = arith.extui %213 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %215 = arith.xori %214, %183 : tensor<256xi32, #blocked> loc(#loc226)
    %216 = arith.cmpi ne, %215, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %217 = arith.xori %195, %196 : tensor<256xi32, #blocked> loc(#loc228)
    %218 = arith.select %216, %217, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %219 = arith.xori %212, %218 : tensor<256xi32, #blocked> loc(#loc230)
    %220 = arith.xori %210, %211 : tensor<256xi16, #blocked> loc(#loc231)
    %221 = arith.select %216, %220, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %222 = arith.xori %180, %221 : tensor<256xi16, #blocked> loc(#loc233)
    %223 = tt.bitcast %219 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %224 = tt.reshape %223 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc188)
    %225 = tt.bitcast %224 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc189)
    %226 = arith.muli %225, %107 : tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %227 = "tt.reduce"(%226) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc235)
    %228 = tt.expand_dims %227 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc195)
    %229 = tt.broadcast %228 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc196)
    %230 = arith.muli %225, %36 : tensor<64x2x2xi32, #blocked2> loc(#loc197)
    %231 = "tt.reduce"(%230) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc238)
    %232 = tt.expand_dims %231 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc201)
    %233 = tt.broadcast %232 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc202)
    %234 = tt.reshape %229 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc203)
    %235 = tt.reshape %233 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc204)
    %236 = tt.bitcast %234 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %237 = tt.bitcast %235 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %238 = tt.reshape %222 : tensor<256xi16, #blocked> -> tensor<64x2x2xi16, #blocked2> loc(#loc207)
    %239 = arith.muli %238, %121 : tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %240 = "tt.reduce"(%239) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc241)
    %241 = tt.expand_dims %240 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc213)
    %242 = tt.broadcast %241 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc214)
    %243 = arith.muli %238, %126 : tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %244 = "tt.reduce"(%243) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %245 = tt.expand_dims %244 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc220)
    %246 = tt.broadcast %245 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc221)
    %247 = tt.reshape %242 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc222)
    %248 = tt.reshape %246 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc223)
    %249 = tt.bitcast %223 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %250 = arith.cmpf olt, %236, %237 : tensor<256xf32, #blocked> loc(#loc225)
    %251 = arith.extui %250 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %252 = arith.xori %251, %183 : tensor<256xi32, #blocked> loc(#loc226)
    %253 = arith.cmpi ne, %252, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %254 = arith.xori %234, %235 : tensor<256xi32, #blocked> loc(#loc228)
    %255 = arith.select %253, %254, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %256 = arith.xori %249, %255 : tensor<256xi32, #blocked> loc(#loc230)
    %257 = arith.xori %247, %248 : tensor<256xi16, #blocked> loc(#loc231)
    %258 = arith.select %253, %257, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %259 = arith.xori %222, %258 : tensor<256xi16, #blocked> loc(#loc233)
    %260 = tt.bitcast %256 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %261 = tt.reshape %260 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %262 = tt.bitcast %261 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %263 = arith.muli %262, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %264 = "tt.reduce"(%263) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %265 = tt.expand_dims %264 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %266 = tt.broadcast %265 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %267 = arith.muli %262, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %268 = "tt.reduce"(%267) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %269 = tt.expand_dims %268 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %270 = tt.broadcast %269 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %271 = tt.reshape %266 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %272 = tt.reshape %270 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %273 = tt.bitcast %271 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %274 = tt.bitcast %272 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %275 = tt.reshape %259 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %276 = arith.muli %275, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %277 = "tt.reduce"(%276) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %278 = tt.expand_dims %277 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %279 = tt.broadcast %278 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %280 = arith.muli %275, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %281 = "tt.reduce"(%280) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %282 = tt.expand_dims %281 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %283 = tt.broadcast %282 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %284 = tt.reshape %279 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %285 = tt.reshape %283 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %286 = tt.bitcast %260 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %287 = arith.cmpf olt, %273, %274 : tensor<256xf32, #blocked> loc(#loc225)
    %288 = arith.extui %287 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %289 = arith.xori %288, %183 : tensor<256xi32, #blocked> loc(#loc226)
    %290 = arith.cmpi ne, %289, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %291 = arith.xori %271, %272 : tensor<256xi32, #blocked> loc(#loc228)
    %292 = arith.select %290, %291, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %293 = arith.xori %286, %292 : tensor<256xi32, #blocked> loc(#loc230)
    %294 = arith.xori %284, %285 : tensor<256xi16, #blocked> loc(#loc231)
    %295 = arith.select %290, %294, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %296 = arith.xori %259, %295 : tensor<256xi16, #blocked> loc(#loc233)
    %297 = tt.bitcast %293 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %298 = tt.broadcast %32 : tensor<1x2x1xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc138)
    %299 = tt.reshape %298 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc139)
    %300 = tt.reshape %297 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc188)
    %301 = tt.bitcast %300 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc189)
    %302 = tt.broadcast %43 : tensor<1x2x1xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc191)
    %303 = arith.muli %301, %302 : tensor<16x2x8xi32, #blocked4> loc(#loc191)
    %304 = "tt.reduce"(%303) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc235)
    %305 = tt.expand_dims %304 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc195)
    %306 = tt.broadcast %305 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc196)
    %307 = arith.muli %301, %182 : tensor<16x2x8xi32, #blocked4> loc(#loc197)
    %308 = "tt.reduce"(%307) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc238)
    %309 = tt.expand_dims %308 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc201)
    %310 = tt.broadcast %309 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc202)
    %311 = tt.reshape %306 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc203)
    %312 = tt.reshape %310 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc204)
    %313 = tt.bitcast %311 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %314 = tt.bitcast %312 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %315 = tt.reshape %296 : tensor<256xi16, #blocked> -> tensor<16x2x8xi16, #blocked4> loc(#loc207)
    %316 = tt.broadcast %66 : tensor<1x2x1xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc209)
    %317 = arith.muli %315, %316 : tensor<16x2x8xi16, #blocked4> loc(#loc209)
    %318 = "tt.reduce"(%317) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc241)
    %319 = tt.expand_dims %318 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc213)
    %320 = tt.broadcast %319 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc214)
    %321 = tt.broadcast %79 : tensor<1x2x1xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc216)
    %322 = arith.muli %315, %321 : tensor<16x2x8xi16, #blocked4> loc(#loc216)
    %323 = "tt.reduce"(%322) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %324 = tt.expand_dims %323 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc220)
    %325 = tt.broadcast %324 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc221)
    %326 = tt.reshape %320 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc222)
    %327 = tt.reshape %325 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc223)
    %328 = tt.bitcast %297 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %329 = arith.cmpf olt, %313, %314 : tensor<256xf32, #blocked> loc(#loc225)
    %330 = arith.extui %329 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %331 = arith.xori %330, %299 : tensor<256xi32, #blocked> loc(#loc226)
    %332 = arith.cmpi ne, %331, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %333 = arith.xori %311, %312 : tensor<256xi32, #blocked> loc(#loc228)
    %334 = arith.select %332, %333, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %335 = arith.xori %328, %334 : tensor<256xi32, #blocked> loc(#loc230)
    %336 = arith.xori %326, %327 : tensor<256xi16, #blocked> loc(#loc231)
    %337 = arith.select %332, %336, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %338 = arith.xori %296, %337 : tensor<256xi16, #blocked> loc(#loc233)
    %339 = tt.bitcast %335 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %340 = tt.reshape %339 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc188)
    %341 = tt.bitcast %340 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc189)
    %342 = arith.muli %341, %186 : tensor<32x2x4xi32, #blocked3> loc(#loc191)
    %343 = "tt.reduce"(%342) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc235)
    %344 = tt.expand_dims %343 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc195)
    %345 = tt.broadcast %344 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc196)
    %346 = arith.muli %341, %103 : tensor<32x2x4xi32, #blocked3> loc(#loc197)
    %347 = "tt.reduce"(%346) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc238)
    %348 = tt.expand_dims %347 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc201)
    %349 = tt.broadcast %348 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc202)
    %350 = tt.reshape %345 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc203)
    %351 = tt.reshape %349 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc204)
    %352 = tt.bitcast %350 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %353 = tt.bitcast %351 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %354 = tt.reshape %338 : tensor<256xi16, #blocked> -> tensor<32x2x4xi16, #blocked3> loc(#loc207)
    %355 = arith.muli %354, %200 : tensor<32x2x4xi16, #blocked3> loc(#loc209)
    %356 = "tt.reduce"(%355) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc241)
    %357 = tt.expand_dims %356 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc213)
    %358 = tt.broadcast %357 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc214)
    %359 = arith.muli %354, %205 : tensor<32x2x4xi16, #blocked3> loc(#loc216)
    %360 = "tt.reduce"(%359) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %361 = tt.expand_dims %360 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc220)
    %362 = tt.broadcast %361 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc221)
    %363 = tt.reshape %358 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc222)
    %364 = tt.reshape %362 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc223)
    %365 = tt.bitcast %339 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %366 = arith.cmpf olt, %352, %353 : tensor<256xf32, #blocked> loc(#loc225)
    %367 = arith.extui %366 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %368 = arith.xori %367, %299 : tensor<256xi32, #blocked> loc(#loc226)
    %369 = arith.cmpi ne, %368, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %370 = arith.xori %350, %351 : tensor<256xi32, #blocked> loc(#loc228)
    %371 = arith.select %369, %370, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %372 = arith.xori %365, %371 : tensor<256xi32, #blocked> loc(#loc230)
    %373 = arith.xori %363, %364 : tensor<256xi16, #blocked> loc(#loc231)
    %374 = arith.select %369, %373, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %375 = arith.xori %338, %374 : tensor<256xi16, #blocked> loc(#loc233)
    %376 = tt.bitcast %372 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %377 = tt.reshape %376 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc188)
    %378 = tt.bitcast %377 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc189)
    %379 = arith.muli %378, %107 : tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %380 = "tt.reduce"(%379) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc235)
    %381 = tt.expand_dims %380 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc195)
    %382 = tt.broadcast %381 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc196)
    %383 = arith.muli %378, %36 : tensor<64x2x2xi32, #blocked2> loc(#loc197)
    %384 = "tt.reduce"(%383) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc238)
    %385 = tt.expand_dims %384 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc201)
    %386 = tt.broadcast %385 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc202)
    %387 = tt.reshape %382 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc203)
    %388 = tt.reshape %386 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc204)
    %389 = tt.bitcast %387 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %390 = tt.bitcast %388 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %391 = tt.reshape %375 : tensor<256xi16, #blocked> -> tensor<64x2x2xi16, #blocked2> loc(#loc207)
    %392 = arith.muli %391, %121 : tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %393 = "tt.reduce"(%392) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc241)
    %394 = tt.expand_dims %393 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc213)
    %395 = tt.broadcast %394 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc214)
    %396 = arith.muli %391, %126 : tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %397 = "tt.reduce"(%396) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %398 = tt.expand_dims %397 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc220)
    %399 = tt.broadcast %398 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc221)
    %400 = tt.reshape %395 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc222)
    %401 = tt.reshape %399 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc223)
    %402 = tt.bitcast %376 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %403 = arith.cmpf olt, %389, %390 : tensor<256xf32, #blocked> loc(#loc225)
    %404 = arith.extui %403 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %405 = arith.xori %404, %299 : tensor<256xi32, #blocked> loc(#loc226)
    %406 = arith.cmpi ne, %405, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %407 = arith.xori %387, %388 : tensor<256xi32, #blocked> loc(#loc228)
    %408 = arith.select %406, %407, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %409 = arith.xori %402, %408 : tensor<256xi32, #blocked> loc(#loc230)
    %410 = arith.xori %400, %401 : tensor<256xi16, #blocked> loc(#loc231)
    %411 = arith.select %406, %410, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %412 = arith.xori %375, %411 : tensor<256xi16, #blocked> loc(#loc233)
    %413 = tt.bitcast %409 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %414 = tt.reshape %413 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %415 = tt.bitcast %414 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %416 = arith.muli %415, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %417 = "tt.reduce"(%416) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %418 = tt.expand_dims %417 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %419 = tt.broadcast %418 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %420 = arith.muli %415, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %421 = "tt.reduce"(%420) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %422 = tt.expand_dims %421 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %423 = tt.broadcast %422 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %424 = tt.reshape %419 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %425 = tt.reshape %423 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %426 = tt.bitcast %424 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %427 = tt.bitcast %425 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %428 = tt.reshape %412 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %429 = arith.muli %428, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %430 = "tt.reduce"(%429) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %431 = tt.expand_dims %430 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %432 = tt.broadcast %431 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %433 = arith.muli %428, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %434 = "tt.reduce"(%433) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %435 = tt.expand_dims %434 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %436 = tt.broadcast %435 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %437 = tt.reshape %432 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %438 = tt.reshape %436 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %439 = tt.bitcast %413 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %440 = arith.cmpf olt, %426, %427 : tensor<256xf32, #blocked> loc(#loc225)
    %441 = arith.extui %440 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %442 = arith.xori %441, %299 : tensor<256xi32, #blocked> loc(#loc226)
    %443 = arith.cmpi ne, %442, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %444 = arith.xori %424, %425 : tensor<256xi32, #blocked> loc(#loc228)
    %445 = arith.select %443, %444, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %446 = arith.xori %439, %445 : tensor<256xi32, #blocked> loc(#loc230)
    %447 = arith.xori %437, %438 : tensor<256xi16, #blocked> loc(#loc231)
    %448 = arith.select %443, %447, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %449 = arith.xori %412, %448 : tensor<256xi16, #blocked> loc(#loc233)
    %450 = tt.bitcast %446 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %451 = tt.broadcast %33 : tensor<1x2x1xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc138)
    %452 = tt.reshape %451 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc139)
    %453 = tt.reshape %450 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc188)
    %454 = tt.bitcast %453 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc189)
    %455 = tt.broadcast %44 : tensor<1x2x1xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc191)
    %456 = arith.muli %454, %455 : tensor<8x2x16xi32, #blocked5> loc(#loc191)
    %457 = "tt.reduce"(%456) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc235)
    %458 = tt.expand_dims %457 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc195)
    %459 = tt.broadcast %458 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc196)
    %460 = arith.muli %454, %298 : tensor<8x2x16xi32, #blocked5> loc(#loc197)
    %461 = "tt.reduce"(%460) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc238)
    %462 = tt.expand_dims %461 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc201)
    %463 = tt.broadcast %462 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc202)
    %464 = tt.reshape %459 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc203)
    %465 = tt.reshape %463 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc204)
    %466 = tt.bitcast %464 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %467 = tt.bitcast %465 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %468 = tt.reshape %449 : tensor<256xi16, #blocked> -> tensor<8x2x16xi16, #blocked5> loc(#loc207)
    %469 = tt.broadcast %67 : tensor<1x2x1xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc209)
    %470 = arith.muli %468, %469 : tensor<8x2x16xi16, #blocked5> loc(#loc209)
    %471 = "tt.reduce"(%470) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc241)
    %472 = tt.expand_dims %471 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc213)
    %473 = tt.broadcast %472 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc214)
    %474 = tt.broadcast %80 : tensor<1x2x1xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc216)
    %475 = arith.muli %468, %474 : tensor<8x2x16xi16, #blocked5> loc(#loc216)
    %476 = "tt.reduce"(%475) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %477 = tt.expand_dims %476 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc220)
    %478 = tt.broadcast %477 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc221)
    %479 = tt.reshape %473 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc222)
    %480 = tt.reshape %478 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc223)
    %481 = tt.bitcast %450 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %482 = arith.cmpf olt, %466, %467 : tensor<256xf32, #blocked> loc(#loc225)
    %483 = arith.extui %482 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %484 = arith.xori %483, %452 : tensor<256xi32, #blocked> loc(#loc226)
    %485 = arith.cmpi ne, %484, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %486 = arith.xori %464, %465 : tensor<256xi32, #blocked> loc(#loc228)
    %487 = arith.select %485, %486, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %488 = arith.xori %481, %487 : tensor<256xi32, #blocked> loc(#loc230)
    %489 = arith.xori %479, %480 : tensor<256xi16, #blocked> loc(#loc231)
    %490 = arith.select %485, %489, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %491 = arith.xori %449, %490 : tensor<256xi16, #blocked> loc(#loc233)
    %492 = tt.bitcast %488 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %493 = tt.reshape %492 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc188)
    %494 = tt.bitcast %493 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc189)
    %495 = arith.muli %494, %302 : tensor<16x2x8xi32, #blocked4> loc(#loc191)
    %496 = "tt.reduce"(%495) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc235)
    %497 = tt.expand_dims %496 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc195)
    %498 = tt.broadcast %497 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc196)
    %499 = arith.muli %494, %182 : tensor<16x2x8xi32, #blocked4> loc(#loc197)
    %500 = "tt.reduce"(%499) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc238)
    %501 = tt.expand_dims %500 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc201)
    %502 = tt.broadcast %501 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc202)
    %503 = tt.reshape %498 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc203)
    %504 = tt.reshape %502 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc204)
    %505 = tt.bitcast %503 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %506 = tt.bitcast %504 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %507 = tt.reshape %491 : tensor<256xi16, #blocked> -> tensor<16x2x8xi16, #blocked4> loc(#loc207)
    %508 = arith.muli %507, %316 : tensor<16x2x8xi16, #blocked4> loc(#loc209)
    %509 = "tt.reduce"(%508) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc241)
    %510 = tt.expand_dims %509 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc213)
    %511 = tt.broadcast %510 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc214)
    %512 = arith.muli %507, %321 : tensor<16x2x8xi16, #blocked4> loc(#loc216)
    %513 = "tt.reduce"(%512) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %514 = tt.expand_dims %513 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc220)
    %515 = tt.broadcast %514 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc221)
    %516 = tt.reshape %511 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc222)
    %517 = tt.reshape %515 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc223)
    %518 = tt.bitcast %492 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %519 = arith.cmpf olt, %505, %506 : tensor<256xf32, #blocked> loc(#loc225)
    %520 = arith.extui %519 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %521 = arith.xori %520, %452 : tensor<256xi32, #blocked> loc(#loc226)
    %522 = arith.cmpi ne, %521, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %523 = arith.xori %503, %504 : tensor<256xi32, #blocked> loc(#loc228)
    %524 = arith.select %522, %523, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %525 = arith.xori %518, %524 : tensor<256xi32, #blocked> loc(#loc230)
    %526 = arith.xori %516, %517 : tensor<256xi16, #blocked> loc(#loc231)
    %527 = arith.select %522, %526, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %528 = arith.xori %491, %527 : tensor<256xi16, #blocked> loc(#loc233)
    %529 = tt.bitcast %525 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %530 = tt.reshape %529 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc188)
    %531 = tt.bitcast %530 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc189)
    %532 = arith.muli %531, %186 : tensor<32x2x4xi32, #blocked3> loc(#loc191)
    %533 = "tt.reduce"(%532) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc235)
    %534 = tt.expand_dims %533 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc195)
    %535 = tt.broadcast %534 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc196)
    %536 = arith.muli %531, %103 : tensor<32x2x4xi32, #blocked3> loc(#loc197)
    %537 = "tt.reduce"(%536) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc238)
    %538 = tt.expand_dims %537 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc201)
    %539 = tt.broadcast %538 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc202)
    %540 = tt.reshape %535 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc203)
    %541 = tt.reshape %539 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc204)
    %542 = tt.bitcast %540 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %543 = tt.bitcast %541 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %544 = tt.reshape %528 : tensor<256xi16, #blocked> -> tensor<32x2x4xi16, #blocked3> loc(#loc207)
    %545 = arith.muli %544, %200 : tensor<32x2x4xi16, #blocked3> loc(#loc209)
    %546 = "tt.reduce"(%545) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc241)
    %547 = tt.expand_dims %546 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc213)
    %548 = tt.broadcast %547 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc214)
    %549 = arith.muli %544, %205 : tensor<32x2x4xi16, #blocked3> loc(#loc216)
    %550 = "tt.reduce"(%549) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %551 = tt.expand_dims %550 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc220)
    %552 = tt.broadcast %551 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc221)
    %553 = tt.reshape %548 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc222)
    %554 = tt.reshape %552 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc223)
    %555 = tt.bitcast %529 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %556 = arith.cmpf olt, %542, %543 : tensor<256xf32, #blocked> loc(#loc225)
    %557 = arith.extui %556 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %558 = arith.xori %557, %452 : tensor<256xi32, #blocked> loc(#loc226)
    %559 = arith.cmpi ne, %558, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %560 = arith.xori %540, %541 : tensor<256xi32, #blocked> loc(#loc228)
    %561 = arith.select %559, %560, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %562 = arith.xori %555, %561 : tensor<256xi32, #blocked> loc(#loc230)
    %563 = arith.xori %553, %554 : tensor<256xi16, #blocked> loc(#loc231)
    %564 = arith.select %559, %563, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %565 = arith.xori %528, %564 : tensor<256xi16, #blocked> loc(#loc233)
    %566 = tt.bitcast %562 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %567 = tt.reshape %566 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc188)
    %568 = tt.bitcast %567 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc189)
    %569 = arith.muli %568, %107 : tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %570 = "tt.reduce"(%569) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc235)
    %571 = tt.expand_dims %570 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc195)
    %572 = tt.broadcast %571 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc196)
    %573 = arith.muli %568, %36 : tensor<64x2x2xi32, #blocked2> loc(#loc197)
    %574 = "tt.reduce"(%573) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc238)
    %575 = tt.expand_dims %574 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc201)
    %576 = tt.broadcast %575 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc202)
    %577 = tt.reshape %572 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc203)
    %578 = tt.reshape %576 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc204)
    %579 = tt.bitcast %577 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %580 = tt.bitcast %578 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %581 = tt.reshape %565 : tensor<256xi16, #blocked> -> tensor<64x2x2xi16, #blocked2> loc(#loc207)
    %582 = arith.muli %581, %121 : tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %583 = "tt.reduce"(%582) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc241)
    %584 = tt.expand_dims %583 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc213)
    %585 = tt.broadcast %584 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc214)
    %586 = arith.muli %581, %126 : tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %587 = "tt.reduce"(%586) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %588 = tt.expand_dims %587 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc220)
    %589 = tt.broadcast %588 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc221)
    %590 = tt.reshape %585 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc222)
    %591 = tt.reshape %589 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc223)
    %592 = tt.bitcast %566 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %593 = arith.cmpf olt, %579, %580 : tensor<256xf32, #blocked> loc(#loc225)
    %594 = arith.extui %593 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %595 = arith.xori %594, %452 : tensor<256xi32, #blocked> loc(#loc226)
    %596 = arith.cmpi ne, %595, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %597 = arith.xori %577, %578 : tensor<256xi32, #blocked> loc(#loc228)
    %598 = arith.select %596, %597, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %599 = arith.xori %592, %598 : tensor<256xi32, #blocked> loc(#loc230)
    %600 = arith.xori %590, %591 : tensor<256xi16, #blocked> loc(#loc231)
    %601 = arith.select %596, %600, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %602 = arith.xori %565, %601 : tensor<256xi16, #blocked> loc(#loc233)
    %603 = tt.bitcast %599 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %604 = tt.reshape %603 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %605 = tt.bitcast %604 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %606 = arith.muli %605, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %607 = "tt.reduce"(%606) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %608 = tt.expand_dims %607 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %609 = tt.broadcast %608 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %610 = arith.muli %605, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %611 = "tt.reduce"(%610) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %612 = tt.expand_dims %611 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %613 = tt.broadcast %612 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %614 = tt.reshape %609 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %615 = tt.reshape %613 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %616 = tt.bitcast %614 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %617 = tt.bitcast %615 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %618 = tt.reshape %602 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %619 = arith.muli %618, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %620 = "tt.reduce"(%619) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %621 = tt.expand_dims %620 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %622 = tt.broadcast %621 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %623 = arith.muli %618, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %624 = "tt.reduce"(%623) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %625 = tt.expand_dims %624 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %626 = tt.broadcast %625 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %627 = tt.reshape %622 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %628 = tt.reshape %626 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %629 = tt.bitcast %603 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %630 = arith.cmpf olt, %616, %617 : tensor<256xf32, #blocked> loc(#loc225)
    %631 = arith.extui %630 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %632 = arith.xori %631, %452 : tensor<256xi32, #blocked> loc(#loc226)
    %633 = arith.cmpi ne, %632, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %634 = arith.xori %614, %615 : tensor<256xi32, #blocked> loc(#loc228)
    %635 = arith.select %633, %634, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %636 = arith.xori %629, %635 : tensor<256xi32, #blocked> loc(#loc230)
    %637 = arith.xori %627, %628 : tensor<256xi16, #blocked> loc(#loc231)
    %638 = arith.select %633, %637, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %639 = arith.xori %602, %638 : tensor<256xi16, #blocked> loc(#loc233)
    %640 = tt.bitcast %636 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %641 = tt.broadcast %34 : tensor<1x2x1xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc138)
    %642 = tt.reshape %641 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc139)
    %643 = tt.reshape %640 : tensor<256xf32, #blocked> -> tensor<4x2x32xf32, #blocked6> loc(#loc188)
    %644 = tt.bitcast %643 : tensor<4x2x32xf32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc189)
    %645 = tt.broadcast %45 : tensor<1x2x1xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc191)
    %646 = arith.muli %644, %645 : tensor<4x2x32xi32, #blocked6> loc(#loc191)
    %647 = "tt.reduce"(%646) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc235)
    %648 = tt.expand_dims %647 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc195)
    %649 = tt.broadcast %648 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc196)
    %650 = arith.muli %644, %451 : tensor<4x2x32xi32, #blocked6> loc(#loc197)
    %651 = "tt.reduce"(%650) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc238)
    %652 = tt.expand_dims %651 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc201)
    %653 = tt.broadcast %652 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc202)
    %654 = tt.reshape %649 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc203)
    %655 = tt.reshape %653 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc204)
    %656 = tt.bitcast %654 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %657 = tt.bitcast %655 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %658 = tt.reshape %639 : tensor<256xi16, #blocked> -> tensor<4x2x32xi16, #blocked6> loc(#loc207)
    %659 = tt.broadcast %68 : tensor<1x2x1xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc209)
    %660 = arith.muli %658, %659 : tensor<4x2x32xi16, #blocked6> loc(#loc209)
    %661 = "tt.reduce"(%660) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<4x2x32xi16, #blocked6>) -> tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc241)
    %662 = tt.expand_dims %661 {axis = 1 : i32} : tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi16, #blocked6> loc(#loc213)
    %663 = tt.broadcast %662 : tensor<4x1x32xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc214)
    %664 = tt.broadcast %81 : tensor<1x2x1xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc216)
    %665 = arith.muli %658, %664 : tensor<4x2x32xi16, #blocked6> loc(#loc216)
    %666 = "tt.reduce"(%665) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<4x2x32xi16, #blocked6>) -> tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %667 = tt.expand_dims %666 {axis = 1 : i32} : tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi16, #blocked6> loc(#loc220)
    %668 = tt.broadcast %667 : tensor<4x1x32xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc221)
    %669 = tt.reshape %663 : tensor<4x2x32xi16, #blocked6> -> tensor<256xi16, #blocked> loc(#loc222)
    %670 = tt.reshape %668 : tensor<4x2x32xi16, #blocked6> -> tensor<256xi16, #blocked> loc(#loc223)
    %671 = tt.bitcast %640 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %672 = arith.cmpf olt, %656, %657 : tensor<256xf32, #blocked> loc(#loc225)
    %673 = arith.extui %672 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %674 = arith.xori %673, %642 : tensor<256xi32, #blocked> loc(#loc226)
    %675 = arith.cmpi ne, %674, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %676 = arith.xori %654, %655 : tensor<256xi32, #blocked> loc(#loc228)
    %677 = arith.select %675, %676, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %678 = arith.xori %671, %677 : tensor<256xi32, #blocked> loc(#loc230)
    %679 = arith.xori %669, %670 : tensor<256xi16, #blocked> loc(#loc231)
    %680 = arith.select %675, %679, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %681 = arith.xori %639, %680 : tensor<256xi16, #blocked> loc(#loc233)
    %682 = tt.bitcast %678 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %683 = tt.reshape %682 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc188)
    %684 = tt.bitcast %683 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc189)
    %685 = arith.muli %684, %455 : tensor<8x2x16xi32, #blocked5> loc(#loc191)
    %686 = "tt.reduce"(%685) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc235)
    %687 = tt.expand_dims %686 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc195)
    %688 = tt.broadcast %687 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc196)
    %689 = arith.muli %684, %298 : tensor<8x2x16xi32, #blocked5> loc(#loc197)
    %690 = "tt.reduce"(%689) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc238)
    %691 = tt.expand_dims %690 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc201)
    %692 = tt.broadcast %691 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc202)
    %693 = tt.reshape %688 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc203)
    %694 = tt.reshape %692 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc204)
    %695 = tt.bitcast %693 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %696 = tt.bitcast %694 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %697 = tt.reshape %681 : tensor<256xi16, #blocked> -> tensor<8x2x16xi16, #blocked5> loc(#loc207)
    %698 = arith.muli %697, %469 : tensor<8x2x16xi16, #blocked5> loc(#loc209)
    %699 = "tt.reduce"(%698) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc241)
    %700 = tt.expand_dims %699 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc213)
    %701 = tt.broadcast %700 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc214)
    %702 = arith.muli %697, %474 : tensor<8x2x16xi16, #blocked5> loc(#loc216)
    %703 = "tt.reduce"(%702) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %704 = tt.expand_dims %703 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc220)
    %705 = tt.broadcast %704 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc221)
    %706 = tt.reshape %701 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc222)
    %707 = tt.reshape %705 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc223)
    %708 = tt.bitcast %682 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %709 = arith.cmpf olt, %695, %696 : tensor<256xf32, #blocked> loc(#loc225)
    %710 = arith.extui %709 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %711 = arith.xori %710, %642 : tensor<256xi32, #blocked> loc(#loc226)
    %712 = arith.cmpi ne, %711, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %713 = arith.xori %693, %694 : tensor<256xi32, #blocked> loc(#loc228)
    %714 = arith.select %712, %713, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %715 = arith.xori %708, %714 : tensor<256xi32, #blocked> loc(#loc230)
    %716 = arith.xori %706, %707 : tensor<256xi16, #blocked> loc(#loc231)
    %717 = arith.select %712, %716, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %718 = arith.xori %681, %717 : tensor<256xi16, #blocked> loc(#loc233)
    %719 = tt.bitcast %715 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %720 = tt.reshape %719 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc188)
    %721 = tt.bitcast %720 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc189)
    %722 = arith.muli %721, %302 : tensor<16x2x8xi32, #blocked4> loc(#loc191)
    %723 = "tt.reduce"(%722) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc235)
    %724 = tt.expand_dims %723 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc195)
    %725 = tt.broadcast %724 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc196)
    %726 = arith.muli %721, %182 : tensor<16x2x8xi32, #blocked4> loc(#loc197)
    %727 = "tt.reduce"(%726) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc238)
    %728 = tt.expand_dims %727 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc201)
    %729 = tt.broadcast %728 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc202)
    %730 = tt.reshape %725 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc203)
    %731 = tt.reshape %729 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc204)
    %732 = tt.bitcast %730 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %733 = tt.bitcast %731 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %734 = tt.reshape %718 : tensor<256xi16, #blocked> -> tensor<16x2x8xi16, #blocked4> loc(#loc207)
    %735 = arith.muli %734, %316 : tensor<16x2x8xi16, #blocked4> loc(#loc209)
    %736 = "tt.reduce"(%735) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc241)
    %737 = tt.expand_dims %736 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc213)
    %738 = tt.broadcast %737 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc214)
    %739 = arith.muli %734, %321 : tensor<16x2x8xi16, #blocked4> loc(#loc216)
    %740 = "tt.reduce"(%739) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %741 = tt.expand_dims %740 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc220)
    %742 = tt.broadcast %741 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc221)
    %743 = tt.reshape %738 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc222)
    %744 = tt.reshape %742 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc223)
    %745 = tt.bitcast %719 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %746 = arith.cmpf olt, %732, %733 : tensor<256xf32, #blocked> loc(#loc225)
    %747 = arith.extui %746 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %748 = arith.xori %747, %642 : tensor<256xi32, #blocked> loc(#loc226)
    %749 = arith.cmpi ne, %748, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %750 = arith.xori %730, %731 : tensor<256xi32, #blocked> loc(#loc228)
    %751 = arith.select %749, %750, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %752 = arith.xori %745, %751 : tensor<256xi32, #blocked> loc(#loc230)
    %753 = arith.xori %743, %744 : tensor<256xi16, #blocked> loc(#loc231)
    %754 = arith.select %749, %753, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %755 = arith.xori %718, %754 : tensor<256xi16, #blocked> loc(#loc233)
    %756 = tt.bitcast %752 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %757 = tt.reshape %756 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc188)
    %758 = tt.bitcast %757 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc189)
    %759 = arith.muli %758, %186 : tensor<32x2x4xi32, #blocked3> loc(#loc191)
    %760 = "tt.reduce"(%759) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc235)
    %761 = tt.expand_dims %760 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc195)
    %762 = tt.broadcast %761 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc196)
    %763 = arith.muli %758, %103 : tensor<32x2x4xi32, #blocked3> loc(#loc197)
    %764 = "tt.reduce"(%763) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc238)
    %765 = tt.expand_dims %764 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc201)
    %766 = tt.broadcast %765 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc202)
    %767 = tt.reshape %762 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc203)
    %768 = tt.reshape %766 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc204)
    %769 = tt.bitcast %767 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %770 = tt.bitcast %768 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %771 = tt.reshape %755 : tensor<256xi16, #blocked> -> tensor<32x2x4xi16, #blocked3> loc(#loc207)
    %772 = arith.muli %771, %200 : tensor<32x2x4xi16, #blocked3> loc(#loc209)
    %773 = "tt.reduce"(%772) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc241)
    %774 = tt.expand_dims %773 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc213)
    %775 = tt.broadcast %774 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc214)
    %776 = arith.muli %771, %205 : tensor<32x2x4xi16, #blocked3> loc(#loc216)
    %777 = "tt.reduce"(%776) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %778 = tt.expand_dims %777 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc220)
    %779 = tt.broadcast %778 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc221)
    %780 = tt.reshape %775 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc222)
    %781 = tt.reshape %779 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc223)
    %782 = tt.bitcast %756 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %783 = arith.cmpf olt, %769, %770 : tensor<256xf32, #blocked> loc(#loc225)
    %784 = arith.extui %783 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %785 = arith.xori %784, %642 : tensor<256xi32, #blocked> loc(#loc226)
    %786 = arith.cmpi ne, %785, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %787 = arith.xori %767, %768 : tensor<256xi32, #blocked> loc(#loc228)
    %788 = arith.select %786, %787, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %789 = arith.xori %782, %788 : tensor<256xi32, #blocked> loc(#loc230)
    %790 = arith.xori %780, %781 : tensor<256xi16, #blocked> loc(#loc231)
    %791 = arith.select %786, %790, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %792 = arith.xori %755, %791 : tensor<256xi16, #blocked> loc(#loc233)
    %793 = tt.bitcast %789 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %794 = tt.reshape %793 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc188)
    %795 = tt.bitcast %794 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc189)
    %796 = arith.muli %795, %107 : tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %797 = "tt.reduce"(%796) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc235)
    %798 = tt.expand_dims %797 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc195)
    %799 = tt.broadcast %798 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc196)
    %800 = arith.muli %795, %36 : tensor<64x2x2xi32, #blocked2> loc(#loc197)
    %801 = "tt.reduce"(%800) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc238)
    %802 = tt.expand_dims %801 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc201)
    %803 = tt.broadcast %802 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc202)
    %804 = tt.reshape %799 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc203)
    %805 = tt.reshape %803 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc204)
    %806 = tt.bitcast %804 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %807 = tt.bitcast %805 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %808 = tt.reshape %792 : tensor<256xi16, #blocked> -> tensor<64x2x2xi16, #blocked2> loc(#loc207)
    %809 = arith.muli %808, %121 : tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %810 = "tt.reduce"(%809) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc241)
    %811 = tt.expand_dims %810 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc213)
    %812 = tt.broadcast %811 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc214)
    %813 = arith.muli %808, %126 : tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %814 = "tt.reduce"(%813) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %815 = tt.expand_dims %814 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc220)
    %816 = tt.broadcast %815 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc221)
    %817 = tt.reshape %812 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc222)
    %818 = tt.reshape %816 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc223)
    %819 = tt.bitcast %793 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %820 = arith.cmpf olt, %806, %807 : tensor<256xf32, #blocked> loc(#loc225)
    %821 = arith.extui %820 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %822 = arith.xori %821, %642 : tensor<256xi32, #blocked> loc(#loc226)
    %823 = arith.cmpi ne, %822, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %824 = arith.xori %804, %805 : tensor<256xi32, #blocked> loc(#loc228)
    %825 = arith.select %823, %824, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %826 = arith.xori %819, %825 : tensor<256xi32, #blocked> loc(#loc230)
    %827 = arith.xori %817, %818 : tensor<256xi16, #blocked> loc(#loc231)
    %828 = arith.select %823, %827, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %829 = arith.xori %792, %828 : tensor<256xi16, #blocked> loc(#loc233)
    %830 = tt.bitcast %826 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %831 = tt.reshape %830 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %832 = tt.bitcast %831 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %833 = arith.muli %832, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %834 = "tt.reduce"(%833) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %835 = tt.expand_dims %834 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %836 = tt.broadcast %835 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %837 = arith.muli %832, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %838 = "tt.reduce"(%837) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %839 = tt.expand_dims %838 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %840 = tt.broadcast %839 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %841 = tt.reshape %836 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %842 = tt.reshape %840 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %843 = tt.bitcast %841 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %844 = tt.bitcast %842 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %845 = tt.reshape %829 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %846 = arith.muli %845, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %847 = "tt.reduce"(%846) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %848 = tt.expand_dims %847 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %849 = tt.broadcast %848 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %850 = arith.muli %845, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %851 = "tt.reduce"(%850) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %852 = tt.expand_dims %851 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %853 = tt.broadcast %852 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %854 = tt.reshape %849 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %855 = tt.reshape %853 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %856 = tt.bitcast %830 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %857 = arith.cmpf olt, %843, %844 : tensor<256xf32, #blocked> loc(#loc225)
    %858 = arith.extui %857 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %859 = arith.xori %858, %642 : tensor<256xi32, #blocked> loc(#loc226)
    %860 = arith.cmpi ne, %859, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %861 = arith.xori %841, %842 : tensor<256xi32, #blocked> loc(#loc228)
    %862 = arith.select %860, %861, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %863 = arith.xori %856, %862 : tensor<256xi32, #blocked> loc(#loc230)
    %864 = arith.xori %854, %855 : tensor<256xi16, #blocked> loc(#loc231)
    %865 = arith.select %860, %864, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %866 = arith.xori %829, %865 : tensor<256xi16, #blocked> loc(#loc233)
    %867 = tt.bitcast %863 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %868 = tt.broadcast %35 : tensor<1x2x1xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc138)
    %869 = tt.reshape %868 : tensor<1x2x128xi32, #blocked8> -> tensor<256xi32, #blocked> loc(#loc139)
    %870 = tt.reshape %867 : tensor<256xf32, #blocked> -> tensor<2x2x64xf32, #blocked7> loc(#loc188)
    %871 = tt.bitcast %870 : tensor<2x2x64xf32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc189)
    %872 = tt.broadcast %46 : tensor<1x2x1xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc191)
    %873 = arith.muli %871, %872 : tensor<2x2x64xi32, #blocked7> loc(#loc191)
    %874 = "tt.reduce"(%873) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc235)
    %875 = tt.expand_dims %874 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc195)
    %876 = tt.broadcast %875 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc196)
    %877 = arith.muli %871, %641 : tensor<2x2x64xi32, #blocked7> loc(#loc197)
    %878 = "tt.reduce"(%877) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc238)
    %879 = tt.expand_dims %878 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc201)
    %880 = tt.broadcast %879 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc202)
    %881 = tt.reshape %876 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc203)
    %882 = tt.reshape %880 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc204)
    %883 = tt.bitcast %881 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %884 = tt.bitcast %882 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %885 = tt.reshape %866 : tensor<256xi16, #blocked> -> tensor<2x2x64xi16, #blocked7> loc(#loc207)
    %886 = tt.broadcast %69 : tensor<1x2x1xi16, #blocked7> -> tensor<2x2x64xi16, #blocked7> loc(#loc209)
    %887 = arith.muli %885, %886 : tensor<2x2x64xi16, #blocked7> loc(#loc209)
    %888 = "tt.reduce"(%887) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<2x2x64xi16, #blocked7>) -> tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc241)
    %889 = tt.expand_dims %888 {axis = 1 : i32} : tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi16, #blocked7> loc(#loc213)
    %890 = tt.broadcast %889 : tensor<2x1x64xi16, #blocked7> -> tensor<2x2x64xi16, #blocked7> loc(#loc214)
    %891 = tt.broadcast %82 : tensor<1x2x1xi16, #blocked7> -> tensor<2x2x64xi16, #blocked7> loc(#loc216)
    %892 = arith.muli %885, %891 : tensor<2x2x64xi16, #blocked7> loc(#loc216)
    %893 = "tt.reduce"(%892) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<2x2x64xi16, #blocked7>) -> tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %894 = tt.expand_dims %893 {axis = 1 : i32} : tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi16, #blocked7> loc(#loc220)
    %895 = tt.broadcast %894 : tensor<2x1x64xi16, #blocked7> -> tensor<2x2x64xi16, #blocked7> loc(#loc221)
    %896 = tt.reshape %890 : tensor<2x2x64xi16, #blocked7> -> tensor<256xi16, #blocked> loc(#loc222)
    %897 = tt.reshape %895 : tensor<2x2x64xi16, #blocked7> -> tensor<256xi16, #blocked> loc(#loc223)
    %898 = tt.bitcast %867 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %899 = arith.cmpf olt, %883, %884 : tensor<256xf32, #blocked> loc(#loc225)
    %900 = arith.extui %899 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %901 = arith.xori %900, %869 : tensor<256xi32, #blocked> loc(#loc226)
    %902 = arith.cmpi ne, %901, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %903 = arith.xori %881, %882 : tensor<256xi32, #blocked> loc(#loc228)
    %904 = arith.select %902, %903, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %905 = arith.xori %898, %904 : tensor<256xi32, #blocked> loc(#loc230)
    %906 = arith.xori %896, %897 : tensor<256xi16, #blocked> loc(#loc231)
    %907 = arith.select %902, %906, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %908 = arith.xori %866, %907 : tensor<256xi16, #blocked> loc(#loc233)
    %909 = tt.bitcast %905 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %910 = tt.reshape %909 : tensor<256xf32, #blocked> -> tensor<4x2x32xf32, #blocked6> loc(#loc188)
    %911 = tt.bitcast %910 : tensor<4x2x32xf32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc189)
    %912 = arith.muli %911, %645 : tensor<4x2x32xi32, #blocked6> loc(#loc191)
    %913 = "tt.reduce"(%912) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc235)
    %914 = tt.expand_dims %913 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc195)
    %915 = tt.broadcast %914 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc196)
    %916 = arith.muli %911, %451 : tensor<4x2x32xi32, #blocked6> loc(#loc197)
    %917 = "tt.reduce"(%916) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc238)
    %918 = tt.expand_dims %917 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc201)
    %919 = tt.broadcast %918 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc202)
    %920 = tt.reshape %915 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc203)
    %921 = tt.reshape %919 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc204)
    %922 = tt.bitcast %920 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %923 = tt.bitcast %921 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %924 = tt.reshape %908 : tensor<256xi16, #blocked> -> tensor<4x2x32xi16, #blocked6> loc(#loc207)
    %925 = arith.muli %924, %659 : tensor<4x2x32xi16, #blocked6> loc(#loc209)
    %926 = "tt.reduce"(%925) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<4x2x32xi16, #blocked6>) -> tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc241)
    %927 = tt.expand_dims %926 {axis = 1 : i32} : tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi16, #blocked6> loc(#loc213)
    %928 = tt.broadcast %927 : tensor<4x1x32xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc214)
    %929 = arith.muli %924, %664 : tensor<4x2x32xi16, #blocked6> loc(#loc216)
    %930 = "tt.reduce"(%929) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<4x2x32xi16, #blocked6>) -> tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %931 = tt.expand_dims %930 {axis = 1 : i32} : tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi16, #blocked6> loc(#loc220)
    %932 = tt.broadcast %931 : tensor<4x1x32xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc221)
    %933 = tt.reshape %928 : tensor<4x2x32xi16, #blocked6> -> tensor<256xi16, #blocked> loc(#loc222)
    %934 = tt.reshape %932 : tensor<4x2x32xi16, #blocked6> -> tensor<256xi16, #blocked> loc(#loc223)
    %935 = tt.bitcast %909 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %936 = arith.cmpf olt, %922, %923 : tensor<256xf32, #blocked> loc(#loc225)
    %937 = arith.extui %936 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %938 = arith.xori %937, %869 : tensor<256xi32, #blocked> loc(#loc226)
    %939 = arith.cmpi ne, %938, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %940 = arith.xori %920, %921 : tensor<256xi32, #blocked> loc(#loc228)
    %941 = arith.select %939, %940, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %942 = arith.xori %935, %941 : tensor<256xi32, #blocked> loc(#loc230)
    %943 = arith.xori %933, %934 : tensor<256xi16, #blocked> loc(#loc231)
    %944 = arith.select %939, %943, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %945 = arith.xori %908, %944 : tensor<256xi16, #blocked> loc(#loc233)
    %946 = tt.bitcast %942 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %947 = tt.reshape %946 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc188)
    %948 = tt.bitcast %947 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc189)
    %949 = arith.muli %948, %455 : tensor<8x2x16xi32, #blocked5> loc(#loc191)
    %950 = "tt.reduce"(%949) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc235)
    %951 = tt.expand_dims %950 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc195)
    %952 = tt.broadcast %951 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc196)
    %953 = arith.muli %948, %298 : tensor<8x2x16xi32, #blocked5> loc(#loc197)
    %954 = "tt.reduce"(%953) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc238)
    %955 = tt.expand_dims %954 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc201)
    %956 = tt.broadcast %955 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc202)
    %957 = tt.reshape %952 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc203)
    %958 = tt.reshape %956 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc204)
    %959 = tt.bitcast %957 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %960 = tt.bitcast %958 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %961 = tt.reshape %945 : tensor<256xi16, #blocked> -> tensor<8x2x16xi16, #blocked5> loc(#loc207)
    %962 = arith.muli %961, %469 : tensor<8x2x16xi16, #blocked5> loc(#loc209)
    %963 = "tt.reduce"(%962) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc241)
    %964 = tt.expand_dims %963 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc213)
    %965 = tt.broadcast %964 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc214)
    %966 = arith.muli %961, %474 : tensor<8x2x16xi16, #blocked5> loc(#loc216)
    %967 = "tt.reduce"(%966) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %968 = tt.expand_dims %967 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc220)
    %969 = tt.broadcast %968 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc221)
    %970 = tt.reshape %965 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc222)
    %971 = tt.reshape %969 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc223)
    %972 = tt.bitcast %946 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %973 = arith.cmpf olt, %959, %960 : tensor<256xf32, #blocked> loc(#loc225)
    %974 = arith.extui %973 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %975 = arith.xori %974, %869 : tensor<256xi32, #blocked> loc(#loc226)
    %976 = arith.cmpi ne, %975, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %977 = arith.xori %957, %958 : tensor<256xi32, #blocked> loc(#loc228)
    %978 = arith.select %976, %977, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %979 = arith.xori %972, %978 : tensor<256xi32, #blocked> loc(#loc230)
    %980 = arith.xori %970, %971 : tensor<256xi16, #blocked> loc(#loc231)
    %981 = arith.select %976, %980, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %982 = arith.xori %945, %981 : tensor<256xi16, #blocked> loc(#loc233)
    %983 = tt.bitcast %979 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %984 = tt.reshape %983 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc188)
    %985 = tt.bitcast %984 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc189)
    %986 = arith.muli %985, %302 : tensor<16x2x8xi32, #blocked4> loc(#loc191)
    %987 = "tt.reduce"(%986) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc235)
    %988 = tt.expand_dims %987 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc195)
    %989 = tt.broadcast %988 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc196)
    %990 = arith.muli %985, %182 : tensor<16x2x8xi32, #blocked4> loc(#loc197)
    %991 = "tt.reduce"(%990) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc238)
    %992 = tt.expand_dims %991 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc201)
    %993 = tt.broadcast %992 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc202)
    %994 = tt.reshape %989 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc203)
    %995 = tt.reshape %993 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc204)
    %996 = tt.bitcast %994 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %997 = tt.bitcast %995 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %998 = tt.reshape %982 : tensor<256xi16, #blocked> -> tensor<16x2x8xi16, #blocked4> loc(#loc207)
    %999 = arith.muli %998, %316 : tensor<16x2x8xi16, #blocked4> loc(#loc209)
    %1000 = "tt.reduce"(%999) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc241)
    %1001 = tt.expand_dims %1000 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc213)
    %1002 = tt.broadcast %1001 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc214)
    %1003 = arith.muli %998, %321 : tensor<16x2x8xi16, #blocked4> loc(#loc216)
    %1004 = "tt.reduce"(%1003) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %1005 = tt.expand_dims %1004 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc220)
    %1006 = tt.broadcast %1005 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc221)
    %1007 = tt.reshape %1002 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc222)
    %1008 = tt.reshape %1006 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc223)
    %1009 = tt.bitcast %983 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1010 = arith.cmpf olt, %996, %997 : tensor<256xf32, #blocked> loc(#loc225)
    %1011 = arith.extui %1010 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %1012 = arith.xori %1011, %869 : tensor<256xi32, #blocked> loc(#loc226)
    %1013 = arith.cmpi ne, %1012, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %1014 = arith.xori %994, %995 : tensor<256xi32, #blocked> loc(#loc228)
    %1015 = arith.select %1013, %1014, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1016 = arith.xori %1009, %1015 : tensor<256xi32, #blocked> loc(#loc230)
    %1017 = arith.xori %1007, %1008 : tensor<256xi16, #blocked> loc(#loc231)
    %1018 = arith.select %1013, %1017, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1019 = arith.xori %982, %1018 : tensor<256xi16, #blocked> loc(#loc233)
    %1020 = tt.bitcast %1016 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1021 = tt.reshape %1020 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc188)
    %1022 = tt.bitcast %1021 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc189)
    %1023 = arith.muli %1022, %186 : tensor<32x2x4xi32, #blocked3> loc(#loc191)
    %1024 = "tt.reduce"(%1023) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc235)
    %1025 = tt.expand_dims %1024 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc195)
    %1026 = tt.broadcast %1025 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc196)
    %1027 = arith.muli %1022, %103 : tensor<32x2x4xi32, #blocked3> loc(#loc197)
    %1028 = "tt.reduce"(%1027) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc238)
    %1029 = tt.expand_dims %1028 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc201)
    %1030 = tt.broadcast %1029 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc202)
    %1031 = tt.reshape %1026 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc203)
    %1032 = tt.reshape %1030 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc204)
    %1033 = tt.bitcast %1031 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1034 = tt.bitcast %1032 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1035 = tt.reshape %1019 : tensor<256xi16, #blocked> -> tensor<32x2x4xi16, #blocked3> loc(#loc207)
    %1036 = arith.muli %1035, %200 : tensor<32x2x4xi16, #blocked3> loc(#loc209)
    %1037 = "tt.reduce"(%1036) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc241)
    %1038 = tt.expand_dims %1037 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc213)
    %1039 = tt.broadcast %1038 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc214)
    %1040 = arith.muli %1035, %205 : tensor<32x2x4xi16, #blocked3> loc(#loc216)
    %1041 = "tt.reduce"(%1040) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %1042 = tt.expand_dims %1041 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc220)
    %1043 = tt.broadcast %1042 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc221)
    %1044 = tt.reshape %1039 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc222)
    %1045 = tt.reshape %1043 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc223)
    %1046 = tt.bitcast %1020 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1047 = arith.cmpf olt, %1033, %1034 : tensor<256xf32, #blocked> loc(#loc225)
    %1048 = arith.extui %1047 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %1049 = arith.xori %1048, %869 : tensor<256xi32, #blocked> loc(#loc226)
    %1050 = arith.cmpi ne, %1049, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %1051 = arith.xori %1031, %1032 : tensor<256xi32, #blocked> loc(#loc228)
    %1052 = arith.select %1050, %1051, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1053 = arith.xori %1046, %1052 : tensor<256xi32, #blocked> loc(#loc230)
    %1054 = arith.xori %1044, %1045 : tensor<256xi16, #blocked> loc(#loc231)
    %1055 = arith.select %1050, %1054, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1056 = arith.xori %1019, %1055 : tensor<256xi16, #blocked> loc(#loc233)
    %1057 = tt.bitcast %1053 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1058 = tt.reshape %1057 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc188)
    %1059 = tt.bitcast %1058 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc189)
    %1060 = arith.muli %1059, %107 : tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %1061 = "tt.reduce"(%1060) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc235)
    %1062 = tt.expand_dims %1061 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc195)
    %1063 = tt.broadcast %1062 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc196)
    %1064 = arith.muli %1059, %36 : tensor<64x2x2xi32, #blocked2> loc(#loc197)
    %1065 = "tt.reduce"(%1064) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc238)
    %1066 = tt.expand_dims %1065 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc201)
    %1067 = tt.broadcast %1066 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc202)
    %1068 = tt.reshape %1063 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc203)
    %1069 = tt.reshape %1067 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc204)
    %1070 = tt.bitcast %1068 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1071 = tt.bitcast %1069 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1072 = tt.reshape %1056 : tensor<256xi16, #blocked> -> tensor<64x2x2xi16, #blocked2> loc(#loc207)
    %1073 = arith.muli %1072, %121 : tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %1074 = "tt.reduce"(%1073) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc241)
    %1075 = tt.expand_dims %1074 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc213)
    %1076 = tt.broadcast %1075 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc214)
    %1077 = arith.muli %1072, %126 : tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %1078 = "tt.reduce"(%1077) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %1079 = tt.expand_dims %1078 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc220)
    %1080 = tt.broadcast %1079 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc221)
    %1081 = tt.reshape %1076 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc222)
    %1082 = tt.reshape %1080 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc223)
    %1083 = tt.bitcast %1057 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1084 = arith.cmpf olt, %1070, %1071 : tensor<256xf32, #blocked> loc(#loc225)
    %1085 = arith.extui %1084 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %1086 = arith.xori %1085, %869 : tensor<256xi32, #blocked> loc(#loc226)
    %1087 = arith.cmpi ne, %1086, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %1088 = arith.xori %1068, %1069 : tensor<256xi32, #blocked> loc(#loc228)
    %1089 = arith.select %1087, %1088, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1090 = arith.xori %1083, %1089 : tensor<256xi32, #blocked> loc(#loc230)
    %1091 = arith.xori %1081, %1082 : tensor<256xi16, #blocked> loc(#loc231)
    %1092 = arith.select %1087, %1091, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1093 = arith.xori %1056, %1092 : tensor<256xi16, #blocked> loc(#loc233)
    %1094 = tt.bitcast %1090 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1095 = tt.reshape %1094 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %1096 = tt.bitcast %1095 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %1097 = arith.muli %1096, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %1098 = "tt.reduce"(%1097) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %1099 = tt.expand_dims %1098 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %1100 = tt.broadcast %1099 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %1101 = arith.muli %1096, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %1102 = "tt.reduce"(%1101) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %1103 = tt.expand_dims %1102 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %1104 = tt.broadcast %1103 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %1105 = tt.reshape %1100 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %1106 = tt.reshape %1104 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %1107 = tt.bitcast %1105 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1108 = tt.bitcast %1106 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1109 = tt.reshape %1093 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %1110 = arith.muli %1109, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %1111 = "tt.reduce"(%1110) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %1112 = tt.expand_dims %1111 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %1113 = tt.broadcast %1112 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %1114 = arith.muli %1109, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %1115 = "tt.reduce"(%1114) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %1116 = tt.expand_dims %1115 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %1117 = tt.broadcast %1116 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %1118 = tt.reshape %1113 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %1119 = tt.reshape %1117 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %1120 = tt.bitcast %1094 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1121 = arith.cmpf olt, %1107, %1108 : tensor<256xf32, #blocked> loc(#loc225)
    %1122 = arith.extui %1121 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc226)
    %1123 = arith.xori %1122, %869 : tensor<256xi32, #blocked> loc(#loc226)
    %1124 = arith.cmpi ne, %1123, %cst_3 : tensor<256xi32, #blocked> loc(#loc227)
    %1125 = arith.xori %1105, %1106 : tensor<256xi32, #blocked> loc(#loc228)
    %1126 = arith.select %1124, %1125, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1127 = arith.xori %1120, %1126 : tensor<256xi32, #blocked> loc(#loc230)
    %1128 = arith.xori %1118, %1119 : tensor<256xi16, #blocked> loc(#loc231)
    %1129 = arith.select %1124, %1128, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1130 = arith.xori %1093, %1129 : tensor<256xi16, #blocked> loc(#loc233)
    %1131 = tt.bitcast %1127 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1132 = tt.reshape %1131 : tensor<256xf32, #blocked> -> tensor<1x2x128xf32, #blocked8> loc(#loc188)
    %1133 = tt.bitcast %1132 : tensor<1x2x128xf32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc189)
    %1134 = tt.broadcast %47 : tensor<1x2x1xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc191)
    %1135 = arith.muli %1133, %1134 : tensor<1x2x128xi32, #blocked8> loc(#loc191)
    %1136 = "tt.reduce"(%1135) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<1x2x128xi32, #blocked8>) -> tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> loc(#loc235)
    %1137 = tt.expand_dims %1136 {axis = 1 : i32} : tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> -> tensor<1x1x128xi32, #blocked8> loc(#loc195)
    %1138 = tt.broadcast %1137 : tensor<1x1x128xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc196)
    %1139 = arith.muli %1133, %868 : tensor<1x2x128xi32, #blocked8> loc(#loc197)
    %1140 = "tt.reduce"(%1139) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<1x2x128xi32, #blocked8>) -> tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> loc(#loc238)
    %1141 = tt.expand_dims %1140 {axis = 1 : i32} : tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> -> tensor<1x1x128xi32, #blocked8> loc(#loc201)
    %1142 = tt.broadcast %1141 : tensor<1x1x128xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc202)
    %1143 = tt.reshape %1138 : tensor<1x2x128xi32, #blocked8> -> tensor<256xi32, #blocked> loc(#loc203)
    %1144 = tt.reshape %1142 : tensor<1x2x128xi32, #blocked8> -> tensor<256xi32, #blocked> loc(#loc204)
    %1145 = tt.bitcast %1143 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1146 = tt.bitcast %1144 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1147 = tt.reshape %1130 : tensor<256xi16, #blocked> -> tensor<1x2x128xi16, #blocked8> loc(#loc207)
    %1148 = tt.broadcast %70 : tensor<1x2x1xi16, #blocked8> -> tensor<1x2x128xi16, #blocked8> loc(#loc209)
    %1149 = arith.muli %1147, %1148 : tensor<1x2x128xi16, #blocked8> loc(#loc209)
    %1150 = "tt.reduce"(%1149) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<1x2x128xi16, #blocked8>) -> tensor<1x128xi16, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> loc(#loc241)
    %1151 = tt.expand_dims %1150 {axis = 1 : i32} : tensor<1x128xi16, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> -> tensor<1x1x128xi16, #blocked8> loc(#loc213)
    %1152 = tt.broadcast %1151 : tensor<1x1x128xi16, #blocked8> -> tensor<1x2x128xi16, #blocked8> loc(#loc214)
    %1153 = tt.broadcast %83 : tensor<1x2x1xi16, #blocked8> -> tensor<1x2x128xi16, #blocked8> loc(#loc216)
    %1154 = arith.muli %1147, %1153 : tensor<1x2x128xi16, #blocked8> loc(#loc216)
    %1155 = "tt.reduce"(%1154) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<1x2x128xi16, #blocked8>) -> tensor<1x128xi16, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> loc(#loc244)
    %1156 = tt.expand_dims %1155 {axis = 1 : i32} : tensor<1x128xi16, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> -> tensor<1x1x128xi16, #blocked8> loc(#loc220)
    %1157 = tt.broadcast %1156 : tensor<1x1x128xi16, #blocked8> -> tensor<1x2x128xi16, #blocked8> loc(#loc221)
    %1158 = tt.reshape %1152 : tensor<1x2x128xi16, #blocked8> -> tensor<256xi16, #blocked> loc(#loc222)
    %1159 = tt.reshape %1157 : tensor<1x2x128xi16, #blocked8> -> tensor<256xi16, #blocked> loc(#loc223)
    %1160 = tt.bitcast %1131 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1161 = arith.cmpf olt, %1145, %1146 : tensor<256xf32, #blocked> loc(#loc225)
    %1162 = arith.xori %1143, %1144 : tensor<256xi32, #blocked> loc(#loc228)
    %1163 = arith.select %1161, %1162, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1164 = arith.xori %1160, %1163 : tensor<256xi32, #blocked> loc(#loc230)
    %1165 = arith.xori %1158, %1159 : tensor<256xi16, #blocked> loc(#loc231)
    %1166 = arith.select %1161, %1165, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1167 = arith.xori %1130, %1166 : tensor<256xi16, #blocked> loc(#loc233)
    %1168 = tt.bitcast %1164 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1169 = tt.reshape %1168 : tensor<256xf32, #blocked> -> tensor<2x2x64xf32, #blocked7> loc(#loc188)
    %1170 = tt.bitcast %1169 : tensor<2x2x64xf32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc189)
    %1171 = arith.muli %1170, %872 : tensor<2x2x64xi32, #blocked7> loc(#loc191)
    %1172 = "tt.reduce"(%1171) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc235)
    %1173 = tt.expand_dims %1172 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc195)
    %1174 = tt.broadcast %1173 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc196)
    %1175 = arith.muli %1170, %641 : tensor<2x2x64xi32, #blocked7> loc(#loc197)
    %1176 = "tt.reduce"(%1175) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc238)
    %1177 = tt.expand_dims %1176 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc201)
    %1178 = tt.broadcast %1177 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc202)
    %1179 = tt.reshape %1174 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc203)
    %1180 = tt.reshape %1178 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc204)
    %1181 = tt.bitcast %1179 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1182 = tt.bitcast %1180 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1183 = tt.reshape %1167 : tensor<256xi16, #blocked> -> tensor<2x2x64xi16, #blocked7> loc(#loc207)
    %1184 = arith.muli %1183, %886 : tensor<2x2x64xi16, #blocked7> loc(#loc209)
    %1185 = "tt.reduce"(%1184) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<2x2x64xi16, #blocked7>) -> tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc241)
    %1186 = tt.expand_dims %1185 {axis = 1 : i32} : tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi16, #blocked7> loc(#loc213)
    %1187 = tt.broadcast %1186 : tensor<2x1x64xi16, #blocked7> -> tensor<2x2x64xi16, #blocked7> loc(#loc214)
    %1188 = arith.muli %1183, %891 : tensor<2x2x64xi16, #blocked7> loc(#loc216)
    %1189 = "tt.reduce"(%1188) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<2x2x64xi16, #blocked7>) -> tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %1190 = tt.expand_dims %1189 {axis = 1 : i32} : tensor<2x64xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi16, #blocked7> loc(#loc220)
    %1191 = tt.broadcast %1190 : tensor<2x1x64xi16, #blocked7> -> tensor<2x2x64xi16, #blocked7> loc(#loc221)
    %1192 = tt.reshape %1187 : tensor<2x2x64xi16, #blocked7> -> tensor<256xi16, #blocked> loc(#loc222)
    %1193 = tt.reshape %1191 : tensor<2x2x64xi16, #blocked7> -> tensor<256xi16, #blocked> loc(#loc223)
    %1194 = tt.bitcast %1168 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1195 = arith.cmpf olt, %1181, %1182 : tensor<256xf32, #blocked> loc(#loc225)
    %1196 = arith.xori %1179, %1180 : tensor<256xi32, #blocked> loc(#loc228)
    %1197 = arith.select %1195, %1196, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1198 = arith.xori %1194, %1197 : tensor<256xi32, #blocked> loc(#loc230)
    %1199 = arith.xori %1192, %1193 : tensor<256xi16, #blocked> loc(#loc231)
    %1200 = arith.select %1195, %1199, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1201 = arith.xori %1167, %1200 : tensor<256xi16, #blocked> loc(#loc233)
    %1202 = tt.bitcast %1198 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1203 = tt.reshape %1202 : tensor<256xf32, #blocked> -> tensor<4x2x32xf32, #blocked6> loc(#loc188)
    %1204 = tt.bitcast %1203 : tensor<4x2x32xf32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc189)
    %1205 = arith.muli %1204, %645 : tensor<4x2x32xi32, #blocked6> loc(#loc191)
    %1206 = "tt.reduce"(%1205) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc235)
    %1207 = tt.expand_dims %1206 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc195)
    %1208 = tt.broadcast %1207 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc196)
    %1209 = arith.muli %1204, %451 : tensor<4x2x32xi32, #blocked6> loc(#loc197)
    %1210 = "tt.reduce"(%1209) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc238)
    %1211 = tt.expand_dims %1210 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc201)
    %1212 = tt.broadcast %1211 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc202)
    %1213 = tt.reshape %1208 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc203)
    %1214 = tt.reshape %1212 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc204)
    %1215 = tt.bitcast %1213 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1216 = tt.bitcast %1214 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1217 = tt.reshape %1201 : tensor<256xi16, #blocked> -> tensor<4x2x32xi16, #blocked6> loc(#loc207)
    %1218 = arith.muli %1217, %659 : tensor<4x2x32xi16, #blocked6> loc(#loc209)
    %1219 = "tt.reduce"(%1218) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<4x2x32xi16, #blocked6>) -> tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc241)
    %1220 = tt.expand_dims %1219 {axis = 1 : i32} : tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi16, #blocked6> loc(#loc213)
    %1221 = tt.broadcast %1220 : tensor<4x1x32xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc214)
    %1222 = arith.muli %1217, %664 : tensor<4x2x32xi16, #blocked6> loc(#loc216)
    %1223 = "tt.reduce"(%1222) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<4x2x32xi16, #blocked6>) -> tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %1224 = tt.expand_dims %1223 {axis = 1 : i32} : tensor<4x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi16, #blocked6> loc(#loc220)
    %1225 = tt.broadcast %1224 : tensor<4x1x32xi16, #blocked6> -> tensor<4x2x32xi16, #blocked6> loc(#loc221)
    %1226 = tt.reshape %1221 : tensor<4x2x32xi16, #blocked6> -> tensor<256xi16, #blocked> loc(#loc222)
    %1227 = tt.reshape %1225 : tensor<4x2x32xi16, #blocked6> -> tensor<256xi16, #blocked> loc(#loc223)
    %1228 = tt.bitcast %1202 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1229 = arith.cmpf olt, %1215, %1216 : tensor<256xf32, #blocked> loc(#loc225)
    %1230 = arith.xori %1213, %1214 : tensor<256xi32, #blocked> loc(#loc228)
    %1231 = arith.select %1229, %1230, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1232 = arith.xori %1228, %1231 : tensor<256xi32, #blocked> loc(#loc230)
    %1233 = arith.xori %1226, %1227 : tensor<256xi16, #blocked> loc(#loc231)
    %1234 = arith.select %1229, %1233, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1235 = arith.xori %1201, %1234 : tensor<256xi16, #blocked> loc(#loc233)
    %1236 = tt.bitcast %1232 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1237 = tt.reshape %1236 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc188)
    %1238 = tt.bitcast %1237 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc189)
    %1239 = arith.muli %1238, %455 : tensor<8x2x16xi32, #blocked5> loc(#loc191)
    %1240 = "tt.reduce"(%1239) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc235)
    %1241 = tt.expand_dims %1240 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc195)
    %1242 = tt.broadcast %1241 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc196)
    %1243 = arith.muli %1238, %298 : tensor<8x2x16xi32, #blocked5> loc(#loc197)
    %1244 = "tt.reduce"(%1243) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc238)
    %1245 = tt.expand_dims %1244 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc201)
    %1246 = tt.broadcast %1245 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc202)
    %1247 = tt.reshape %1242 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc203)
    %1248 = tt.reshape %1246 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc204)
    %1249 = tt.bitcast %1247 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1250 = tt.bitcast %1248 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1251 = tt.reshape %1235 : tensor<256xi16, #blocked> -> tensor<8x2x16xi16, #blocked5> loc(#loc207)
    %1252 = arith.muli %1251, %469 : tensor<8x2x16xi16, #blocked5> loc(#loc209)
    %1253 = "tt.reduce"(%1252) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc241)
    %1254 = tt.expand_dims %1253 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc213)
    %1255 = tt.broadcast %1254 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc214)
    %1256 = arith.muli %1251, %474 : tensor<8x2x16xi16, #blocked5> loc(#loc216)
    %1257 = "tt.reduce"(%1256) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<8x2x16xi16, #blocked5>) -> tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %1258 = tt.expand_dims %1257 {axis = 1 : i32} : tensor<8x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi16, #blocked5> loc(#loc220)
    %1259 = tt.broadcast %1258 : tensor<8x1x16xi16, #blocked5> -> tensor<8x2x16xi16, #blocked5> loc(#loc221)
    %1260 = tt.reshape %1255 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc222)
    %1261 = tt.reshape %1259 : tensor<8x2x16xi16, #blocked5> -> tensor<256xi16, #blocked> loc(#loc223)
    %1262 = tt.bitcast %1236 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1263 = arith.cmpf olt, %1249, %1250 : tensor<256xf32, #blocked> loc(#loc225)
    %1264 = arith.xori %1247, %1248 : tensor<256xi32, #blocked> loc(#loc228)
    %1265 = arith.select %1263, %1264, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1266 = arith.xori %1262, %1265 : tensor<256xi32, #blocked> loc(#loc230)
    %1267 = arith.xori %1260, %1261 : tensor<256xi16, #blocked> loc(#loc231)
    %1268 = arith.select %1263, %1267, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1269 = arith.xori %1235, %1268 : tensor<256xi16, #blocked> loc(#loc233)
    %1270 = tt.bitcast %1266 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1271 = tt.reshape %1270 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc188)
    %1272 = tt.bitcast %1271 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc189)
    %1273 = arith.muli %1272, %302 : tensor<16x2x8xi32, #blocked4> loc(#loc191)
    %1274 = "tt.reduce"(%1273) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc235)
    %1275 = tt.expand_dims %1274 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc195)
    %1276 = tt.broadcast %1275 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc196)
    %1277 = arith.muli %1272, %182 : tensor<16x2x8xi32, #blocked4> loc(#loc197)
    %1278 = "tt.reduce"(%1277) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc238)
    %1279 = tt.expand_dims %1278 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc201)
    %1280 = tt.broadcast %1279 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc202)
    %1281 = tt.reshape %1276 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc203)
    %1282 = tt.reshape %1280 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc204)
    %1283 = tt.bitcast %1281 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1284 = tt.bitcast %1282 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1285 = tt.reshape %1269 : tensor<256xi16, #blocked> -> tensor<16x2x8xi16, #blocked4> loc(#loc207)
    %1286 = arith.muli %1285, %316 : tensor<16x2x8xi16, #blocked4> loc(#loc209)
    %1287 = "tt.reduce"(%1286) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc241)
    %1288 = tt.expand_dims %1287 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc213)
    %1289 = tt.broadcast %1288 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc214)
    %1290 = arith.muli %1285, %321 : tensor<16x2x8xi16, #blocked4> loc(#loc216)
    %1291 = "tt.reduce"(%1290) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<16x2x8xi16, #blocked4>) -> tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %1292 = tt.expand_dims %1291 {axis = 1 : i32} : tensor<16x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi16, #blocked4> loc(#loc220)
    %1293 = tt.broadcast %1292 : tensor<16x1x8xi16, #blocked4> -> tensor<16x2x8xi16, #blocked4> loc(#loc221)
    %1294 = tt.reshape %1289 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc222)
    %1295 = tt.reshape %1293 : tensor<16x2x8xi16, #blocked4> -> tensor<256xi16, #blocked> loc(#loc223)
    %1296 = tt.bitcast %1270 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1297 = arith.cmpf olt, %1283, %1284 : tensor<256xf32, #blocked> loc(#loc225)
    %1298 = arith.xori %1281, %1282 : tensor<256xi32, #blocked> loc(#loc228)
    %1299 = arith.select %1297, %1298, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1300 = arith.xori %1296, %1299 : tensor<256xi32, #blocked> loc(#loc230)
    %1301 = arith.xori %1294, %1295 : tensor<256xi16, #blocked> loc(#loc231)
    %1302 = arith.select %1297, %1301, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1303 = arith.xori %1269, %1302 : tensor<256xi16, #blocked> loc(#loc233)
    %1304 = tt.bitcast %1300 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1305 = tt.reshape %1304 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc188)
    %1306 = tt.bitcast %1305 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc189)
    %1307 = arith.muli %1306, %186 : tensor<32x2x4xi32, #blocked3> loc(#loc191)
    %1308 = "tt.reduce"(%1307) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc235)
    %1309 = tt.expand_dims %1308 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc195)
    %1310 = tt.broadcast %1309 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc196)
    %1311 = arith.muli %1306, %103 : tensor<32x2x4xi32, #blocked3> loc(#loc197)
    %1312 = "tt.reduce"(%1311) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc238)
    %1313 = tt.expand_dims %1312 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc201)
    %1314 = tt.broadcast %1313 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc202)
    %1315 = tt.reshape %1310 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc203)
    %1316 = tt.reshape %1314 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc204)
    %1317 = tt.bitcast %1315 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1318 = tt.bitcast %1316 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1319 = tt.reshape %1303 : tensor<256xi16, #blocked> -> tensor<32x2x4xi16, #blocked3> loc(#loc207)
    %1320 = arith.muli %1319, %200 : tensor<32x2x4xi16, #blocked3> loc(#loc209)
    %1321 = "tt.reduce"(%1320) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc241)
    %1322 = tt.expand_dims %1321 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc213)
    %1323 = tt.broadcast %1322 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc214)
    %1324 = arith.muli %1319, %205 : tensor<32x2x4xi16, #blocked3> loc(#loc216)
    %1325 = "tt.reduce"(%1324) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<32x2x4xi16, #blocked3>) -> tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %1326 = tt.expand_dims %1325 {axis = 1 : i32} : tensor<32x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi16, #blocked3> loc(#loc220)
    %1327 = tt.broadcast %1326 : tensor<32x1x4xi16, #blocked3> -> tensor<32x2x4xi16, #blocked3> loc(#loc221)
    %1328 = tt.reshape %1323 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc222)
    %1329 = tt.reshape %1327 : tensor<32x2x4xi16, #blocked3> -> tensor<256xi16, #blocked> loc(#loc223)
    %1330 = tt.bitcast %1304 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1331 = arith.cmpf olt, %1317, %1318 : tensor<256xf32, #blocked> loc(#loc225)
    %1332 = arith.xori %1315, %1316 : tensor<256xi32, #blocked> loc(#loc228)
    %1333 = arith.select %1331, %1332, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1334 = arith.xori %1330, %1333 : tensor<256xi32, #blocked> loc(#loc230)
    %1335 = arith.xori %1328, %1329 : tensor<256xi16, #blocked> loc(#loc231)
    %1336 = arith.select %1331, %1335, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1337 = arith.xori %1303, %1336 : tensor<256xi16, #blocked> loc(#loc233)
    %1338 = tt.bitcast %1334 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1339 = tt.reshape %1338 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc188)
    %1340 = tt.bitcast %1339 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc189)
    %1341 = arith.muli %1340, %107 : tensor<64x2x2xi32, #blocked2> loc(#loc191)
    %1342 = "tt.reduce"(%1341) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc235)
    %1343 = tt.expand_dims %1342 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc195)
    %1344 = tt.broadcast %1343 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc196)
    %1345 = arith.muli %1340, %36 : tensor<64x2x2xi32, #blocked2> loc(#loc197)
    %1346 = "tt.reduce"(%1345) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc238)
    %1347 = tt.expand_dims %1346 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc201)
    %1348 = tt.broadcast %1347 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc202)
    %1349 = tt.reshape %1344 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc203)
    %1350 = tt.reshape %1348 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc204)
    %1351 = tt.bitcast %1349 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1352 = tt.bitcast %1350 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1353 = tt.reshape %1337 : tensor<256xi16, #blocked> -> tensor<64x2x2xi16, #blocked2> loc(#loc207)
    %1354 = arith.muli %1353, %121 : tensor<64x2x2xi16, #blocked2> loc(#loc209)
    %1355 = "tt.reduce"(%1354) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc241)
    %1356 = tt.expand_dims %1355 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc213)
    %1357 = tt.broadcast %1356 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc214)
    %1358 = arith.muli %1353, %126 : tensor<64x2x2xi16, #blocked2> loc(#loc216)
    %1359 = "tt.reduce"(%1358) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<64x2x2xi16, #blocked2>) -> tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %1360 = tt.expand_dims %1359 {axis = 1 : i32} : tensor<64x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi16, #blocked2> loc(#loc220)
    %1361 = tt.broadcast %1360 : tensor<64x1x2xi16, #blocked2> -> tensor<64x2x2xi16, #blocked2> loc(#loc221)
    %1362 = tt.reshape %1357 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc222)
    %1363 = tt.reshape %1361 : tensor<64x2x2xi16, #blocked2> -> tensor<256xi16, #blocked> loc(#loc223)
    %1364 = tt.bitcast %1338 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1365 = arith.cmpf olt, %1351, %1352 : tensor<256xf32, #blocked> loc(#loc225)
    %1366 = arith.xori %1349, %1350 : tensor<256xi32, #blocked> loc(#loc228)
    %1367 = arith.select %1365, %1366, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1368 = arith.xori %1364, %1367 : tensor<256xi32, #blocked> loc(#loc230)
    %1369 = arith.xori %1362, %1363 : tensor<256xi16, #blocked> loc(#loc231)
    %1370 = arith.select %1365, %1369, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1371 = arith.xori %1337, %1370 : tensor<256xi16, #blocked> loc(#loc233)
    %1372 = tt.bitcast %1368 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1373 = tt.reshape %1372 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc188)
    %1374 = tt.bitcast %1373 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc189)
    %1375 = arith.muli %1374, %48 : tensor<128x2x1xi32, #blocked1> loc(#loc191)
    %1376 = "tt.reduce"(%1375) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc193 at #loc14)), %arg8: i32 loc(callsite(#loc193 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc247)
      tt.reduce.return %1430 : i32 loc(#loc235)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc235)
    %1377 = tt.expand_dims %1376 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc195)
    %1378 = tt.broadcast %1377 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc196)
    %1379 = arith.muli %1374, %53 : tensor<128x2x1xi32, #blocked1> loc(#loc197)
    %1380 = "tt.reduce"(%1379) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc199 at #loc14)), %arg8: i32 loc(callsite(#loc199 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i32 loc(#loc248)
      tt.reduce.return %1430 : i32 loc(#loc238)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc238)
    %1381 = tt.expand_dims %1380 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc201)
    %1382 = tt.broadcast %1381 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc202)
    %1383 = tt.reshape %1378 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc203)
    %1384 = tt.reshape %1382 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc204)
    %1385 = tt.bitcast %1383 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc205)
    %1386 = tt.bitcast %1384 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc206)
    %1387 = tt.reshape %1371 : tensor<256xi16, #blocked> -> tensor<128x2x1xi16, #blocked1> loc(#loc207)
    %1388 = arith.muli %1387, %71 : tensor<128x2x1xi16, #blocked1> loc(#loc209)
    %1389 = "tt.reduce"(%1388) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc211 at #loc14)), %arg8: i16 loc(callsite(#loc211 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc249)
      tt.reduce.return %1430 : i16 loc(#loc241)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc241)
    %1390 = tt.expand_dims %1389 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc213)
    %1391 = tt.broadcast %1390 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc214)
    %1392 = arith.muli %1387, %84 : tensor<128x2x1xi16, #blocked1> loc(#loc216)
    %1393 = "tt.reduce"(%1392) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc218 at #loc14)), %arg8: i16 loc(callsite(#loc218 at #loc14))):
      %1430 = arith.addi %arg7, %arg8 : i16 loc(#loc250)
      tt.reduce.return %1430 : i16 loc(#loc244)
    }) : (tensor<128x2x1xi16, #blocked1>) -> tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc244)
    %1394 = tt.expand_dims %1393 {axis = 1 : i32} : tensor<128x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi16, #blocked1> loc(#loc220)
    %1395 = tt.broadcast %1394 : tensor<128x1x1xi16, #blocked1> -> tensor<128x2x1xi16, #blocked1> loc(#loc221)
    %1396 = tt.reshape %1391 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc222)
    %1397 = tt.reshape %1395 : tensor<128x2x1xi16, #blocked1> -> tensor<256xi16, #blocked> loc(#loc223)
    %1398 = tt.bitcast %1372 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc224)
    %1399 = arith.cmpf olt, %1385, %1386 : tensor<256xf32, #blocked> loc(#loc225)
    %1400 = arith.xori %1383, %1384 : tensor<256xi32, #blocked> loc(#loc228)
    %1401 = arith.select %1399, %1400, %cst_3 : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc229)
    %1402 = arith.xori %1398, %1401 : tensor<256xi32, #blocked> loc(#loc230)
    %1403 = arith.xori %1396, %1397 : tensor<256xi16, #blocked> loc(#loc231)
    %1404 = arith.select %1399, %1403, %cst_4 : tensor<256xi1, #blocked>, tensor<256xi16, #blocked> loc(#loc232)
    %1405 = arith.xori %1371, %1404 : tensor<256xi16, #blocked> loc(#loc233)
    %1406 = tt.bitcast %1402 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc234)
    %1407 = arith.extsi %1405 : tensor<256xi16, #blocked> to tensor<256xi64, #blocked> loc(#loc59)
    %1408 = arith.addi %1407, %cst_1 : tensor<256xi64, #blocked> loc(#loc60)
    %1409 = arith.cmpi slt, %1407, %cst_2 : tensor<256xi64, #blocked> loc(#loc61)
    %1410 = arith.select %1409, %1408, %1407 : tensor<256xi1, #blocked>, tensor<256xi64, #blocked> loc(#loc62)
    %1411 = arith.cmpi sge, %1410, %cst_2 : tensor<256xi64, #blocked> loc(#loc63)
    %1412 = arith.cmpi slt, %1410, %cst_1 : tensor<256xi64, #blocked> loc(#loc64)
    %1413 = arith.andi %1411, %1412 : tensor<256xi1, #blocked> loc(#loc65)
    tt.assert %1413, "index out of bounds: 0 <= tmp18 < 256" : tensor<256xi1, #blocked> loc(#loc66)
    %1414 = tt.addptr %4, %1410 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi64, #blocked> loc(#loc67)
    %1415 = tt.load %1414 evictionPolicy = evict_last : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc68)
    %1416 = "tt.reduce"(%1415) <{axis = 0 : i32}> ({
    ^bb0(%arg7: f32 loc(callsite(#loc1 at #loc69)), %arg8: f32 loc(callsite(#loc1 at #loc69))):
      %1430 = arith.addf %arg7, %arg8 : f32 loc(#loc187)
      tt.reduce.return %1430 : f32 loc(#loc132)
    }) : (tensor<256xf32, #blocked>) -> f32 loc(#loc132)
    %1417 = arith.addf %1416, %cst_5 : f32 loc(#loc134)
    %1418 = tt.splat %1417 : f32 -> tensor<1xf32, #blocked9> loc(#loc134)
    %1419 = "tt.scan"(%1415) <{axis = 0 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %1430 = arith.addf %arg7, %arg8 : f32 loc(#loc135)
      tt.scan.return %1430 : f32 loc(#loc72)
    }) : (tensor<256xf32, #blocked>) -> tensor<256xf32, #blocked> loc(#loc72)
    %1420 = arith.subf %cst_0, %1415 : tensor<256xf32, #blocked> loc(#loc74)
    %1421 = "tt.scan"(%1420) <{axis = 0 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %1430 = arith.addf %arg7, %arg8 : f32 loc(#loc136)
      tt.scan.return %1430 : f32 loc(#loc75)
    }) : (tensor<256xf32, #blocked>) -> tensor<256xf32, #blocked> loc(#loc75)
    %1422 = tt.splat %arg2 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc76)
    %1423 = tt.addptr %1422, %0 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc76)
    tt.store %1423, %1406 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc77)
    %1424 = tt.splat %arg4 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc78)
    %1425 = tt.addptr %1424, %0 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc78)
    tt.store %1425, %1419 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc79)
    %1426 = tt.splat %arg5 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc80)
    %1427 = tt.addptr %1426, %0 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc80)
    tt.store %1427, %1421 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc81)
    %1428 = tt.addptr %arg3, %c0_i32 : !tt.ptr<f32>, i32 loc(#loc82)
    %1429 = tt.splat %1428 : !tt.ptr<f32> -> tensor<1x!tt.ptr<f32>, #blocked9> loc(#loc82)
    tt.store %1429, %1418 : tensor<1x!tt.ptr<f32>, #blocked9> loc(#loc83)
    tt.return loc(#loc84)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":32:26)
#loc3 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":36:30)
#loc4 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":36:35)
#loc5 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":37:30)
#loc6 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":37:35)
#loc7 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":39:18)
#loc8 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":41:18)
#loc9 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":42:18)
#loc10 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":43:18)
#loc11 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":45:19)
#loc12 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:44)
#loc15 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:60)
#loc16 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:68)
#loc17 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":501:22)
#loc19 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":502:14)
#loc20 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":505:21)
#loc21 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:40)
#loc22 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":267:36)
#loc24 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":256:15)
#loc25 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:54)
#loc26 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:67)
#loc27 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:41)
#loc29 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:56)
#loc30 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:69)
#loc31 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":508:30)
#loc32 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":509:32)
#loc33 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":510:20)
#loc34 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":511:22)
#loc35 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":514:29)
#loc36 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:36)
#loc37 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:23)
#loc39 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:53)
#loc40 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:66)
#loc41 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:37)
#loc42 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:23)
#loc44 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:54)
#loc45 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:67)
#loc46 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":521:36)
#loc47 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":522:38)
#loc48 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":533:14)
#loc49 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":536:22)
#loc50 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:19)
#loc51 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:28)
#loc52 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:38)
#loc53 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:46)
#loc54 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:15)
#loc55 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:48)
#loc56 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:59)
#loc57 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:22)
#loc58 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":551:18)
#loc59 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":49:21)
#loc60 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":51:20)
#loc61 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":52:20)
#loc62 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":53:35)
#loc63 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:27)
#loc64 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:45)
#loc65 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:37)
#loc66 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":54:51)
#loc67 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":55:31)
#loc68 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":55:39)
#loc70 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":73:15)
#loc71 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":57:45)
#loc72 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":60:46)
#loc73 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":13:20)
#loc74 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":61:19)
#loc75 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":64:46)
#loc76 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":65:25)
#loc77 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":65:64)
#loc78 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":66:25)
#loc79 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":66:64)
#loc80 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":67:25)
#loc81 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":67:64)
#loc82 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":68:25)
#loc83 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":68:60)
#loc84 = loc("inductor_cache/bi/cbidvvppow55ovsd3ldirnuri4ao4mv2bleubtzbebhqnb6l54gp.py":68:4)
#loc85 = loc(callsite(#loc12 at #loc13))
#loc86 = loc(callsite(#loc15 at #loc13))
#loc87 = loc(callsite(#loc16 at #loc13))
#loc88 = loc(callsite(#loc17 at #loc18))
#loc89 = loc(callsite(#loc19 at #loc18))
#loc90 = loc(callsite(#loc20 at #loc18))
#loc91 = loc(callsite(#loc21 at #loc18))
#loc92 = loc(callsite(#loc22 at #loc23))
#loc94 = loc(callsite(#loc24 at #loc22))
#loc95 = loc(callsite(#loc25 at #loc18))
#loc96 = loc(callsite(#loc26 at #loc18))
#loc97 = loc(callsite(#loc27 at #loc18))
#loc98 = loc(callsite(#loc22 at #loc28))
#loc100 = loc(callsite(#loc29 at #loc18))
#loc101 = loc(callsite(#loc30 at #loc18))
#loc102 = loc(callsite(#loc31 at #loc18))
#loc103 = loc(callsite(#loc32 at #loc18))
#loc104 = loc(callsite(#loc33 at #loc18))
#loc105 = loc(callsite(#loc34 at #loc18))
#loc106 = loc(callsite(#loc35 at #loc18))
#loc107 = loc(callsite(#loc36 at #loc18))
#loc108 = loc(callsite(#loc37 at #loc18))
#loc109 = loc(callsite(#loc22 at #loc38))
#loc111 = loc(callsite(#loc39 at #loc18))
#loc112 = loc(callsite(#loc40 at #loc18))
#loc113 = loc(callsite(#loc41 at #loc18))
#loc114 = loc(callsite(#loc42 at #loc18))
#loc115 = loc(callsite(#loc22 at #loc43))
#loc117 = loc(callsite(#loc44 at #loc18))
#loc118 = loc(callsite(#loc45 at #loc18))
#loc119 = loc(callsite(#loc46 at #loc18))
#loc120 = loc(callsite(#loc47 at #loc18))
#loc121 = loc(callsite(#loc48 at #loc18))
#loc122 = loc(callsite(#loc49 at #loc18))
#loc123 = loc(callsite(#loc50 at #loc18))
#loc124 = loc(callsite(#loc51 at #loc18))
#loc125 = loc(callsite(#loc52 at #loc18))
#loc126 = loc(callsite(#loc53 at #loc18))
#loc127 = loc(callsite(#loc54 at #loc18))
#loc128 = loc(callsite(#loc55 at #loc18))
#loc129 = loc(callsite(#loc56 at #loc18))
#loc130 = loc(callsite(#loc57 at #loc18))
#loc131 = loc(callsite(#loc58 at #loc18))
#loc132 = loc(callsite(#loc22 at #loc69))
#loc134 = loc(callsite(#loc70 at #loc71))
#loc135 = loc(callsite(#loc73 at #loc72))
#loc136 = loc(callsite(#loc73 at #loc75))
#loc137 = loc(callsite(#loc85 at #loc14))
#loc138 = loc(callsite(#loc86 at #loc14))
#loc139 = loc(callsite(#loc87 at #loc14))
#loc140 = loc(callsite(#loc88 at #loc13))
#loc141 = loc(callsite(#loc89 at #loc13))
#loc142 = loc(callsite(#loc90 at #loc13))
#loc143 = loc(callsite(#loc91 at #loc13))
#loc144 = loc(callsite(#loc92 at #loc18))
#loc146 = loc(callsite(#loc94 at #loc23))
#loc147 = loc(callsite(#loc95 at #loc13))
#loc148 = loc(callsite(#loc96 at #loc13))
#loc149 = loc(callsite(#loc97 at #loc13))
#loc150 = loc(callsite(#loc98 at #loc18))
#loc152 = loc(callsite(#loc94 at #loc28))
#loc153 = loc(callsite(#loc100 at #loc13))
#loc154 = loc(callsite(#loc101 at #loc13))
#loc155 = loc(callsite(#loc102 at #loc13))
#loc156 = loc(callsite(#loc103 at #loc13))
#loc157 = loc(callsite(#loc104 at #loc13))
#loc158 = loc(callsite(#loc105 at #loc13))
#loc159 = loc(callsite(#loc106 at #loc13))
#loc160 = loc(callsite(#loc107 at #loc13))
#loc161 = loc(callsite(#loc108 at #loc13))
#loc162 = loc(callsite(#loc109 at #loc18))
#loc164 = loc(callsite(#loc94 at #loc38))
#loc165 = loc(callsite(#loc111 at #loc13))
#loc166 = loc(callsite(#loc112 at #loc13))
#loc167 = loc(callsite(#loc113 at #loc13))
#loc168 = loc(callsite(#loc114 at #loc13))
#loc169 = loc(callsite(#loc115 at #loc18))
#loc171 = loc(callsite(#loc94 at #loc43))
#loc172 = loc(callsite(#loc117 at #loc13))
#loc173 = loc(callsite(#loc118 at #loc13))
#loc174 = loc(callsite(#loc119 at #loc13))
#loc175 = loc(callsite(#loc120 at #loc13))
#loc176 = loc(callsite(#loc121 at #loc13))
#loc177 = loc(callsite(#loc122 at #loc13))
#loc178 = loc(callsite(#loc123 at #loc13))
#loc179 = loc(callsite(#loc124 at #loc13))
#loc180 = loc(callsite(#loc125 at #loc13))
#loc181 = loc(callsite(#loc126 at #loc13))
#loc182 = loc(callsite(#loc127 at #loc13))
#loc183 = loc(callsite(#loc128 at #loc13))
#loc184 = loc(callsite(#loc129 at #loc13))
#loc185 = loc(callsite(#loc130 at #loc13))
#loc186 = loc(callsite(#loc131 at #loc13))
#loc187 = loc(callsite(#loc94 at #loc69))
#loc188 = loc(callsite(#loc140 at #loc14))
#loc189 = loc(callsite(#loc141 at #loc14))
#loc190 = loc(callsite(#loc142 at #loc14))
#loc191 = loc(callsite(#loc143 at #loc14))
#loc192 = loc(callsite(#loc144 at #loc13))
#loc194 = loc(callsite(#loc146 at #loc18))
#loc195 = loc(callsite(#loc147 at #loc14))
#loc196 = loc(callsite(#loc148 at #loc14))
#loc197 = loc(callsite(#loc149 at #loc14))
#loc198 = loc(callsite(#loc150 at #loc13))
#loc200 = loc(callsite(#loc152 at #loc18))
#loc201 = loc(callsite(#loc153 at #loc14))
#loc202 = loc(callsite(#loc154 at #loc14))
#loc203 = loc(callsite(#loc155 at #loc14))
#loc204 = loc(callsite(#loc156 at #loc14))
#loc205 = loc(callsite(#loc157 at #loc14))
#loc206 = loc(callsite(#loc158 at #loc14))
#loc207 = loc(callsite(#loc159 at #loc14))
#loc208 = loc(callsite(#loc160 at #loc14))
#loc209 = loc(callsite(#loc161 at #loc14))
#loc210 = loc(callsite(#loc162 at #loc13))
#loc212 = loc(callsite(#loc164 at #loc18))
#loc213 = loc(callsite(#loc165 at #loc14))
#loc214 = loc(callsite(#loc166 at #loc14))
#loc215 = loc(callsite(#loc167 at #loc14))
#loc216 = loc(callsite(#loc168 at #loc14))
#loc217 = loc(callsite(#loc169 at #loc13))
#loc219 = loc(callsite(#loc171 at #loc18))
#loc220 = loc(callsite(#loc172 at #loc14))
#loc221 = loc(callsite(#loc173 at #loc14))
#loc222 = loc(callsite(#loc174 at #loc14))
#loc223 = loc(callsite(#loc175 at #loc14))
#loc224 = loc(callsite(#loc176 at #loc14))
#loc225 = loc(callsite(#loc177 at #loc14))
#loc226 = loc(callsite(#loc178 at #loc14))
#loc227 = loc(callsite(#loc179 at #loc14))
#loc228 = loc(callsite(#loc180 at #loc14))
#loc229 = loc(callsite(#loc181 at #loc14))
#loc230 = loc(callsite(#loc182 at #loc14))
#loc231 = loc(callsite(#loc183 at #loc14))
#loc232 = loc(callsite(#loc184 at #loc14))
#loc233 = loc(callsite(#loc185 at #loc14))
#loc234 = loc(callsite(#loc186 at #loc14))
#loc235 = loc(callsite(#loc192 at #loc14))
#loc237 = loc(callsite(#loc194 at #loc13))
#loc238 = loc(callsite(#loc198 at #loc14))
#loc240 = loc(callsite(#loc200 at #loc13))
#loc241 = loc(callsite(#loc210 at #loc14))
#loc243 = loc(callsite(#loc212 at #loc13))
#loc244 = loc(callsite(#loc217 at #loc14))
#loc246 = loc(callsite(#loc219 at #loc13))
#loc247 = loc(callsite(#loc237 at #loc14))
#loc248 = loc(callsite(#loc240 at #loc14))
#loc249 = loc(callsite(#loc243 at #loc14))
#loc250 = loc(callsite(#loc246 at #loc14))
