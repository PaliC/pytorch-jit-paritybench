#blocked = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 2], order = [1, 0]}>
#blocked1 = #triton_gpu.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 2], order = [0, 1]}>
#blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 1, 32], warpsPerCTA = [1, 2, 1], order = [2, 1, 0]}>
#blocked3 = #triton_gpu.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 2, 16], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked4 = #triton_gpu.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [2, 2, 8], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked5 = #triton_gpu.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [4, 2, 4], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked6 = #triton_gpu.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [8, 2, 2], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked7 = #triton_gpu.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [16, 2, 1], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#loc = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0)
#loc1 = loc(unknown)
#loc18 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":610:12)
#loc19 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":47:71)
#loc23 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":582:73)
#loc28 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:51)
#loc33 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:53)
#loc43 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:50)
#loc48 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:51)
#loc80 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":56:26)
#loc103 = loc(callsite(#loc1 at #loc28))
#loc109 = loc(callsite(#loc1 at #loc33))
#loc120 = loc(callsite(#loc1 at #loc43))
#loc126 = loc(callsite(#loc1 at #loc48))
#loc143 = loc(callsite(#loc1 at #loc80))
#loc154 = loc(callsite(#loc103 at #loc23))
#loc160 = loc(callsite(#loc109 at #loc23))
#loc172 = loc(callsite(#loc120 at #loc23))
#loc179 = loc(callsite(#loc126 at #loc23))
#loc202 = loc(callsite(#loc154 at #loc18))
#loc208 = loc(callsite(#loc160 at #loc18))
#loc220 = loc(callsite(#loc172 at #loc18))
#loc227 = loc(callsite(#loc179 at #loc18))
#loc245 = loc(callsite(#loc202 at #loc19))
#loc248 = loc(callsite(#loc208 at #loc19))
#loc251 = loc(callsite(#loc220 at #loc19))
#loc254 = loc(callsite(#loc227 at #loc19))
module attributes {"triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 2 : i32, triton_gpu.target = "cuda:90", "triton_gpu.threads-per-warp" = 32 : i32} {
  tt.func public @triton_per_fused_cumsum_index_mul_rsub_sort_sub_sum_5(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0), %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0), %arg3: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0), %arg4: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0), %arg5: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0), %arg6: i32 {tt.divisibility = 16 : i32} loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":24:0)) attributes {noinline = false} {
    %cst = arith.constant dense<64> : tensor<1x64xi64, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<1.000000e+00> : tensor<1x64xf32, #blocked> loc(#loc1)
    %cst_1 = arith.constant dense<1.000000e+00> : tensor<1x64xf32, #blocked1> loc(#loc1)
    %cst_2 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked2> loc(#loc1)
    %cst_3 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked3> loc(#loc1)
    %cst_4 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked4> loc(#loc1)
    %cst_5 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked5> loc(#loc1)
    %cst_6 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked6> loc(#loc1)
    %cst_7 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked7> loc(#loc1)
    %cst_8 = arith.constant dense<0> : tensor<1x64xi32, #blocked> loc(#loc1)
    %cst_9 = arith.constant dense<0> : tensor<1x64xi16, #blocked> loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %cst_10 = arith.constant dense<2.000000e+00> : tensor<1x64xf32, #blocked> loc(#loc1)
    %cst_11 = arith.constant dense<48> : tensor<1x64xi32, #blocked> loc(#loc1)
    %cst_12 = arith.constant dense<64> : tensor<1x64xi32, #blocked> loc(#loc1)
    %cst_13 = arith.constant dense<16> : tensor<1x64xi32, #blocked> loc(#loc1)
    %cst_14 = arith.constant dense<0> : tensor<1x64xi64, #blocked> loc(#loc1)
    %cst_15 = arith.constant dense<0> : tensor<1x64xi64, #blocked1> loc(#loc1)
    %cst_16 = arith.constant dense<64> : tensor<1x64xi64, #blocked1> loc(#loc1)
    %cst_17 = arith.constant dense<48> : tensor<1x64xi64, #blocked1> loc(#loc1)
    %cst_18 = arith.constant dense<4> : tensor<1x64xi64, #blocked1> loc(#loc1)
    %cst_19 = arith.constant dense<16> : tensor<1x64xi64, #blocked1> loc(#loc1)
    %0 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>> loc(#loc2)
    %1 = tt.expand_dims %0 {axis = 0 : i32} : tensor<64xi32, #triton_gpu.slice<{dim = 0, parent = #blocked}>> -> tensor<1x64xi32, #blocked> loc(#loc2)
    %2 = arith.divsi %1, %cst_13 : tensor<1x64xi32, #blocked> loc(#loc3)
    %3 = arith.muli %2, %cst_12 : tensor<1x64xi32, #blocked> loc(#loc4)
    %4 = arith.addi %3, %cst_11 : tensor<1x64xi32, #blocked> loc(#loc5)
    %5 = arith.remsi %1, %cst_13 : tensor<1x64xi32, #blocked> loc(#loc6)
    %6 = arith.addi %4, %5 : tensor<1x64xi32, #blocked> loc(#loc7)
    %7 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc8)
    %8 = tt.addptr %7, %6 : tensor<1x64x!tt.ptr<f32>, #blocked>, tensor<1x64xi32, #blocked> loc(#loc8)
    %9 = tt.load %8 : tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc9)
    %10 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>, #blocked1> loc(#loc10)
    %11 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc10)
    %12 = tt.addptr %11, %6 : tensor<1x64x!tt.ptr<f32>, #blocked>, tensor<1x64xi32, #blocked> loc(#loc10)
    %13 = tt.load %12 : tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc11)
    %14 = arith.mulf %13, %cst_10 : tensor<1x64xf32, #blocked> loc(#loc12)
    %15 = arith.subf %14, %cst_0 : tensor<1x64xf32, #blocked> loc(#loc13)
    %16 = arith.mulf %9, %15 : tensor<1x64xf32, #blocked> loc(#loc14)
    %17 = arith.subf %cst_0, %16 : tensor<1x64xf32, #blocked> loc(#loc15)
    %18 = arith.trunci %1 : tensor<1x64xi32, #blocked> to tensor<1x64xi16, #blocked> loc(#loc16)
    %19 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked6}>}>> loc(#loc146)
    %20 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked5}>}>> loc(#loc146)
    %21 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked4}>}>> loc(#loc146)
    %22 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked3}>}>> loc(#loc146)
    %23 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked2}>}>> loc(#loc146)
    %24 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked7}>}>> loc(#loc146)
    %25 = tt.expand_dims %19 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked6}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked6}>> loc(#loc146)
    %26 = tt.expand_dims %20 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked5}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked5}>> loc(#loc146)
    %27 = tt.expand_dims %21 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked4}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked4}>> loc(#loc146)
    %28 = tt.expand_dims %22 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked3}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked3}>> loc(#loc146)
    %29 = tt.expand_dims %23 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked2}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked2}>> loc(#loc146)
    %30 = tt.expand_dims %24 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked7}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked7}>> loc(#loc146)
    %31 = tt.expand_dims %25 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked6}>> -> tensor<1x2x1xi32, #blocked6> loc(#loc146)
    %32 = tt.expand_dims %26 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked5}>> -> tensor<1x2x1xi32, #blocked5> loc(#loc146)
    %33 = tt.expand_dims %27 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked4}>> -> tensor<1x2x1xi32, #blocked4> loc(#loc146)
    %34 = tt.expand_dims %28 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked3}>> -> tensor<1x2x1xi32, #blocked3> loc(#loc146)
    %35 = tt.expand_dims %29 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked2}>> -> tensor<1x2x1xi32, #blocked2> loc(#loc146)
    %36 = tt.expand_dims %30 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked7}>> -> tensor<1x2x1xi32, #blocked7> loc(#loc146)
    %37 = tt.broadcast %31 : tensor<1x2x1xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc147)
    %38 = tt.reshape %37 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc148)
    %39 = tt.reshape %17 : tensor<1x64xf32, #blocked> -> tensor<32x2x1xf32, #blocked7> loc(#loc197)
    %40 = tt.bitcast %39 : tensor<32x2x1xf32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc198)
    %41 = arith.subi %cst_6, %31 : tensor<1x2x1xi32, #blocked6> loc(#loc199)
    %42 = arith.subi %cst_5, %32 : tensor<1x2x1xi32, #blocked5> loc(#loc199)
    %43 = arith.subi %cst_4, %33 : tensor<1x2x1xi32, #blocked4> loc(#loc199)
    %44 = arith.subi %cst_3, %34 : tensor<1x2x1xi32, #blocked3> loc(#loc199)
    %45 = arith.subi %cst_2, %35 : tensor<1x2x1xi32, #blocked2> loc(#loc199)
    %46 = arith.subi %cst_7, %36 : tensor<1x2x1xi32, #blocked7> loc(#loc199)
    %47 = tt.broadcast %46 : tensor<1x2x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc200)
    %48 = arith.muli %40, %47 : tensor<32x2x1xi32, #blocked7> loc(#loc200)
    %49 = "tt.reduce"(%48) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %50 = tt.expand_dims %49 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc204)
    %51 = tt.broadcast %50 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc205)
    %52 = tt.broadcast %36 : tensor<1x2x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc206)
    %53 = arith.muli %40, %52 : tensor<32x2x1xi32, #blocked7> loc(#loc206)
    %54 = "tt.reduce"(%53) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc247)
    %55 = tt.expand_dims %54 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc210)
    %56 = tt.broadcast %55 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc211)
    %57 = tt.reshape %51 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %58 = tt.reshape %56 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %59 = tt.bitcast %57 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %60 = tt.bitcast %58 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %61 = tt.reshape %18 : tensor<1x64xi16, #blocked> -> tensor<32x2x1xi16, #blocked7> loc(#loc216)
    %62 = arith.trunci %41 : tensor<1x2x1xi32, #blocked6> to tensor<1x2x1xi16, #blocked6> loc(#loc217)
    %63 = arith.trunci %42 : tensor<1x2x1xi32, #blocked5> to tensor<1x2x1xi16, #blocked5> loc(#loc217)
    %64 = arith.trunci %43 : tensor<1x2x1xi32, #blocked4> to tensor<1x2x1xi16, #blocked4> loc(#loc217)
    %65 = arith.trunci %44 : tensor<1x2x1xi32, #blocked3> to tensor<1x2x1xi16, #blocked3> loc(#loc217)
    %66 = arith.trunci %45 : tensor<1x2x1xi32, #blocked2> to tensor<1x2x1xi16, #blocked2> loc(#loc217)
    %67 = arith.trunci %46 : tensor<1x2x1xi32, #blocked7> to tensor<1x2x1xi16, #blocked7> loc(#loc217)
    %68 = tt.broadcast %67 : tensor<1x2x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc218)
    %69 = arith.muli %61, %68 : tensor<32x2x1xi16, #blocked7> loc(#loc218)
    %70 = "tt.reduce"(%69) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc250)
    %71 = tt.expand_dims %70 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc222)
    %72 = tt.broadcast %71 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc223)
    %73 = arith.trunci %31 : tensor<1x2x1xi32, #blocked6> to tensor<1x2x1xi16, #blocked6> loc(#loc224)
    %74 = arith.trunci %32 : tensor<1x2x1xi32, #blocked5> to tensor<1x2x1xi16, #blocked5> loc(#loc224)
    %75 = arith.trunci %33 : tensor<1x2x1xi32, #blocked4> to tensor<1x2x1xi16, #blocked4> loc(#loc224)
    %76 = arith.trunci %34 : tensor<1x2x1xi32, #blocked3> to tensor<1x2x1xi16, #blocked3> loc(#loc224)
    %77 = arith.trunci %35 : tensor<1x2x1xi32, #blocked2> to tensor<1x2x1xi16, #blocked2> loc(#loc224)
    %78 = arith.trunci %36 : tensor<1x2x1xi32, #blocked7> to tensor<1x2x1xi16, #blocked7> loc(#loc224)
    %79 = tt.broadcast %78 : tensor<1x2x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc225)
    %80 = arith.muli %61, %79 : tensor<32x2x1xi16, #blocked7> loc(#loc225)
    %81 = "tt.reduce"(%80) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc253)
    %82 = tt.expand_dims %81 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc229)
    %83 = tt.broadcast %82 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc230)
    %84 = tt.reshape %72 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %85 = tt.reshape %83 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %86 = tt.bitcast %17 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %87 = arith.cmpf olt, %59, %60 : tensor<1x64xf32, #blocked> loc(#loc234)
    %88 = arith.extui %87 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %89 = arith.xori %88, %38 : tensor<1x64xi32, #blocked> loc(#loc235)
    %90 = arith.cmpi ne, %89, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %91 = arith.xori %57, %58 : tensor<1x64xi32, #blocked> loc(#loc237)
    %92 = arith.select %90, %91, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %93 = arith.xori %86, %92 : tensor<1x64xi32, #blocked> loc(#loc239)
    %94 = arith.xori %84, %85 : tensor<1x64xi16, #blocked> loc(#loc240)
    %95 = arith.select %90, %94, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %96 = arith.xori %18, %95 : tensor<1x64xi16, #blocked> loc(#loc242)
    %97 = tt.bitcast %93 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %98 = tt.broadcast %32 : tensor<1x2x1xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc147)
    %99 = tt.reshape %98 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc148)
    %100 = tt.reshape %97 : tensor<1x64xf32, #blocked> -> tensor<16x2x2xf32, #blocked6> loc(#loc197)
    %101 = tt.bitcast %100 : tensor<16x2x2xf32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc198)
    %102 = tt.broadcast %41 : tensor<1x2x1xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc200)
    %103 = arith.muli %101, %102 : tensor<16x2x2xi32, #blocked6> loc(#loc200)
    %104 = "tt.reduce"(%103) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %105 = tt.expand_dims %104 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc204)
    %106 = tt.broadcast %105 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc205)
    %107 = arith.muli %101, %37 : tensor<16x2x2xi32, #blocked6> loc(#loc206)
    %108 = "tt.reduce"(%107) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc247)
    %109 = tt.expand_dims %108 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc210)
    %110 = tt.broadcast %109 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc211)
    %111 = tt.reshape %106 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %112 = tt.reshape %110 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %113 = tt.bitcast %111 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %114 = tt.bitcast %112 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %115 = tt.reshape %96 : tensor<1x64xi16, #blocked> -> tensor<16x2x2xi16, #blocked6> loc(#loc216)
    %116 = tt.broadcast %62 : tensor<1x2x1xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc218)
    %117 = arith.muli %115, %116 : tensor<16x2x2xi16, #blocked6> loc(#loc218)
    %118 = "tt.reduce"(%117) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc250)
    %119 = tt.expand_dims %118 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc222)
    %120 = tt.broadcast %119 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc223)
    %121 = tt.broadcast %73 : tensor<1x2x1xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc225)
    %122 = arith.muli %115, %121 : tensor<16x2x2xi16, #blocked6> loc(#loc225)
    %123 = "tt.reduce"(%122) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc253)
    %124 = tt.expand_dims %123 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc229)
    %125 = tt.broadcast %124 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc230)
    %126 = tt.reshape %120 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %127 = tt.reshape %125 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %128 = tt.bitcast %97 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %129 = arith.cmpf olt, %113, %114 : tensor<1x64xf32, #blocked> loc(#loc234)
    %130 = arith.extui %129 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %131 = arith.xori %130, %99 : tensor<1x64xi32, #blocked> loc(#loc235)
    %132 = arith.cmpi ne, %131, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %133 = arith.xori %111, %112 : tensor<1x64xi32, #blocked> loc(#loc237)
    %134 = arith.select %132, %133, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %135 = arith.xori %128, %134 : tensor<1x64xi32, #blocked> loc(#loc239)
    %136 = arith.xori %126, %127 : tensor<1x64xi16, #blocked> loc(#loc240)
    %137 = arith.select %132, %136, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %138 = arith.xori %96, %137 : tensor<1x64xi16, #blocked> loc(#loc242)
    %139 = tt.bitcast %135 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %140 = tt.reshape %139 : tensor<1x64xf32, #blocked> -> tensor<32x2x1xf32, #blocked7> loc(#loc197)
    %141 = tt.bitcast %140 : tensor<32x2x1xf32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc198)
    %142 = arith.muli %141, %47 : tensor<32x2x1xi32, #blocked7> loc(#loc200)
    %143 = "tt.reduce"(%142) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %144 = tt.expand_dims %143 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc204)
    %145 = tt.broadcast %144 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc205)
    %146 = arith.muli %141, %52 : tensor<32x2x1xi32, #blocked7> loc(#loc206)
    %147 = "tt.reduce"(%146) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc247)
    %148 = tt.expand_dims %147 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc210)
    %149 = tt.broadcast %148 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc211)
    %150 = tt.reshape %145 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %151 = tt.reshape %149 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %152 = tt.bitcast %150 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %153 = tt.bitcast %151 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %154 = tt.reshape %138 : tensor<1x64xi16, #blocked> -> tensor<32x2x1xi16, #blocked7> loc(#loc216)
    %155 = arith.muli %154, %68 : tensor<32x2x1xi16, #blocked7> loc(#loc218)
    %156 = "tt.reduce"(%155) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc250)
    %157 = tt.expand_dims %156 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc222)
    %158 = tt.broadcast %157 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc223)
    %159 = arith.muli %154, %79 : tensor<32x2x1xi16, #blocked7> loc(#loc225)
    %160 = "tt.reduce"(%159) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc253)
    %161 = tt.expand_dims %160 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc229)
    %162 = tt.broadcast %161 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc230)
    %163 = tt.reshape %158 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %164 = tt.reshape %162 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %165 = tt.bitcast %139 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %166 = arith.cmpf olt, %152, %153 : tensor<1x64xf32, #blocked> loc(#loc234)
    %167 = arith.extui %166 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %168 = arith.xori %167, %99 : tensor<1x64xi32, #blocked> loc(#loc235)
    %169 = arith.cmpi ne, %168, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %170 = arith.xori %150, %151 : tensor<1x64xi32, #blocked> loc(#loc237)
    %171 = arith.select %169, %170, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %172 = arith.xori %165, %171 : tensor<1x64xi32, #blocked> loc(#loc239)
    %173 = arith.xori %163, %164 : tensor<1x64xi16, #blocked> loc(#loc240)
    %174 = arith.select %169, %173, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %175 = arith.xori %138, %174 : tensor<1x64xi16, #blocked> loc(#loc242)
    %176 = tt.bitcast %172 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %177 = tt.broadcast %33 : tensor<1x2x1xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc147)
    %178 = tt.reshape %177 : tensor<4x2x8xi32, #blocked4> -> tensor<1x64xi32, #blocked> loc(#loc148)
    %179 = tt.reshape %176 : tensor<1x64xf32, #blocked> -> tensor<8x2x4xf32, #blocked5> loc(#loc197)
    %180 = tt.bitcast %179 : tensor<8x2x4xf32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc198)
    %181 = tt.broadcast %42 : tensor<1x2x1xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc200)
    %182 = arith.muli %180, %181 : tensor<8x2x4xi32, #blocked5> loc(#loc200)
    %183 = "tt.reduce"(%182) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %184 = tt.expand_dims %183 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc204)
    %185 = tt.broadcast %184 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc205)
    %186 = arith.muli %180, %98 : tensor<8x2x4xi32, #blocked5> loc(#loc206)
    %187 = "tt.reduce"(%186) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc247)
    %188 = tt.expand_dims %187 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc210)
    %189 = tt.broadcast %188 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc211)
    %190 = tt.reshape %185 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %191 = tt.reshape %189 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %192 = tt.bitcast %190 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %193 = tt.bitcast %191 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %194 = tt.reshape %175 : tensor<1x64xi16, #blocked> -> tensor<8x2x4xi16, #blocked5> loc(#loc216)
    %195 = tt.broadcast %63 : tensor<1x2x1xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc218)
    %196 = arith.muli %194, %195 : tensor<8x2x4xi16, #blocked5> loc(#loc218)
    %197 = "tt.reduce"(%196) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc250)
    %198 = tt.expand_dims %197 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc222)
    %199 = tt.broadcast %198 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc223)
    %200 = tt.broadcast %74 : tensor<1x2x1xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc225)
    %201 = arith.muli %194, %200 : tensor<8x2x4xi16, #blocked5> loc(#loc225)
    %202 = "tt.reduce"(%201) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc253)
    %203 = tt.expand_dims %202 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc229)
    %204 = tt.broadcast %203 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc230)
    %205 = tt.reshape %199 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %206 = tt.reshape %204 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %207 = tt.bitcast %176 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %208 = arith.cmpf olt, %192, %193 : tensor<1x64xf32, #blocked> loc(#loc234)
    %209 = arith.extui %208 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %210 = arith.xori %209, %178 : tensor<1x64xi32, #blocked> loc(#loc235)
    %211 = arith.cmpi ne, %210, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %212 = arith.xori %190, %191 : tensor<1x64xi32, #blocked> loc(#loc237)
    %213 = arith.select %211, %212, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %214 = arith.xori %207, %213 : tensor<1x64xi32, #blocked> loc(#loc239)
    %215 = arith.xori %205, %206 : tensor<1x64xi16, #blocked> loc(#loc240)
    %216 = arith.select %211, %215, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %217 = arith.xori %175, %216 : tensor<1x64xi16, #blocked> loc(#loc242)
    %218 = tt.bitcast %214 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %219 = tt.reshape %218 : tensor<1x64xf32, #blocked> -> tensor<16x2x2xf32, #blocked6> loc(#loc197)
    %220 = tt.bitcast %219 : tensor<16x2x2xf32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc198)
    %221 = arith.muli %220, %102 : tensor<16x2x2xi32, #blocked6> loc(#loc200)
    %222 = "tt.reduce"(%221) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %223 = tt.expand_dims %222 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc204)
    %224 = tt.broadcast %223 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc205)
    %225 = arith.muli %220, %37 : tensor<16x2x2xi32, #blocked6> loc(#loc206)
    %226 = "tt.reduce"(%225) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc247)
    %227 = tt.expand_dims %226 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc210)
    %228 = tt.broadcast %227 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc211)
    %229 = tt.reshape %224 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %230 = tt.reshape %228 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %231 = tt.bitcast %229 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %232 = tt.bitcast %230 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %233 = tt.reshape %217 : tensor<1x64xi16, #blocked> -> tensor<16x2x2xi16, #blocked6> loc(#loc216)
    %234 = arith.muli %233, %116 : tensor<16x2x2xi16, #blocked6> loc(#loc218)
    %235 = "tt.reduce"(%234) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc250)
    %236 = tt.expand_dims %235 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc222)
    %237 = tt.broadcast %236 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc223)
    %238 = arith.muli %233, %121 : tensor<16x2x2xi16, #blocked6> loc(#loc225)
    %239 = "tt.reduce"(%238) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc253)
    %240 = tt.expand_dims %239 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc229)
    %241 = tt.broadcast %240 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc230)
    %242 = tt.reshape %237 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %243 = tt.reshape %241 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %244 = tt.bitcast %218 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %245 = arith.cmpf olt, %231, %232 : tensor<1x64xf32, #blocked> loc(#loc234)
    %246 = arith.extui %245 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %247 = arith.xori %246, %178 : tensor<1x64xi32, #blocked> loc(#loc235)
    %248 = arith.cmpi ne, %247, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %249 = arith.xori %229, %230 : tensor<1x64xi32, #blocked> loc(#loc237)
    %250 = arith.select %248, %249, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %251 = arith.xori %244, %250 : tensor<1x64xi32, #blocked> loc(#loc239)
    %252 = arith.xori %242, %243 : tensor<1x64xi16, #blocked> loc(#loc240)
    %253 = arith.select %248, %252, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %254 = arith.xori %217, %253 : tensor<1x64xi16, #blocked> loc(#loc242)
    %255 = tt.bitcast %251 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %256 = tt.reshape %255 : tensor<1x64xf32, #blocked> -> tensor<32x2x1xf32, #blocked7> loc(#loc197)
    %257 = tt.bitcast %256 : tensor<32x2x1xf32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc198)
    %258 = arith.muli %257, %47 : tensor<32x2x1xi32, #blocked7> loc(#loc200)
    %259 = "tt.reduce"(%258) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %260 = tt.expand_dims %259 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc204)
    %261 = tt.broadcast %260 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc205)
    %262 = arith.muli %257, %52 : tensor<32x2x1xi32, #blocked7> loc(#loc206)
    %263 = "tt.reduce"(%262) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc247)
    %264 = tt.expand_dims %263 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc210)
    %265 = tt.broadcast %264 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc211)
    %266 = tt.reshape %261 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %267 = tt.reshape %265 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %268 = tt.bitcast %266 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %269 = tt.bitcast %267 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %270 = tt.reshape %254 : tensor<1x64xi16, #blocked> -> tensor<32x2x1xi16, #blocked7> loc(#loc216)
    %271 = arith.muli %270, %68 : tensor<32x2x1xi16, #blocked7> loc(#loc218)
    %272 = "tt.reduce"(%271) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc250)
    %273 = tt.expand_dims %272 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc222)
    %274 = tt.broadcast %273 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc223)
    %275 = arith.muli %270, %79 : tensor<32x2x1xi16, #blocked7> loc(#loc225)
    %276 = "tt.reduce"(%275) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc253)
    %277 = tt.expand_dims %276 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc229)
    %278 = tt.broadcast %277 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc230)
    %279 = tt.reshape %274 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %280 = tt.reshape %278 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %281 = tt.bitcast %255 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %282 = arith.cmpf olt, %268, %269 : tensor<1x64xf32, #blocked> loc(#loc234)
    %283 = arith.extui %282 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %284 = arith.xori %283, %178 : tensor<1x64xi32, #blocked> loc(#loc235)
    %285 = arith.cmpi ne, %284, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %286 = arith.xori %266, %267 : tensor<1x64xi32, #blocked> loc(#loc237)
    %287 = arith.select %285, %286, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %288 = arith.xori %281, %287 : tensor<1x64xi32, #blocked> loc(#loc239)
    %289 = arith.xori %279, %280 : tensor<1x64xi16, #blocked> loc(#loc240)
    %290 = arith.select %285, %289, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %291 = arith.xori %254, %290 : tensor<1x64xi16, #blocked> loc(#loc242)
    %292 = tt.bitcast %288 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %293 = tt.broadcast %34 : tensor<1x2x1xi32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc147)
    %294 = tt.reshape %293 : tensor<2x2x16xi32, #blocked3> -> tensor<1x64xi32, #blocked> loc(#loc148)
    %295 = tt.reshape %292 : tensor<1x64xf32, #blocked> -> tensor<4x2x8xf32, #blocked4> loc(#loc197)
    %296 = tt.bitcast %295 : tensor<4x2x8xf32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc198)
    %297 = tt.broadcast %43 : tensor<1x2x1xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc200)
    %298 = arith.muli %296, %297 : tensor<4x2x8xi32, #blocked4> loc(#loc200)
    %299 = "tt.reduce"(%298) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<4x2x8xi32, #blocked4>) -> tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %300 = tt.expand_dims %299 {axis = 1 : i32} : tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi32, #blocked4> loc(#loc204)
    %301 = tt.broadcast %300 : tensor<4x1x8xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc205)
    %302 = arith.muli %296, %177 : tensor<4x2x8xi32, #blocked4> loc(#loc206)
    %303 = "tt.reduce"(%302) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<4x2x8xi32, #blocked4>) -> tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc247)
    %304 = tt.expand_dims %303 {axis = 1 : i32} : tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi32, #blocked4> loc(#loc210)
    %305 = tt.broadcast %304 : tensor<4x1x8xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc211)
    %306 = tt.reshape %301 : tensor<4x2x8xi32, #blocked4> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %307 = tt.reshape %305 : tensor<4x2x8xi32, #blocked4> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %308 = tt.bitcast %306 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %309 = tt.bitcast %307 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %310 = tt.reshape %291 : tensor<1x64xi16, #blocked> -> tensor<4x2x8xi16, #blocked4> loc(#loc216)
    %311 = tt.broadcast %64 : tensor<1x2x1xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc218)
    %312 = arith.muli %310, %311 : tensor<4x2x8xi16, #blocked4> loc(#loc218)
    %313 = "tt.reduce"(%312) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<4x2x8xi16, #blocked4>) -> tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc250)
    %314 = tt.expand_dims %313 {axis = 1 : i32} : tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi16, #blocked4> loc(#loc222)
    %315 = tt.broadcast %314 : tensor<4x1x8xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc223)
    %316 = tt.broadcast %75 : tensor<1x2x1xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc225)
    %317 = arith.muli %310, %316 : tensor<4x2x8xi16, #blocked4> loc(#loc225)
    %318 = "tt.reduce"(%317) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<4x2x8xi16, #blocked4>) -> tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc253)
    %319 = tt.expand_dims %318 {axis = 1 : i32} : tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi16, #blocked4> loc(#loc229)
    %320 = tt.broadcast %319 : tensor<4x1x8xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc230)
    %321 = tt.reshape %315 : tensor<4x2x8xi16, #blocked4> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %322 = tt.reshape %320 : tensor<4x2x8xi16, #blocked4> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %323 = tt.bitcast %292 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %324 = arith.cmpf olt, %308, %309 : tensor<1x64xf32, #blocked> loc(#loc234)
    %325 = arith.extui %324 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %326 = arith.xori %325, %294 : tensor<1x64xi32, #blocked> loc(#loc235)
    %327 = arith.cmpi ne, %326, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %328 = arith.xori %306, %307 : tensor<1x64xi32, #blocked> loc(#loc237)
    %329 = arith.select %327, %328, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %330 = arith.xori %323, %329 : tensor<1x64xi32, #blocked> loc(#loc239)
    %331 = arith.xori %321, %322 : tensor<1x64xi16, #blocked> loc(#loc240)
    %332 = arith.select %327, %331, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %333 = arith.xori %291, %332 : tensor<1x64xi16, #blocked> loc(#loc242)
    %334 = tt.bitcast %330 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %335 = tt.reshape %334 : tensor<1x64xf32, #blocked> -> tensor<8x2x4xf32, #blocked5> loc(#loc197)
    %336 = tt.bitcast %335 : tensor<8x2x4xf32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc198)
    %337 = arith.muli %336, %181 : tensor<8x2x4xi32, #blocked5> loc(#loc200)
    %338 = "tt.reduce"(%337) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %339 = tt.expand_dims %338 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc204)
    %340 = tt.broadcast %339 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc205)
    %341 = arith.muli %336, %98 : tensor<8x2x4xi32, #blocked5> loc(#loc206)
    %342 = "tt.reduce"(%341) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc247)
    %343 = tt.expand_dims %342 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc210)
    %344 = tt.broadcast %343 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc211)
    %345 = tt.reshape %340 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %346 = tt.reshape %344 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %347 = tt.bitcast %345 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %348 = tt.bitcast %346 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %349 = tt.reshape %333 : tensor<1x64xi16, #blocked> -> tensor<8x2x4xi16, #blocked5> loc(#loc216)
    %350 = arith.muli %349, %195 : tensor<8x2x4xi16, #blocked5> loc(#loc218)
    %351 = "tt.reduce"(%350) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc250)
    %352 = tt.expand_dims %351 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc222)
    %353 = tt.broadcast %352 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc223)
    %354 = arith.muli %349, %200 : tensor<8x2x4xi16, #blocked5> loc(#loc225)
    %355 = "tt.reduce"(%354) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc253)
    %356 = tt.expand_dims %355 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc229)
    %357 = tt.broadcast %356 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc230)
    %358 = tt.reshape %353 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %359 = tt.reshape %357 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %360 = tt.bitcast %334 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %361 = arith.cmpf olt, %347, %348 : tensor<1x64xf32, #blocked> loc(#loc234)
    %362 = arith.extui %361 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %363 = arith.xori %362, %294 : tensor<1x64xi32, #blocked> loc(#loc235)
    %364 = arith.cmpi ne, %363, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %365 = arith.xori %345, %346 : tensor<1x64xi32, #blocked> loc(#loc237)
    %366 = arith.select %364, %365, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %367 = arith.xori %360, %366 : tensor<1x64xi32, #blocked> loc(#loc239)
    %368 = arith.xori %358, %359 : tensor<1x64xi16, #blocked> loc(#loc240)
    %369 = arith.select %364, %368, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %370 = arith.xori %333, %369 : tensor<1x64xi16, #blocked> loc(#loc242)
    %371 = tt.bitcast %367 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %372 = tt.reshape %371 : tensor<1x64xf32, #blocked> -> tensor<16x2x2xf32, #blocked6> loc(#loc197)
    %373 = tt.bitcast %372 : tensor<16x2x2xf32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc198)
    %374 = arith.muli %373, %102 : tensor<16x2x2xi32, #blocked6> loc(#loc200)
    %375 = "tt.reduce"(%374) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %376 = tt.expand_dims %375 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc204)
    %377 = tt.broadcast %376 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc205)
    %378 = arith.muli %373, %37 : tensor<16x2x2xi32, #blocked6> loc(#loc206)
    %379 = "tt.reduce"(%378) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc247)
    %380 = tt.expand_dims %379 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc210)
    %381 = tt.broadcast %380 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc211)
    %382 = tt.reshape %377 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %383 = tt.reshape %381 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %384 = tt.bitcast %382 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %385 = tt.bitcast %383 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %386 = tt.reshape %370 : tensor<1x64xi16, #blocked> -> tensor<16x2x2xi16, #blocked6> loc(#loc216)
    %387 = arith.muli %386, %116 : tensor<16x2x2xi16, #blocked6> loc(#loc218)
    %388 = "tt.reduce"(%387) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc250)
    %389 = tt.expand_dims %388 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc222)
    %390 = tt.broadcast %389 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc223)
    %391 = arith.muli %386, %121 : tensor<16x2x2xi16, #blocked6> loc(#loc225)
    %392 = "tt.reduce"(%391) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc253)
    %393 = tt.expand_dims %392 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc229)
    %394 = tt.broadcast %393 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc230)
    %395 = tt.reshape %390 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %396 = tt.reshape %394 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %397 = tt.bitcast %371 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %398 = arith.cmpf olt, %384, %385 : tensor<1x64xf32, #blocked> loc(#loc234)
    %399 = arith.extui %398 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %400 = arith.xori %399, %294 : tensor<1x64xi32, #blocked> loc(#loc235)
    %401 = arith.cmpi ne, %400, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %402 = arith.xori %382, %383 : tensor<1x64xi32, #blocked> loc(#loc237)
    %403 = arith.select %401, %402, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %404 = arith.xori %397, %403 : tensor<1x64xi32, #blocked> loc(#loc239)
    %405 = arith.xori %395, %396 : tensor<1x64xi16, #blocked> loc(#loc240)
    %406 = arith.select %401, %405, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %407 = arith.xori %370, %406 : tensor<1x64xi16, #blocked> loc(#loc242)
    %408 = tt.bitcast %404 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %409 = tt.reshape %408 : tensor<1x64xf32, #blocked> -> tensor<32x2x1xf32, #blocked7> loc(#loc197)
    %410 = tt.bitcast %409 : tensor<32x2x1xf32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc198)
    %411 = arith.muli %410, %47 : tensor<32x2x1xi32, #blocked7> loc(#loc200)
    %412 = "tt.reduce"(%411) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %413 = tt.expand_dims %412 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc204)
    %414 = tt.broadcast %413 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc205)
    %415 = arith.muli %410, %52 : tensor<32x2x1xi32, #blocked7> loc(#loc206)
    %416 = "tt.reduce"(%415) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc247)
    %417 = tt.expand_dims %416 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc210)
    %418 = tt.broadcast %417 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc211)
    %419 = tt.reshape %414 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %420 = tt.reshape %418 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %421 = tt.bitcast %419 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %422 = tt.bitcast %420 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %423 = tt.reshape %407 : tensor<1x64xi16, #blocked> -> tensor<32x2x1xi16, #blocked7> loc(#loc216)
    %424 = arith.muli %423, %68 : tensor<32x2x1xi16, #blocked7> loc(#loc218)
    %425 = "tt.reduce"(%424) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc250)
    %426 = tt.expand_dims %425 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc222)
    %427 = tt.broadcast %426 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc223)
    %428 = arith.muli %423, %79 : tensor<32x2x1xi16, #blocked7> loc(#loc225)
    %429 = "tt.reduce"(%428) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc253)
    %430 = tt.expand_dims %429 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc229)
    %431 = tt.broadcast %430 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc230)
    %432 = tt.reshape %427 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %433 = tt.reshape %431 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %434 = tt.bitcast %408 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %435 = arith.cmpf olt, %421, %422 : tensor<1x64xf32, #blocked> loc(#loc234)
    %436 = arith.extui %435 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %437 = arith.xori %436, %294 : tensor<1x64xi32, #blocked> loc(#loc235)
    %438 = arith.cmpi ne, %437, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %439 = arith.xori %419, %420 : tensor<1x64xi32, #blocked> loc(#loc237)
    %440 = arith.select %438, %439, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %441 = arith.xori %434, %440 : tensor<1x64xi32, #blocked> loc(#loc239)
    %442 = arith.xori %432, %433 : tensor<1x64xi16, #blocked> loc(#loc240)
    %443 = arith.select %438, %442, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %444 = arith.xori %407, %443 : tensor<1x64xi16, #blocked> loc(#loc242)
    %445 = tt.bitcast %441 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %446 = tt.broadcast %35 : tensor<1x2x1xi32, #blocked2> -> tensor<1x2x32xi32, #blocked2> loc(#loc147)
    %447 = tt.reshape %446 : tensor<1x2x32xi32, #blocked2> -> tensor<1x64xi32, #blocked> loc(#loc148)
    %448 = tt.reshape %445 : tensor<1x64xf32, #blocked> -> tensor<2x2x16xf32, #blocked3> loc(#loc197)
    %449 = tt.bitcast %448 : tensor<2x2x16xf32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc198)
    %450 = tt.broadcast %44 : tensor<1x2x1xi32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc200)
    %451 = arith.muli %449, %450 : tensor<2x2x16xi32, #blocked3> loc(#loc200)
    %452 = "tt.reduce"(%451) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<2x2x16xi32, #blocked3>) -> tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %453 = tt.expand_dims %452 {axis = 1 : i32} : tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi32, #blocked3> loc(#loc204)
    %454 = tt.broadcast %453 : tensor<2x1x16xi32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc205)
    %455 = arith.muli %449, %293 : tensor<2x2x16xi32, #blocked3> loc(#loc206)
    %456 = "tt.reduce"(%455) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<2x2x16xi32, #blocked3>) -> tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc247)
    %457 = tt.expand_dims %456 {axis = 1 : i32} : tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi32, #blocked3> loc(#loc210)
    %458 = tt.broadcast %457 : tensor<2x1x16xi32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc211)
    %459 = tt.reshape %454 : tensor<2x2x16xi32, #blocked3> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %460 = tt.reshape %458 : tensor<2x2x16xi32, #blocked3> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %461 = tt.bitcast %459 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %462 = tt.bitcast %460 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %463 = tt.reshape %444 : tensor<1x64xi16, #blocked> -> tensor<2x2x16xi16, #blocked3> loc(#loc216)
    %464 = tt.broadcast %65 : tensor<1x2x1xi16, #blocked3> -> tensor<2x2x16xi16, #blocked3> loc(#loc218)
    %465 = arith.muli %463, %464 : tensor<2x2x16xi16, #blocked3> loc(#loc218)
    %466 = "tt.reduce"(%465) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<2x2x16xi16, #blocked3>) -> tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc250)
    %467 = tt.expand_dims %466 {axis = 1 : i32} : tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi16, #blocked3> loc(#loc222)
    %468 = tt.broadcast %467 : tensor<2x1x16xi16, #blocked3> -> tensor<2x2x16xi16, #blocked3> loc(#loc223)
    %469 = tt.broadcast %76 : tensor<1x2x1xi16, #blocked3> -> tensor<2x2x16xi16, #blocked3> loc(#loc225)
    %470 = arith.muli %463, %469 : tensor<2x2x16xi16, #blocked3> loc(#loc225)
    %471 = "tt.reduce"(%470) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<2x2x16xi16, #blocked3>) -> tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc253)
    %472 = tt.expand_dims %471 {axis = 1 : i32} : tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi16, #blocked3> loc(#loc229)
    %473 = tt.broadcast %472 : tensor<2x1x16xi16, #blocked3> -> tensor<2x2x16xi16, #blocked3> loc(#loc230)
    %474 = tt.reshape %468 : tensor<2x2x16xi16, #blocked3> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %475 = tt.reshape %473 : tensor<2x2x16xi16, #blocked3> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %476 = tt.bitcast %445 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %477 = arith.cmpf olt, %461, %462 : tensor<1x64xf32, #blocked> loc(#loc234)
    %478 = arith.extui %477 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %479 = arith.xori %478, %447 : tensor<1x64xi32, #blocked> loc(#loc235)
    %480 = arith.cmpi ne, %479, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %481 = arith.xori %459, %460 : tensor<1x64xi32, #blocked> loc(#loc237)
    %482 = arith.select %480, %481, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %483 = arith.xori %476, %482 : tensor<1x64xi32, #blocked> loc(#loc239)
    %484 = arith.xori %474, %475 : tensor<1x64xi16, #blocked> loc(#loc240)
    %485 = arith.select %480, %484, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %486 = arith.xori %444, %485 : tensor<1x64xi16, #blocked> loc(#loc242)
    %487 = tt.bitcast %483 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %488 = tt.reshape %487 : tensor<1x64xf32, #blocked> -> tensor<4x2x8xf32, #blocked4> loc(#loc197)
    %489 = tt.bitcast %488 : tensor<4x2x8xf32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc198)
    %490 = arith.muli %489, %297 : tensor<4x2x8xi32, #blocked4> loc(#loc200)
    %491 = "tt.reduce"(%490) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<4x2x8xi32, #blocked4>) -> tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %492 = tt.expand_dims %491 {axis = 1 : i32} : tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi32, #blocked4> loc(#loc204)
    %493 = tt.broadcast %492 : tensor<4x1x8xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc205)
    %494 = arith.muli %489, %177 : tensor<4x2x8xi32, #blocked4> loc(#loc206)
    %495 = "tt.reduce"(%494) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<4x2x8xi32, #blocked4>) -> tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc247)
    %496 = tt.expand_dims %495 {axis = 1 : i32} : tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi32, #blocked4> loc(#loc210)
    %497 = tt.broadcast %496 : tensor<4x1x8xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc211)
    %498 = tt.reshape %493 : tensor<4x2x8xi32, #blocked4> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %499 = tt.reshape %497 : tensor<4x2x8xi32, #blocked4> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %500 = tt.bitcast %498 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %501 = tt.bitcast %499 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %502 = tt.reshape %486 : tensor<1x64xi16, #blocked> -> tensor<4x2x8xi16, #blocked4> loc(#loc216)
    %503 = arith.muli %502, %311 : tensor<4x2x8xi16, #blocked4> loc(#loc218)
    %504 = "tt.reduce"(%503) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<4x2x8xi16, #blocked4>) -> tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc250)
    %505 = tt.expand_dims %504 {axis = 1 : i32} : tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi16, #blocked4> loc(#loc222)
    %506 = tt.broadcast %505 : tensor<4x1x8xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc223)
    %507 = arith.muli %502, %316 : tensor<4x2x8xi16, #blocked4> loc(#loc225)
    %508 = "tt.reduce"(%507) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<4x2x8xi16, #blocked4>) -> tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc253)
    %509 = tt.expand_dims %508 {axis = 1 : i32} : tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi16, #blocked4> loc(#loc229)
    %510 = tt.broadcast %509 : tensor<4x1x8xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc230)
    %511 = tt.reshape %506 : tensor<4x2x8xi16, #blocked4> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %512 = tt.reshape %510 : tensor<4x2x8xi16, #blocked4> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %513 = tt.bitcast %487 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %514 = arith.cmpf olt, %500, %501 : tensor<1x64xf32, #blocked> loc(#loc234)
    %515 = arith.extui %514 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %516 = arith.xori %515, %447 : tensor<1x64xi32, #blocked> loc(#loc235)
    %517 = arith.cmpi ne, %516, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %518 = arith.xori %498, %499 : tensor<1x64xi32, #blocked> loc(#loc237)
    %519 = arith.select %517, %518, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %520 = arith.xori %513, %519 : tensor<1x64xi32, #blocked> loc(#loc239)
    %521 = arith.xori %511, %512 : tensor<1x64xi16, #blocked> loc(#loc240)
    %522 = arith.select %517, %521, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %523 = arith.xori %486, %522 : tensor<1x64xi16, #blocked> loc(#loc242)
    %524 = tt.bitcast %520 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %525 = tt.reshape %524 : tensor<1x64xf32, #blocked> -> tensor<8x2x4xf32, #blocked5> loc(#loc197)
    %526 = tt.bitcast %525 : tensor<8x2x4xf32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc198)
    %527 = arith.muli %526, %181 : tensor<8x2x4xi32, #blocked5> loc(#loc200)
    %528 = "tt.reduce"(%527) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %529 = tt.expand_dims %528 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc204)
    %530 = tt.broadcast %529 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc205)
    %531 = arith.muli %526, %98 : tensor<8x2x4xi32, #blocked5> loc(#loc206)
    %532 = "tt.reduce"(%531) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc247)
    %533 = tt.expand_dims %532 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc210)
    %534 = tt.broadcast %533 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc211)
    %535 = tt.reshape %530 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %536 = tt.reshape %534 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %537 = tt.bitcast %535 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %538 = tt.bitcast %536 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %539 = tt.reshape %523 : tensor<1x64xi16, #blocked> -> tensor<8x2x4xi16, #blocked5> loc(#loc216)
    %540 = arith.muli %539, %195 : tensor<8x2x4xi16, #blocked5> loc(#loc218)
    %541 = "tt.reduce"(%540) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc250)
    %542 = tt.expand_dims %541 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc222)
    %543 = tt.broadcast %542 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc223)
    %544 = arith.muli %539, %200 : tensor<8x2x4xi16, #blocked5> loc(#loc225)
    %545 = "tt.reduce"(%544) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc253)
    %546 = tt.expand_dims %545 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc229)
    %547 = tt.broadcast %546 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc230)
    %548 = tt.reshape %543 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %549 = tt.reshape %547 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %550 = tt.bitcast %524 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %551 = arith.cmpf olt, %537, %538 : tensor<1x64xf32, #blocked> loc(#loc234)
    %552 = arith.extui %551 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %553 = arith.xori %552, %447 : tensor<1x64xi32, #blocked> loc(#loc235)
    %554 = arith.cmpi ne, %553, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %555 = arith.xori %535, %536 : tensor<1x64xi32, #blocked> loc(#loc237)
    %556 = arith.select %554, %555, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %557 = arith.xori %550, %556 : tensor<1x64xi32, #blocked> loc(#loc239)
    %558 = arith.xori %548, %549 : tensor<1x64xi16, #blocked> loc(#loc240)
    %559 = arith.select %554, %558, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %560 = arith.xori %523, %559 : tensor<1x64xi16, #blocked> loc(#loc242)
    %561 = tt.bitcast %557 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %562 = tt.reshape %561 : tensor<1x64xf32, #blocked> -> tensor<16x2x2xf32, #blocked6> loc(#loc197)
    %563 = tt.bitcast %562 : tensor<16x2x2xf32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc198)
    %564 = arith.muli %563, %102 : tensor<16x2x2xi32, #blocked6> loc(#loc200)
    %565 = "tt.reduce"(%564) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %566 = tt.expand_dims %565 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc204)
    %567 = tt.broadcast %566 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc205)
    %568 = arith.muli %563, %37 : tensor<16x2x2xi32, #blocked6> loc(#loc206)
    %569 = "tt.reduce"(%568) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc247)
    %570 = tt.expand_dims %569 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc210)
    %571 = tt.broadcast %570 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc211)
    %572 = tt.reshape %567 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %573 = tt.reshape %571 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %574 = tt.bitcast %572 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %575 = tt.bitcast %573 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %576 = tt.reshape %560 : tensor<1x64xi16, #blocked> -> tensor<16x2x2xi16, #blocked6> loc(#loc216)
    %577 = arith.muli %576, %116 : tensor<16x2x2xi16, #blocked6> loc(#loc218)
    %578 = "tt.reduce"(%577) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc250)
    %579 = tt.expand_dims %578 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc222)
    %580 = tt.broadcast %579 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc223)
    %581 = arith.muli %576, %121 : tensor<16x2x2xi16, #blocked6> loc(#loc225)
    %582 = "tt.reduce"(%581) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc253)
    %583 = tt.expand_dims %582 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc229)
    %584 = tt.broadcast %583 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc230)
    %585 = tt.reshape %580 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %586 = tt.reshape %584 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %587 = tt.bitcast %561 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %588 = arith.cmpf olt, %574, %575 : tensor<1x64xf32, #blocked> loc(#loc234)
    %589 = arith.extui %588 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %590 = arith.xori %589, %447 : tensor<1x64xi32, #blocked> loc(#loc235)
    %591 = arith.cmpi ne, %590, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %592 = arith.xori %572, %573 : tensor<1x64xi32, #blocked> loc(#loc237)
    %593 = arith.select %591, %592, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %594 = arith.xori %587, %593 : tensor<1x64xi32, #blocked> loc(#loc239)
    %595 = arith.xori %585, %586 : tensor<1x64xi16, #blocked> loc(#loc240)
    %596 = arith.select %591, %595, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %597 = arith.xori %560, %596 : tensor<1x64xi16, #blocked> loc(#loc242)
    %598 = tt.bitcast %594 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %599 = tt.reshape %598 : tensor<1x64xf32, #blocked> -> tensor<32x2x1xf32, #blocked7> loc(#loc197)
    %600 = tt.bitcast %599 : tensor<32x2x1xf32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc198)
    %601 = arith.muli %600, %47 : tensor<32x2x1xi32, #blocked7> loc(#loc200)
    %602 = "tt.reduce"(%601) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %603 = tt.expand_dims %602 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc204)
    %604 = tt.broadcast %603 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc205)
    %605 = arith.muli %600, %52 : tensor<32x2x1xi32, #blocked7> loc(#loc206)
    %606 = "tt.reduce"(%605) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc247)
    %607 = tt.expand_dims %606 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc210)
    %608 = tt.broadcast %607 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc211)
    %609 = tt.reshape %604 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %610 = tt.reshape %608 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %611 = tt.bitcast %609 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %612 = tt.bitcast %610 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %613 = tt.reshape %597 : tensor<1x64xi16, #blocked> -> tensor<32x2x1xi16, #blocked7> loc(#loc216)
    %614 = arith.muli %613, %68 : tensor<32x2x1xi16, #blocked7> loc(#loc218)
    %615 = "tt.reduce"(%614) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc250)
    %616 = tt.expand_dims %615 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc222)
    %617 = tt.broadcast %616 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc223)
    %618 = arith.muli %613, %79 : tensor<32x2x1xi16, #blocked7> loc(#loc225)
    %619 = "tt.reduce"(%618) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc253)
    %620 = tt.expand_dims %619 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc229)
    %621 = tt.broadcast %620 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc230)
    %622 = tt.reshape %617 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %623 = tt.reshape %621 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %624 = tt.bitcast %598 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %625 = arith.cmpf olt, %611, %612 : tensor<1x64xf32, #blocked> loc(#loc234)
    %626 = arith.extui %625 : tensor<1x64xi1, #blocked> to tensor<1x64xi32, #blocked> loc(#loc235)
    %627 = arith.xori %626, %447 : tensor<1x64xi32, #blocked> loc(#loc235)
    %628 = arith.cmpi ne, %627, %cst_8 : tensor<1x64xi32, #blocked> loc(#loc236)
    %629 = arith.xori %609, %610 : tensor<1x64xi32, #blocked> loc(#loc237)
    %630 = arith.select %628, %629, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %631 = arith.xori %624, %630 : tensor<1x64xi32, #blocked> loc(#loc239)
    %632 = arith.xori %622, %623 : tensor<1x64xi16, #blocked> loc(#loc240)
    %633 = arith.select %628, %632, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %634 = arith.xori %597, %633 : tensor<1x64xi16, #blocked> loc(#loc242)
    %635 = tt.bitcast %631 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %636 = tt.reshape %635 : tensor<1x64xf32, #blocked> -> tensor<1x2x32xf32, #blocked2> loc(#loc197)
    %637 = tt.bitcast %636 : tensor<1x2x32xf32, #blocked2> -> tensor<1x2x32xi32, #blocked2> loc(#loc198)
    %638 = tt.broadcast %45 : tensor<1x2x1xi32, #blocked2> -> tensor<1x2x32xi32, #blocked2> loc(#loc200)
    %639 = arith.muli %637, %638 : tensor<1x2x32xi32, #blocked2> loc(#loc200)
    %640 = "tt.reduce"(%639) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<1x2x32xi32, #blocked2>) -> tensor<1x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc244)
    %641 = tt.expand_dims %640 {axis = 1 : i32} : tensor<1x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<1x1x32xi32, #blocked2> loc(#loc204)
    %642 = tt.broadcast %641 : tensor<1x1x32xi32, #blocked2> -> tensor<1x2x32xi32, #blocked2> loc(#loc205)
    %643 = arith.muli %637, %446 : tensor<1x2x32xi32, #blocked2> loc(#loc206)
    %644 = "tt.reduce"(%643) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<1x2x32xi32, #blocked2>) -> tensor<1x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc247)
    %645 = tt.expand_dims %644 {axis = 1 : i32} : tensor<1x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<1x1x32xi32, #blocked2> loc(#loc210)
    %646 = tt.broadcast %645 : tensor<1x1x32xi32, #blocked2> -> tensor<1x2x32xi32, #blocked2> loc(#loc211)
    %647 = tt.reshape %642 : tensor<1x2x32xi32, #blocked2> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %648 = tt.reshape %646 : tensor<1x2x32xi32, #blocked2> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %649 = tt.bitcast %647 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %650 = tt.bitcast %648 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %651 = tt.reshape %634 : tensor<1x64xi16, #blocked> -> tensor<1x2x32xi16, #blocked2> loc(#loc216)
    %652 = tt.broadcast %66 : tensor<1x2x1xi16, #blocked2> -> tensor<1x2x32xi16, #blocked2> loc(#loc218)
    %653 = arith.muli %651, %652 : tensor<1x2x32xi16, #blocked2> loc(#loc218)
    %654 = "tt.reduce"(%653) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<1x2x32xi16, #blocked2>) -> tensor<1x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc250)
    %655 = tt.expand_dims %654 {axis = 1 : i32} : tensor<1x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<1x1x32xi16, #blocked2> loc(#loc222)
    %656 = tt.broadcast %655 : tensor<1x1x32xi16, #blocked2> -> tensor<1x2x32xi16, #blocked2> loc(#loc223)
    %657 = tt.broadcast %77 : tensor<1x2x1xi16, #blocked2> -> tensor<1x2x32xi16, #blocked2> loc(#loc225)
    %658 = arith.muli %651, %657 : tensor<1x2x32xi16, #blocked2> loc(#loc225)
    %659 = "tt.reduce"(%658) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<1x2x32xi16, #blocked2>) -> tensor<1x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc253)
    %660 = tt.expand_dims %659 {axis = 1 : i32} : tensor<1x32xi16, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<1x1x32xi16, #blocked2> loc(#loc229)
    %661 = tt.broadcast %660 : tensor<1x1x32xi16, #blocked2> -> tensor<1x2x32xi16, #blocked2> loc(#loc230)
    %662 = tt.reshape %656 : tensor<1x2x32xi16, #blocked2> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %663 = tt.reshape %661 : tensor<1x2x32xi16, #blocked2> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %664 = tt.bitcast %635 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %665 = arith.cmpf olt, %649, %650 : tensor<1x64xf32, #blocked> loc(#loc234)
    %666 = arith.xori %647, %648 : tensor<1x64xi32, #blocked> loc(#loc237)
    %667 = arith.select %665, %666, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %668 = arith.xori %664, %667 : tensor<1x64xi32, #blocked> loc(#loc239)
    %669 = arith.xori %662, %663 : tensor<1x64xi16, #blocked> loc(#loc240)
    %670 = arith.select %665, %669, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %671 = arith.xori %634, %670 : tensor<1x64xi16, #blocked> loc(#loc242)
    %672 = tt.bitcast %668 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %673 = tt.reshape %672 : tensor<1x64xf32, #blocked> -> tensor<2x2x16xf32, #blocked3> loc(#loc197)
    %674 = tt.bitcast %673 : tensor<2x2x16xf32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc198)
    %675 = arith.muli %674, %450 : tensor<2x2x16xi32, #blocked3> loc(#loc200)
    %676 = "tt.reduce"(%675) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<2x2x16xi32, #blocked3>) -> tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc244)
    %677 = tt.expand_dims %676 {axis = 1 : i32} : tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi32, #blocked3> loc(#loc204)
    %678 = tt.broadcast %677 : tensor<2x1x16xi32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc205)
    %679 = arith.muli %674, %293 : tensor<2x2x16xi32, #blocked3> loc(#loc206)
    %680 = "tt.reduce"(%679) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<2x2x16xi32, #blocked3>) -> tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc247)
    %681 = tt.expand_dims %680 {axis = 1 : i32} : tensor<2x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi32, #blocked3> loc(#loc210)
    %682 = tt.broadcast %681 : tensor<2x1x16xi32, #blocked3> -> tensor<2x2x16xi32, #blocked3> loc(#loc211)
    %683 = tt.reshape %678 : tensor<2x2x16xi32, #blocked3> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %684 = tt.reshape %682 : tensor<2x2x16xi32, #blocked3> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %685 = tt.bitcast %683 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %686 = tt.bitcast %684 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %687 = tt.reshape %671 : tensor<1x64xi16, #blocked> -> tensor<2x2x16xi16, #blocked3> loc(#loc216)
    %688 = arith.muli %687, %464 : tensor<2x2x16xi16, #blocked3> loc(#loc218)
    %689 = "tt.reduce"(%688) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<2x2x16xi16, #blocked3>) -> tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc250)
    %690 = tt.expand_dims %689 {axis = 1 : i32} : tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi16, #blocked3> loc(#loc222)
    %691 = tt.broadcast %690 : tensor<2x1x16xi16, #blocked3> -> tensor<2x2x16xi16, #blocked3> loc(#loc223)
    %692 = arith.muli %687, %469 : tensor<2x2x16xi16, #blocked3> loc(#loc225)
    %693 = "tt.reduce"(%692) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<2x2x16xi16, #blocked3>) -> tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc253)
    %694 = tt.expand_dims %693 {axis = 1 : i32} : tensor<2x16xi16, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<2x1x16xi16, #blocked3> loc(#loc229)
    %695 = tt.broadcast %694 : tensor<2x1x16xi16, #blocked3> -> tensor<2x2x16xi16, #blocked3> loc(#loc230)
    %696 = tt.reshape %691 : tensor<2x2x16xi16, #blocked3> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %697 = tt.reshape %695 : tensor<2x2x16xi16, #blocked3> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %698 = tt.bitcast %672 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %699 = arith.cmpf olt, %685, %686 : tensor<1x64xf32, #blocked> loc(#loc234)
    %700 = arith.xori %683, %684 : tensor<1x64xi32, #blocked> loc(#loc237)
    %701 = arith.select %699, %700, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %702 = arith.xori %698, %701 : tensor<1x64xi32, #blocked> loc(#loc239)
    %703 = arith.xori %696, %697 : tensor<1x64xi16, #blocked> loc(#loc240)
    %704 = arith.select %699, %703, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %705 = arith.xori %671, %704 : tensor<1x64xi16, #blocked> loc(#loc242)
    %706 = tt.bitcast %702 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %707 = tt.reshape %706 : tensor<1x64xf32, #blocked> -> tensor<4x2x8xf32, #blocked4> loc(#loc197)
    %708 = tt.bitcast %707 : tensor<4x2x8xf32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc198)
    %709 = arith.muli %708, %297 : tensor<4x2x8xi32, #blocked4> loc(#loc200)
    %710 = "tt.reduce"(%709) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<4x2x8xi32, #blocked4>) -> tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc244)
    %711 = tt.expand_dims %710 {axis = 1 : i32} : tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi32, #blocked4> loc(#loc204)
    %712 = tt.broadcast %711 : tensor<4x1x8xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc205)
    %713 = arith.muli %708, %177 : tensor<4x2x8xi32, #blocked4> loc(#loc206)
    %714 = "tt.reduce"(%713) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<4x2x8xi32, #blocked4>) -> tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc247)
    %715 = tt.expand_dims %714 {axis = 1 : i32} : tensor<4x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi32, #blocked4> loc(#loc210)
    %716 = tt.broadcast %715 : tensor<4x1x8xi32, #blocked4> -> tensor<4x2x8xi32, #blocked4> loc(#loc211)
    %717 = tt.reshape %712 : tensor<4x2x8xi32, #blocked4> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %718 = tt.reshape %716 : tensor<4x2x8xi32, #blocked4> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %719 = tt.bitcast %717 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %720 = tt.bitcast %718 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %721 = tt.reshape %705 : tensor<1x64xi16, #blocked> -> tensor<4x2x8xi16, #blocked4> loc(#loc216)
    %722 = arith.muli %721, %311 : tensor<4x2x8xi16, #blocked4> loc(#loc218)
    %723 = "tt.reduce"(%722) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<4x2x8xi16, #blocked4>) -> tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc250)
    %724 = tt.expand_dims %723 {axis = 1 : i32} : tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi16, #blocked4> loc(#loc222)
    %725 = tt.broadcast %724 : tensor<4x1x8xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc223)
    %726 = arith.muli %721, %316 : tensor<4x2x8xi16, #blocked4> loc(#loc225)
    %727 = "tt.reduce"(%726) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<4x2x8xi16, #blocked4>) -> tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc253)
    %728 = tt.expand_dims %727 {axis = 1 : i32} : tensor<4x8xi16, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<4x1x8xi16, #blocked4> loc(#loc229)
    %729 = tt.broadcast %728 : tensor<4x1x8xi16, #blocked4> -> tensor<4x2x8xi16, #blocked4> loc(#loc230)
    %730 = tt.reshape %725 : tensor<4x2x8xi16, #blocked4> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %731 = tt.reshape %729 : tensor<4x2x8xi16, #blocked4> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %732 = tt.bitcast %706 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %733 = arith.cmpf olt, %719, %720 : tensor<1x64xf32, #blocked> loc(#loc234)
    %734 = arith.xori %717, %718 : tensor<1x64xi32, #blocked> loc(#loc237)
    %735 = arith.select %733, %734, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %736 = arith.xori %732, %735 : tensor<1x64xi32, #blocked> loc(#loc239)
    %737 = arith.xori %730, %731 : tensor<1x64xi16, #blocked> loc(#loc240)
    %738 = arith.select %733, %737, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %739 = arith.xori %705, %738 : tensor<1x64xi16, #blocked> loc(#loc242)
    %740 = tt.bitcast %736 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %741 = tt.reshape %740 : tensor<1x64xf32, #blocked> -> tensor<8x2x4xf32, #blocked5> loc(#loc197)
    %742 = tt.bitcast %741 : tensor<8x2x4xf32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc198)
    %743 = arith.muli %742, %181 : tensor<8x2x4xi32, #blocked5> loc(#loc200)
    %744 = "tt.reduce"(%743) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc244)
    %745 = tt.expand_dims %744 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc204)
    %746 = tt.broadcast %745 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc205)
    %747 = arith.muli %742, %98 : tensor<8x2x4xi32, #blocked5> loc(#loc206)
    %748 = "tt.reduce"(%747) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<8x2x4xi32, #blocked5>) -> tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc247)
    %749 = tt.expand_dims %748 {axis = 1 : i32} : tensor<8x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi32, #blocked5> loc(#loc210)
    %750 = tt.broadcast %749 : tensor<8x1x4xi32, #blocked5> -> tensor<8x2x4xi32, #blocked5> loc(#loc211)
    %751 = tt.reshape %746 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %752 = tt.reshape %750 : tensor<8x2x4xi32, #blocked5> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %753 = tt.bitcast %751 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %754 = tt.bitcast %752 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %755 = tt.reshape %739 : tensor<1x64xi16, #blocked> -> tensor<8x2x4xi16, #blocked5> loc(#loc216)
    %756 = arith.muli %755, %195 : tensor<8x2x4xi16, #blocked5> loc(#loc218)
    %757 = "tt.reduce"(%756) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc250)
    %758 = tt.expand_dims %757 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc222)
    %759 = tt.broadcast %758 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc223)
    %760 = arith.muli %755, %200 : tensor<8x2x4xi16, #blocked5> loc(#loc225)
    %761 = "tt.reduce"(%760) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<8x2x4xi16, #blocked5>) -> tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc253)
    %762 = tt.expand_dims %761 {axis = 1 : i32} : tensor<8x4xi16, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x4xi16, #blocked5> loc(#loc229)
    %763 = tt.broadcast %762 : tensor<8x1x4xi16, #blocked5> -> tensor<8x2x4xi16, #blocked5> loc(#loc230)
    %764 = tt.reshape %759 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %765 = tt.reshape %763 : tensor<8x2x4xi16, #blocked5> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %766 = tt.bitcast %740 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %767 = arith.cmpf olt, %753, %754 : tensor<1x64xf32, #blocked> loc(#loc234)
    %768 = arith.xori %751, %752 : tensor<1x64xi32, #blocked> loc(#loc237)
    %769 = arith.select %767, %768, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %770 = arith.xori %766, %769 : tensor<1x64xi32, #blocked> loc(#loc239)
    %771 = arith.xori %764, %765 : tensor<1x64xi16, #blocked> loc(#loc240)
    %772 = arith.select %767, %771, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %773 = arith.xori %739, %772 : tensor<1x64xi16, #blocked> loc(#loc242)
    %774 = tt.bitcast %770 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %775 = tt.reshape %774 : tensor<1x64xf32, #blocked> -> tensor<16x2x2xf32, #blocked6> loc(#loc197)
    %776 = tt.bitcast %775 : tensor<16x2x2xf32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc198)
    %777 = arith.muli %776, %102 : tensor<16x2x2xi32, #blocked6> loc(#loc200)
    %778 = "tt.reduce"(%777) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc244)
    %779 = tt.expand_dims %778 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc204)
    %780 = tt.broadcast %779 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc205)
    %781 = arith.muli %776, %37 : tensor<16x2x2xi32, #blocked6> loc(#loc206)
    %782 = "tt.reduce"(%781) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<16x2x2xi32, #blocked6>) -> tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc247)
    %783 = tt.expand_dims %782 {axis = 1 : i32} : tensor<16x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi32, #blocked6> loc(#loc210)
    %784 = tt.broadcast %783 : tensor<16x1x2xi32, #blocked6> -> tensor<16x2x2xi32, #blocked6> loc(#loc211)
    %785 = tt.reshape %780 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %786 = tt.reshape %784 : tensor<16x2x2xi32, #blocked6> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %787 = tt.bitcast %785 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %788 = tt.bitcast %786 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %789 = tt.reshape %773 : tensor<1x64xi16, #blocked> -> tensor<16x2x2xi16, #blocked6> loc(#loc216)
    %790 = arith.muli %789, %116 : tensor<16x2x2xi16, #blocked6> loc(#loc218)
    %791 = "tt.reduce"(%790) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc250)
    %792 = tt.expand_dims %791 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc222)
    %793 = tt.broadcast %792 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc223)
    %794 = arith.muli %789, %121 : tensor<16x2x2xi16, #blocked6> loc(#loc225)
    %795 = "tt.reduce"(%794) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<16x2x2xi16, #blocked6>) -> tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc253)
    %796 = tt.expand_dims %795 {axis = 1 : i32} : tensor<16x2xi16, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<16x1x2xi16, #blocked6> loc(#loc229)
    %797 = tt.broadcast %796 : tensor<16x1x2xi16, #blocked6> -> tensor<16x2x2xi16, #blocked6> loc(#loc230)
    %798 = tt.reshape %793 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %799 = tt.reshape %797 : tensor<16x2x2xi16, #blocked6> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %800 = tt.bitcast %774 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %801 = arith.cmpf olt, %787, %788 : tensor<1x64xf32, #blocked> loc(#loc234)
    %802 = arith.xori %785, %786 : tensor<1x64xi32, #blocked> loc(#loc237)
    %803 = arith.select %801, %802, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %804 = arith.xori %800, %803 : tensor<1x64xi32, #blocked> loc(#loc239)
    %805 = arith.xori %798, %799 : tensor<1x64xi16, #blocked> loc(#loc240)
    %806 = arith.select %801, %805, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %807 = arith.xori %773, %806 : tensor<1x64xi16, #blocked> loc(#loc242)
    %808 = tt.bitcast %804 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %809 = tt.reshape %808 : tensor<1x64xf32, #blocked> -> tensor<32x2x1xf32, #blocked7> loc(#loc197)
    %810 = tt.bitcast %809 : tensor<32x2x1xf32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc198)
    %811 = arith.muli %810, %47 : tensor<32x2x1xi32, #blocked7> loc(#loc200)
    %812 = "tt.reduce"(%811) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc202 at #loc19)), %arg8: i32 loc(callsite(#loc202 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc256)
      tt.reduce.return %878 : i32 loc(#loc244)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc244)
    %813 = tt.expand_dims %812 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc204)
    %814 = tt.broadcast %813 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc205)
    %815 = arith.muli %810, %52 : tensor<32x2x1xi32, #blocked7> loc(#loc206)
    %816 = "tt.reduce"(%815) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i32 loc(callsite(#loc208 at #loc19)), %arg8: i32 loc(callsite(#loc208 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i32 loc(#loc257)
      tt.reduce.return %878 : i32 loc(#loc247)
    }) : (tensor<32x2x1xi32, #blocked7>) -> tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc247)
    %817 = tt.expand_dims %816 {axis = 1 : i32} : tensor<32x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi32, #blocked7> loc(#loc210)
    %818 = tt.broadcast %817 : tensor<32x1x1xi32, #blocked7> -> tensor<32x2x1xi32, #blocked7> loc(#loc211)
    %819 = tt.reshape %814 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc212)
    %820 = tt.reshape %818 : tensor<32x2x1xi32, #blocked7> -> tensor<1x64xi32, #blocked> loc(#loc213)
    %821 = tt.bitcast %819 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc214)
    %822 = tt.bitcast %820 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc215)
    %823 = tt.reshape %807 : tensor<1x64xi16, #blocked> -> tensor<32x2x1xi16, #blocked7> loc(#loc216)
    %824 = arith.muli %823, %68 : tensor<32x2x1xi16, #blocked7> loc(#loc218)
    %825 = "tt.reduce"(%824) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc220 at #loc19)), %arg8: i16 loc(callsite(#loc220 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc258)
      tt.reduce.return %878 : i16 loc(#loc250)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc250)
    %826 = tt.expand_dims %825 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc222)
    %827 = tt.broadcast %826 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc223)
    %828 = arith.muli %823, %79 : tensor<32x2x1xi16, #blocked7> loc(#loc225)
    %829 = "tt.reduce"(%828) <{axis = 1 : i32}> ({
    ^bb0(%arg7: i16 loc(callsite(#loc227 at #loc19)), %arg8: i16 loc(callsite(#loc227 at #loc19))):
      %878 = arith.addi %arg7, %arg8 : i16 loc(#loc259)
      tt.reduce.return %878 : i16 loc(#loc253)
    }) : (tensor<32x2x1xi16, #blocked7>) -> tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc253)
    %830 = tt.expand_dims %829 {axis = 1 : i32} : tensor<32x1xi16, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<32x1x1xi16, #blocked7> loc(#loc229)
    %831 = tt.broadcast %830 : tensor<32x1x1xi16, #blocked7> -> tensor<32x2x1xi16, #blocked7> loc(#loc230)
    %832 = tt.reshape %827 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc231)
    %833 = tt.reshape %831 : tensor<32x2x1xi16, #blocked7> -> tensor<1x64xi16, #blocked> loc(#loc232)
    %834 = tt.bitcast %808 : tensor<1x64xf32, #blocked> -> tensor<1x64xi32, #blocked> loc(#loc233)
    %835 = arith.cmpf olt, %821, %822 : tensor<1x64xf32, #blocked> loc(#loc234)
    %836 = arith.xori %819, %820 : tensor<1x64xi32, #blocked> loc(#loc237)
    %837 = arith.select %835, %836, %cst_8 : tensor<1x64xi1, #blocked>, tensor<1x64xi32, #blocked> loc(#loc238)
    %838 = arith.xori %834, %837 : tensor<1x64xi32, #blocked> loc(#loc239)
    %839 = arith.xori %832, %833 : tensor<1x64xi16, #blocked> loc(#loc240)
    %840 = arith.select %835, %839, %cst_9 : tensor<1x64xi1, #blocked>, tensor<1x64xi16, #blocked> loc(#loc241)
    %841 = arith.xori %807, %840 : tensor<1x64xi16, #blocked> loc(#loc242)
    %842 = tt.bitcast %838 : tensor<1x64xi32, #blocked> -> tensor<1x64xf32, #blocked> loc(#loc243)
    %843 = triton_gpu.convert_layout %841 : tensor<1x64xi16, #blocked> -> tensor<1x64xi16, #blocked1> loc(#loc64)
    %844 = arith.extsi %843 : tensor<1x64xi16, #blocked1> to tensor<1x64xi64, #blocked1> loc(#loc65)
    %845 = arith.extsi %841 : tensor<1x64xi16, #blocked> to tensor<1x64xi64, #blocked> loc(#loc65)
    %846 = arith.addi %844, %cst_16 : tensor<1x64xi64, #blocked1> loc(#loc66)
    %847 = arith.addi %845, %cst : tensor<1x64xi64, #blocked> loc(#loc66)
    %848 = arith.cmpi slt, %844, %cst_15 : tensor<1x64xi64, #blocked1> loc(#loc67)
    %849 = arith.cmpi slt, %845, %cst_14 : tensor<1x64xi64, #blocked> loc(#loc67)
    %850 = arith.select %848, %846, %844 : tensor<1x64xi1, #blocked1>, tensor<1x64xi64, #blocked1> loc(#loc68)
    %851 = arith.select %849, %847, %845 : tensor<1x64xi1, #blocked>, tensor<1x64xi64, #blocked> loc(#loc68)
    %852 = arith.cmpi sge, %851, %cst_14 : tensor<1x64xi64, #blocked> loc(#loc69)
    %853 = arith.cmpi slt, %851, %cst : tensor<1x64xi64, #blocked> loc(#loc70)
    %854 = arith.andi %852, %853 : tensor<1x64xi1, #blocked> loc(#loc71)
    tt.assert %854, "index out of bounds: 0 <= tmp18 < 64" : tensor<1x64xi1, #blocked> loc(#loc72)
    %855 = arith.divsi %850, %cst_19 : tensor<1x64xi64, #blocked1> loc(#loc73)
    %856 = arith.remsi %855, %cst_18 : tensor<1x64xi64, #blocked1> loc(#loc74)
    %857 = arith.muli %856, %cst_16 : tensor<1x64xi64, #blocked1> loc(#loc75)
    %858 = arith.addi %857, %cst_17 : tensor<1x64xi64, #blocked1> loc(#loc76)
    %859 = arith.remsi %850, %cst_19 : tensor<1x64xi64, #blocked1> loc(#loc77)
    %860 = arith.addi %858, %859 : tensor<1x64xi64, #blocked1> loc(#loc78)
    %861 = tt.addptr %10, %860 : tensor<1x64x!tt.ptr<f32>, #blocked1>, tensor<1x64xi64, #blocked1> loc(#loc64)
    %862 = tt.load %861 evictionPolicy = evict_last : tensor<1x64x!tt.ptr<f32>, #blocked1> loc(#loc79)
    %863 = "tt.reduce"(%862) <{axis = 1 : i32}> ({
    ^bb0(%arg7: f32 loc(callsite(#loc1 at #loc80)), %arg8: f32 loc(callsite(#loc1 at #loc80))):
      %878 = arith.addf %arg7, %arg8 : f32 loc(#loc196)
      tt.reduce.return %878 : f32 loc(#loc142)
    }) : (tensor<1x64xf32, #blocked1>) -> tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc142)
    %864 = tt.expand_dims %863 {axis = 1 : i32} : tensor<1xf32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<1x1xf32, #blocked1> loc(#loc81)
    %865 = "tt.scan"(%862) <{axis = 1 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %878 = arith.addf %arg7, %arg8 : f32 loc(#loc144)
      tt.scan.return %878 : f32 loc(#loc82)
    }) : (tensor<1x64xf32, #blocked1>) -> tensor<1x64xf32, #blocked1> loc(#loc82)
    %866 = arith.subf %cst_1, %862 : tensor<1x64xf32, #blocked1> loc(#loc84)
    %867 = "tt.scan"(%866) <{axis = 1 : i32, reverse = false}> ({
    ^bb0(%arg7: f32 loc(unknown), %arg8: f32 loc(unknown)):
      %878 = arith.addf %arg7, %arg8 : f32 loc(#loc145)
      tt.scan.return %878 : f32 loc(#loc85)
    }) : (tensor<1x64xf32, #blocked1>) -> tensor<1x64xf32, #blocked1> loc(#loc85)
    %868 = tt.splat %arg2 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc86)
    %869 = tt.addptr %868, %1 : tensor<1x64x!tt.ptr<f32>, #blocked>, tensor<1x64xi32, #blocked> loc(#loc86)
    tt.store %869, %842 : tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc87)
    %870 = tt.splat %arg4 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc88)
    %871 = tt.addptr %870, %1 : tensor<1x64x!tt.ptr<f32>, #blocked>, tensor<1x64xi32, #blocked> loc(#loc88)
    %872 = triton_gpu.convert_layout %865 : tensor<1x64xf32, #blocked1> -> tensor<1x64xf32, #blocked> loc(#loc89)
    tt.store %871, %872 : tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc89)
    %873 = tt.splat %arg5 : !tt.ptr<f32> -> tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc90)
    %874 = tt.addptr %873, %1 : tensor<1x64x!tt.ptr<f32>, #blocked>, tensor<1x64xi32, #blocked> loc(#loc90)
    %875 = triton_gpu.convert_layout %867 : tensor<1x64xf32, #blocked1> -> tensor<1x64xf32, #blocked> loc(#loc91)
    tt.store %874, %875 : tensor<1x64x!tt.ptr<f32>, #blocked> loc(#loc91)
    %876 = tt.addptr %arg3, %c0_i32 : !tt.ptr<f32>, i32 loc(#loc92)
    %877 = tt.splat %876 : !tt.ptr<f32> -> tensor<1x1x!tt.ptr<f32>, #blocked1> loc(#loc93)
    tt.store %877, %864 : tensor<1x1x!tt.ptr<f32>, #blocked1> loc(#loc93)
    tt.return loc(#loc94)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":31:34)
#loc3 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":35:45)
#loc4 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":35:39)
#loc5 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":35:35)
#loc6 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":35:58)
#loc7 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":35:53)
#loc8 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":35:30)
#loc9 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":35:65)
#loc10 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":36:30)
#loc11 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":36:65)
#loc12 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":38:18)
#loc13 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":40:18)
#loc14 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":41:18)
#loc15 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":42:18)
#loc16 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":44:19)
#loc17 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:44)
#loc20 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:60)
#loc21 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:68)
#loc22 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":501:22)
#loc24 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":502:14)
#loc25 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":505:21)
#loc26 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:40)
#loc27 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":267:36)
#loc29 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":256:15)
#loc30 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:54)
#loc31 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:67)
#loc32 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:41)
#loc34 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:56)
#loc35 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:69)
#loc36 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":508:30)
#loc37 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":509:32)
#loc38 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":510:20)
#loc39 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":511:22)
#loc40 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":514:29)
#loc41 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:36)
#loc42 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:23)
#loc44 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:53)
#loc45 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":516:66)
#loc46 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:37)
#loc47 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:23)
#loc49 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:54)
#loc50 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":519:67)
#loc51 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":521:36)
#loc52 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":522:38)
#loc53 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":533:14)
#loc54 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":536:22)
#loc55 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:19)
#loc56 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:28)
#loc57 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:38)
#loc58 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:46)
#loc59 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:15)
#loc60 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:48)
#loc61 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:59)
#loc62 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":549:22)
#loc63 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":551:18)
#loc64 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:31)
#loc65 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":48:21)
#loc66 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":50:20)
#loc67 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":51:20)
#loc68 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":52:35)
#loc69 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":53:27)
#loc70 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":53:45)
#loc71 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":53:37)
#loc72 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":53:50)
#loc73 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:51)
#loc74 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:57)
#loc75 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:41)
#loc76 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:36)
#loc77 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:73)
#loc78 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:65)
#loc79 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":54:80)
#loc81 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":56:29)
#loc82 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":59:46)
#loc83 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":13:20)
#loc84 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":60:19)
#loc85 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":63:46)
#loc86 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":64:25)
#loc87 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":64:72)
#loc88 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":65:25)
#loc89 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":65:72)
#loc90 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":66:25)
#loc91 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":66:72)
#loc92 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":67:25)
#loc93 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":67:68)
#loc94 = loc("inductor_cache/bg/cbgwn6c4thbkbme2uo2t2m4s2rpcaqeupbfwgcgqorit6gogaz2y.py":67:4)
#loc95 = loc(callsite(#loc17 at #loc18))
#loc96 = loc(callsite(#loc20 at #loc18))
#loc97 = loc(callsite(#loc21 at #loc18))
#loc98 = loc(callsite(#loc22 at #loc23))
#loc99 = loc(callsite(#loc24 at #loc23))
#loc100 = loc(callsite(#loc25 at #loc23))
#loc101 = loc(callsite(#loc26 at #loc23))
#loc102 = loc(callsite(#loc27 at #loc28))
#loc104 = loc(callsite(#loc29 at #loc27))
#loc105 = loc(callsite(#loc30 at #loc23))
#loc106 = loc(callsite(#loc31 at #loc23))
#loc107 = loc(callsite(#loc32 at #loc23))
#loc108 = loc(callsite(#loc27 at #loc33))
#loc110 = loc(callsite(#loc34 at #loc23))
#loc111 = loc(callsite(#loc35 at #loc23))
#loc112 = loc(callsite(#loc36 at #loc23))
#loc113 = loc(callsite(#loc37 at #loc23))
#loc114 = loc(callsite(#loc38 at #loc23))
#loc115 = loc(callsite(#loc39 at #loc23))
#loc116 = loc(callsite(#loc40 at #loc23))
#loc117 = loc(callsite(#loc41 at #loc23))
#loc118 = loc(callsite(#loc42 at #loc23))
#loc119 = loc(callsite(#loc27 at #loc43))
#loc121 = loc(callsite(#loc44 at #loc23))
#loc122 = loc(callsite(#loc45 at #loc23))
#loc123 = loc(callsite(#loc46 at #loc23))
#loc124 = loc(callsite(#loc47 at #loc23))
#loc125 = loc(callsite(#loc27 at #loc48))
#loc127 = loc(callsite(#loc49 at #loc23))
#loc128 = loc(callsite(#loc50 at #loc23))
#loc129 = loc(callsite(#loc51 at #loc23))
#loc130 = loc(callsite(#loc52 at #loc23))
#loc131 = loc(callsite(#loc53 at #loc23))
#loc132 = loc(callsite(#loc54 at #loc23))
#loc133 = loc(callsite(#loc55 at #loc23))
#loc134 = loc(callsite(#loc56 at #loc23))
#loc135 = loc(callsite(#loc57 at #loc23))
#loc136 = loc(callsite(#loc58 at #loc23))
#loc137 = loc(callsite(#loc59 at #loc23))
#loc138 = loc(callsite(#loc60 at #loc23))
#loc139 = loc(callsite(#loc61 at #loc23))
#loc140 = loc(callsite(#loc62 at #loc23))
#loc141 = loc(callsite(#loc63 at #loc23))
#loc142 = loc(callsite(#loc27 at #loc80))
#loc144 = loc(callsite(#loc83 at #loc82))
#loc145 = loc(callsite(#loc83 at #loc85))
#loc146 = loc(callsite(#loc95 at #loc19))
#loc147 = loc(callsite(#loc96 at #loc19))
#loc148 = loc(callsite(#loc97 at #loc19))
#loc149 = loc(callsite(#loc98 at #loc18))
#loc150 = loc(callsite(#loc99 at #loc18))
#loc151 = loc(callsite(#loc100 at #loc18))
#loc152 = loc(callsite(#loc101 at #loc18))
#loc153 = loc(callsite(#loc102 at #loc23))
#loc155 = loc(callsite(#loc104 at #loc28))
#loc156 = loc(callsite(#loc105 at #loc18))
#loc157 = loc(callsite(#loc106 at #loc18))
#loc158 = loc(callsite(#loc107 at #loc18))
#loc159 = loc(callsite(#loc108 at #loc23))
#loc161 = loc(callsite(#loc104 at #loc33))
#loc162 = loc(callsite(#loc110 at #loc18))
#loc163 = loc(callsite(#loc111 at #loc18))
#loc164 = loc(callsite(#loc112 at #loc18))
#loc165 = loc(callsite(#loc113 at #loc18))
#loc166 = loc(callsite(#loc114 at #loc18))
#loc167 = loc(callsite(#loc115 at #loc18))
#loc168 = loc(callsite(#loc116 at #loc18))
#loc169 = loc(callsite(#loc117 at #loc18))
#loc170 = loc(callsite(#loc118 at #loc18))
#loc171 = loc(callsite(#loc119 at #loc23))
#loc173 = loc(callsite(#loc104 at #loc43))
#loc174 = loc(callsite(#loc121 at #loc18))
#loc175 = loc(callsite(#loc122 at #loc18))
#loc176 = loc(callsite(#loc123 at #loc18))
#loc177 = loc(callsite(#loc124 at #loc18))
#loc178 = loc(callsite(#loc125 at #loc23))
#loc180 = loc(callsite(#loc104 at #loc48))
#loc181 = loc(callsite(#loc127 at #loc18))
#loc182 = loc(callsite(#loc128 at #loc18))
#loc183 = loc(callsite(#loc129 at #loc18))
#loc184 = loc(callsite(#loc130 at #loc18))
#loc185 = loc(callsite(#loc131 at #loc18))
#loc186 = loc(callsite(#loc132 at #loc18))
#loc187 = loc(callsite(#loc133 at #loc18))
#loc188 = loc(callsite(#loc134 at #loc18))
#loc189 = loc(callsite(#loc135 at #loc18))
#loc190 = loc(callsite(#loc136 at #loc18))
#loc191 = loc(callsite(#loc137 at #loc18))
#loc192 = loc(callsite(#loc138 at #loc18))
#loc193 = loc(callsite(#loc139 at #loc18))
#loc194 = loc(callsite(#loc140 at #loc18))
#loc195 = loc(callsite(#loc141 at #loc18))
#loc196 = loc(callsite(#loc104 at #loc80))
#loc197 = loc(callsite(#loc149 at #loc19))
#loc198 = loc(callsite(#loc150 at #loc19))
#loc199 = loc(callsite(#loc151 at #loc19))
#loc200 = loc(callsite(#loc152 at #loc19))
#loc201 = loc(callsite(#loc153 at #loc18))
#loc203 = loc(callsite(#loc155 at #loc23))
#loc204 = loc(callsite(#loc156 at #loc19))
#loc205 = loc(callsite(#loc157 at #loc19))
#loc206 = loc(callsite(#loc158 at #loc19))
#loc207 = loc(callsite(#loc159 at #loc18))
#loc209 = loc(callsite(#loc161 at #loc23))
#loc210 = loc(callsite(#loc162 at #loc19))
#loc211 = loc(callsite(#loc163 at #loc19))
#loc212 = loc(callsite(#loc164 at #loc19))
#loc213 = loc(callsite(#loc165 at #loc19))
#loc214 = loc(callsite(#loc166 at #loc19))
#loc215 = loc(callsite(#loc167 at #loc19))
#loc216 = loc(callsite(#loc168 at #loc19))
#loc217 = loc(callsite(#loc169 at #loc19))
#loc218 = loc(callsite(#loc170 at #loc19))
#loc219 = loc(callsite(#loc171 at #loc18))
#loc221 = loc(callsite(#loc173 at #loc23))
#loc222 = loc(callsite(#loc174 at #loc19))
#loc223 = loc(callsite(#loc175 at #loc19))
#loc224 = loc(callsite(#loc176 at #loc19))
#loc225 = loc(callsite(#loc177 at #loc19))
#loc226 = loc(callsite(#loc178 at #loc18))
#loc228 = loc(callsite(#loc180 at #loc23))
#loc229 = loc(callsite(#loc181 at #loc19))
#loc230 = loc(callsite(#loc182 at #loc19))
#loc231 = loc(callsite(#loc183 at #loc19))
#loc232 = loc(callsite(#loc184 at #loc19))
#loc233 = loc(callsite(#loc185 at #loc19))
#loc234 = loc(callsite(#loc186 at #loc19))
#loc235 = loc(callsite(#loc187 at #loc19))
#loc236 = loc(callsite(#loc188 at #loc19))
#loc237 = loc(callsite(#loc189 at #loc19))
#loc238 = loc(callsite(#loc190 at #loc19))
#loc239 = loc(callsite(#loc191 at #loc19))
#loc240 = loc(callsite(#loc192 at #loc19))
#loc241 = loc(callsite(#loc193 at #loc19))
#loc242 = loc(callsite(#loc194 at #loc19))
#loc243 = loc(callsite(#loc195 at #loc19))
#loc244 = loc(callsite(#loc201 at #loc19))
#loc246 = loc(callsite(#loc203 at #loc18))
#loc247 = loc(callsite(#loc207 at #loc19))
#loc249 = loc(callsite(#loc209 at #loc18))
#loc250 = loc(callsite(#loc219 at #loc19))
#loc252 = loc(callsite(#loc221 at #loc18))
#loc253 = loc(callsite(#loc226 at #loc19))
#loc255 = loc(callsite(#loc228 at #loc18))
#loc256 = loc(callsite(#loc246 at #loc19))
#loc257 = loc(callsite(#loc249 at #loc19))
#loc258 = loc(callsite(#loc252 at #loc19))
#loc259 = loc(callsite(#loc255 at #loc19))
