#loc = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0)
#loc1 = loc(unknown)
#loc7 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":610:12)
#loc8 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":37:67)
#loc13 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":582:73)
#loc18 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:51)
#loc23 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:53)
#loc50 = loc(callsite(#loc1 at #loc18))
#loc56 = loc(callsite(#loc1 at #loc23))
#loc80 = loc(callsite(#loc50 at #loc13))
#loc86 = loc(callsite(#loc56 at #loc13))
#loc107 = loc(callsite(#loc80 at #loc7))
#loc113 = loc(callsite(#loc86 at #loc7))
#loc130 = loc(callsite(#loc107 at #loc8))
#loc133 = loc(callsite(#loc113 at #loc8))
module {
  tt.func public @triton_per_fused_sort_0(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0), %arg2: i32 {tt.divisibility = 16 : i32} loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0> : tensor<256xi32> loc(#loc1)
    %cst_0 = arith.constant dense<1> : tensor<1x2x1xi32> loc(#loc1)
    %0 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32> loc(#loc2)
    %1 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>> loc(#loc3)
    %2 = tt.addptr %1, %0 : tensor<256x!tt.ptr<f32>>, tensor<256xi32> loc(#loc3)
    %3 = tt.load %2 : tensor<256x!tt.ptr<f32>> loc(#loc4)
    %4 = math.absf %3 : tensor<256xf32> loc(#loc5)
    %5 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32> loc(#loc71)
    %6 = tt.expand_dims %5 {axis = 0 : i32} : tensor<2xi32> -> tensor<1x2xi32> loc(#loc72)
    %7 = tt.expand_dims %6 {axis = 2 : i32} : tensor<1x2xi32> -> tensor<1x2x1xi32> loc(#loc72)
    %8 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<64x2x2xi32> loc(#loc73)
    %9 = tt.reshape %8 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc74)
    %10 = tt.reshape %4 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %11 = tt.bitcast %10 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %12 = arith.subi %cst_0, %7 : tensor<1x2x1xi32> loc(#loc104)
    %13 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<128x2x1xi32> loc(#loc105)
    %14 = arith.muli %11, %13 : tensor<128x2x1xi32> loc(#loc105)
    %15 = "tt.reduce"(%14) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %16 = tt.expand_dims %15 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %17 = tt.broadcast %16 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %18 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<128x2x1xi32> loc(#loc111)
    %19 = arith.muli %11, %18 : tensor<128x2x1xi32> loc(#loc111)
    %20 = "tt.reduce"(%19) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %21 = tt.expand_dims %20 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %22 = tt.broadcast %21 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %23 = tt.reshape %17 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %24 = tt.reshape %22 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %25 = tt.bitcast %23 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %26 = tt.bitcast %24 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %27 = tt.bitcast %4 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %28 = arith.cmpf olt, %25, %26 : tensor<256xf32> loc(#loc122)
    %29 = arith.extui %28 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %30 = arith.xori %29, %9 : tensor<256xi32> loc(#loc123)
    %31 = arith.cmpi ne, %30, %cst : tensor<256xi32> loc(#loc124)
    %32 = arith.xori %23, %24 : tensor<256xi32> loc(#loc125)
    %33 = arith.select %31, %32, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %34 = arith.xori %27, %33 : tensor<256xi32> loc(#loc127)
    %35 = tt.bitcast %34 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %36 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<32x2x4xi32> loc(#loc73)
    %37 = tt.reshape %36 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc74)
    %38 = tt.reshape %35 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc102)
    %39 = tt.bitcast %38 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc103)
    %40 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<64x2x2xi32> loc(#loc105)
    %41 = arith.muli %39, %40 : tensor<64x2x2xi32> loc(#loc105)
    %42 = "tt.reduce"(%41) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc129)
    %43 = tt.expand_dims %42 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc109)
    %44 = tt.broadcast %43 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc110)
    %45 = arith.muli %39, %8 : tensor<64x2x2xi32> loc(#loc111)
    %46 = "tt.reduce"(%45) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc132)
    %47 = tt.expand_dims %46 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc115)
    %48 = tt.broadcast %47 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc116)
    %49 = tt.reshape %44 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc117)
    %50 = tt.reshape %48 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc118)
    %51 = tt.bitcast %49 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %52 = tt.bitcast %50 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %53 = tt.bitcast %35 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %54 = arith.cmpf olt, %51, %52 : tensor<256xf32> loc(#loc122)
    %55 = arith.extui %54 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %56 = arith.xori %55, %37 : tensor<256xi32> loc(#loc123)
    %57 = arith.cmpi ne, %56, %cst : tensor<256xi32> loc(#loc124)
    %58 = arith.xori %49, %50 : tensor<256xi32> loc(#loc125)
    %59 = arith.select %57, %58, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %60 = arith.xori %53, %59 : tensor<256xi32> loc(#loc127)
    %61 = tt.bitcast %60 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %62 = tt.reshape %61 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %63 = tt.bitcast %62 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %64 = arith.muli %63, %13 : tensor<128x2x1xi32> loc(#loc105)
    %65 = "tt.reduce"(%64) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %66 = tt.expand_dims %65 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %67 = tt.broadcast %66 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %68 = arith.muli %63, %18 : tensor<128x2x1xi32> loc(#loc111)
    %69 = "tt.reduce"(%68) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %70 = tt.expand_dims %69 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %71 = tt.broadcast %70 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %72 = tt.reshape %67 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %73 = tt.reshape %71 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %74 = tt.bitcast %72 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %75 = tt.bitcast %73 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %76 = tt.bitcast %61 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %77 = arith.cmpf olt, %74, %75 : tensor<256xf32> loc(#loc122)
    %78 = arith.extui %77 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %79 = arith.xori %78, %37 : tensor<256xi32> loc(#loc123)
    %80 = arith.cmpi ne, %79, %cst : tensor<256xi32> loc(#loc124)
    %81 = arith.xori %72, %73 : tensor<256xi32> loc(#loc125)
    %82 = arith.select %80, %81, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %83 = arith.xori %76, %82 : tensor<256xi32> loc(#loc127)
    %84 = tt.bitcast %83 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %85 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<16x2x8xi32> loc(#loc73)
    %86 = tt.reshape %85 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc74)
    %87 = tt.reshape %84 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc102)
    %88 = tt.bitcast %87 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc103)
    %89 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<32x2x4xi32> loc(#loc105)
    %90 = arith.muli %88, %89 : tensor<32x2x4xi32> loc(#loc105)
    %91 = "tt.reduce"(%90) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc129)
    %92 = tt.expand_dims %91 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc109)
    %93 = tt.broadcast %92 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc110)
    %94 = arith.muli %88, %36 : tensor<32x2x4xi32> loc(#loc111)
    %95 = "tt.reduce"(%94) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc132)
    %96 = tt.expand_dims %95 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc115)
    %97 = tt.broadcast %96 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc116)
    %98 = tt.reshape %93 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc117)
    %99 = tt.reshape %97 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc118)
    %100 = tt.bitcast %98 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %101 = tt.bitcast %99 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %102 = tt.bitcast %84 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %103 = arith.cmpf olt, %100, %101 : tensor<256xf32> loc(#loc122)
    %104 = arith.extui %103 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %105 = arith.xori %104, %86 : tensor<256xi32> loc(#loc123)
    %106 = arith.cmpi ne, %105, %cst : tensor<256xi32> loc(#loc124)
    %107 = arith.xori %98, %99 : tensor<256xi32> loc(#loc125)
    %108 = arith.select %106, %107, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %109 = arith.xori %102, %108 : tensor<256xi32> loc(#loc127)
    %110 = tt.bitcast %109 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %111 = tt.reshape %110 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc102)
    %112 = tt.bitcast %111 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc103)
    %113 = arith.muli %112, %40 : tensor<64x2x2xi32> loc(#loc105)
    %114 = "tt.reduce"(%113) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc129)
    %115 = tt.expand_dims %114 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc109)
    %116 = tt.broadcast %115 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc110)
    %117 = arith.muli %112, %8 : tensor<64x2x2xi32> loc(#loc111)
    %118 = "tt.reduce"(%117) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc132)
    %119 = tt.expand_dims %118 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc115)
    %120 = tt.broadcast %119 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc116)
    %121 = tt.reshape %116 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc117)
    %122 = tt.reshape %120 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc118)
    %123 = tt.bitcast %121 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %124 = tt.bitcast %122 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %125 = tt.bitcast %110 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %126 = arith.cmpf olt, %123, %124 : tensor<256xf32> loc(#loc122)
    %127 = arith.extui %126 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %128 = arith.xori %127, %86 : tensor<256xi32> loc(#loc123)
    %129 = arith.cmpi ne, %128, %cst : tensor<256xi32> loc(#loc124)
    %130 = arith.xori %121, %122 : tensor<256xi32> loc(#loc125)
    %131 = arith.select %129, %130, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %132 = arith.xori %125, %131 : tensor<256xi32> loc(#loc127)
    %133 = tt.bitcast %132 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %134 = tt.reshape %133 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %135 = tt.bitcast %134 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %136 = arith.muli %135, %13 : tensor<128x2x1xi32> loc(#loc105)
    %137 = "tt.reduce"(%136) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %138 = tt.expand_dims %137 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %139 = tt.broadcast %138 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %140 = arith.muli %135, %18 : tensor<128x2x1xi32> loc(#loc111)
    %141 = "tt.reduce"(%140) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %142 = tt.expand_dims %141 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %143 = tt.broadcast %142 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %144 = tt.reshape %139 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %145 = tt.reshape %143 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %146 = tt.bitcast %144 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %147 = tt.bitcast %145 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %148 = tt.bitcast %133 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %149 = arith.cmpf olt, %146, %147 : tensor<256xf32> loc(#loc122)
    %150 = arith.extui %149 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %151 = arith.xori %150, %86 : tensor<256xi32> loc(#loc123)
    %152 = arith.cmpi ne, %151, %cst : tensor<256xi32> loc(#loc124)
    %153 = arith.xori %144, %145 : tensor<256xi32> loc(#loc125)
    %154 = arith.select %152, %153, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %155 = arith.xori %148, %154 : tensor<256xi32> loc(#loc127)
    %156 = tt.bitcast %155 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %157 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<8x2x16xi32> loc(#loc73)
    %158 = tt.reshape %157 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc74)
    %159 = tt.reshape %156 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc102)
    %160 = tt.bitcast %159 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc103)
    %161 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<16x2x8xi32> loc(#loc105)
    %162 = arith.muli %160, %161 : tensor<16x2x8xi32> loc(#loc105)
    %163 = "tt.reduce"(%162) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc129)
    %164 = tt.expand_dims %163 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc109)
    %165 = tt.broadcast %164 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc110)
    %166 = arith.muli %160, %85 : tensor<16x2x8xi32> loc(#loc111)
    %167 = "tt.reduce"(%166) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc132)
    %168 = tt.expand_dims %167 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc115)
    %169 = tt.broadcast %168 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc116)
    %170 = tt.reshape %165 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc117)
    %171 = tt.reshape %169 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc118)
    %172 = tt.bitcast %170 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %173 = tt.bitcast %171 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %174 = tt.bitcast %156 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %175 = arith.cmpf olt, %172, %173 : tensor<256xf32> loc(#loc122)
    %176 = arith.extui %175 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %177 = arith.xori %176, %158 : tensor<256xi32> loc(#loc123)
    %178 = arith.cmpi ne, %177, %cst : tensor<256xi32> loc(#loc124)
    %179 = arith.xori %170, %171 : tensor<256xi32> loc(#loc125)
    %180 = arith.select %178, %179, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %181 = arith.xori %174, %180 : tensor<256xi32> loc(#loc127)
    %182 = tt.bitcast %181 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %183 = tt.reshape %182 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc102)
    %184 = tt.bitcast %183 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc103)
    %185 = arith.muli %184, %89 : tensor<32x2x4xi32> loc(#loc105)
    %186 = "tt.reduce"(%185) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc129)
    %187 = tt.expand_dims %186 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc109)
    %188 = tt.broadcast %187 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc110)
    %189 = arith.muli %184, %36 : tensor<32x2x4xi32> loc(#loc111)
    %190 = "tt.reduce"(%189) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc132)
    %191 = tt.expand_dims %190 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc115)
    %192 = tt.broadcast %191 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc116)
    %193 = tt.reshape %188 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc117)
    %194 = tt.reshape %192 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc118)
    %195 = tt.bitcast %193 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %196 = tt.bitcast %194 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %197 = tt.bitcast %182 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %198 = arith.cmpf olt, %195, %196 : tensor<256xf32> loc(#loc122)
    %199 = arith.extui %198 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %200 = arith.xori %199, %158 : tensor<256xi32> loc(#loc123)
    %201 = arith.cmpi ne, %200, %cst : tensor<256xi32> loc(#loc124)
    %202 = arith.xori %193, %194 : tensor<256xi32> loc(#loc125)
    %203 = arith.select %201, %202, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %204 = arith.xori %197, %203 : tensor<256xi32> loc(#loc127)
    %205 = tt.bitcast %204 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %206 = tt.reshape %205 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc102)
    %207 = tt.bitcast %206 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc103)
    %208 = arith.muli %207, %40 : tensor<64x2x2xi32> loc(#loc105)
    %209 = "tt.reduce"(%208) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc129)
    %210 = tt.expand_dims %209 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc109)
    %211 = tt.broadcast %210 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc110)
    %212 = arith.muli %207, %8 : tensor<64x2x2xi32> loc(#loc111)
    %213 = "tt.reduce"(%212) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc132)
    %214 = tt.expand_dims %213 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc115)
    %215 = tt.broadcast %214 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc116)
    %216 = tt.reshape %211 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc117)
    %217 = tt.reshape %215 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc118)
    %218 = tt.bitcast %216 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %219 = tt.bitcast %217 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %220 = tt.bitcast %205 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %221 = arith.cmpf olt, %218, %219 : tensor<256xf32> loc(#loc122)
    %222 = arith.extui %221 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %223 = arith.xori %222, %158 : tensor<256xi32> loc(#loc123)
    %224 = arith.cmpi ne, %223, %cst : tensor<256xi32> loc(#loc124)
    %225 = arith.xori %216, %217 : tensor<256xi32> loc(#loc125)
    %226 = arith.select %224, %225, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %227 = arith.xori %220, %226 : tensor<256xi32> loc(#loc127)
    %228 = tt.bitcast %227 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %229 = tt.reshape %228 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %230 = tt.bitcast %229 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %231 = arith.muli %230, %13 : tensor<128x2x1xi32> loc(#loc105)
    %232 = "tt.reduce"(%231) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %233 = tt.expand_dims %232 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %234 = tt.broadcast %233 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %235 = arith.muli %230, %18 : tensor<128x2x1xi32> loc(#loc111)
    %236 = "tt.reduce"(%235) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %237 = tt.expand_dims %236 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %238 = tt.broadcast %237 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %239 = tt.reshape %234 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %240 = tt.reshape %238 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %241 = tt.bitcast %239 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %242 = tt.bitcast %240 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %243 = tt.bitcast %228 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %244 = arith.cmpf olt, %241, %242 : tensor<256xf32> loc(#loc122)
    %245 = arith.extui %244 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %246 = arith.xori %245, %158 : tensor<256xi32> loc(#loc123)
    %247 = arith.cmpi ne, %246, %cst : tensor<256xi32> loc(#loc124)
    %248 = arith.xori %239, %240 : tensor<256xi32> loc(#loc125)
    %249 = arith.select %247, %248, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %250 = arith.xori %243, %249 : tensor<256xi32> loc(#loc127)
    %251 = tt.bitcast %250 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %252 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<4x2x32xi32> loc(#loc73)
    %253 = tt.reshape %252 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc74)
    %254 = tt.reshape %251 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc102)
    %255 = tt.bitcast %254 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc103)
    %256 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<8x2x16xi32> loc(#loc105)
    %257 = arith.muli %255, %256 : tensor<8x2x16xi32> loc(#loc105)
    %258 = "tt.reduce"(%257) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc129)
    %259 = tt.expand_dims %258 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc109)
    %260 = tt.broadcast %259 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc110)
    %261 = arith.muli %255, %157 : tensor<8x2x16xi32> loc(#loc111)
    %262 = "tt.reduce"(%261) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc132)
    %263 = tt.expand_dims %262 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc115)
    %264 = tt.broadcast %263 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc116)
    %265 = tt.reshape %260 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc117)
    %266 = tt.reshape %264 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc118)
    %267 = tt.bitcast %265 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %268 = tt.bitcast %266 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %269 = tt.bitcast %251 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %270 = arith.cmpf olt, %267, %268 : tensor<256xf32> loc(#loc122)
    %271 = arith.extui %270 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %272 = arith.xori %271, %253 : tensor<256xi32> loc(#loc123)
    %273 = arith.cmpi ne, %272, %cst : tensor<256xi32> loc(#loc124)
    %274 = arith.xori %265, %266 : tensor<256xi32> loc(#loc125)
    %275 = arith.select %273, %274, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %276 = arith.xori %269, %275 : tensor<256xi32> loc(#loc127)
    %277 = tt.bitcast %276 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %278 = tt.reshape %277 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc102)
    %279 = tt.bitcast %278 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc103)
    %280 = arith.muli %279, %161 : tensor<16x2x8xi32> loc(#loc105)
    %281 = "tt.reduce"(%280) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc129)
    %282 = tt.expand_dims %281 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc109)
    %283 = tt.broadcast %282 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc110)
    %284 = arith.muli %279, %85 : tensor<16x2x8xi32> loc(#loc111)
    %285 = "tt.reduce"(%284) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc132)
    %286 = tt.expand_dims %285 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc115)
    %287 = tt.broadcast %286 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc116)
    %288 = tt.reshape %283 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc117)
    %289 = tt.reshape %287 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc118)
    %290 = tt.bitcast %288 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %291 = tt.bitcast %289 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %292 = tt.bitcast %277 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %293 = arith.cmpf olt, %290, %291 : tensor<256xf32> loc(#loc122)
    %294 = arith.extui %293 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %295 = arith.xori %294, %253 : tensor<256xi32> loc(#loc123)
    %296 = arith.cmpi ne, %295, %cst : tensor<256xi32> loc(#loc124)
    %297 = arith.xori %288, %289 : tensor<256xi32> loc(#loc125)
    %298 = arith.select %296, %297, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %299 = arith.xori %292, %298 : tensor<256xi32> loc(#loc127)
    %300 = tt.bitcast %299 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %301 = tt.reshape %300 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc102)
    %302 = tt.bitcast %301 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc103)
    %303 = arith.muli %302, %89 : tensor<32x2x4xi32> loc(#loc105)
    %304 = "tt.reduce"(%303) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc129)
    %305 = tt.expand_dims %304 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc109)
    %306 = tt.broadcast %305 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc110)
    %307 = arith.muli %302, %36 : tensor<32x2x4xi32> loc(#loc111)
    %308 = "tt.reduce"(%307) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc132)
    %309 = tt.expand_dims %308 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc115)
    %310 = tt.broadcast %309 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc116)
    %311 = tt.reshape %306 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc117)
    %312 = tt.reshape %310 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc118)
    %313 = tt.bitcast %311 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %314 = tt.bitcast %312 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %315 = tt.bitcast %300 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %316 = arith.cmpf olt, %313, %314 : tensor<256xf32> loc(#loc122)
    %317 = arith.extui %316 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %318 = arith.xori %317, %253 : tensor<256xi32> loc(#loc123)
    %319 = arith.cmpi ne, %318, %cst : tensor<256xi32> loc(#loc124)
    %320 = arith.xori %311, %312 : tensor<256xi32> loc(#loc125)
    %321 = arith.select %319, %320, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %322 = arith.xori %315, %321 : tensor<256xi32> loc(#loc127)
    %323 = tt.bitcast %322 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %324 = tt.reshape %323 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc102)
    %325 = tt.bitcast %324 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc103)
    %326 = arith.muli %325, %40 : tensor<64x2x2xi32> loc(#loc105)
    %327 = "tt.reduce"(%326) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc129)
    %328 = tt.expand_dims %327 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc109)
    %329 = tt.broadcast %328 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc110)
    %330 = arith.muli %325, %8 : tensor<64x2x2xi32> loc(#loc111)
    %331 = "tt.reduce"(%330) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc132)
    %332 = tt.expand_dims %331 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc115)
    %333 = tt.broadcast %332 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc116)
    %334 = tt.reshape %329 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc117)
    %335 = tt.reshape %333 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc118)
    %336 = tt.bitcast %334 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %337 = tt.bitcast %335 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %338 = tt.bitcast %323 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %339 = arith.cmpf olt, %336, %337 : tensor<256xf32> loc(#loc122)
    %340 = arith.extui %339 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %341 = arith.xori %340, %253 : tensor<256xi32> loc(#loc123)
    %342 = arith.cmpi ne, %341, %cst : tensor<256xi32> loc(#loc124)
    %343 = arith.xori %334, %335 : tensor<256xi32> loc(#loc125)
    %344 = arith.select %342, %343, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %345 = arith.xori %338, %344 : tensor<256xi32> loc(#loc127)
    %346 = tt.bitcast %345 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %347 = tt.reshape %346 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %348 = tt.bitcast %347 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %349 = arith.muli %348, %13 : tensor<128x2x1xi32> loc(#loc105)
    %350 = "tt.reduce"(%349) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %351 = tt.expand_dims %350 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %352 = tt.broadcast %351 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %353 = arith.muli %348, %18 : tensor<128x2x1xi32> loc(#loc111)
    %354 = "tt.reduce"(%353) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %355 = tt.expand_dims %354 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %356 = tt.broadcast %355 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %357 = tt.reshape %352 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %358 = tt.reshape %356 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %359 = tt.bitcast %357 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %360 = tt.bitcast %358 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %361 = tt.bitcast %346 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %362 = arith.cmpf olt, %359, %360 : tensor<256xf32> loc(#loc122)
    %363 = arith.extui %362 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %364 = arith.xori %363, %253 : tensor<256xi32> loc(#loc123)
    %365 = arith.cmpi ne, %364, %cst : tensor<256xi32> loc(#loc124)
    %366 = arith.xori %357, %358 : tensor<256xi32> loc(#loc125)
    %367 = arith.select %365, %366, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %368 = arith.xori %361, %367 : tensor<256xi32> loc(#loc127)
    %369 = tt.bitcast %368 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %370 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<2x2x64xi32> loc(#loc73)
    %371 = tt.reshape %370 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc74)
    %372 = tt.reshape %369 : tensor<256xf32> -> tensor<4x2x32xf32> loc(#loc102)
    %373 = tt.bitcast %372 : tensor<4x2x32xf32> -> tensor<4x2x32xi32> loc(#loc103)
    %374 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<4x2x32xi32> loc(#loc105)
    %375 = arith.muli %373, %374 : tensor<4x2x32xi32> loc(#loc105)
    %376 = "tt.reduce"(%375) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc129)
    %377 = tt.expand_dims %376 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc109)
    %378 = tt.broadcast %377 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc110)
    %379 = arith.muli %373, %252 : tensor<4x2x32xi32> loc(#loc111)
    %380 = "tt.reduce"(%379) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc132)
    %381 = tt.expand_dims %380 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc115)
    %382 = tt.broadcast %381 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc116)
    %383 = tt.reshape %378 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc117)
    %384 = tt.reshape %382 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc118)
    %385 = tt.bitcast %383 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %386 = tt.bitcast %384 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %387 = tt.bitcast %369 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %388 = arith.cmpf olt, %385, %386 : tensor<256xf32> loc(#loc122)
    %389 = arith.extui %388 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %390 = arith.xori %389, %371 : tensor<256xi32> loc(#loc123)
    %391 = arith.cmpi ne, %390, %cst : tensor<256xi32> loc(#loc124)
    %392 = arith.xori %383, %384 : tensor<256xi32> loc(#loc125)
    %393 = arith.select %391, %392, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %394 = arith.xori %387, %393 : tensor<256xi32> loc(#loc127)
    %395 = tt.bitcast %394 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %396 = tt.reshape %395 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc102)
    %397 = tt.bitcast %396 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc103)
    %398 = arith.muli %397, %256 : tensor<8x2x16xi32> loc(#loc105)
    %399 = "tt.reduce"(%398) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc129)
    %400 = tt.expand_dims %399 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc109)
    %401 = tt.broadcast %400 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc110)
    %402 = arith.muli %397, %157 : tensor<8x2x16xi32> loc(#loc111)
    %403 = "tt.reduce"(%402) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc132)
    %404 = tt.expand_dims %403 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc115)
    %405 = tt.broadcast %404 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc116)
    %406 = tt.reshape %401 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc117)
    %407 = tt.reshape %405 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc118)
    %408 = tt.bitcast %406 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %409 = tt.bitcast %407 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %410 = tt.bitcast %395 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %411 = arith.cmpf olt, %408, %409 : tensor<256xf32> loc(#loc122)
    %412 = arith.extui %411 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %413 = arith.xori %412, %371 : tensor<256xi32> loc(#loc123)
    %414 = arith.cmpi ne, %413, %cst : tensor<256xi32> loc(#loc124)
    %415 = arith.xori %406, %407 : tensor<256xi32> loc(#loc125)
    %416 = arith.select %414, %415, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %417 = arith.xori %410, %416 : tensor<256xi32> loc(#loc127)
    %418 = tt.bitcast %417 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %419 = tt.reshape %418 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc102)
    %420 = tt.bitcast %419 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc103)
    %421 = arith.muli %420, %161 : tensor<16x2x8xi32> loc(#loc105)
    %422 = "tt.reduce"(%421) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc129)
    %423 = tt.expand_dims %422 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc109)
    %424 = tt.broadcast %423 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc110)
    %425 = arith.muli %420, %85 : tensor<16x2x8xi32> loc(#loc111)
    %426 = "tt.reduce"(%425) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc132)
    %427 = tt.expand_dims %426 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc115)
    %428 = tt.broadcast %427 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc116)
    %429 = tt.reshape %424 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc117)
    %430 = tt.reshape %428 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc118)
    %431 = tt.bitcast %429 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %432 = tt.bitcast %430 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %433 = tt.bitcast %418 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %434 = arith.cmpf olt, %431, %432 : tensor<256xf32> loc(#loc122)
    %435 = arith.extui %434 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %436 = arith.xori %435, %371 : tensor<256xi32> loc(#loc123)
    %437 = arith.cmpi ne, %436, %cst : tensor<256xi32> loc(#loc124)
    %438 = arith.xori %429, %430 : tensor<256xi32> loc(#loc125)
    %439 = arith.select %437, %438, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %440 = arith.xori %433, %439 : tensor<256xi32> loc(#loc127)
    %441 = tt.bitcast %440 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %442 = tt.reshape %441 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc102)
    %443 = tt.bitcast %442 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc103)
    %444 = arith.muli %443, %89 : tensor<32x2x4xi32> loc(#loc105)
    %445 = "tt.reduce"(%444) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc129)
    %446 = tt.expand_dims %445 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc109)
    %447 = tt.broadcast %446 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc110)
    %448 = arith.muli %443, %36 : tensor<32x2x4xi32> loc(#loc111)
    %449 = "tt.reduce"(%448) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc132)
    %450 = tt.expand_dims %449 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc115)
    %451 = tt.broadcast %450 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc116)
    %452 = tt.reshape %447 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc117)
    %453 = tt.reshape %451 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc118)
    %454 = tt.bitcast %452 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %455 = tt.bitcast %453 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %456 = tt.bitcast %441 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %457 = arith.cmpf olt, %454, %455 : tensor<256xf32> loc(#loc122)
    %458 = arith.extui %457 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %459 = arith.xori %458, %371 : tensor<256xi32> loc(#loc123)
    %460 = arith.cmpi ne, %459, %cst : tensor<256xi32> loc(#loc124)
    %461 = arith.xori %452, %453 : tensor<256xi32> loc(#loc125)
    %462 = arith.select %460, %461, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %463 = arith.xori %456, %462 : tensor<256xi32> loc(#loc127)
    %464 = tt.bitcast %463 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %465 = tt.reshape %464 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc102)
    %466 = tt.bitcast %465 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc103)
    %467 = arith.muli %466, %40 : tensor<64x2x2xi32> loc(#loc105)
    %468 = "tt.reduce"(%467) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc129)
    %469 = tt.expand_dims %468 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc109)
    %470 = tt.broadcast %469 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc110)
    %471 = arith.muli %466, %8 : tensor<64x2x2xi32> loc(#loc111)
    %472 = "tt.reduce"(%471) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc132)
    %473 = tt.expand_dims %472 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc115)
    %474 = tt.broadcast %473 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc116)
    %475 = tt.reshape %470 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc117)
    %476 = tt.reshape %474 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc118)
    %477 = tt.bitcast %475 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %478 = tt.bitcast %476 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %479 = tt.bitcast %464 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %480 = arith.cmpf olt, %477, %478 : tensor<256xf32> loc(#loc122)
    %481 = arith.extui %480 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %482 = arith.xori %481, %371 : tensor<256xi32> loc(#loc123)
    %483 = arith.cmpi ne, %482, %cst : tensor<256xi32> loc(#loc124)
    %484 = arith.xori %475, %476 : tensor<256xi32> loc(#loc125)
    %485 = arith.select %483, %484, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %486 = arith.xori %479, %485 : tensor<256xi32> loc(#loc127)
    %487 = tt.bitcast %486 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %488 = tt.reshape %487 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %489 = tt.bitcast %488 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %490 = arith.muli %489, %13 : tensor<128x2x1xi32> loc(#loc105)
    %491 = "tt.reduce"(%490) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %492 = tt.expand_dims %491 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %493 = tt.broadcast %492 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %494 = arith.muli %489, %18 : tensor<128x2x1xi32> loc(#loc111)
    %495 = "tt.reduce"(%494) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %496 = tt.expand_dims %495 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %497 = tt.broadcast %496 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %498 = tt.reshape %493 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %499 = tt.reshape %497 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %500 = tt.bitcast %498 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %501 = tt.bitcast %499 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %502 = tt.bitcast %487 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %503 = arith.cmpf olt, %500, %501 : tensor<256xf32> loc(#loc122)
    %504 = arith.extui %503 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %505 = arith.xori %504, %371 : tensor<256xi32> loc(#loc123)
    %506 = arith.cmpi ne, %505, %cst : tensor<256xi32> loc(#loc124)
    %507 = arith.xori %498, %499 : tensor<256xi32> loc(#loc125)
    %508 = arith.select %506, %507, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %509 = arith.xori %502, %508 : tensor<256xi32> loc(#loc127)
    %510 = tt.bitcast %509 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %511 = tt.broadcast %7 : tensor<1x2x1xi32> -> tensor<1x2x128xi32> loc(#loc73)
    %512 = tt.reshape %511 : tensor<1x2x128xi32> -> tensor<256xi32> loc(#loc74)
    %513 = tt.reshape %510 : tensor<256xf32> -> tensor<2x2x64xf32> loc(#loc102)
    %514 = tt.bitcast %513 : tensor<2x2x64xf32> -> tensor<2x2x64xi32> loc(#loc103)
    %515 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<2x2x64xi32> loc(#loc105)
    %516 = arith.muli %514, %515 : tensor<2x2x64xi32> loc(#loc105)
    %517 = "tt.reduce"(%516) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc129)
    %518 = tt.expand_dims %517 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc109)
    %519 = tt.broadcast %518 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc110)
    %520 = arith.muli %514, %370 : tensor<2x2x64xi32> loc(#loc111)
    %521 = "tt.reduce"(%520) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc132)
    %522 = tt.expand_dims %521 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc115)
    %523 = tt.broadcast %522 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc116)
    %524 = tt.reshape %519 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc117)
    %525 = tt.reshape %523 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc118)
    %526 = tt.bitcast %524 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %527 = tt.bitcast %525 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %528 = tt.bitcast %510 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %529 = arith.cmpf olt, %526, %527 : tensor<256xf32> loc(#loc122)
    %530 = arith.extui %529 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %531 = arith.xori %530, %512 : tensor<256xi32> loc(#loc123)
    %532 = arith.cmpi ne, %531, %cst : tensor<256xi32> loc(#loc124)
    %533 = arith.xori %524, %525 : tensor<256xi32> loc(#loc125)
    %534 = arith.select %532, %533, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %535 = arith.xori %528, %534 : tensor<256xi32> loc(#loc127)
    %536 = tt.bitcast %535 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %537 = tt.reshape %536 : tensor<256xf32> -> tensor<4x2x32xf32> loc(#loc102)
    %538 = tt.bitcast %537 : tensor<4x2x32xf32> -> tensor<4x2x32xi32> loc(#loc103)
    %539 = arith.muli %538, %374 : tensor<4x2x32xi32> loc(#loc105)
    %540 = "tt.reduce"(%539) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc129)
    %541 = tt.expand_dims %540 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc109)
    %542 = tt.broadcast %541 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc110)
    %543 = arith.muli %538, %252 : tensor<4x2x32xi32> loc(#loc111)
    %544 = "tt.reduce"(%543) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc132)
    %545 = tt.expand_dims %544 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc115)
    %546 = tt.broadcast %545 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc116)
    %547 = tt.reshape %542 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc117)
    %548 = tt.reshape %546 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc118)
    %549 = tt.bitcast %547 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %550 = tt.bitcast %548 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %551 = tt.bitcast %536 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %552 = arith.cmpf olt, %549, %550 : tensor<256xf32> loc(#loc122)
    %553 = arith.extui %552 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %554 = arith.xori %553, %512 : tensor<256xi32> loc(#loc123)
    %555 = arith.cmpi ne, %554, %cst : tensor<256xi32> loc(#loc124)
    %556 = arith.xori %547, %548 : tensor<256xi32> loc(#loc125)
    %557 = arith.select %555, %556, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %558 = arith.xori %551, %557 : tensor<256xi32> loc(#loc127)
    %559 = tt.bitcast %558 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %560 = tt.reshape %559 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc102)
    %561 = tt.bitcast %560 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc103)
    %562 = arith.muli %561, %256 : tensor<8x2x16xi32> loc(#loc105)
    %563 = "tt.reduce"(%562) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc129)
    %564 = tt.expand_dims %563 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc109)
    %565 = tt.broadcast %564 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc110)
    %566 = arith.muli %561, %157 : tensor<8x2x16xi32> loc(#loc111)
    %567 = "tt.reduce"(%566) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc132)
    %568 = tt.expand_dims %567 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc115)
    %569 = tt.broadcast %568 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc116)
    %570 = tt.reshape %565 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc117)
    %571 = tt.reshape %569 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc118)
    %572 = tt.bitcast %570 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %573 = tt.bitcast %571 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %574 = tt.bitcast %559 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %575 = arith.cmpf olt, %572, %573 : tensor<256xf32> loc(#loc122)
    %576 = arith.extui %575 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %577 = arith.xori %576, %512 : tensor<256xi32> loc(#loc123)
    %578 = arith.cmpi ne, %577, %cst : tensor<256xi32> loc(#loc124)
    %579 = arith.xori %570, %571 : tensor<256xi32> loc(#loc125)
    %580 = arith.select %578, %579, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %581 = arith.xori %574, %580 : tensor<256xi32> loc(#loc127)
    %582 = tt.bitcast %581 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %583 = tt.reshape %582 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc102)
    %584 = tt.bitcast %583 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc103)
    %585 = arith.muli %584, %161 : tensor<16x2x8xi32> loc(#loc105)
    %586 = "tt.reduce"(%585) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc129)
    %587 = tt.expand_dims %586 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc109)
    %588 = tt.broadcast %587 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc110)
    %589 = arith.muli %584, %85 : tensor<16x2x8xi32> loc(#loc111)
    %590 = "tt.reduce"(%589) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc132)
    %591 = tt.expand_dims %590 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc115)
    %592 = tt.broadcast %591 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc116)
    %593 = tt.reshape %588 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc117)
    %594 = tt.reshape %592 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc118)
    %595 = tt.bitcast %593 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %596 = tt.bitcast %594 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %597 = tt.bitcast %582 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %598 = arith.cmpf olt, %595, %596 : tensor<256xf32> loc(#loc122)
    %599 = arith.extui %598 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %600 = arith.xori %599, %512 : tensor<256xi32> loc(#loc123)
    %601 = arith.cmpi ne, %600, %cst : tensor<256xi32> loc(#loc124)
    %602 = arith.xori %593, %594 : tensor<256xi32> loc(#loc125)
    %603 = arith.select %601, %602, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %604 = arith.xori %597, %603 : tensor<256xi32> loc(#loc127)
    %605 = tt.bitcast %604 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %606 = tt.reshape %605 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc102)
    %607 = tt.bitcast %606 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc103)
    %608 = arith.muli %607, %89 : tensor<32x2x4xi32> loc(#loc105)
    %609 = "tt.reduce"(%608) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc129)
    %610 = tt.expand_dims %609 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc109)
    %611 = tt.broadcast %610 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc110)
    %612 = arith.muli %607, %36 : tensor<32x2x4xi32> loc(#loc111)
    %613 = "tt.reduce"(%612) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc132)
    %614 = tt.expand_dims %613 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc115)
    %615 = tt.broadcast %614 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc116)
    %616 = tt.reshape %611 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc117)
    %617 = tt.reshape %615 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc118)
    %618 = tt.bitcast %616 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %619 = tt.bitcast %617 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %620 = tt.bitcast %605 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %621 = arith.cmpf olt, %618, %619 : tensor<256xf32> loc(#loc122)
    %622 = arith.extui %621 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %623 = arith.xori %622, %512 : tensor<256xi32> loc(#loc123)
    %624 = arith.cmpi ne, %623, %cst : tensor<256xi32> loc(#loc124)
    %625 = arith.xori %616, %617 : tensor<256xi32> loc(#loc125)
    %626 = arith.select %624, %625, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %627 = arith.xori %620, %626 : tensor<256xi32> loc(#loc127)
    %628 = tt.bitcast %627 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %629 = tt.reshape %628 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc102)
    %630 = tt.bitcast %629 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc103)
    %631 = arith.muli %630, %40 : tensor<64x2x2xi32> loc(#loc105)
    %632 = "tt.reduce"(%631) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc129)
    %633 = tt.expand_dims %632 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc109)
    %634 = tt.broadcast %633 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc110)
    %635 = arith.muli %630, %8 : tensor<64x2x2xi32> loc(#loc111)
    %636 = "tt.reduce"(%635) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc132)
    %637 = tt.expand_dims %636 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc115)
    %638 = tt.broadcast %637 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc116)
    %639 = tt.reshape %634 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc117)
    %640 = tt.reshape %638 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc118)
    %641 = tt.bitcast %639 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %642 = tt.bitcast %640 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %643 = tt.bitcast %628 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %644 = arith.cmpf olt, %641, %642 : tensor<256xf32> loc(#loc122)
    %645 = arith.extui %644 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %646 = arith.xori %645, %512 : tensor<256xi32> loc(#loc123)
    %647 = arith.cmpi ne, %646, %cst : tensor<256xi32> loc(#loc124)
    %648 = arith.xori %639, %640 : tensor<256xi32> loc(#loc125)
    %649 = arith.select %647, %648, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %650 = arith.xori %643, %649 : tensor<256xi32> loc(#loc127)
    %651 = tt.bitcast %650 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %652 = tt.reshape %651 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %653 = tt.bitcast %652 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %654 = arith.muli %653, %13 : tensor<128x2x1xi32> loc(#loc105)
    %655 = "tt.reduce"(%654) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %656 = tt.expand_dims %655 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %657 = tt.broadcast %656 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %658 = arith.muli %653, %18 : tensor<128x2x1xi32> loc(#loc111)
    %659 = "tt.reduce"(%658) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %660 = tt.expand_dims %659 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %661 = tt.broadcast %660 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %662 = tt.reshape %657 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %663 = tt.reshape %661 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %664 = tt.bitcast %662 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %665 = tt.bitcast %663 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %666 = tt.bitcast %651 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %667 = arith.cmpf olt, %664, %665 : tensor<256xf32> loc(#loc122)
    %668 = arith.extui %667 : tensor<256xi1> to tensor<256xi32> loc(#loc123)
    %669 = arith.xori %668, %512 : tensor<256xi32> loc(#loc123)
    %670 = arith.cmpi ne, %669, %cst : tensor<256xi32> loc(#loc124)
    %671 = arith.xori %662, %663 : tensor<256xi32> loc(#loc125)
    %672 = arith.select %670, %671, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %673 = arith.xori %666, %672 : tensor<256xi32> loc(#loc127)
    %674 = tt.bitcast %673 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %675 = tt.reshape %674 : tensor<256xf32> -> tensor<1x2x128xf32> loc(#loc102)
    %676 = tt.bitcast %675 : tensor<1x2x128xf32> -> tensor<1x2x128xi32> loc(#loc103)
    %677 = tt.broadcast %12 : tensor<1x2x1xi32> -> tensor<1x2x128xi32> loc(#loc105)
    %678 = arith.muli %676, %677 : tensor<1x2x128xi32> loc(#loc105)
    %679 = "tt.reduce"(%678) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<1x2x128xi32>) -> tensor<1x128xi32> loc(#loc129)
    %680 = tt.expand_dims %679 {axis = 1 : i32} : tensor<1x128xi32> -> tensor<1x1x128xi32> loc(#loc109)
    %681 = tt.broadcast %680 : tensor<1x1x128xi32> -> tensor<1x2x128xi32> loc(#loc110)
    %682 = arith.muli %676, %511 : tensor<1x2x128xi32> loc(#loc111)
    %683 = "tt.reduce"(%682) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<1x2x128xi32>) -> tensor<1x128xi32> loc(#loc132)
    %684 = tt.expand_dims %683 {axis = 1 : i32} : tensor<1x128xi32> -> tensor<1x1x128xi32> loc(#loc115)
    %685 = tt.broadcast %684 : tensor<1x1x128xi32> -> tensor<1x2x128xi32> loc(#loc116)
    %686 = tt.reshape %681 : tensor<1x2x128xi32> -> tensor<256xi32> loc(#loc117)
    %687 = tt.reshape %685 : tensor<1x2x128xi32> -> tensor<256xi32> loc(#loc118)
    %688 = tt.bitcast %686 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %689 = tt.bitcast %687 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %690 = tt.bitcast %674 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %691 = arith.cmpf olt, %688, %689 : tensor<256xf32> loc(#loc122)
    %692 = arith.xori %686, %687 : tensor<256xi32> loc(#loc125)
    %693 = arith.select %691, %692, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %694 = arith.xori %690, %693 : tensor<256xi32> loc(#loc127)
    %695 = tt.bitcast %694 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %696 = tt.reshape %695 : tensor<256xf32> -> tensor<2x2x64xf32> loc(#loc102)
    %697 = tt.bitcast %696 : tensor<2x2x64xf32> -> tensor<2x2x64xi32> loc(#loc103)
    %698 = arith.muli %697, %515 : tensor<2x2x64xi32> loc(#loc105)
    %699 = "tt.reduce"(%698) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc129)
    %700 = tt.expand_dims %699 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc109)
    %701 = tt.broadcast %700 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc110)
    %702 = arith.muli %697, %370 : tensor<2x2x64xi32> loc(#loc111)
    %703 = "tt.reduce"(%702) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<2x2x64xi32>) -> tensor<2x64xi32> loc(#loc132)
    %704 = tt.expand_dims %703 {axis = 1 : i32} : tensor<2x64xi32> -> tensor<2x1x64xi32> loc(#loc115)
    %705 = tt.broadcast %704 : tensor<2x1x64xi32> -> tensor<2x2x64xi32> loc(#loc116)
    %706 = tt.reshape %701 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc117)
    %707 = tt.reshape %705 : tensor<2x2x64xi32> -> tensor<256xi32> loc(#loc118)
    %708 = tt.bitcast %706 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %709 = tt.bitcast %707 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %710 = tt.bitcast %695 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %711 = arith.cmpf olt, %708, %709 : tensor<256xf32> loc(#loc122)
    %712 = arith.xori %706, %707 : tensor<256xi32> loc(#loc125)
    %713 = arith.select %711, %712, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %714 = arith.xori %710, %713 : tensor<256xi32> loc(#loc127)
    %715 = tt.bitcast %714 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %716 = tt.reshape %715 : tensor<256xf32> -> tensor<4x2x32xf32> loc(#loc102)
    %717 = tt.bitcast %716 : tensor<4x2x32xf32> -> tensor<4x2x32xi32> loc(#loc103)
    %718 = arith.muli %717, %374 : tensor<4x2x32xi32> loc(#loc105)
    %719 = "tt.reduce"(%718) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc129)
    %720 = tt.expand_dims %719 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc109)
    %721 = tt.broadcast %720 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc110)
    %722 = arith.muli %717, %252 : tensor<4x2x32xi32> loc(#loc111)
    %723 = "tt.reduce"(%722) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<4x2x32xi32>) -> tensor<4x32xi32> loc(#loc132)
    %724 = tt.expand_dims %723 {axis = 1 : i32} : tensor<4x32xi32> -> tensor<4x1x32xi32> loc(#loc115)
    %725 = tt.broadcast %724 : tensor<4x1x32xi32> -> tensor<4x2x32xi32> loc(#loc116)
    %726 = tt.reshape %721 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc117)
    %727 = tt.reshape %725 : tensor<4x2x32xi32> -> tensor<256xi32> loc(#loc118)
    %728 = tt.bitcast %726 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %729 = tt.bitcast %727 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %730 = tt.bitcast %715 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %731 = arith.cmpf olt, %728, %729 : tensor<256xf32> loc(#loc122)
    %732 = arith.xori %726, %727 : tensor<256xi32> loc(#loc125)
    %733 = arith.select %731, %732, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %734 = arith.xori %730, %733 : tensor<256xi32> loc(#loc127)
    %735 = tt.bitcast %734 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %736 = tt.reshape %735 : tensor<256xf32> -> tensor<8x2x16xf32> loc(#loc102)
    %737 = tt.bitcast %736 : tensor<8x2x16xf32> -> tensor<8x2x16xi32> loc(#loc103)
    %738 = arith.muli %737, %256 : tensor<8x2x16xi32> loc(#loc105)
    %739 = "tt.reduce"(%738) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc129)
    %740 = tt.expand_dims %739 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc109)
    %741 = tt.broadcast %740 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc110)
    %742 = arith.muli %737, %157 : tensor<8x2x16xi32> loc(#loc111)
    %743 = "tt.reduce"(%742) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<8x2x16xi32>) -> tensor<8x16xi32> loc(#loc132)
    %744 = tt.expand_dims %743 {axis = 1 : i32} : tensor<8x16xi32> -> tensor<8x1x16xi32> loc(#loc115)
    %745 = tt.broadcast %744 : tensor<8x1x16xi32> -> tensor<8x2x16xi32> loc(#loc116)
    %746 = tt.reshape %741 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc117)
    %747 = tt.reshape %745 : tensor<8x2x16xi32> -> tensor<256xi32> loc(#loc118)
    %748 = tt.bitcast %746 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %749 = tt.bitcast %747 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %750 = tt.bitcast %735 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %751 = arith.cmpf olt, %748, %749 : tensor<256xf32> loc(#loc122)
    %752 = arith.xori %746, %747 : tensor<256xi32> loc(#loc125)
    %753 = arith.select %751, %752, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %754 = arith.xori %750, %753 : tensor<256xi32> loc(#loc127)
    %755 = tt.bitcast %754 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %756 = tt.reshape %755 : tensor<256xf32> -> tensor<16x2x8xf32> loc(#loc102)
    %757 = tt.bitcast %756 : tensor<16x2x8xf32> -> tensor<16x2x8xi32> loc(#loc103)
    %758 = arith.muli %757, %161 : tensor<16x2x8xi32> loc(#loc105)
    %759 = "tt.reduce"(%758) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc129)
    %760 = tt.expand_dims %759 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc109)
    %761 = tt.broadcast %760 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc110)
    %762 = arith.muli %757, %85 : tensor<16x2x8xi32> loc(#loc111)
    %763 = "tt.reduce"(%762) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<16x2x8xi32>) -> tensor<16x8xi32> loc(#loc132)
    %764 = tt.expand_dims %763 {axis = 1 : i32} : tensor<16x8xi32> -> tensor<16x1x8xi32> loc(#loc115)
    %765 = tt.broadcast %764 : tensor<16x1x8xi32> -> tensor<16x2x8xi32> loc(#loc116)
    %766 = tt.reshape %761 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc117)
    %767 = tt.reshape %765 : tensor<16x2x8xi32> -> tensor<256xi32> loc(#loc118)
    %768 = tt.bitcast %766 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %769 = tt.bitcast %767 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %770 = tt.bitcast %755 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %771 = arith.cmpf olt, %768, %769 : tensor<256xf32> loc(#loc122)
    %772 = arith.xori %766, %767 : tensor<256xi32> loc(#loc125)
    %773 = arith.select %771, %772, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %774 = arith.xori %770, %773 : tensor<256xi32> loc(#loc127)
    %775 = tt.bitcast %774 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %776 = tt.reshape %775 : tensor<256xf32> -> tensor<32x2x4xf32> loc(#loc102)
    %777 = tt.bitcast %776 : tensor<32x2x4xf32> -> tensor<32x2x4xi32> loc(#loc103)
    %778 = arith.muli %777, %89 : tensor<32x2x4xi32> loc(#loc105)
    %779 = "tt.reduce"(%778) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc129)
    %780 = tt.expand_dims %779 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc109)
    %781 = tt.broadcast %780 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc110)
    %782 = arith.muli %777, %36 : tensor<32x2x4xi32> loc(#loc111)
    %783 = "tt.reduce"(%782) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<32x2x4xi32>) -> tensor<32x4xi32> loc(#loc132)
    %784 = tt.expand_dims %783 {axis = 1 : i32} : tensor<32x4xi32> -> tensor<32x1x4xi32> loc(#loc115)
    %785 = tt.broadcast %784 : tensor<32x1x4xi32> -> tensor<32x2x4xi32> loc(#loc116)
    %786 = tt.reshape %781 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc117)
    %787 = tt.reshape %785 : tensor<32x2x4xi32> -> tensor<256xi32> loc(#loc118)
    %788 = tt.bitcast %786 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %789 = tt.bitcast %787 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %790 = tt.bitcast %775 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %791 = arith.cmpf olt, %788, %789 : tensor<256xf32> loc(#loc122)
    %792 = arith.xori %786, %787 : tensor<256xi32> loc(#loc125)
    %793 = arith.select %791, %792, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %794 = arith.xori %790, %793 : tensor<256xi32> loc(#loc127)
    %795 = tt.bitcast %794 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %796 = tt.reshape %795 : tensor<256xf32> -> tensor<64x2x2xf32> loc(#loc102)
    %797 = tt.bitcast %796 : tensor<64x2x2xf32> -> tensor<64x2x2xi32> loc(#loc103)
    %798 = arith.muli %797, %40 : tensor<64x2x2xi32> loc(#loc105)
    %799 = "tt.reduce"(%798) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc129)
    %800 = tt.expand_dims %799 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc109)
    %801 = tt.broadcast %800 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc110)
    %802 = arith.muli %797, %8 : tensor<64x2x2xi32> loc(#loc111)
    %803 = "tt.reduce"(%802) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<64x2x2xi32>) -> tensor<64x2xi32> loc(#loc132)
    %804 = tt.expand_dims %803 {axis = 1 : i32} : tensor<64x2xi32> -> tensor<64x1x2xi32> loc(#loc115)
    %805 = tt.broadcast %804 : tensor<64x1x2xi32> -> tensor<64x2x2xi32> loc(#loc116)
    %806 = tt.reshape %801 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc117)
    %807 = tt.reshape %805 : tensor<64x2x2xi32> -> tensor<256xi32> loc(#loc118)
    %808 = tt.bitcast %806 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %809 = tt.bitcast %807 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %810 = tt.bitcast %795 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %811 = arith.cmpf olt, %808, %809 : tensor<256xf32> loc(#loc122)
    %812 = arith.xori %806, %807 : tensor<256xi32> loc(#loc125)
    %813 = arith.select %811, %812, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %814 = arith.xori %810, %813 : tensor<256xi32> loc(#loc127)
    %815 = tt.bitcast %814 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %816 = tt.reshape %815 : tensor<256xf32> -> tensor<128x2x1xf32> loc(#loc102)
    %817 = tt.bitcast %816 : tensor<128x2x1xf32> -> tensor<128x2x1xi32> loc(#loc103)
    %818 = arith.muli %817, %13 : tensor<128x2x1xi32> loc(#loc105)
    %819 = "tt.reduce"(%818) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc107 at #loc8)), %arg4: i32 loc(callsite(#loc107 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc135)
      tt.reduce.return %838 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc129)
    %820 = tt.expand_dims %819 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc109)
    %821 = tt.broadcast %820 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc110)
    %822 = arith.muli %817, %18 : tensor<128x2x1xi32> loc(#loc111)
    %823 = "tt.reduce"(%822) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc113 at #loc8)), %arg4: i32 loc(callsite(#loc113 at #loc8))):
      %838 = arith.addi %arg3, %arg4 : i32 loc(#loc136)
      tt.reduce.return %838 : i32 loc(#loc132)
    }) : (tensor<128x2x1xi32>) -> tensor<128x1xi32> loc(#loc132)
    %824 = tt.expand_dims %823 {axis = 1 : i32} : tensor<128x1xi32> -> tensor<128x1x1xi32> loc(#loc115)
    %825 = tt.broadcast %824 : tensor<128x1x1xi32> -> tensor<128x2x1xi32> loc(#loc116)
    %826 = tt.reshape %821 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc117)
    %827 = tt.reshape %825 : tensor<128x2x1xi32> -> tensor<256xi32> loc(#loc118)
    %828 = tt.bitcast %826 : tensor<256xi32> -> tensor<256xf32> loc(#loc119)
    %829 = tt.bitcast %827 : tensor<256xi32> -> tensor<256xf32> loc(#loc120)
    %830 = tt.bitcast %815 : tensor<256xf32> -> tensor<256xi32> loc(#loc121)
    %831 = arith.cmpf olt, %828, %829 : tensor<256xf32> loc(#loc122)
    %832 = arith.xori %826, %827 : tensor<256xi32> loc(#loc125)
    %833 = arith.select %831, %832, %cst : tensor<256xi1>, tensor<256xi32> loc(#loc126)
    %834 = arith.xori %830, %833 : tensor<256xi32> loc(#loc127)
    %835 = tt.bitcast %834 : tensor<256xi32> -> tensor<256xf32> loc(#loc128)
    %836 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>> loc(#loc38)
    %837 = tt.addptr %836, %0 : tensor<256x!tt.ptr<f32>>, tensor<256xi32> loc(#loc38)
    tt.store %837, %835 : tensor<256x!tt.ptr<f32>> loc(#loc39)
    tt.return loc(#loc40)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":27:26)
#loc3 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":31:30)
#loc4 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":31:35)
#loc5 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":32:23)
#loc6 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:41)
#loc9 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:44)
#loc10 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:60)
#loc11 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:68)
#loc12 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":501:22)
#loc14 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":502:14)
#loc15 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":505:21)
#loc16 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:40)
#loc17 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":267:36)
#loc19 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":256:15)
#loc20 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:54)
#loc21 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:67)
#loc22 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:41)
#loc24 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:56)
#loc25 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:69)
#loc26 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":508:30)
#loc27 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":509:32)
#loc28 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":510:20)
#loc29 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":511:22)
#loc30 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":533:14)
#loc31 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":536:22)
#loc32 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:19)
#loc33 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:28)
#loc34 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:38)
#loc35 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:46)
#loc36 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:15)
#loc37 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":551:18)
#loc38 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":38:25)
#loc39 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":38:63)
#loc40 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":38:4)
#loc41 = loc(callsite(#loc6 at #loc7))
#loc42 = loc(callsite(#loc9 at #loc7))
#loc43 = loc(callsite(#loc10 at #loc7))
#loc44 = loc(callsite(#loc11 at #loc7))
#loc45 = loc(callsite(#loc12 at #loc13))
#loc46 = loc(callsite(#loc14 at #loc13))
#loc47 = loc(callsite(#loc15 at #loc13))
#loc48 = loc(callsite(#loc16 at #loc13))
#loc49 = loc(callsite(#loc17 at #loc18))
#loc51 = loc(callsite(#loc19 at #loc17))
#loc52 = loc(callsite(#loc20 at #loc13))
#loc53 = loc(callsite(#loc21 at #loc13))
#loc54 = loc(callsite(#loc22 at #loc13))
#loc55 = loc(callsite(#loc17 at #loc23))
#loc57 = loc(callsite(#loc24 at #loc13))
#loc58 = loc(callsite(#loc25 at #loc13))
#loc59 = loc(callsite(#loc26 at #loc13))
#loc60 = loc(callsite(#loc27 at #loc13))
#loc61 = loc(callsite(#loc28 at #loc13))
#loc62 = loc(callsite(#loc29 at #loc13))
#loc63 = loc(callsite(#loc30 at #loc13))
#loc64 = loc(callsite(#loc31 at #loc13))
#loc65 = loc(callsite(#loc32 at #loc13))
#loc66 = loc(callsite(#loc33 at #loc13))
#loc67 = loc(callsite(#loc34 at #loc13))
#loc68 = loc(callsite(#loc35 at #loc13))
#loc69 = loc(callsite(#loc36 at #loc13))
#loc70 = loc(callsite(#loc37 at #loc13))
#loc71 = loc(callsite(#loc41 at #loc8))
#loc72 = loc(callsite(#loc42 at #loc8))
#loc73 = loc(callsite(#loc43 at #loc8))
#loc74 = loc(callsite(#loc44 at #loc8))
#loc75 = loc(callsite(#loc45 at #loc7))
#loc76 = loc(callsite(#loc46 at #loc7))
#loc77 = loc(callsite(#loc47 at #loc7))
#loc78 = loc(callsite(#loc48 at #loc7))
#loc79 = loc(callsite(#loc49 at #loc13))
#loc81 = loc(callsite(#loc51 at #loc18))
#loc82 = loc(callsite(#loc52 at #loc7))
#loc83 = loc(callsite(#loc53 at #loc7))
#loc84 = loc(callsite(#loc54 at #loc7))
#loc85 = loc(callsite(#loc55 at #loc13))
#loc87 = loc(callsite(#loc51 at #loc23))
#loc88 = loc(callsite(#loc57 at #loc7))
#loc89 = loc(callsite(#loc58 at #loc7))
#loc90 = loc(callsite(#loc59 at #loc7))
#loc91 = loc(callsite(#loc60 at #loc7))
#loc92 = loc(callsite(#loc61 at #loc7))
#loc93 = loc(callsite(#loc62 at #loc7))
#loc94 = loc(callsite(#loc63 at #loc7))
#loc95 = loc(callsite(#loc64 at #loc7))
#loc96 = loc(callsite(#loc65 at #loc7))
#loc97 = loc(callsite(#loc66 at #loc7))
#loc98 = loc(callsite(#loc67 at #loc7))
#loc99 = loc(callsite(#loc68 at #loc7))
#loc100 = loc(callsite(#loc69 at #loc7))
#loc101 = loc(callsite(#loc70 at #loc7))
#loc102 = loc(callsite(#loc75 at #loc8))
#loc103 = loc(callsite(#loc76 at #loc8))
#loc104 = loc(callsite(#loc77 at #loc8))
#loc105 = loc(callsite(#loc78 at #loc8))
#loc106 = loc(callsite(#loc79 at #loc7))
#loc108 = loc(callsite(#loc81 at #loc13))
#loc109 = loc(callsite(#loc82 at #loc8))
#loc110 = loc(callsite(#loc83 at #loc8))
#loc111 = loc(callsite(#loc84 at #loc8))
#loc112 = loc(callsite(#loc85 at #loc7))
#loc114 = loc(callsite(#loc87 at #loc13))
#loc115 = loc(callsite(#loc88 at #loc8))
#loc116 = loc(callsite(#loc89 at #loc8))
#loc117 = loc(callsite(#loc90 at #loc8))
#loc118 = loc(callsite(#loc91 at #loc8))
#loc119 = loc(callsite(#loc92 at #loc8))
#loc120 = loc(callsite(#loc93 at #loc8))
#loc121 = loc(callsite(#loc94 at #loc8))
#loc122 = loc(callsite(#loc95 at #loc8))
#loc123 = loc(callsite(#loc96 at #loc8))
#loc124 = loc(callsite(#loc97 at #loc8))
#loc125 = loc(callsite(#loc98 at #loc8))
#loc126 = loc(callsite(#loc99 at #loc8))
#loc127 = loc(callsite(#loc100 at #loc8))
#loc128 = loc(callsite(#loc101 at #loc8))
#loc129 = loc(callsite(#loc106 at #loc8))
#loc131 = loc(callsite(#loc108 at #loc7))
#loc132 = loc(callsite(#loc112 at #loc8))
#loc134 = loc(callsite(#loc114 at #loc7))
#loc135 = loc(callsite(#loc131 at #loc8))
#loc136 = loc(callsite(#loc134 at #loc8))
