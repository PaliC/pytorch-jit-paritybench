#blocked = #triton_gpu.blocked<{sizePerThread = [4], threadsPerWarp = [32], warpsPerCTA = [2], order = [0]}>
#blocked1 = #triton_gpu.blocked<{sizePerThread = [2, 2, 1], threadsPerWarp = [32, 1, 1], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked2 = #triton_gpu.blocked<{sizePerThread = [1, 2, 2], threadsPerWarp = [32, 1, 1], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked3 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [16, 2, 1], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked4 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [8, 2, 2], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked5 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [4, 2, 4], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked6 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [2, 2, 8], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked7 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [1, 2, 16], warpsPerCTA = [2, 1, 1], order = [2, 1, 0]}>
#blocked8 = #triton_gpu.blocked<{sizePerThread = [1, 1, 4], threadsPerWarp = [1, 1, 32], warpsPerCTA = [1, 2, 1], order = [2, 1, 0]}>
#loc = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0)
#loc1 = loc(unknown)
#loc7 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":610:12)
#loc8 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":37:67)
#loc12 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":582:73)
#loc17 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:51)
#loc22 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:53)
#loc48 = loc(callsite(#loc1 at #loc17))
#loc54 = loc(callsite(#loc1 at #loc22))
#loc77 = loc(callsite(#loc48 at #loc12))
#loc83 = loc(callsite(#loc54 at #loc12))
#loc104 = loc(callsite(#loc77 at #loc7))
#loc110 = loc(callsite(#loc83 at #loc7))
#loc127 = loc(callsite(#loc104 at #loc8))
#loc130 = loc(callsite(#loc110 at #loc8))
module attributes {"triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 2 : i32, triton_gpu.target = "cuda:90", "triton_gpu.threads-per-warp" = 32 : i32} {
  tt.func public @triton_per_fused_sort_0(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0), %arg2: i32 {tt.divisibility = 16 : i32} loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":19:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0> : tensor<256xi32, #blocked> loc(#loc1)
    %cst_0 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked2> loc(#loc1)
    %cst_2 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked3> loc(#loc1)
    %cst_3 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked4> loc(#loc1)
    %cst_4 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked5> loc(#loc1)
    %cst_5 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked6> loc(#loc1)
    %cst_6 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked7> loc(#loc1)
    %cst_7 = arith.constant dense<1> : tensor<1x2x1xi32, #blocked8> loc(#loc1)
    %0 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked> loc(#loc2)
    %1 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc3)
    %2 = tt.addptr %1, %0 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc3)
    %3 = tt.load %2 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc4)
    %4 = math.absf %3 : tensor<256xf32, #blocked> loc(#loc5)
    %5 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked2}>}>> loc(#loc69)
    %6 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked1}>}>> loc(#loc69)
    %7 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked3}>}>> loc(#loc69)
    %8 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked4}>}>> loc(#loc69)
    %9 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked5}>}>> loc(#loc69)
    %10 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked6}>}>> loc(#loc69)
    %11 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked7}>}>> loc(#loc69)
    %12 = tt.make_range {end = 2 : i32, start = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked8}>}>> loc(#loc69)
    %13 = tt.expand_dims %5 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked2}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked2}>> loc(#loc69)
    %14 = tt.expand_dims %6 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked1}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked1}>> loc(#loc69)
    %15 = tt.expand_dims %7 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked3}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked3}>> loc(#loc69)
    %16 = tt.expand_dims %8 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked4}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked4}>> loc(#loc69)
    %17 = tt.expand_dims %9 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked5}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked5}>> loc(#loc69)
    %18 = tt.expand_dims %10 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked6}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked6}>> loc(#loc69)
    %19 = tt.expand_dims %11 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked7}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked7}>> loc(#loc69)
    %20 = tt.expand_dims %12 {axis = 0 : i32} : tensor<2xi32, #triton_gpu.slice<{dim = 0, parent = #triton_gpu.slice<{dim = 2, parent = #blocked8}>}>> -> tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked8}>> loc(#loc69)
    %21 = tt.expand_dims %13 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked2}>> -> tensor<1x2x1xi32, #blocked2> loc(#loc69)
    %22 = tt.expand_dims %14 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked1}>> -> tensor<1x2x1xi32, #blocked1> loc(#loc69)
    %23 = tt.expand_dims %15 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked3}>> -> tensor<1x2x1xi32, #blocked3> loc(#loc69)
    %24 = tt.expand_dims %16 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked4}>> -> tensor<1x2x1xi32, #blocked4> loc(#loc69)
    %25 = tt.expand_dims %17 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked5}>> -> tensor<1x2x1xi32, #blocked5> loc(#loc69)
    %26 = tt.expand_dims %18 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked6}>> -> tensor<1x2x1xi32, #blocked6> loc(#loc69)
    %27 = tt.expand_dims %19 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked7}>> -> tensor<1x2x1xi32, #blocked7> loc(#loc69)
    %28 = tt.expand_dims %20 {axis = 2 : i32} : tensor<1x2xi32, #triton_gpu.slice<{dim = 2, parent = #blocked8}>> -> tensor<1x2x1xi32, #blocked8> loc(#loc69)
    %29 = tt.broadcast %21 : tensor<1x2x1xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc70)
    %30 = tt.reshape %29 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc71)
    %31 = tt.reshape %4 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %32 = tt.bitcast %31 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %33 = arith.subi %cst_0, %22 : tensor<1x2x1xi32, #blocked1> loc(#loc101)
    %34 = arith.subi %cst_1, %21 : tensor<1x2x1xi32, #blocked2> loc(#loc101)
    %35 = arith.subi %cst_2, %23 : tensor<1x2x1xi32, #blocked3> loc(#loc101)
    %36 = arith.subi %cst_3, %24 : tensor<1x2x1xi32, #blocked4> loc(#loc101)
    %37 = arith.subi %cst_4, %25 : tensor<1x2x1xi32, #blocked5> loc(#loc101)
    %38 = arith.subi %cst_5, %26 : tensor<1x2x1xi32, #blocked6> loc(#loc101)
    %39 = arith.subi %cst_6, %27 : tensor<1x2x1xi32, #blocked7> loc(#loc101)
    %40 = arith.subi %cst_7, %28 : tensor<1x2x1xi32, #blocked8> loc(#loc101)
    %41 = tt.broadcast %33 : tensor<1x2x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %42 = arith.muli %32, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %43 = "tt.reduce"(%42) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %45 = tt.broadcast %44 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %46 = tt.broadcast %22 : tensor<1x2x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %47 = arith.muli %32, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %48 = "tt.reduce"(%47) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %49 = tt.expand_dims %48 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %50 = tt.broadcast %49 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %51 = tt.reshape %45 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %52 = tt.reshape %50 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %53 = tt.bitcast %51 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %54 = tt.bitcast %52 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %55 = tt.bitcast %4 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %56 = arith.cmpf olt, %53, %54 : tensor<256xf32, #blocked> loc(#loc119)
    %57 = arith.extui %56 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %58 = arith.xori %57, %30 : tensor<256xi32, #blocked> loc(#loc120)
    %59 = arith.cmpi ne, %58, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %60 = arith.xori %51, %52 : tensor<256xi32, #blocked> loc(#loc122)
    %61 = arith.select %59, %60, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %62 = arith.xori %55, %61 : tensor<256xi32, #blocked> loc(#loc124)
    %63 = tt.bitcast %62 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %64 = tt.broadcast %23 : tensor<1x2x1xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc70)
    %65 = tt.reshape %64 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc71)
    %66 = tt.reshape %63 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc99)
    %67 = tt.bitcast %66 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc100)
    %68 = tt.broadcast %34 : tensor<1x2x1xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %69 = arith.muli %67, %68 : tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %70 = "tt.reduce"(%69) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc126)
    %71 = tt.expand_dims %70 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc106)
    %72 = tt.broadcast %71 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc107)
    %73 = arith.muli %67, %29 : tensor<64x2x2xi32, #blocked2> loc(#loc108)
    %74 = "tt.reduce"(%73) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc129)
    %75 = tt.expand_dims %74 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc112)
    %76 = tt.broadcast %75 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc113)
    %77 = tt.reshape %72 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc114)
    %78 = tt.reshape %76 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc115)
    %79 = tt.bitcast %77 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %80 = tt.bitcast %78 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %81 = tt.bitcast %63 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %82 = arith.cmpf olt, %79, %80 : tensor<256xf32, #blocked> loc(#loc119)
    %83 = arith.extui %82 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %84 = arith.xori %83, %65 : tensor<256xi32, #blocked> loc(#loc120)
    %85 = arith.cmpi ne, %84, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %86 = arith.xori %77, %78 : tensor<256xi32, #blocked> loc(#loc122)
    %87 = arith.select %85, %86, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %88 = arith.xori %81, %87 : tensor<256xi32, #blocked> loc(#loc124)
    %89 = tt.bitcast %88 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %90 = tt.reshape %89 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %91 = tt.bitcast %90 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %92 = arith.muli %91, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %93 = "tt.reduce"(%92) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %94 = tt.expand_dims %93 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %95 = tt.broadcast %94 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %96 = arith.muli %91, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %97 = "tt.reduce"(%96) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %98 = tt.expand_dims %97 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %99 = tt.broadcast %98 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %100 = tt.reshape %95 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %101 = tt.reshape %99 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %102 = tt.bitcast %100 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %103 = tt.bitcast %101 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %104 = tt.bitcast %89 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %105 = arith.cmpf olt, %102, %103 : tensor<256xf32, #blocked> loc(#loc119)
    %106 = arith.extui %105 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %107 = arith.xori %106, %65 : tensor<256xi32, #blocked> loc(#loc120)
    %108 = arith.cmpi ne, %107, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %109 = arith.xori %100, %101 : tensor<256xi32, #blocked> loc(#loc122)
    %110 = arith.select %108, %109, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %111 = arith.xori %104, %110 : tensor<256xi32, #blocked> loc(#loc124)
    %112 = tt.bitcast %111 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %113 = tt.broadcast %24 : tensor<1x2x1xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc70)
    %114 = tt.reshape %113 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc71)
    %115 = tt.reshape %112 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc99)
    %116 = tt.bitcast %115 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc100)
    %117 = tt.broadcast %35 : tensor<1x2x1xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc102)
    %118 = arith.muli %116, %117 : tensor<32x2x4xi32, #blocked3> loc(#loc102)
    %119 = "tt.reduce"(%118) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc126)
    %120 = tt.expand_dims %119 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc106)
    %121 = tt.broadcast %120 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc107)
    %122 = arith.muli %116, %64 : tensor<32x2x4xi32, #blocked3> loc(#loc108)
    %123 = "tt.reduce"(%122) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc129)
    %124 = tt.expand_dims %123 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc112)
    %125 = tt.broadcast %124 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc113)
    %126 = tt.reshape %121 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc114)
    %127 = tt.reshape %125 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc115)
    %128 = tt.bitcast %126 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %129 = tt.bitcast %127 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %130 = tt.bitcast %112 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %131 = arith.cmpf olt, %128, %129 : tensor<256xf32, #blocked> loc(#loc119)
    %132 = arith.extui %131 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %133 = arith.xori %132, %114 : tensor<256xi32, #blocked> loc(#loc120)
    %134 = arith.cmpi ne, %133, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %135 = arith.xori %126, %127 : tensor<256xi32, #blocked> loc(#loc122)
    %136 = arith.select %134, %135, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %137 = arith.xori %130, %136 : tensor<256xi32, #blocked> loc(#loc124)
    %138 = tt.bitcast %137 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %139 = tt.reshape %138 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc99)
    %140 = tt.bitcast %139 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc100)
    %141 = arith.muli %140, %68 : tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %142 = "tt.reduce"(%141) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc126)
    %143 = tt.expand_dims %142 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc106)
    %144 = tt.broadcast %143 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc107)
    %145 = arith.muli %140, %29 : tensor<64x2x2xi32, #blocked2> loc(#loc108)
    %146 = "tt.reduce"(%145) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc129)
    %147 = tt.expand_dims %146 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc112)
    %148 = tt.broadcast %147 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc113)
    %149 = tt.reshape %144 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc114)
    %150 = tt.reshape %148 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc115)
    %151 = tt.bitcast %149 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %152 = tt.bitcast %150 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %153 = tt.bitcast %138 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %154 = arith.cmpf olt, %151, %152 : tensor<256xf32, #blocked> loc(#loc119)
    %155 = arith.extui %154 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %156 = arith.xori %155, %114 : tensor<256xi32, #blocked> loc(#loc120)
    %157 = arith.cmpi ne, %156, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %158 = arith.xori %149, %150 : tensor<256xi32, #blocked> loc(#loc122)
    %159 = arith.select %157, %158, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %160 = arith.xori %153, %159 : tensor<256xi32, #blocked> loc(#loc124)
    %161 = tt.bitcast %160 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %162 = tt.reshape %161 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %163 = tt.bitcast %162 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %164 = arith.muli %163, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %165 = "tt.reduce"(%164) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %166 = tt.expand_dims %165 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %167 = tt.broadcast %166 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %168 = arith.muli %163, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %169 = "tt.reduce"(%168) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %170 = tt.expand_dims %169 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %171 = tt.broadcast %170 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %172 = tt.reshape %167 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %173 = tt.reshape %171 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %174 = tt.bitcast %172 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %175 = tt.bitcast %173 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %176 = tt.bitcast %161 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %177 = arith.cmpf olt, %174, %175 : tensor<256xf32, #blocked> loc(#loc119)
    %178 = arith.extui %177 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %179 = arith.xori %178, %114 : tensor<256xi32, #blocked> loc(#loc120)
    %180 = arith.cmpi ne, %179, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %181 = arith.xori %172, %173 : tensor<256xi32, #blocked> loc(#loc122)
    %182 = arith.select %180, %181, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %183 = arith.xori %176, %182 : tensor<256xi32, #blocked> loc(#loc124)
    %184 = tt.bitcast %183 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %185 = tt.broadcast %25 : tensor<1x2x1xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc70)
    %186 = tt.reshape %185 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc71)
    %187 = tt.reshape %184 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc99)
    %188 = tt.bitcast %187 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc100)
    %189 = tt.broadcast %36 : tensor<1x2x1xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc102)
    %190 = arith.muli %188, %189 : tensor<16x2x8xi32, #blocked4> loc(#loc102)
    %191 = "tt.reduce"(%190) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc126)
    %192 = tt.expand_dims %191 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc106)
    %193 = tt.broadcast %192 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc107)
    %194 = arith.muli %188, %113 : tensor<16x2x8xi32, #blocked4> loc(#loc108)
    %195 = "tt.reduce"(%194) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc129)
    %196 = tt.expand_dims %195 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc112)
    %197 = tt.broadcast %196 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc113)
    %198 = tt.reshape %193 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc114)
    %199 = tt.reshape %197 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc115)
    %200 = tt.bitcast %198 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %201 = tt.bitcast %199 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %202 = tt.bitcast %184 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %203 = arith.cmpf olt, %200, %201 : tensor<256xf32, #blocked> loc(#loc119)
    %204 = arith.extui %203 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %205 = arith.xori %204, %186 : tensor<256xi32, #blocked> loc(#loc120)
    %206 = arith.cmpi ne, %205, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %207 = arith.xori %198, %199 : tensor<256xi32, #blocked> loc(#loc122)
    %208 = arith.select %206, %207, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %209 = arith.xori %202, %208 : tensor<256xi32, #blocked> loc(#loc124)
    %210 = tt.bitcast %209 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %211 = tt.reshape %210 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc99)
    %212 = tt.bitcast %211 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc100)
    %213 = arith.muli %212, %117 : tensor<32x2x4xi32, #blocked3> loc(#loc102)
    %214 = "tt.reduce"(%213) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc126)
    %215 = tt.expand_dims %214 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc106)
    %216 = tt.broadcast %215 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc107)
    %217 = arith.muli %212, %64 : tensor<32x2x4xi32, #blocked3> loc(#loc108)
    %218 = "tt.reduce"(%217) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc129)
    %219 = tt.expand_dims %218 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc112)
    %220 = tt.broadcast %219 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc113)
    %221 = tt.reshape %216 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc114)
    %222 = tt.reshape %220 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc115)
    %223 = tt.bitcast %221 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %224 = tt.bitcast %222 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %225 = tt.bitcast %210 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %226 = arith.cmpf olt, %223, %224 : tensor<256xf32, #blocked> loc(#loc119)
    %227 = arith.extui %226 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %228 = arith.xori %227, %186 : tensor<256xi32, #blocked> loc(#loc120)
    %229 = arith.cmpi ne, %228, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %230 = arith.xori %221, %222 : tensor<256xi32, #blocked> loc(#loc122)
    %231 = arith.select %229, %230, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %232 = arith.xori %225, %231 : tensor<256xi32, #blocked> loc(#loc124)
    %233 = tt.bitcast %232 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %234 = tt.reshape %233 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc99)
    %235 = tt.bitcast %234 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc100)
    %236 = arith.muli %235, %68 : tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %237 = "tt.reduce"(%236) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc126)
    %238 = tt.expand_dims %237 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc106)
    %239 = tt.broadcast %238 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc107)
    %240 = arith.muli %235, %29 : tensor<64x2x2xi32, #blocked2> loc(#loc108)
    %241 = "tt.reduce"(%240) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc129)
    %242 = tt.expand_dims %241 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc112)
    %243 = tt.broadcast %242 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc113)
    %244 = tt.reshape %239 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc114)
    %245 = tt.reshape %243 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc115)
    %246 = tt.bitcast %244 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %247 = tt.bitcast %245 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %248 = tt.bitcast %233 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %249 = arith.cmpf olt, %246, %247 : tensor<256xf32, #blocked> loc(#loc119)
    %250 = arith.extui %249 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %251 = arith.xori %250, %186 : tensor<256xi32, #blocked> loc(#loc120)
    %252 = arith.cmpi ne, %251, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %253 = arith.xori %244, %245 : tensor<256xi32, #blocked> loc(#loc122)
    %254 = arith.select %252, %253, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %255 = arith.xori %248, %254 : tensor<256xi32, #blocked> loc(#loc124)
    %256 = tt.bitcast %255 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %257 = tt.reshape %256 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %258 = tt.bitcast %257 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %259 = arith.muli %258, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %260 = "tt.reduce"(%259) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %261 = tt.expand_dims %260 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %262 = tt.broadcast %261 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %263 = arith.muli %258, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %264 = "tt.reduce"(%263) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %265 = tt.expand_dims %264 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %266 = tt.broadcast %265 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %267 = tt.reshape %262 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %268 = tt.reshape %266 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %269 = tt.bitcast %267 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %270 = tt.bitcast %268 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %271 = tt.bitcast %256 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %272 = arith.cmpf olt, %269, %270 : tensor<256xf32, #blocked> loc(#loc119)
    %273 = arith.extui %272 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %274 = arith.xori %273, %186 : tensor<256xi32, #blocked> loc(#loc120)
    %275 = arith.cmpi ne, %274, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %276 = arith.xori %267, %268 : tensor<256xi32, #blocked> loc(#loc122)
    %277 = arith.select %275, %276, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %278 = arith.xori %271, %277 : tensor<256xi32, #blocked> loc(#loc124)
    %279 = tt.bitcast %278 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %280 = tt.broadcast %26 : tensor<1x2x1xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc70)
    %281 = tt.reshape %280 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc71)
    %282 = tt.reshape %279 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc99)
    %283 = tt.bitcast %282 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc100)
    %284 = tt.broadcast %37 : tensor<1x2x1xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc102)
    %285 = arith.muli %283, %284 : tensor<8x2x16xi32, #blocked5> loc(#loc102)
    %286 = "tt.reduce"(%285) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc126)
    %287 = tt.expand_dims %286 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc106)
    %288 = tt.broadcast %287 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc107)
    %289 = arith.muli %283, %185 : tensor<8x2x16xi32, #blocked5> loc(#loc108)
    %290 = "tt.reduce"(%289) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc129)
    %291 = tt.expand_dims %290 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc112)
    %292 = tt.broadcast %291 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc113)
    %293 = tt.reshape %288 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc114)
    %294 = tt.reshape %292 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc115)
    %295 = tt.bitcast %293 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %296 = tt.bitcast %294 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %297 = tt.bitcast %279 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %298 = arith.cmpf olt, %295, %296 : tensor<256xf32, #blocked> loc(#loc119)
    %299 = arith.extui %298 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %300 = arith.xori %299, %281 : tensor<256xi32, #blocked> loc(#loc120)
    %301 = arith.cmpi ne, %300, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %302 = arith.xori %293, %294 : tensor<256xi32, #blocked> loc(#loc122)
    %303 = arith.select %301, %302, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %304 = arith.xori %297, %303 : tensor<256xi32, #blocked> loc(#loc124)
    %305 = tt.bitcast %304 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %306 = tt.reshape %305 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc99)
    %307 = tt.bitcast %306 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc100)
    %308 = arith.muli %307, %189 : tensor<16x2x8xi32, #blocked4> loc(#loc102)
    %309 = "tt.reduce"(%308) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc126)
    %310 = tt.expand_dims %309 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc106)
    %311 = tt.broadcast %310 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc107)
    %312 = arith.muli %307, %113 : tensor<16x2x8xi32, #blocked4> loc(#loc108)
    %313 = "tt.reduce"(%312) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc129)
    %314 = tt.expand_dims %313 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc112)
    %315 = tt.broadcast %314 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc113)
    %316 = tt.reshape %311 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc114)
    %317 = tt.reshape %315 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc115)
    %318 = tt.bitcast %316 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %319 = tt.bitcast %317 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %320 = tt.bitcast %305 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %321 = arith.cmpf olt, %318, %319 : tensor<256xf32, #blocked> loc(#loc119)
    %322 = arith.extui %321 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %323 = arith.xori %322, %281 : tensor<256xi32, #blocked> loc(#loc120)
    %324 = arith.cmpi ne, %323, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %325 = arith.xori %316, %317 : tensor<256xi32, #blocked> loc(#loc122)
    %326 = arith.select %324, %325, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %327 = arith.xori %320, %326 : tensor<256xi32, #blocked> loc(#loc124)
    %328 = tt.bitcast %327 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %329 = tt.reshape %328 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc99)
    %330 = tt.bitcast %329 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc100)
    %331 = arith.muli %330, %117 : tensor<32x2x4xi32, #blocked3> loc(#loc102)
    %332 = "tt.reduce"(%331) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc126)
    %333 = tt.expand_dims %332 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc106)
    %334 = tt.broadcast %333 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc107)
    %335 = arith.muli %330, %64 : tensor<32x2x4xi32, #blocked3> loc(#loc108)
    %336 = "tt.reduce"(%335) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc129)
    %337 = tt.expand_dims %336 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc112)
    %338 = tt.broadcast %337 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc113)
    %339 = tt.reshape %334 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc114)
    %340 = tt.reshape %338 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc115)
    %341 = tt.bitcast %339 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %342 = tt.bitcast %340 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %343 = tt.bitcast %328 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %344 = arith.cmpf olt, %341, %342 : tensor<256xf32, #blocked> loc(#loc119)
    %345 = arith.extui %344 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %346 = arith.xori %345, %281 : tensor<256xi32, #blocked> loc(#loc120)
    %347 = arith.cmpi ne, %346, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %348 = arith.xori %339, %340 : tensor<256xi32, #blocked> loc(#loc122)
    %349 = arith.select %347, %348, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %350 = arith.xori %343, %349 : tensor<256xi32, #blocked> loc(#loc124)
    %351 = tt.bitcast %350 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %352 = tt.reshape %351 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc99)
    %353 = tt.bitcast %352 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc100)
    %354 = arith.muli %353, %68 : tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %355 = "tt.reduce"(%354) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc126)
    %356 = tt.expand_dims %355 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc106)
    %357 = tt.broadcast %356 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc107)
    %358 = arith.muli %353, %29 : tensor<64x2x2xi32, #blocked2> loc(#loc108)
    %359 = "tt.reduce"(%358) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc129)
    %360 = tt.expand_dims %359 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc112)
    %361 = tt.broadcast %360 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc113)
    %362 = tt.reshape %357 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc114)
    %363 = tt.reshape %361 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc115)
    %364 = tt.bitcast %362 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %365 = tt.bitcast %363 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %366 = tt.bitcast %351 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %367 = arith.cmpf olt, %364, %365 : tensor<256xf32, #blocked> loc(#loc119)
    %368 = arith.extui %367 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %369 = arith.xori %368, %281 : tensor<256xi32, #blocked> loc(#loc120)
    %370 = arith.cmpi ne, %369, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %371 = arith.xori %362, %363 : tensor<256xi32, #blocked> loc(#loc122)
    %372 = arith.select %370, %371, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %373 = arith.xori %366, %372 : tensor<256xi32, #blocked> loc(#loc124)
    %374 = tt.bitcast %373 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %375 = tt.reshape %374 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %376 = tt.bitcast %375 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %377 = arith.muli %376, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %378 = "tt.reduce"(%377) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %379 = tt.expand_dims %378 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %380 = tt.broadcast %379 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %381 = arith.muli %376, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %382 = "tt.reduce"(%381) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %383 = tt.expand_dims %382 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %384 = tt.broadcast %383 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %385 = tt.reshape %380 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %386 = tt.reshape %384 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %387 = tt.bitcast %385 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %388 = tt.bitcast %386 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %389 = tt.bitcast %374 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %390 = arith.cmpf olt, %387, %388 : tensor<256xf32, #blocked> loc(#loc119)
    %391 = arith.extui %390 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %392 = arith.xori %391, %281 : tensor<256xi32, #blocked> loc(#loc120)
    %393 = arith.cmpi ne, %392, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %394 = arith.xori %385, %386 : tensor<256xi32, #blocked> loc(#loc122)
    %395 = arith.select %393, %394, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %396 = arith.xori %389, %395 : tensor<256xi32, #blocked> loc(#loc124)
    %397 = tt.bitcast %396 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %398 = tt.broadcast %27 : tensor<1x2x1xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc70)
    %399 = tt.reshape %398 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc71)
    %400 = tt.reshape %397 : tensor<256xf32, #blocked> -> tensor<4x2x32xf32, #blocked6> loc(#loc99)
    %401 = tt.bitcast %400 : tensor<4x2x32xf32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc100)
    %402 = tt.broadcast %38 : tensor<1x2x1xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc102)
    %403 = arith.muli %401, %402 : tensor<4x2x32xi32, #blocked6> loc(#loc102)
    %404 = "tt.reduce"(%403) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc126)
    %405 = tt.expand_dims %404 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc106)
    %406 = tt.broadcast %405 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc107)
    %407 = arith.muli %401, %280 : tensor<4x2x32xi32, #blocked6> loc(#loc108)
    %408 = "tt.reduce"(%407) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc129)
    %409 = tt.expand_dims %408 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc112)
    %410 = tt.broadcast %409 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc113)
    %411 = tt.reshape %406 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc114)
    %412 = tt.reshape %410 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc115)
    %413 = tt.bitcast %411 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %414 = tt.bitcast %412 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %415 = tt.bitcast %397 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %416 = arith.cmpf olt, %413, %414 : tensor<256xf32, #blocked> loc(#loc119)
    %417 = arith.extui %416 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %418 = arith.xori %417, %399 : tensor<256xi32, #blocked> loc(#loc120)
    %419 = arith.cmpi ne, %418, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %420 = arith.xori %411, %412 : tensor<256xi32, #blocked> loc(#loc122)
    %421 = arith.select %419, %420, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %422 = arith.xori %415, %421 : tensor<256xi32, #blocked> loc(#loc124)
    %423 = tt.bitcast %422 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %424 = tt.reshape %423 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc99)
    %425 = tt.bitcast %424 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc100)
    %426 = arith.muli %425, %284 : tensor<8x2x16xi32, #blocked5> loc(#loc102)
    %427 = "tt.reduce"(%426) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc126)
    %428 = tt.expand_dims %427 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc106)
    %429 = tt.broadcast %428 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc107)
    %430 = arith.muli %425, %185 : tensor<8x2x16xi32, #blocked5> loc(#loc108)
    %431 = "tt.reduce"(%430) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc129)
    %432 = tt.expand_dims %431 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc112)
    %433 = tt.broadcast %432 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc113)
    %434 = tt.reshape %429 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc114)
    %435 = tt.reshape %433 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc115)
    %436 = tt.bitcast %434 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %437 = tt.bitcast %435 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %438 = tt.bitcast %423 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %439 = arith.cmpf olt, %436, %437 : tensor<256xf32, #blocked> loc(#loc119)
    %440 = arith.extui %439 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %441 = arith.xori %440, %399 : tensor<256xi32, #blocked> loc(#loc120)
    %442 = arith.cmpi ne, %441, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %443 = arith.xori %434, %435 : tensor<256xi32, #blocked> loc(#loc122)
    %444 = arith.select %442, %443, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %445 = arith.xori %438, %444 : tensor<256xi32, #blocked> loc(#loc124)
    %446 = tt.bitcast %445 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %447 = tt.reshape %446 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc99)
    %448 = tt.bitcast %447 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc100)
    %449 = arith.muli %448, %189 : tensor<16x2x8xi32, #blocked4> loc(#loc102)
    %450 = "tt.reduce"(%449) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc126)
    %451 = tt.expand_dims %450 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc106)
    %452 = tt.broadcast %451 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc107)
    %453 = arith.muli %448, %113 : tensor<16x2x8xi32, #blocked4> loc(#loc108)
    %454 = "tt.reduce"(%453) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc129)
    %455 = tt.expand_dims %454 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc112)
    %456 = tt.broadcast %455 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc113)
    %457 = tt.reshape %452 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc114)
    %458 = tt.reshape %456 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc115)
    %459 = tt.bitcast %457 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %460 = tt.bitcast %458 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %461 = tt.bitcast %446 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %462 = arith.cmpf olt, %459, %460 : tensor<256xf32, #blocked> loc(#loc119)
    %463 = arith.extui %462 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %464 = arith.xori %463, %399 : tensor<256xi32, #blocked> loc(#loc120)
    %465 = arith.cmpi ne, %464, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %466 = arith.xori %457, %458 : tensor<256xi32, #blocked> loc(#loc122)
    %467 = arith.select %465, %466, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %468 = arith.xori %461, %467 : tensor<256xi32, #blocked> loc(#loc124)
    %469 = tt.bitcast %468 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %470 = tt.reshape %469 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc99)
    %471 = tt.bitcast %470 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc100)
    %472 = arith.muli %471, %117 : tensor<32x2x4xi32, #blocked3> loc(#loc102)
    %473 = "tt.reduce"(%472) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc126)
    %474 = tt.expand_dims %473 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc106)
    %475 = tt.broadcast %474 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc107)
    %476 = arith.muli %471, %64 : tensor<32x2x4xi32, #blocked3> loc(#loc108)
    %477 = "tt.reduce"(%476) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc129)
    %478 = tt.expand_dims %477 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc112)
    %479 = tt.broadcast %478 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc113)
    %480 = tt.reshape %475 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc114)
    %481 = tt.reshape %479 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc115)
    %482 = tt.bitcast %480 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %483 = tt.bitcast %481 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %484 = tt.bitcast %469 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %485 = arith.cmpf olt, %482, %483 : tensor<256xf32, #blocked> loc(#loc119)
    %486 = arith.extui %485 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %487 = arith.xori %486, %399 : tensor<256xi32, #blocked> loc(#loc120)
    %488 = arith.cmpi ne, %487, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %489 = arith.xori %480, %481 : tensor<256xi32, #blocked> loc(#loc122)
    %490 = arith.select %488, %489, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %491 = arith.xori %484, %490 : tensor<256xi32, #blocked> loc(#loc124)
    %492 = tt.bitcast %491 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %493 = tt.reshape %492 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc99)
    %494 = tt.bitcast %493 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc100)
    %495 = arith.muli %494, %68 : tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %496 = "tt.reduce"(%495) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc126)
    %497 = tt.expand_dims %496 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc106)
    %498 = tt.broadcast %497 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc107)
    %499 = arith.muli %494, %29 : tensor<64x2x2xi32, #blocked2> loc(#loc108)
    %500 = "tt.reduce"(%499) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc129)
    %501 = tt.expand_dims %500 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc112)
    %502 = tt.broadcast %501 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc113)
    %503 = tt.reshape %498 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc114)
    %504 = tt.reshape %502 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc115)
    %505 = tt.bitcast %503 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %506 = tt.bitcast %504 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %507 = tt.bitcast %492 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %508 = arith.cmpf olt, %505, %506 : tensor<256xf32, #blocked> loc(#loc119)
    %509 = arith.extui %508 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %510 = arith.xori %509, %399 : tensor<256xi32, #blocked> loc(#loc120)
    %511 = arith.cmpi ne, %510, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %512 = arith.xori %503, %504 : tensor<256xi32, #blocked> loc(#loc122)
    %513 = arith.select %511, %512, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %514 = arith.xori %507, %513 : tensor<256xi32, #blocked> loc(#loc124)
    %515 = tt.bitcast %514 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %516 = tt.reshape %515 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %517 = tt.bitcast %516 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %518 = arith.muli %517, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %519 = "tt.reduce"(%518) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %520 = tt.expand_dims %519 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %521 = tt.broadcast %520 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %522 = arith.muli %517, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %523 = "tt.reduce"(%522) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %524 = tt.expand_dims %523 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %525 = tt.broadcast %524 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %526 = tt.reshape %521 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %527 = tt.reshape %525 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %528 = tt.bitcast %526 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %529 = tt.bitcast %527 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %530 = tt.bitcast %515 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %531 = arith.cmpf olt, %528, %529 : tensor<256xf32, #blocked> loc(#loc119)
    %532 = arith.extui %531 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %533 = arith.xori %532, %399 : tensor<256xi32, #blocked> loc(#loc120)
    %534 = arith.cmpi ne, %533, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %535 = arith.xori %526, %527 : tensor<256xi32, #blocked> loc(#loc122)
    %536 = arith.select %534, %535, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %537 = arith.xori %530, %536 : tensor<256xi32, #blocked> loc(#loc124)
    %538 = tt.bitcast %537 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %539 = tt.broadcast %28 : tensor<1x2x1xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc70)
    %540 = tt.reshape %539 : tensor<1x2x128xi32, #blocked8> -> tensor<256xi32, #blocked> loc(#loc71)
    %541 = tt.reshape %538 : tensor<256xf32, #blocked> -> tensor<2x2x64xf32, #blocked7> loc(#loc99)
    %542 = tt.bitcast %541 : tensor<2x2x64xf32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc100)
    %543 = tt.broadcast %39 : tensor<1x2x1xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc102)
    %544 = arith.muli %542, %543 : tensor<2x2x64xi32, #blocked7> loc(#loc102)
    %545 = "tt.reduce"(%544) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc126)
    %546 = tt.expand_dims %545 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc106)
    %547 = tt.broadcast %546 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc107)
    %548 = arith.muli %542, %398 : tensor<2x2x64xi32, #blocked7> loc(#loc108)
    %549 = "tt.reduce"(%548) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc129)
    %550 = tt.expand_dims %549 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc112)
    %551 = tt.broadcast %550 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc113)
    %552 = tt.reshape %547 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc114)
    %553 = tt.reshape %551 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc115)
    %554 = tt.bitcast %552 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %555 = tt.bitcast %553 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %556 = tt.bitcast %538 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %557 = arith.cmpf olt, %554, %555 : tensor<256xf32, #blocked> loc(#loc119)
    %558 = arith.extui %557 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %559 = arith.xori %558, %540 : tensor<256xi32, #blocked> loc(#loc120)
    %560 = arith.cmpi ne, %559, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %561 = arith.xori %552, %553 : tensor<256xi32, #blocked> loc(#loc122)
    %562 = arith.select %560, %561, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %563 = arith.xori %556, %562 : tensor<256xi32, #blocked> loc(#loc124)
    %564 = tt.bitcast %563 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %565 = tt.reshape %564 : tensor<256xf32, #blocked> -> tensor<4x2x32xf32, #blocked6> loc(#loc99)
    %566 = tt.bitcast %565 : tensor<4x2x32xf32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc100)
    %567 = arith.muli %566, %402 : tensor<4x2x32xi32, #blocked6> loc(#loc102)
    %568 = "tt.reduce"(%567) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc126)
    %569 = tt.expand_dims %568 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc106)
    %570 = tt.broadcast %569 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc107)
    %571 = arith.muli %566, %280 : tensor<4x2x32xi32, #blocked6> loc(#loc108)
    %572 = "tt.reduce"(%571) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc129)
    %573 = tt.expand_dims %572 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc112)
    %574 = tt.broadcast %573 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc113)
    %575 = tt.reshape %570 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc114)
    %576 = tt.reshape %574 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc115)
    %577 = tt.bitcast %575 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %578 = tt.bitcast %576 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %579 = tt.bitcast %564 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %580 = arith.cmpf olt, %577, %578 : tensor<256xf32, #blocked> loc(#loc119)
    %581 = arith.extui %580 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %582 = arith.xori %581, %540 : tensor<256xi32, #blocked> loc(#loc120)
    %583 = arith.cmpi ne, %582, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %584 = arith.xori %575, %576 : tensor<256xi32, #blocked> loc(#loc122)
    %585 = arith.select %583, %584, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %586 = arith.xori %579, %585 : tensor<256xi32, #blocked> loc(#loc124)
    %587 = tt.bitcast %586 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %588 = tt.reshape %587 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc99)
    %589 = tt.bitcast %588 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc100)
    %590 = arith.muli %589, %284 : tensor<8x2x16xi32, #blocked5> loc(#loc102)
    %591 = "tt.reduce"(%590) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc126)
    %592 = tt.expand_dims %591 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc106)
    %593 = tt.broadcast %592 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc107)
    %594 = arith.muli %589, %185 : tensor<8x2x16xi32, #blocked5> loc(#loc108)
    %595 = "tt.reduce"(%594) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc129)
    %596 = tt.expand_dims %595 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc112)
    %597 = tt.broadcast %596 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc113)
    %598 = tt.reshape %593 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc114)
    %599 = tt.reshape %597 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc115)
    %600 = tt.bitcast %598 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %601 = tt.bitcast %599 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %602 = tt.bitcast %587 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %603 = arith.cmpf olt, %600, %601 : tensor<256xf32, #blocked> loc(#loc119)
    %604 = arith.extui %603 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %605 = arith.xori %604, %540 : tensor<256xi32, #blocked> loc(#loc120)
    %606 = arith.cmpi ne, %605, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %607 = arith.xori %598, %599 : tensor<256xi32, #blocked> loc(#loc122)
    %608 = arith.select %606, %607, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %609 = arith.xori %602, %608 : tensor<256xi32, #blocked> loc(#loc124)
    %610 = tt.bitcast %609 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %611 = tt.reshape %610 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc99)
    %612 = tt.bitcast %611 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc100)
    %613 = arith.muli %612, %189 : tensor<16x2x8xi32, #blocked4> loc(#loc102)
    %614 = "tt.reduce"(%613) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc126)
    %615 = tt.expand_dims %614 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc106)
    %616 = tt.broadcast %615 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc107)
    %617 = arith.muli %612, %113 : tensor<16x2x8xi32, #blocked4> loc(#loc108)
    %618 = "tt.reduce"(%617) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc129)
    %619 = tt.expand_dims %618 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc112)
    %620 = tt.broadcast %619 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc113)
    %621 = tt.reshape %616 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc114)
    %622 = tt.reshape %620 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc115)
    %623 = tt.bitcast %621 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %624 = tt.bitcast %622 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %625 = tt.bitcast %610 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %626 = arith.cmpf olt, %623, %624 : tensor<256xf32, #blocked> loc(#loc119)
    %627 = arith.extui %626 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %628 = arith.xori %627, %540 : tensor<256xi32, #blocked> loc(#loc120)
    %629 = arith.cmpi ne, %628, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %630 = arith.xori %621, %622 : tensor<256xi32, #blocked> loc(#loc122)
    %631 = arith.select %629, %630, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %632 = arith.xori %625, %631 : tensor<256xi32, #blocked> loc(#loc124)
    %633 = tt.bitcast %632 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %634 = tt.reshape %633 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc99)
    %635 = tt.bitcast %634 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc100)
    %636 = arith.muli %635, %117 : tensor<32x2x4xi32, #blocked3> loc(#loc102)
    %637 = "tt.reduce"(%636) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc126)
    %638 = tt.expand_dims %637 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc106)
    %639 = tt.broadcast %638 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc107)
    %640 = arith.muli %635, %64 : tensor<32x2x4xi32, #blocked3> loc(#loc108)
    %641 = "tt.reduce"(%640) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc129)
    %642 = tt.expand_dims %641 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc112)
    %643 = tt.broadcast %642 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc113)
    %644 = tt.reshape %639 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc114)
    %645 = tt.reshape %643 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc115)
    %646 = tt.bitcast %644 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %647 = tt.bitcast %645 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %648 = tt.bitcast %633 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %649 = arith.cmpf olt, %646, %647 : tensor<256xf32, #blocked> loc(#loc119)
    %650 = arith.extui %649 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %651 = arith.xori %650, %540 : tensor<256xi32, #blocked> loc(#loc120)
    %652 = arith.cmpi ne, %651, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %653 = arith.xori %644, %645 : tensor<256xi32, #blocked> loc(#loc122)
    %654 = arith.select %652, %653, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %655 = arith.xori %648, %654 : tensor<256xi32, #blocked> loc(#loc124)
    %656 = tt.bitcast %655 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %657 = tt.reshape %656 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc99)
    %658 = tt.bitcast %657 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc100)
    %659 = arith.muli %658, %68 : tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %660 = "tt.reduce"(%659) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc126)
    %661 = tt.expand_dims %660 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc106)
    %662 = tt.broadcast %661 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc107)
    %663 = arith.muli %658, %29 : tensor<64x2x2xi32, #blocked2> loc(#loc108)
    %664 = "tt.reduce"(%663) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc129)
    %665 = tt.expand_dims %664 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc112)
    %666 = tt.broadcast %665 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc113)
    %667 = tt.reshape %662 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc114)
    %668 = tt.reshape %666 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc115)
    %669 = tt.bitcast %667 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %670 = tt.bitcast %668 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %671 = tt.bitcast %656 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %672 = arith.cmpf olt, %669, %670 : tensor<256xf32, #blocked> loc(#loc119)
    %673 = arith.extui %672 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %674 = arith.xori %673, %540 : tensor<256xi32, #blocked> loc(#loc120)
    %675 = arith.cmpi ne, %674, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %676 = arith.xori %667, %668 : tensor<256xi32, #blocked> loc(#loc122)
    %677 = arith.select %675, %676, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %678 = arith.xori %671, %677 : tensor<256xi32, #blocked> loc(#loc124)
    %679 = tt.bitcast %678 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %680 = tt.reshape %679 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %681 = tt.bitcast %680 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %682 = arith.muli %681, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %683 = "tt.reduce"(%682) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %684 = tt.expand_dims %683 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %685 = tt.broadcast %684 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %686 = arith.muli %681, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %687 = "tt.reduce"(%686) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %688 = tt.expand_dims %687 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %689 = tt.broadcast %688 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %690 = tt.reshape %685 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %691 = tt.reshape %689 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %692 = tt.bitcast %690 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %693 = tt.bitcast %691 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %694 = tt.bitcast %679 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %695 = arith.cmpf olt, %692, %693 : tensor<256xf32, #blocked> loc(#loc119)
    %696 = arith.extui %695 : tensor<256xi1, #blocked> to tensor<256xi32, #blocked> loc(#loc120)
    %697 = arith.xori %696, %540 : tensor<256xi32, #blocked> loc(#loc120)
    %698 = arith.cmpi ne, %697, %cst : tensor<256xi32, #blocked> loc(#loc121)
    %699 = arith.xori %690, %691 : tensor<256xi32, #blocked> loc(#loc122)
    %700 = arith.select %698, %699, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %701 = arith.xori %694, %700 : tensor<256xi32, #blocked> loc(#loc124)
    %702 = tt.bitcast %701 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %703 = tt.reshape %702 : tensor<256xf32, #blocked> -> tensor<1x2x128xf32, #blocked8> loc(#loc99)
    %704 = tt.bitcast %703 : tensor<1x2x128xf32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc100)
    %705 = tt.broadcast %40 : tensor<1x2x1xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc102)
    %706 = arith.muli %704, %705 : tensor<1x2x128xi32, #blocked8> loc(#loc102)
    %707 = "tt.reduce"(%706) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<1x2x128xi32, #blocked8>) -> tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> loc(#loc126)
    %708 = tt.expand_dims %707 {axis = 1 : i32} : tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> -> tensor<1x1x128xi32, #blocked8> loc(#loc106)
    %709 = tt.broadcast %708 : tensor<1x1x128xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc107)
    %710 = arith.muli %704, %539 : tensor<1x2x128xi32, #blocked8> loc(#loc108)
    %711 = "tt.reduce"(%710) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<1x2x128xi32, #blocked8>) -> tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> loc(#loc129)
    %712 = tt.expand_dims %711 {axis = 1 : i32} : tensor<1x128xi32, #triton_gpu.slice<{dim = 1, parent = #blocked8}>> -> tensor<1x1x128xi32, #blocked8> loc(#loc112)
    %713 = tt.broadcast %712 : tensor<1x1x128xi32, #blocked8> -> tensor<1x2x128xi32, #blocked8> loc(#loc113)
    %714 = tt.reshape %709 : tensor<1x2x128xi32, #blocked8> -> tensor<256xi32, #blocked> loc(#loc114)
    %715 = tt.reshape %713 : tensor<1x2x128xi32, #blocked8> -> tensor<256xi32, #blocked> loc(#loc115)
    %716 = tt.bitcast %714 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %717 = tt.bitcast %715 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %718 = tt.bitcast %702 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %719 = arith.cmpf olt, %716, %717 : tensor<256xf32, #blocked> loc(#loc119)
    %720 = arith.xori %714, %715 : tensor<256xi32, #blocked> loc(#loc122)
    %721 = arith.select %719, %720, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %722 = arith.xori %718, %721 : tensor<256xi32, #blocked> loc(#loc124)
    %723 = tt.bitcast %722 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %724 = tt.reshape %723 : tensor<256xf32, #blocked> -> tensor<2x2x64xf32, #blocked7> loc(#loc99)
    %725 = tt.bitcast %724 : tensor<2x2x64xf32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc100)
    %726 = arith.muli %725, %543 : tensor<2x2x64xi32, #blocked7> loc(#loc102)
    %727 = "tt.reduce"(%726) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc126)
    %728 = tt.expand_dims %727 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc106)
    %729 = tt.broadcast %728 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc107)
    %730 = arith.muli %725, %398 : tensor<2x2x64xi32, #blocked7> loc(#loc108)
    %731 = "tt.reduce"(%730) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<2x2x64xi32, #blocked7>) -> tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> loc(#loc129)
    %732 = tt.expand_dims %731 {axis = 1 : i32} : tensor<2x64xi32, #triton_gpu.slice<{dim = 1, parent = #blocked7}>> -> tensor<2x1x64xi32, #blocked7> loc(#loc112)
    %733 = tt.broadcast %732 : tensor<2x1x64xi32, #blocked7> -> tensor<2x2x64xi32, #blocked7> loc(#loc113)
    %734 = tt.reshape %729 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc114)
    %735 = tt.reshape %733 : tensor<2x2x64xi32, #blocked7> -> tensor<256xi32, #blocked> loc(#loc115)
    %736 = tt.bitcast %734 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %737 = tt.bitcast %735 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %738 = tt.bitcast %723 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %739 = arith.cmpf olt, %736, %737 : tensor<256xf32, #blocked> loc(#loc119)
    %740 = arith.xori %734, %735 : tensor<256xi32, #blocked> loc(#loc122)
    %741 = arith.select %739, %740, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %742 = arith.xori %738, %741 : tensor<256xi32, #blocked> loc(#loc124)
    %743 = tt.bitcast %742 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %744 = tt.reshape %743 : tensor<256xf32, #blocked> -> tensor<4x2x32xf32, #blocked6> loc(#loc99)
    %745 = tt.bitcast %744 : tensor<4x2x32xf32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc100)
    %746 = arith.muli %745, %402 : tensor<4x2x32xi32, #blocked6> loc(#loc102)
    %747 = "tt.reduce"(%746) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc126)
    %748 = tt.expand_dims %747 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc106)
    %749 = tt.broadcast %748 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc107)
    %750 = arith.muli %745, %280 : tensor<4x2x32xi32, #blocked6> loc(#loc108)
    %751 = "tt.reduce"(%750) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<4x2x32xi32, #blocked6>) -> tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> loc(#loc129)
    %752 = tt.expand_dims %751 {axis = 1 : i32} : tensor<4x32xi32, #triton_gpu.slice<{dim = 1, parent = #blocked6}>> -> tensor<4x1x32xi32, #blocked6> loc(#loc112)
    %753 = tt.broadcast %752 : tensor<4x1x32xi32, #blocked6> -> tensor<4x2x32xi32, #blocked6> loc(#loc113)
    %754 = tt.reshape %749 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc114)
    %755 = tt.reshape %753 : tensor<4x2x32xi32, #blocked6> -> tensor<256xi32, #blocked> loc(#loc115)
    %756 = tt.bitcast %754 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %757 = tt.bitcast %755 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %758 = tt.bitcast %743 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %759 = arith.cmpf olt, %756, %757 : tensor<256xf32, #blocked> loc(#loc119)
    %760 = arith.xori %754, %755 : tensor<256xi32, #blocked> loc(#loc122)
    %761 = arith.select %759, %760, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %762 = arith.xori %758, %761 : tensor<256xi32, #blocked> loc(#loc124)
    %763 = tt.bitcast %762 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %764 = tt.reshape %763 : tensor<256xf32, #blocked> -> tensor<8x2x16xf32, #blocked5> loc(#loc99)
    %765 = tt.bitcast %764 : tensor<8x2x16xf32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc100)
    %766 = arith.muli %765, %284 : tensor<8x2x16xi32, #blocked5> loc(#loc102)
    %767 = "tt.reduce"(%766) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc126)
    %768 = tt.expand_dims %767 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc106)
    %769 = tt.broadcast %768 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc107)
    %770 = arith.muli %765, %185 : tensor<8x2x16xi32, #blocked5> loc(#loc108)
    %771 = "tt.reduce"(%770) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<8x2x16xi32, #blocked5>) -> tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> loc(#loc129)
    %772 = tt.expand_dims %771 {axis = 1 : i32} : tensor<8x16xi32, #triton_gpu.slice<{dim = 1, parent = #blocked5}>> -> tensor<8x1x16xi32, #blocked5> loc(#loc112)
    %773 = tt.broadcast %772 : tensor<8x1x16xi32, #blocked5> -> tensor<8x2x16xi32, #blocked5> loc(#loc113)
    %774 = tt.reshape %769 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc114)
    %775 = tt.reshape %773 : tensor<8x2x16xi32, #blocked5> -> tensor<256xi32, #blocked> loc(#loc115)
    %776 = tt.bitcast %774 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %777 = tt.bitcast %775 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %778 = tt.bitcast %763 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %779 = arith.cmpf olt, %776, %777 : tensor<256xf32, #blocked> loc(#loc119)
    %780 = arith.xori %774, %775 : tensor<256xi32, #blocked> loc(#loc122)
    %781 = arith.select %779, %780, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %782 = arith.xori %778, %781 : tensor<256xi32, #blocked> loc(#loc124)
    %783 = tt.bitcast %782 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %784 = tt.reshape %783 : tensor<256xf32, #blocked> -> tensor<16x2x8xf32, #blocked4> loc(#loc99)
    %785 = tt.bitcast %784 : tensor<16x2x8xf32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc100)
    %786 = arith.muli %785, %189 : tensor<16x2x8xi32, #blocked4> loc(#loc102)
    %787 = "tt.reduce"(%786) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc126)
    %788 = tt.expand_dims %787 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc106)
    %789 = tt.broadcast %788 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc107)
    %790 = arith.muli %785, %113 : tensor<16x2x8xi32, #blocked4> loc(#loc108)
    %791 = "tt.reduce"(%790) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<16x2x8xi32, #blocked4>) -> tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> loc(#loc129)
    %792 = tt.expand_dims %791 {axis = 1 : i32} : tensor<16x8xi32, #triton_gpu.slice<{dim = 1, parent = #blocked4}>> -> tensor<16x1x8xi32, #blocked4> loc(#loc112)
    %793 = tt.broadcast %792 : tensor<16x1x8xi32, #blocked4> -> tensor<16x2x8xi32, #blocked4> loc(#loc113)
    %794 = tt.reshape %789 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc114)
    %795 = tt.reshape %793 : tensor<16x2x8xi32, #blocked4> -> tensor<256xi32, #blocked> loc(#loc115)
    %796 = tt.bitcast %794 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %797 = tt.bitcast %795 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %798 = tt.bitcast %783 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %799 = arith.cmpf olt, %796, %797 : tensor<256xf32, #blocked> loc(#loc119)
    %800 = arith.xori %794, %795 : tensor<256xi32, #blocked> loc(#loc122)
    %801 = arith.select %799, %800, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %802 = arith.xori %798, %801 : tensor<256xi32, #blocked> loc(#loc124)
    %803 = tt.bitcast %802 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %804 = tt.reshape %803 : tensor<256xf32, #blocked> -> tensor<32x2x4xf32, #blocked3> loc(#loc99)
    %805 = tt.bitcast %804 : tensor<32x2x4xf32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc100)
    %806 = arith.muli %805, %117 : tensor<32x2x4xi32, #blocked3> loc(#loc102)
    %807 = "tt.reduce"(%806) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc126)
    %808 = tt.expand_dims %807 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc106)
    %809 = tt.broadcast %808 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc107)
    %810 = arith.muli %805, %64 : tensor<32x2x4xi32, #blocked3> loc(#loc108)
    %811 = "tt.reduce"(%810) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<32x2x4xi32, #blocked3>) -> tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> loc(#loc129)
    %812 = tt.expand_dims %811 {axis = 1 : i32} : tensor<32x4xi32, #triton_gpu.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1x4xi32, #blocked3> loc(#loc112)
    %813 = tt.broadcast %812 : tensor<32x1x4xi32, #blocked3> -> tensor<32x2x4xi32, #blocked3> loc(#loc113)
    %814 = tt.reshape %809 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc114)
    %815 = tt.reshape %813 : tensor<32x2x4xi32, #blocked3> -> tensor<256xi32, #blocked> loc(#loc115)
    %816 = tt.bitcast %814 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %817 = tt.bitcast %815 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %818 = tt.bitcast %803 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %819 = arith.cmpf olt, %816, %817 : tensor<256xf32, #blocked> loc(#loc119)
    %820 = arith.xori %814, %815 : tensor<256xi32, #blocked> loc(#loc122)
    %821 = arith.select %819, %820, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %822 = arith.xori %818, %821 : tensor<256xi32, #blocked> loc(#loc124)
    %823 = tt.bitcast %822 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %824 = tt.reshape %823 : tensor<256xf32, #blocked> -> tensor<64x2x2xf32, #blocked2> loc(#loc99)
    %825 = tt.bitcast %824 : tensor<64x2x2xf32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc100)
    %826 = arith.muli %825, %68 : tensor<64x2x2xi32, #blocked2> loc(#loc102)
    %827 = "tt.reduce"(%826) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc126)
    %828 = tt.expand_dims %827 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc106)
    %829 = tt.broadcast %828 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc107)
    %830 = arith.muli %825, %29 : tensor<64x2x2xi32, #blocked2> loc(#loc108)
    %831 = "tt.reduce"(%830) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<64x2x2xi32, #blocked2>) -> tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> loc(#loc129)
    %832 = tt.expand_dims %831 {axis = 1 : i32} : tensor<64x2xi32, #triton_gpu.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1x2xi32, #blocked2> loc(#loc112)
    %833 = tt.broadcast %832 : tensor<64x1x2xi32, #blocked2> -> tensor<64x2x2xi32, #blocked2> loc(#loc113)
    %834 = tt.reshape %829 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc114)
    %835 = tt.reshape %833 : tensor<64x2x2xi32, #blocked2> -> tensor<256xi32, #blocked> loc(#loc115)
    %836 = tt.bitcast %834 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %837 = tt.bitcast %835 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %838 = tt.bitcast %823 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %839 = arith.cmpf olt, %836, %837 : tensor<256xf32, #blocked> loc(#loc119)
    %840 = arith.xori %834, %835 : tensor<256xi32, #blocked> loc(#loc122)
    %841 = arith.select %839, %840, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %842 = arith.xori %838, %841 : tensor<256xi32, #blocked> loc(#loc124)
    %843 = tt.bitcast %842 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %844 = tt.reshape %843 : tensor<256xf32, #blocked> -> tensor<128x2x1xf32, #blocked1> loc(#loc99)
    %845 = tt.bitcast %844 : tensor<128x2x1xf32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc100)
    %846 = arith.muli %845, %41 : tensor<128x2x1xi32, #blocked1> loc(#loc102)
    %847 = "tt.reduce"(%846) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc104 at #loc8)), %arg4: i32 loc(callsite(#loc104 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc132)
      tt.reduce.return %866 : i32 loc(#loc126)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc126)
    %848 = tt.expand_dims %847 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc106)
    %849 = tt.broadcast %848 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc107)
    %850 = arith.muli %845, %46 : tensor<128x2x1xi32, #blocked1> loc(#loc108)
    %851 = "tt.reduce"(%850) <{axis = 1 : i32}> ({
    ^bb0(%arg3: i32 loc(callsite(#loc110 at #loc8)), %arg4: i32 loc(callsite(#loc110 at #loc8))):
      %866 = arith.addi %arg3, %arg4 : i32 loc(#loc133)
      tt.reduce.return %866 : i32 loc(#loc129)
    }) : (tensor<128x2x1xi32, #blocked1>) -> tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> loc(#loc129)
    %852 = tt.expand_dims %851 {axis = 1 : i32} : tensor<128x1xi32, #triton_gpu.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1x1xi32, #blocked1> loc(#loc112)
    %853 = tt.broadcast %852 : tensor<128x1x1xi32, #blocked1> -> tensor<128x2x1xi32, #blocked1> loc(#loc113)
    %854 = tt.reshape %849 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc114)
    %855 = tt.reshape %853 : tensor<128x2x1xi32, #blocked1> -> tensor<256xi32, #blocked> loc(#loc115)
    %856 = tt.bitcast %854 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc116)
    %857 = tt.bitcast %855 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc117)
    %858 = tt.bitcast %843 : tensor<256xf32, #blocked> -> tensor<256xi32, #blocked> loc(#loc118)
    %859 = arith.cmpf olt, %856, %857 : tensor<256xf32, #blocked> loc(#loc119)
    %860 = arith.xori %854, %855 : tensor<256xi32, #blocked> loc(#loc122)
    %861 = arith.select %859, %860, %cst : tensor<256xi1, #blocked>, tensor<256xi32, #blocked> loc(#loc123)
    %862 = arith.xori %858, %861 : tensor<256xi32, #blocked> loc(#loc124)
    %863 = tt.bitcast %862 : tensor<256xi32, #blocked> -> tensor<256xf32, #blocked> loc(#loc125)
    %864 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc37)
    %865 = tt.addptr %864, %0 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc37)
    tt.store %865, %863 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc38)
    tt.return loc(#loc39)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":27:26)
#loc3 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":31:30)
#loc4 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":31:35)
#loc5 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":32:23)
#loc6 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:44)
#loc9 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:60)
#loc10 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":575:68)
#loc11 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":501:22)
#loc13 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":502:14)
#loc14 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":505:21)
#loc15 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:40)
#loc16 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":267:36)
#loc18 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/triton/language/standard.py":256:15)
#loc19 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:54)
#loc20 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":506:67)
#loc21 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:41)
#loc23 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:56)
#loc24 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":507:69)
#loc25 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":508:30)
#loc26 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":509:32)
#loc27 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":510:20)
#loc28 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":511:22)
#loc29 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":533:14)
#loc30 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":536:22)
#loc31 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:19)
#loc32 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":547:28)
#loc33 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:38)
#loc34 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:46)
#loc35 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":548:15)
#loc36 = loc("/home/sahanp/.conda/envs/parity-bench/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py":551:18)
#loc37 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":38:25)
#loc38 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":38:63)
#loc39 = loc("inductor_cache/zm/czmxe4pwy2v4qecsr3sizppkxtkpdmrtt54rvjcwha5pbqhx3myk.py":38:4)
#loc40 = loc(callsite(#loc6 at #loc7))
#loc41 = loc(callsite(#loc9 at #loc7))
#loc42 = loc(callsite(#loc10 at #loc7))
#loc43 = loc(callsite(#loc11 at #loc12))
#loc44 = loc(callsite(#loc13 at #loc12))
#loc45 = loc(callsite(#loc14 at #loc12))
#loc46 = loc(callsite(#loc15 at #loc12))
#loc47 = loc(callsite(#loc16 at #loc17))
#loc49 = loc(callsite(#loc18 at #loc16))
#loc50 = loc(callsite(#loc19 at #loc12))
#loc51 = loc(callsite(#loc20 at #loc12))
#loc52 = loc(callsite(#loc21 at #loc12))
#loc53 = loc(callsite(#loc16 at #loc22))
#loc55 = loc(callsite(#loc23 at #loc12))
#loc56 = loc(callsite(#loc24 at #loc12))
#loc57 = loc(callsite(#loc25 at #loc12))
#loc58 = loc(callsite(#loc26 at #loc12))
#loc59 = loc(callsite(#loc27 at #loc12))
#loc60 = loc(callsite(#loc28 at #loc12))
#loc61 = loc(callsite(#loc29 at #loc12))
#loc62 = loc(callsite(#loc30 at #loc12))
#loc63 = loc(callsite(#loc31 at #loc12))
#loc64 = loc(callsite(#loc32 at #loc12))
#loc65 = loc(callsite(#loc33 at #loc12))
#loc66 = loc(callsite(#loc34 at #loc12))
#loc67 = loc(callsite(#loc35 at #loc12))
#loc68 = loc(callsite(#loc36 at #loc12))
#loc69 = loc(callsite(#loc40 at #loc8))
#loc70 = loc(callsite(#loc41 at #loc8))
#loc71 = loc(callsite(#loc42 at #loc8))
#loc72 = loc(callsite(#loc43 at #loc7))
#loc73 = loc(callsite(#loc44 at #loc7))
#loc74 = loc(callsite(#loc45 at #loc7))
#loc75 = loc(callsite(#loc46 at #loc7))
#loc76 = loc(callsite(#loc47 at #loc12))
#loc78 = loc(callsite(#loc49 at #loc17))
#loc79 = loc(callsite(#loc50 at #loc7))
#loc80 = loc(callsite(#loc51 at #loc7))
#loc81 = loc(callsite(#loc52 at #loc7))
#loc82 = loc(callsite(#loc53 at #loc12))
#loc84 = loc(callsite(#loc49 at #loc22))
#loc85 = loc(callsite(#loc55 at #loc7))
#loc86 = loc(callsite(#loc56 at #loc7))
#loc87 = loc(callsite(#loc57 at #loc7))
#loc88 = loc(callsite(#loc58 at #loc7))
#loc89 = loc(callsite(#loc59 at #loc7))
#loc90 = loc(callsite(#loc60 at #loc7))
#loc91 = loc(callsite(#loc61 at #loc7))
#loc92 = loc(callsite(#loc62 at #loc7))
#loc93 = loc(callsite(#loc63 at #loc7))
#loc94 = loc(callsite(#loc64 at #loc7))
#loc95 = loc(callsite(#loc65 at #loc7))
#loc96 = loc(callsite(#loc66 at #loc7))
#loc97 = loc(callsite(#loc67 at #loc7))
#loc98 = loc(callsite(#loc68 at #loc7))
#loc99 = loc(callsite(#loc72 at #loc8))
#loc100 = loc(callsite(#loc73 at #loc8))
#loc101 = loc(callsite(#loc74 at #loc8))
#loc102 = loc(callsite(#loc75 at #loc8))
#loc103 = loc(callsite(#loc76 at #loc7))
#loc105 = loc(callsite(#loc78 at #loc12))
#loc106 = loc(callsite(#loc79 at #loc8))
#loc107 = loc(callsite(#loc80 at #loc8))
#loc108 = loc(callsite(#loc81 at #loc8))
#loc109 = loc(callsite(#loc82 at #loc7))
#loc111 = loc(callsite(#loc84 at #loc12))
#loc112 = loc(callsite(#loc85 at #loc8))
#loc113 = loc(callsite(#loc86 at #loc8))
#loc114 = loc(callsite(#loc87 at #loc8))
#loc115 = loc(callsite(#loc88 at #loc8))
#loc116 = loc(callsite(#loc89 at #loc8))
#loc117 = loc(callsite(#loc90 at #loc8))
#loc118 = loc(callsite(#loc91 at #loc8))
#loc119 = loc(callsite(#loc92 at #loc8))
#loc120 = loc(callsite(#loc93 at #loc8))
#loc121 = loc(callsite(#loc94 at #loc8))
#loc122 = loc(callsite(#loc95 at #loc8))
#loc123 = loc(callsite(#loc96 at #loc8))
#loc124 = loc(callsite(#loc97 at #loc8))
#loc125 = loc(callsite(#loc98 at #loc8))
#loc126 = loc(callsite(#loc103 at #loc8))
#loc128 = loc(callsite(#loc105 at #loc7))
#loc129 = loc(callsite(#loc109 at #loc8))
#loc131 = loc(callsite(#loc111 at #loc7))
#loc132 = loc(callsite(#loc128 at #loc8))
#loc133 = loc(callsite(#loc131 at #loc8))
